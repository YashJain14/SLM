{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to find a deleted file in the project commit history?\n\nOnce upon a time, there was a file in my project that I would now like to be able to get.\nThe problem is: I have no idea of when have I deleted it and on which path it was.\nHow can I locate the commits of this file when it existed?"}, {"role": "assistant", "content": "If you do not know the exact path you may use\ngit log --all --full-history -- \"**/thefile.*\"\n\nIf you know the path the file was at, you can do this:\ngit log --all --full-history -- <path-to-file>\n\nThis should show a list of commits in all branches which touched that file. Then, you can find the version of the file you want, and display it with...\ngit show <SHA> -- <path-to-file>\n\nOr restore it into your working copy with:\ngit checkout <SHA>^ -- <path-to-file>\nNote the caret symbol (^), which gets the checkout prior to the one identified, because at the moment of <SHA> commit the file is deleted, we need to look at the previous commit to get the deleted file's contents"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Pull request vs Merge request\n\nWhat is the difference between a Pull request and a Merge request?\nIn GitHub, it's a Pull Request while in GitLab, for example, it's a Merge Request. So, is there a difference between both of these?"}, {"role": "assistant", "content": "GitLab's \"merge request\" feature is equivalent to GitHub's \"pull request\" feature.  Both are means of pulling changes from another branch or fork into your branch and merging the changes with your existing code. They are useful tools for code review and change management.\nAn article from GitLab discusses the differences in naming the feature:\n\nMerge or pull requests are created in a git management application and ask an assigned person to merge two branches. Tools such as GitHub and Bitbucket choose the name pull request since the first manual action would be to pull the feature branch. Tools such as GitLab and Gitorious choose the name merge request since that is the final action that is requested of the assignee. In this article we'll refer to them as merge requests.\n\nA \"merge request\" should not be confused with the git merge command. Neither should a \"pull request\" be confused with the git pull command.  Both git commands are used behind the scenes in both pull requests and merge requests, but a merge/pull request refers to a much broader topic than just these two commands."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Fix GitLab error: \"you are not allowed to push code to protected branches on this project\"?\n\nI have a problem when I push my code to git while I have developer access in my project, but everything is okay when I have master access. Where is the problem come from? And how to fix it?\nError message:\n\nerror: You are not allowed to push code to protected branches on this project.\n...\nerror: failed to push some refs to ..."}, {"role": "assistant", "content": "there's no problem - everything works as expected.\nIn GitLab some branches can be protected. By default only Maintainer/Owner users can commit to protected branches (see permissions docs). master branch is protected by default - it forces developers to issue merge requests to be validated by project maintainers before integrating them into main code.\nYou can turn on and off protection on selected branches in Project Settings (where exactly depends on GitLab version - see instructions below). \nOn the same settings page you can also allow developers to push into the protected branches. With this setting on, protection will be limited to rejecting operations requiring git push --force (rebase etc.)\nSince GitLab 9.3\nGo to project: \"Settings\" \u2192 \"Repository\" \u2192 \"Expand\" on \"Protected branches\"\n\nI'm not really sure when this change was introduced, screenshots are from 10.3 version.\nNow you can select who is allowed to merge or push into selected branches (for example: you can turn off pushes to master at all, forcing all changes to branch to be made via Merge Requests). Or you can click \"Unprotect\" to completely remove protection from branch.\nSince GitLab 9.0\nSimilarly to GitLab 9.3, but no need to click \"Expand\" - everything is already expanded:\nGo to project:  \"Settings\" \u2192 \"Repository\" \u2192 scroll down to \"Protected branches\".\n\nPre GitLab 9.0\nProject: \"Settings\" \u2192 \"Protected branches\" (if you are at least 'Master' of given project).\n\nThen click on \"Unprotect\" or \"Developers can push\":"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab remote: HTTP Basic: Access denied and fatal Authentication\n\nUnlike this post, I am on macOS.\nI have the password configured in GitLab. I also have an SSL key created after the project was made on GitLab.\nWhen I use an existing folder for a new project and follow the steps below, I am prompted to enter my GitLab username and password.\nExisting folder\ncd existing_folder\ngit init\ngit remote add origin https://gitlab.com/sobopla/Geronimod.git\ngit add .\ngit commit -m \"Initial commit\"\ngit push -u origin master\n\nAfter the password is entered I get the following error.\n\nremote: HTTP Basic: Access denied\nfatal: Authentication failed for 'https://gitlab.com/myname/myproject'"}, {"role": "assistant", "content": "It happens every time I'm forced to change the Windows password and none of the above answers helped me.\nTry the below solution which works for me:\n\nGo to Windows Credential Manager. This is done in an EN-US Windows by pressing the Windows Key and typing 'credential'. In other\nlocalized Windows variants you need to use the localized term (See\ncomments for some examples).\nalternatively you can use the shortcut\ncontrol /name Microsoft.CredentialManager in the run dialog\n(WIN+R)\n\nEdit the git entry under Windows Credentials, replacing old\npassword with the new one."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Server certificate verification failed. CAfile: /etc/ssl/certs/ca-certificates.crt CRLfile: none\n\nI can push by clone project using ssh, but it doesn't work when I clone project with https.\nThe error message that it shows me is:\nserver certificate verification failed. CAfile: /etc/ssl/certs/cacertificates.crt CRLfile: none"}, {"role": "assistant", "content": "TLDR:\nhostname=XXX\nport=443\ntrust_cert_file_location=`curl-config --ca`\n\nsudo bash -c \"echo -n | openssl s_client -showcerts -connect $hostname:$port -servername $hostname \\\n    2>/dev/null  | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p'  \\\n    >> $trust_cert_file_location\"\n\nWarning: as noted in gareththered's excellent answer, this adds all certificates, instead of only the Root CAs.\nBlindly adding all (any) certificates to your truststore without due diligence is not the best course of action.\n\nNote: x-yuri adds in the comments:\n\n\nAlthough echo -n (basically EOF) is a valid way to make s_client exit, you can also do echo Q.\nsed doesn't need -e if there's only one script.\n\n\n\nLong answer\nThe basic reason is that your computer doesn't trust the certificate authority that signed the certificate used on the GitLab server. This doesn't mean the certificate is suspicious, but it could be self-signed or signed by an institution/company that isn't in the list of your OS's list of CAs. What you have to do to circumvent the problem on your computer is telling it to trust that certificate \u2014 if you don't have any reason to be suspicious about it.\nYou need to check the web certificate used for your GitLab server, and add it to your </git_installation_folder>/bin/curl-ca-bundle.crt.\nTo check if at least the clone works without checking said certificate, you can set:\nexport GIT_SSL_NO_VERIFY=1\n#or\ngit config --global http.sslverify false\n\nBut that would be for testing only, as illustrated in \"SSL works with browser, wget, and curl, but fails with git\", or in this blog post.\nCheck your GitLab settings.\n\nTo get that certificate (that you would need to add to your curl-ca-bundle.crt file), type a:\necho -n | openssl s_client -showcerts -connect yourserver.com:YourHttpsGitlabPort \\\n  2>/dev/null  | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p'\n\n(with 'yourserver.com' being your GitLab server name, and YourHttpsGitlabPort is the https port, usually 443)\nTo check the CA (Certificate Authority issuer), type a:\necho -n | openssl s_client -showcerts -connect yourserver.com:YourHttpsGilabPort \\\n  2>/dev/null  | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' \\\n  | openssl x509 -noout -text | grep \"CA Issuers\" | head -1\n\nNote: Valeriy Katkov suggests in the comments to add -servername option to the openssl command; otherwise the command isn't showed certificate for www.github.com in Valeriy's case.\n\nopenssl s_client -showcerts -servername www.github.com -connect www.github.com:443\n\n\n\nFindekano adds in the comments:\n\nto identify the location of curl-ca-bundle.crt, you could use the command\n\ncurl-config --ca\n\n\nAlso, see my more recent answer \"GitHub: server certificate verification failed\": you might have to renistall those certificates:\nsudo apt-get install --reinstall ca-certificates\nsudo mkdir /usr/local/share/ca-certificates/cacert.org\nsudo wget -P /usr/local/share/ca-certificates/cacert.org http://www.cacert.org/certs/root.crt http://www.cacert.org/certs/class3.crt\nsudo update-ca-certificates\ngit config --global http.sslCAinfo /etc/ssl/certs/ca-certificates.crt"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to check the version of GitLab?\n\nHow to check which version of GitLab is installed on the server?   \nI am about version specified in GitLab changelog:\nhttps://gitlab.com/gitlab-org/gitlab-foss/blob/master/CHANGELOG.md\nFor example: \"6.5.0\", \"6.4.3\", etc.\n\u0421an this be done only through the terminal?\nIs there a way to do that remotely (with browser instead of terminal)?"}, {"role": "assistant", "content": "I have updated my server to GitLab 6.6.4 and finally found the way to get version of GitLab remotely without SSH access to server.\nYou should be logged in to access the following page:\nhttps://your.domain.name/help\nIt shows something similar to:\n\nGitLab 6.6.4 42e34ae\nGitLab is open source software to collaborate on code.\n...\netc."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to remove a Gitlab project?\n\nI have created several repositories in GitLab. One of those was for testing purposes and has some commits and branches. I want to delete or remove this repository. How can I do this?"}, {"role": "assistant", "content": "Go to the project page\nSelect \"Settings\"\nSelect the \"General\" section (you must be in the repository you want to delete it)\nIf you have enough rights, then at the bottom of the page will be a button for \"Advanced settings\" (i.e. project settings that may result in data loss) or \"Remove project\" (in newer GitLab versions)\nPush this button and follow the instructions\n\nThis is only available for admins/owner. As a mere project maintainer, you do not see the \"Remove project\" button."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Transfer git repositories from GitLab to GitHub - can we, how to and pitfalls (if any)?\n\nCan one transfer repositories from GitLab to GitHub if the need be. If so, how exactly can I go about doing the same?\nAlso, are there any pitfalls in doing so or precautionary measures that I need to keep in mind  before doing so given that I may decide to eventually move them to GitHub (as it has more features at the moment that I might find handy for my project)."}, {"role": "assistant", "content": "You can transfer those (simply by adding a remote to a GitHub repo and pushing them)\n\ncreate an empty repo on GitHub\ngit remote add github https://[email\u00a0protected]/yourLogin/yourRepoName.git\ngit push --mirror github\n\nThe history will be the same.\nBut you will lose the access control (teams defined in GitLab with specific access rights on your repo)\nIf you face any issue with the https URL of the GitHub repo:\nThe requested URL returned an error: 403\n\nAll you need to do is to enter your GitHub password, but the OP suggests:\n\nThen you might need to push it the ssh way. You can read more on how to do it here.\n\nSee \"Pushing to Git returning Error Code 403 fatal: HTTP request failed\".\n\nNote that mike also adds in the comments:\n\nGitLab can also be set to push mirror to downstream repositories, and there are specific instructions for push mirroring to GitHub.\nThis can use a GitHub Personal Access Token and also be set to periodically push.\nYou might use this option to share on GitHub, but keep your main development activity in your GitLab instance.\n\n\ntswaehn suggests in the comments the tool piceaTech/node-gitlab-2-github\n\nIt is possible to migrate issues, labels, ... with this tool github.com/piceaTech/node-gitlab-2-github: I tested it, not bad.\nBut had issues when transferring attachments of the issues itself.\nStill worth a try, maybe.\n\nFrotz notes in the comments that:\n\nI've since discovered that there's a wait option available to use in the user-editable settings.ts file that's not documented anywhere.\nI discovered it while implementing my own quick-and-dirty delay, which did work in stopping the \"Abuse detected\" slowdowns\n\n\n\nDoes this mean that when I want to push new changes I would have to do git push github [branch_name] instead of using origin?\n\nNo, you can:\n\ndelete origin, (git remote remove origin),\nrename github remote as origin (git remote rename github origin), and\ngo on git push (to origin, which is now GitHub): the transfer from GitLab to GitHub is complete."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Git push error pre-receive hook declined\n\nI have run gitlabhq rails server on virtual machine, following 1-6 steps from this tutorial https://github.com/gitlabhq/gitlab-recipes/blob/master/install/centos/README.md and starts rails server executing command sudo -u git -H bundle exec rails s -e production. After that I created user, using admin tools and created new project under this user. Then I'm trying to push the existing project to this repo as always. But in the last step, git push origin master fails with the error \n\n[remote rejected] master -> master (pre-receive hook declined)\n\nAdditional info:\n1) I haven't activated user (project owner) via email activation link, because I haven't configured post service on server-side and I didn't find instructions how to do that in this manual.\n2) Gitlab server generates tips how to push project to repo and there is not repositories/ in path. I mean it generates git@mygitlabhost:user/repo.git instead of git@mygitlabhost:repositories/user/repo.git which is correct.\n3) When i tried to debug it, I opened pre-receive script inside repo on server and tried to output variables (there is 3 of them): refs = ARGF.read, key_id  = ENV['GL_ID'] and repo_path = Dir.pwd and found, that key_id is always empty. Maybe the problem is here... If so, please give me suggestions on how to fix that. Thanks"}, {"role": "assistant", "content": "GitLab by default marks master branch as protected (See part Protecting your code in https://about.gitlab.com/2014/11/26/keeping-your-code-protected/ why). If so in your case, then this can help:\n\nOpen your project > Settings > Repository and go to \"Protected branches\", find \"master\" branch into the list and click \"Unprotect\" and try again.\n\nvia https://gitlab.com/gitlab-com/support-forum/issues/40\nFor version 8.11 and above how-to here: https://docs.gitlab.com/ee/user/project/protected_branches.html#restricting-push-and-merge-access-to-certain-users"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Using GitLab token to clone without authentication\n\nI want to clone GitLab repository without prompt for my automation script, by using my private token from my GitLab account.\nCan someone provide me a sample?\nI know I can do so with user and password:\ngit clone https://\" + user + \":\" + password + \"@\" + gitlaburl;\n\nand I know it is possible with ssh key\nBut, both options are insufficient."}, {"role": "assistant", "content": "This is how you do it:\ngit clone https://oauth2:[email\u00a0protected]/vendor/package.git"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How can I pass GitLab artifacts to another stage?\n\nI'd like to use GitLab CI with the .gitlab-ci.yml file to run different stages with separate scripts. The first stage produces a tool that must be used in a later stage to perform tests. I've declared the generated tool as an artifact.\nNow how can I execute that tool in a later stage job? What is the correct path, and what files will there be around it?\nFor example the first stage builds artifacts/bin/TestTool/TestTool.exe and that directory contains other required files (DLLs and others). My .gitlab-ci.yml file looks like this:\nreleasebuild:\n  script:\n    - chcp 65001\n    - build.cmd\n  stage: build\n  artifacts:\n    paths:\n      - artifacts/bin/TestTool/\n\nsystemtests:\n  script:\n    - chcp 65001\n    - WHAT TO WRITE HERE?\n  stage: test\n\nThe build and test jobs run on Windows if that's relevant."}, {"role": "assistant", "content": "Use dependencies. With this config, the test stage will download the untracked files that were created during the build stage:\nbuild:\n  stage: build\n  artifacts:\n    untracked: true\n  script:\n    - ./Build.ps1\n\ntest:\n  stage: test\n  dependencies:\n    - build\n  script:\n    - ./Test.ps1"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Change Default branch in gitlab\n\nI accidentally pushed my local master to a branch called origin on gitlab and now it is the default. Is there a way to rename this branch or set a new master branch to master?"}, {"role": "assistant", "content": "Updated:\nPrerequisites:\n\nYou have the Owner or Maintainer role in the project.\n\nTo update the default branch for an individual project:\n\nOn the left sidebar, select Search or go to find your project.\nSelect Settings > Repository.\nExpand Branch defaults. For Default branch, select a new default branch.\nOptional. Select the Auto-close referenced issues on default branch checkbox to close issues when a merge request uses a closing pattern.\nSelect Save changes.\n\n\nTo change a default branch name for an instance or group:\n\nOn the left sidebar, at the bottom, select Admin Area.\nSelect Settings > Repository.\nExpand Default branch.\nFor Initial default branch name, select a new default branch.\nSelect Save changes."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Getting permission denied (public key) on gitlab\n\nMy problem is that I can't push or fetch from GitLab. However, I can clone (via HTTP or via SSH). I get this error when I try to push :\n\nPermission denied (publickey) fatal : Could not read from remote repository\n\nFrom all the threads I've looked, here is what I have done :\n\nSet up an SSH key on my computer and added the public key to GitLab\nDone the config --global for username and email\nCloned via SSH and via HTTP to check if it would resolve the issue\nDone the ssh -T [email\u00a0protected] command\n\nIf you have any insight about how to resolve my issue, it would be greatly appreciated."}, {"role": "assistant", "content": "I found this after searching a lot. It will work perfectly fine for me.\n\nGo to \"Git Bash\" just like cmd. Right click and \"Run as Administrator\".\nType ssh-keygen\nPress enter.\nIt will ask you to save the key to the specific directory.\nPress enter. It will prompt you to type password or enter without password.\nThe public key will be created to the specific directory.\nNow go to the directory and open .ssh folder.\nYou'll see a file id_rsa.pub. Open it on notepad. Copy all text from it.\nGo to https://gitlab.com/-/profile/keys or\nPaste here in the \"key\" textfield.\nNow click on the \"Title\" below. It will automatically get filled.\nThen click \"Add key\".\n\nNow give it a shot and it will work for sure."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "error: RPC failed; curl transfer closed with outstanding read data remaining\n\nI'm facing this error when I try to clone a repository from GitLab (GitLab 6.6.2 4ef8369):\nremote: Counting objects: 66352, done.\nremote: Compressing objects: 100% (10417/10417), done.\nerror: RPC failed; curl 18 transfer closed with outstanding read data remaining\nfatal: The remote end hung up unexpectedly\nfatal: early EOF\nfatal: index-pack failed\n\nThe clone is then aborted. How can I avoid this?"}, {"role": "assistant", "content": "It happens more often than not, I am on a slow internet connection and I have to clone a decently huge git repository. The most common issue is that the connection closes and the whole clone is cancelled.\nCloning into 'large-repository'...\nremote: Counting objects: 20248, done.\nremote: Compressing objects: 100% (10204/10204), done.\nerror: RPC failed; curl 18 transfer closed with outstanding read data remaining \nfatal: The remote end hung up unexpectedly\nfatal: early EOF\nfatal: index-pack failed\n\nAfter a lot of trial and errors and a lot of \u201cremote end hung up unexpectedly\u201d I have a way that works for me. The idea is to do a shallow clone first and then update the repository with its history.\n$ git clone http://github.com/large-repository --depth 1\n$ cd large-repository\n$ git fetch --unshallow"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "This job is stuck, because the project doesn't have any runners online assigned to it. Go to Runners page [closed]\n\nClosed. This question is not about programming or software development. It is not currently accepting answers.\n                                \n                            \n\n\n\n\n\n\n\n\n\n\n\n This question does not appear to be about a specific programming problem, a software algorithm, or software tools primarily used by programmers. If you believe the question would be on-topic on another Stack Exchange site, you can leave a comment to explain where the question may be able to be answered.\n\n\nClosed last year.\n\n\nThe community reviewed whether to reopen this question last year and left it closed:\n\nOriginal close reason(s) were not resolved\n\n\n\n\n\n\n                        Improve this question\n                    \n\n\n\nI am learning GitLab CI/CD.\nI installed GitLab and GitLab Runner from Officials. Whenever I run the pipeline during Maven build, the job gets stuck. I have a registered runner and it is available to my project, but jobs get stuck.\n.gitlab-ci.yml\nimage: docker:latest\nservices:\n- docker:dind\n\nvariables:\n DOCKER_DRIVER: overlay\n SPRING_PROFILES_ACTIVE: gitlab-ci\n\nstages:\n- build\n- package\n- deploy\n\nmaven-build:\n image: maven:3-jdk-8\n stage: build\n script: \"mvn package -B\"\n artifacts:\n paths:\n  - target/*.jar\n\ndocker-build:\nstage: package\nscript:\n - docker build -t registry.com/ci-cd-demo .\n - docker push registry.com/ci-cd-demo\n\nk8s-deploy:\n image: google/cloud-sdk\n stage: deploy\n script:\n  - echo \"$GOOGLE_KEY\" > key.json\n  - gcloud container clusters get-credentials standard-cluster-demo -- \n  zone us-east1-c --project ascendant-study-222206\n   - kubectl apply -f deployment.yml\n\nMy runner settings\n\n\nError message when runner is already associated with project:\n\nCan you help me?"}, {"role": "assistant", "content": "The job is stuck because your runners have tags and your jobs don't. Follow these 4 steps to enable your runner to run without tags:\n\n\nOr set tags to your jobs. For more info: Configuration of your jobs with .gitlab-ci.yml - Tags"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Forking Git repository from GitHub to GitLab\n\nSuppose that I would like to implement a fix to a project of someone else. That project resides on GitHub.\nI could create a fork on GitHub and implement the fix.\nHowever, I would like to create my fork on GitLab rather than on GitHub.\nIs that possible? How?\nI have read this article:\nhttps://about.gitlab.com/2016/12/01/how-to-keep-your-fork-up-to-date-with-its-origin/\nAnyway, I am not sure what should I do in my case.\n\nShould I just create a fork on GitLab of the project from GitHub somehow?\nOr should I create a mirror on GitLab of the project from GitHub?\nOr should I create a mirror on GitLab and then fork the mirror?\nOr should I do  something completely different?\n\nWhat is the correct approach.\nThanks.\nUPDATE\nRepository mirroring on GitLab does not make sense probably. I can create a mirror of MY GitHub repository on GitLab but I cannot create a mirror of a repository of someone else.\nhttps://docs.gitlab.com/ee/user/project/repository/mirror/\nThis is what I have done so far:\nI have cloned the original GitHub project to my local machine. I have commited the fix to a new branch in my local repository. I have created an empty project on GitLab. I have set origin in my local repository to that empty project on GitLab and pushed both branches to GitLab. I have set upstream in my local repository to the GitHub repository.\nWhen I want to get new commits from the original GitHub repository to the repository on GitLab (i.e. sync the repositories), I can do this using my local repo as an intermediate step. However, there is no direct connection between the repo on GitHub and the repo on GitLab. Is my setup correct? Is there any difference if I make a fork on GitHub?"}, {"role": "assistant", "content": "If you just want to track changes, first make an empty repository in GitLab (or whatever else you may be using) and clone it to your computer.\nThen add the GitHub project as the \"upstream\" remote with:\ngit remote add upstream https://github.com/user/repo\n\nNow you can fetch and pull from the upstream should there be any changes. (You can also push or merge to it if you have access rights.)\ngit pull upstream master\n\nFinally, push back to your own GitLab repository:\ngit push origin master\n\nIf you don't want to manually pull upstream/push origin, GitLab offers a mirroring ability in Settings => Repository => Mirroring repositories."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to clone all projects of a group at once in GitLab?\n\nIn my GitLab repository, I have a group with 20 projects. I want to clone all projects at once. Is that possible?"}, {"role": "assistant", "content": "Update Dec. 2022, use glab repo clone\nglab repo clone -g <group> -a=false -p --paginate\n\nWith:\n\n-p, --preserve-namespace: Clone the repo in a subdirectory based on namespace\n--paginate: Make additional HTTP requests to fetch all pages of projects before cloning. Respects --per-page\n-a, --archived: Limit by archived status. Use with -a=false to exclude archived repositories. Used with --group flag\n\nThat does support cloning more than 100 repositories (since MR 1030, and glab v1.24.0, Dec. 2022)\nThis is for gitlab.com or for a self-managed GitLab instance, provided you set the environment variable GITLAB_URI or GITLAB_HOST: it specifies the URL of the GitLab server if self-managed (eg: https://gitlab.example.com).\n\nOriginal answer and updates (starting March 2015):\nNot really, unless:\n\nyou have a 21st project which references the other 20 as submodules.\n(in which case a clone followed by a git submodule update --init would be enough to get all 20 projects cloned and checked out)\n\nor you somehow list the projects you have access (GitLab API for projects), and loop on that result to clone each one (meaning that can be scripted, and then executed as \"one\" command)\n\n\n\nSince 2015, Jay Gabez mentions in the comments (August 2019) the tool gabrie30/ghorg\n\nghorg allows you to quickly clone all of an org's or user's repos into a single directory.\n\nUsage:\n$ ghorg clone someorg\n$ ghorg clone someuser --clone-type=user --protocol=ssh --branch=develop\n$ ghorg clone gitlab-org --scm=gitlab --namespace=gitlab-org/security-products\n$ ghorg clone --help\n\n\nAlso (2020): https://github.com/ezbz/gitlabber\nusage: gitlabber [-h] [-t token] [-u url] [--debug] [-p]\n                [--print-format {json,yaml,tree}] [-i csv] [-x csv]\n                [--version]\n                [dest]\n\nGitlabber - clones or pulls entire groups/projects tree from gitlab"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Import an existing git project into GitLab?\n\nI have an account of a Gitlab installation where I created the repository \"ffki-startseite\"\nNow I want to clone the repository git://freifunk.in-kiel.de/ffki-startseite.git into that repository with all commits and branches, so I can start working on it in my own scope.\nHow can I import it?"}, {"role": "assistant", "content": "I was able to fully export my project along with all commits, branches and tags to gitlab via following commands run locally on my computer:\n\nTo illustrate my example, I will be using https://github.com/raveren/kint as the source repository that I want to import into gitlab. I created an empty project named Kint (under namespace raveren) in gitlab beforehand and it told me the http git url of the newly created project there is http://gitlab.example.com/raveren/kint.git\nThe commands are OS agnostic.\n\nIn a new directory:\ngit clone --mirror https://github.com/raveren/kint\ncd kint.git\ngit remote add gitlab http://gitlab.example.com/raveren/kint.git\ngit push gitlab --mirror\n\nNow if you have a locally cloned repository that you want to keep using with the new remote, just run the following commands* there:\ngit remote remove origin\ngit remote add origin http://gitlab.example.com/raveren/kint.git\ngit fetch --all\n\n*This assumes that you did not rename your remote master from origin, otherwise, change the first two lines to reflect it."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Changing image size in Markdown on Gitlab\n\nI'm trying to post a picture to a file on my Gitlab using markdown\n    ![](test/media/screenshot.png)\n\nseems to work but is far too large.\nOther solutions I've tried and don't seem to work are as follows:\n    <img src=\"https://gitlab.com/example/screenshot\" width=\"48\">\n    ![](test/media/screenshot.png =100x20)\n    ![](test/media/screenshot.png =250x)\n    <img src=\"https://gitlab.com/example/screenshot\" alt=\"Drawing\" style=\"width: 200px;\"/>\n\nAny ideas on what I can do rather than re-sizing every image I have?"}, {"role": "assistant", "content": "Raw HTML works\nTry the following: after uploading your image, use img tag with src pointing to the path of uploaded image, for me it's working:\nThe following is from one of my files\n![](/uploads/d19fcc3d3b4d313c8cd7960a343463b6/table.png)\n<img src=\"/uploads/d19fcc3d3b4d313c8cd7960a343463b6/table.png\"  width=\"120\" height=\"120\">\n\n\nCheck this link, where I've put different size of same image https://gitlab.com/Basel.issmail/resize-image/wikis/resizing-image\nThere is an issue on gitlab discuss Add control over images with Markdown"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to wrap long lines inside of markdown ``` code ``` in Github and Gitlab issues?\n\neg:\n```\nsome very long line; some very long line; some very long line; some very long line; some very long line; some very long line; some very long line; some very long line; some very long line; some very long line; \n```\n\nwill force user to scroll in github/gitlab issues.\nIs there a way to soft-line wrap inside code block ?\nI've read the related questions but they seem different (eg jekyll etc).\nEDIT: manually editing code to limit to 80 columns is not a viable option (eg, when pasting from a compiler output/log etc; that's a lot of work and should not be necessary)\nEDIT: see also https://github.com/softvar/enhanced-github/issues/95"}, {"role": "assistant", "content": "A quick workaround is to quote your codeblocks, e.g.\n\nthis line is very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very long\n\nMake sure you keep the three backticks inline with the very long line. Like this:\n> ```this line is very long```"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Install npm module from gitlab private repository\n\nWe are using GitLab for our private project. There are some forked libraries from github, that we want to install as npm module. Installing that module directly from npm is ok and for example this:\nnpm install git://github.com/FredyC/grunt-stylus-sprite.git\n\n...works correctly too, but doing the same for GitLab, just changing domain gets me this error.\nnpm WARN `git config --get remote.origin.url` returned wrong result (git://git.domain.com/library/grunt-stylus-sprite.git)\nnpm ERR! git clone git://git.domain.com/library/grunt-stylus-sprite.git Cloning into bare repository 'D:\\users\\Fredy\\AppData\\Roaming\\npm-cache\\_git-remotes\\git-git-domain-com-library-grunt-stylus-sprite-git-6f33bc59'...\nnpm ERR! git clone git://git.domain.com/library/grunt-stylus-sprite.git fatal:unable to connect to git.domain.com:\nnpm ERR! git clone git://git.domain.com/library/grunt-stylus-sprite.git git.domain.com[0: 77.93.195.214]: errno=No error\nnpm ERR! Error: Command failed: Cloning into bare repository 'D:\\users\\Fredy\\App\nData\\Roaming\\npm-cache\\_git-remotes\\git-git-domain-com-library-grunt-stylus-spr\nite-git-6f33bc59'...\nnpm ERR! fatal: unable to connect to git.domain.com:\nnpm ERR! git.domain.com[0: xx.xx.xx.xx]: errno=No error\n\nFrom the web interface of GitLab, I have this URL\n[email\u00a0protected]:library/grunt-stylus-sprite.git. Running this against npm install it tries to install git module from npm registry.\nHowever using URL: [email\u00a0protected]:library/grunt-stylus-sprite.git is suddenly asking me for the password. My SSH key doesn't include passphrase, so I assume it wasn't able to load that key. Maybe there is some configuration for that I have missed ? Key is located at standard location in my home directory with the name \"id_rsa\".\nI am on Windows 7 x64.\nUPDATE\nSince NPM v3 there is built-in support for GitLab and other sources (BitBucket, Gist), from where you can install packages. It works for public and private ones so it's not exactly related to this, but some might find it useful.\nnpm install gitlab:<gitlabname>/<gitlabrepo>[#<commit-ish>]\n\nCheck out documentation: https://docs.npmjs.com/cli/install\nI you want to work with private repos in Gitlab you are required to manage your credentials/auth-token in your .npmrc. See here: https://docs.gitlab.com/ee/user/packages/npm_registry/#authenticate-to-the-package-registry"}, {"role": "assistant", "content": "You have the following methods for connecting to a private gitlab repository\nWith SSH\ngit+ssh://[email\u00a0protected]:Username/Repository#{branch|tag}\ngit+ssh://[email\u00a0protected]/Username/Repository#{branch|tag}\n\nWith HTTPS\ngit+https://[email\u00a0protected]/Username/Repository#{branch|tag}\n\nWith HTTPS and deploy token\ngit+https://<token-name>:<token>@gitlab.com/Username/Repository#{branch|tag}"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to fix: error: '<filename>' does not have a commit checked out fatal: adding files failed when inputting \"git add .\" in command prompt\n\nI'm trying to add a ruby rails file to my repository in gitlab, but it doesn't allow me to add the file saying that my file does not have a commit checked out.\nI've tried git pull, and making the the file again and git adding it, but it still doesn't work. This is the error message I get:\nerror: '172069/08_lab_routes_controllers_views_172069_172188-Copy/adventure_game/' does not have a commit checked out\nfatal: adding files failed"}, {"role": "assistant", "content": "If you have a subdirectory with a .git directory and try to git add . you will see this message.\nThis can happen if you have a git repo and then create/clone another repo in a subdirectory under that repo."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What are the pros and cons of git-flow vs github-flow? [closed]\n\nClosed. This question is opinion-based. It is not currently accepting answers.\n                                \n                            \n\n\n\n\n\n\n\n\n\n\n\nWant to improve this question? Update the question so it can be answered with facts and citations by editing this post.\n\n\nClosed 4 years ago.\n\n\n\n\n\n\n\n                        Improve this question\n                    \n\n\n\nWe have recently started to use GitLab.\nCurrently using a \"centralized\" workflow.\nWe are considering moving to the github-flow but I want to make sure.\nWhat are the pros and cons of git-flow vs github-flow?"}, {"role": "assistant", "content": "As discussed in GitMinutes episode 17, by Nicholas Zakas in his article on  \"GitHub workflows inside of a company\":\n\nGit-flow is a process for managing changes in Git that was created by Vincent Driessen and accompanied by some Git extensions for managing that flow.\n  The general idea behind git-flow is to have several separate branches that always exist, each for a different purpose: master, develop, feature, release, and hotfix.\n  The process of feature or bug development flows from one branch into another before it\u2019s finally released.\nSome of the respondents indicated that they use git-flow in general.\n  Some started out with git-flow and moved away from it. \nThe primary reason for moving away is that the git-flow process is hard to deal with in a continuous (or near-continuous) deployment model.\nThe general feeling is that git-flow works well for products in a more traditional release model, where releases are done once every few weeks, but that this process breaks down considerably when you\u2019re releasing once a day or more.\n\nIn short:\nStart with a model as simple as possible (like GitHub flow tends to be), and move towards a more complex model if you need to.\n\nYou can see an interesting illustration of a simple workflow, based on GitHub-Flow at:\n\"A simple git branching model\", with the main elements being:\n\n\nmaster must always be deployable.\nall changes made through feature branches (pull-request + merge)\nrebase to avoid/resolve conflicts; merge in to master\n\n\n\n\nFor an actual more complete and robust workflow, see gitworkflow (one word)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Docker : exec /usr/bin/sh: exec format error\n\nI created a custom docker image and push it to docker hub but when I run it in CI/CD it gives me this error.\nexec /usr/bin/sh: exec format error\nWhere :\nDockerfile\nFROM ubuntu:20.04\nRUN apt-get update\nRUN apt-get install -y software-properties-common\nRUN apt-get install -y python3-pip\nRUN pip3 install robotframework\n\n.gitlab-ci.yml\nrobot-framework:\n  image: rethkevin/rf:v1\n  allow_failure: true\n  script:\n    - ls\n    - pip3 --version\n\nOutput\nRunning with gitlab-runner 15.1.0 (76984217)\n  on runner zgjy8gPC\nPreparing the \"docker\" executor\nUsing Docker executor with image rethkevin/rf:v1 ...\nPulling docker image rethkevin/rf:v1 ...\nUsing docker image sha256:d2db066f04bd0c04f69db1622cd73b2fc2e78a5d95a68445618fe54b87f1d31f for rethkevin/rf:v1 with digest rethkevin/rf@sha256:58a500afcbd75ba477aa3076955967cebf66e2f69d4a5c1cca23d69f6775bf6a ...\nPreparing environment\n00:01\nRunning on runner-zgjy8gpc-project-1049-concurrent-0 via 1c8189df1d47...\nGetting source from Git repository\n00:01\nFetching changes with git depth set to 20...\nReinitialized existing Git repository in /builds/reth.bagares/test-rf/.git/\nChecking out 339458a3 as main...\nSkipping Git submodules setup\nExecuting \"step_script\" stage of the job script\n00:00\nUsing docker image sha256:d2db066f04bd0c04f69db1622cd73b2fc2e78a5d95a68445618fe54b87f1d31f for rethkevin/rf:v1 with digest rethkevin/rf@sha256:58a500afcbd75ba477aa3076955967cebf66e2f69d4a5c1cca23d69f6775bf6a ...\nexec /usr/bin/sh: exec format error\nCleaning up project directory and file based variables\n00:01\nERROR: Job failed: exit code 1\n\nany thoughts on this to resolve the error?"}, {"role": "assistant", "content": "The problem is that you built this image for arm64/v8 -- but your runner is using a different architecture.\nIf you run:\ndocker image inspect rethkevin/rf:v1\n\nYou will see this in the output:\n...\n        \"Architecture\": \"arm64\",\n        \"Variant\": \"v8\",\n        \"Os\": \"linux\",\n...\n\nTry building and pushing your image from your GitLab CI runner so the architecture of the image will match your runner's architecture.\nAlternatively, you can build for multiple architectures using docker buildx . Alternatively still, you could also run a GitLab runner on ARM architecture so that it can run the image for the architecture you built it on.\n\nWith modern versions of docker, you may also explicitly control the platform docker uses. Docker will use platform emulation if the specified platform is different from your native platform.\nFor example:\nUsing the DOCKER_DEFAULT_PLATFORM environment variable:\nDOCKER_DEFAULT_PLATFORM=\"linux/amd64\" docker build -t test .\n\nUsing the --platform argument, either in the CLI or in your dockerfile:\ndocker build --platform=\"linux/amd64\" -t test .\n\nFROM --platform=linux/amd64 ubuntu:jammy\n\nSystems with docker desktop installed should already be able to do this. If your system is using docker without docker desktop, you may need to install the docker-buildx plugins explicitly."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "markdown link to header\n\nI'm using GitLab to write a read.me file.  \nI tried to create a link to a header. According to the wiki an id should be automatically created:\nsee here\nI created a header using:\n### 1. This is my Header\n\nand tried to create a link to it:\n[link](#1--this-is-my-header)\n\nbut it is not working. \nWhat am I doing wrong?"}, {"role": "assistant", "content": "In the Documentation you link to we learn that...\n\nThe IDs are generated from the content of the header according to the\n  following rules:\n\nAll text is converted to lowercase.\nAll non-word text (e.g., punctuation, HTML) is removed.\nAll spaces are converted to hyphens.\nTwo or more hyphens in a row are converted to one.\nIf a header with the same ID has already been generated, a unique incrementing number is appended, starting at 1.\n\n\nNote rule 4: \"Two or more hyphens in a row are converted to one.\" However, the example you tried has two hyphens in a row (after the 1). Remove one of them and you should have it.\n[link](#1-this-is-my-header)\n\nFrom time to time I have encountered a unique header which is converted into an ID in some non-obvious way. A quick way to work out the ID is to use your browser's view source and/or inspect tools to view the HTML source code. For example, you might find the following HTML for your example:\n<h3 id=\"1-this-is-my-header\">1. This is my Header</h3>\n\nThen just use the contents of the id attribute with a hash to link to that header: #1-this-is-my-header."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI vs. Jenkins [closed]\n\nClosed. This question is seeking recommendations for software libraries, tutorials, tools, books, or other off-site resources. It does not meet Stack Overflow guidelines. It is not currently accepting answers.\n                                \n                            \n\n\n\n\n\n\n\n\n\n\n\n We don\u2019t allow questions seeking recommendations for software libraries, tutorials, tools, books, or other off-site resources. You can edit the question so it can be answered with facts and citations.\n\n\nClosed 3 years ago.\n\n\n\n\n\n\n\n                        Improve this question\n                    \n\n\n\nWhat is the difference between Jenkins and other CI like GitLab CI, drone.io coming with the Git distribution. On some research I could only come up that GitLab community edition doesn't allow Jenkins to be added, but GitLab enterprise edition does. Are there any other significant differences?"}, {"role": "assistant", "content": "This is my experience:\nAt my work we manage our repositories with GitLab EE and we have a Jenkins server (1.6) running.\nIn the basis they do pretty much the same. They will run some scripts on a server/Docker image.\nTL;DR;\n\nJenkins is easier to use/learn, but it has the risk to become a plugin hell\nJenkins has a GUI (this can be preferred if it has to be accessible/maintainable by other people)\nIntegration with GitLab is less than with GitLab CI\nJenkins can be split off your repository\n\nMost CI servers are pretty straight forward (concourse.ci, gitlab-ci, circle-ci, travis-ci, drone.io, gocd and what else have you). They allow you to execute shell/bat scripts from a YAML file definition. Jenkins is much more pluggable, and comes with a UI. This can be either an advantage or disadvantage, depending on your needs.\nJenkins is very configurable because of all the plugins that are available. The downside of this is that your CI server can become a spaghetti of plugins.\nIn my opinion chaining and orchestrating of jobs in Jenkins is much simpler (because of the UI) than via YAML (calling curl commands). Besides that Jenkins supports plugins that will install certain binaries when they are not available on your server (don't know about that for the others).\nNowadays (Jenkins 2 also supports more \"proper ci\" with the Jenkinsfile and the pipline plugin which comes default as from Jenkins 2), but used to be less coupled to the repository than i.e. GitLab CI.\nUsing YAML files to define your build pipeline (and in the end running pure shell/bat) is cleaner.\nThe plug-ins available for Jenkins allow you to visualize all kinds of reporting, such as test results, coverage and other static analyzers. Of course, you can always write or use a tool to do this for you, but it is definitely a plus for Jenkins (especially for managers who tend to value these reports too much).\nLately I have been working more and more with GitLab CI. At GitLab they are doing a really great job making the whole experience fun. I understand that people use Jenkins, but when you have GitLab running and available it is really easy to get started with GitLab CI. There won't be anything that will integrate as seamlessly as GitLab CI, even though they put quite some effort in third-party integrations.\n\nTheir documentation should get you started in no time.\nThe threshold to get started is very low.\nMaintenance is easy (no plugins).\nScaling runners is simple.\nCI fully part of your repository.\nJenkins jobs/views can get messy.\n\nSome perks at the time of writing:\n\nOnly support for a single file in the community edition. Multiples files in the enterprise edition."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Automatically access git submodules via ssh or https\n\nQuestion:\nIs there a way to automatically checkout git submodules via the same method (ssh or https) as the main repository?\nBackground:\nWe have a non-public gitlab repository (main) that has a submodule (utils) which is also hosted as a non-public gitlab repository on the same server. Those repositories can be accessed either via ssh or https:\n\n[email\u00a0protected]:my/path/repo.git\nhttps://gitlabserver.com/my/path/repo.git\n\nBoth variants obviously require different forms of authentication and depending on the client computer and the user, one or the other is preferred. \nFor the top level repository (main) that is not an issue, as anyone can choose the method he or she prefers, but for the sub module this depends on the .gitmodules file and hence is (initially) the same for all.\nNow instead of everyone having to adapt the .gitmodules file to whatever they prefer and make sure they don't accidentally commit those changes, it would be nice, if there was a way to just specify the server and repo path and git chooses either the same method that is used for the main repo, or something that can be set in gitconfig."}, {"role": "assistant", "content": "I finally solved this problem by specifying the submodules url as a relative path:\nSo lets say your main git repository can be reached  \n\neither via https://gitlabserver.com/my/path/main.git\nor via [email\u00a0protected]:my/path/main.git\n\nAnd the .gitmodules file looks like this:\n[submodule \"utils\"]     \n    path = libs/utils   \n    url = https://gitlabserver.com/my/path/utils.git\n\nThat would mean that even when you check out the main application via ssh, the submodule utils would still be accessed via https.\nHowever, you can replace the absolute path with a relative one like this: \n[submodule \"utils\"]     \n    path = libs/utils   \n    url = ../utils.git\n\nand from now on use \n\neither git clone --recursive https://gitlabserver.com/my/path/main.git\nor git clone --recursive [email\u00a0protected]:my/path/main.git\n\nto get the whole repository structure which ever way you want. Obviously that doesn't work for cases where the relative ssh and the https paths are not the same, but at least for gitlab hosted repositories this is the case.\nThis is also handy if you (for whatever reason) mirror your repository structure at two different remote sites."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Where do I find the project ID for the GitLab API?\n\nI use GitLab on their servers. I would like to download my latest built artifacts (build via GitLab CI) via the API like this:\ncurl --header \"PRIVATE-TOKEN: 9koXpg98eAheJpvBs5tK\" \"https://gitlab.com/api/v3/projects/1/builds/8/artifacts\"\n\nWhere do I find this project ID? Or is this way of using the API not intended for hosted GitLab projects?"}, {"role": "assistant", "content": "I just found out an even easier way to get the project id: just see the HTML content of the gitlab page hosting your project. There is an input with a field called project_id, e.g:\n<input type=\"hidden\" name=\"project_id\" id=\"project_id\" value=\"335\" />"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "On GitLab, how to compare a file of two different commits\n\nOn GitLab, how to compare a file of two different commits? I know that that on command line git, the command is:\ngit diff commit1 commit12 -- file_name\n\nWhat is the link format to do this on GitLab?\nSee my related question"}, {"role": "assistant", "content": "It will compare commits, you will be able to find file in list.\n\ngo to Repository > Compare\npaste this url: https://gitlab.com/$USER/$REPO/compare?from=$SHA1&to=$SHA2 or https://your gitlab domain/$ORG/$GROUP/$REPO/-/compare?from=$SHA1&to=$SHA2\nhit enter (notice: gitlab will set 'Source' and 'Target' properly)\nclick button 'compare'"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to fix 'The project you were looking for could not be found' when using git clone\n\nI am trying to clone a project from gitlab to my local machine. I have been granted rights as a developer, and use the command 'git clone \n\nNone of the protocols work (ssh and https neither work)\n\nThe error message I am getting:\nremote: The project you were looking for could not be found.\nfatal: repository 'https://gitlab.com/KZA_Connected/skilltree.git/' not found\n\nAny help would be highly appreciated."}, {"role": "assistant", "content": "I solved this by simply adding username to url like below, \nbefore:\nhttps://gitlab.com/gitlab_user/myrepo.git\nafter:\nhttps://[email\u00a0protected]/gitlab_user/myrepo.git"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to fix Invocation failed Unexpected Response from Server: Unauthorized in Android studio\n\nI have one project on Gitlab and I worked with it for the last few days!\nNow i want pull project on my home PC but show me below error : \nInvocation failed Unexpected Response from Server:  Unauthorized\n        java.lang.RuntimeException: Invocation failed Unexpected Response from Server:  Unauthorized\n        at org.jetbrains.git4idea.nativessh.GitNativeSshAskPassXmlRpcClient.handleInput(GitNativeSshAskPassXmlRpcClient.java:34)\n        at org.jetbrains.git4idea.nativessh.GitNativeSshAskPassApp.main(GitNativeSshAskPassApp.java:30)\n        Caused by: java.io.IOException: Unexpected Response from Server:  Unauthorized\n        at org.apache.xmlrpc.LiteXmlRpcTransport.sendRequest(LiteXmlRpcTransport.java:231)\n        at org.apache.xmlrpc.LiteXmlRpcTransport.sendXmlRpc(LiteXmlRpcTransport.java:90)\n        at org.apache.xmlrpc.XmlRpcClientWorker.execute(XmlRpcClientWorker.java:72)\n        at org.apache.xmlrpc.XmlRpcClient.execute(XmlRpcClient.java:194)\n        at org.apache.xmlrpc.XmlRpcClient.execute(XmlRpcClient.java:185)\n        at org.apache.xmlrpc.XmlRpcClient.execute(XmlRpcClient.java:178)\n\nMy android studio version is 3.4 !"}, {"role": "assistant", "content": "Enabling credentials helper worked for me, using Android Studio 3.6.2 on Windows 10\nAndroidStudio -> File -> Settings -> Git ->  Use credential helper"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to create releases in GitLab?\n\nI had created a private repository which I then changed to public repository. However, I could not find any way to release. Is it possible to create releases in GitLab? If so, how are they done?"}, {"role": "assistant", "content": "To create a release on the GitLab website:\n\nGo to your repository\nIn the menu choose Repository > Tags\nAdd a tag for the version of your app. For example, v1.3.1.\nAdd a message (title) about the release. For example, Release 1.3.1.\nAdd a note that describes the details of the release. (Not optional. Adding a note to a tag is what makes it a release.)\nClick Create tag.\n\n\nThe release will now show up under Project > Releases. Read more at the GitLab documentation. GitLab recommends that you use the Release API now, but their documentation is hard to follow. It would be the preferred method for automating everything with CI/CD, though."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to link folder from a git repo to another repo?\n\nI want to create a public repo to put some sample files from my main repo (private). Is there any way to soft link few folders from a git repo to another git repo?"}, {"role": "assistant", "content": "Then you should use submodules for this task.\nSubmodule are different git repositories under the same root.\nThis way you can manage 2 different project at folder level inside the root repository\n\nSubmodules allow foreign repositories to be embedded within a dedicated subdirectory of the source tree, always pointed at a particular commit.\n\n\ngit submodule\nBreak your big project to sub projects as you did so far.\nNow add each sub project to you main project using :\ngit submodule add <url>\n\nOnce the project is added to your repo, you have to init and update it.\ngit submodule init\ngit submodule update\n\nAs of Git 1.8.2 new option --remote was added\ngit submodule update --remote --merge\n\nwill fetch the latest changes from upstream in each submodule, merge them in, and check out the latest revision of the submodule.\nAs the docs describe it:\n\n--remote\nThis option is only valid for the update command. Instead of using the superproject\u2019s recorded SHA-1 to update the submodule, use the status of the submodule\u2019s remote-tracking branch.\n\nThis is equivalent to running git pull in each submodule.\n\n\nHowever, how would I push a commit in the scenario of bug fix in C which affects the code shared with the parent layers?\n\nAgain: using submodule will place your code inside your main project as part of its content. The difference between having it locally inside the folder or having it as part of a submodule is that in submodule the content is managed (commited) to a different standalone repository.\n\nThis is an illustration of submodule - project inside another project in which each project is a standalone project.\n\n\ngit subtree\nGit subtree allows you to insert any repository as a sub-directory of another one\nVery similar to submodule but the main difference is where your code is managed. In submodules the content is placed inside a separate repo and is managed there which allow you to clone it to many other repos as well.\nsubtree is managing the content as part of the root project and not in a separate project.\nInstead of writing down how to set it up and to understand how to use it you can simply read this excellent post which will explain it all.\nhttps://developer.atlassian.com/blog/2015/05/the-power-of-git-subtree/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to restrict access to the master branch in Git\n\nI have a single repository in which I have two user groups:\n\nAdministrators\nHTML/UI Developers\n\nI do not wish to give read/write access of my master branch to my HTML developers as they do not need to work on it and should not be misusing the core code.\nThough they need to work on their own branch ui-developers. How do I do this on Git?\nP.S.: I am using Bitbucket\n\nI had posted this question when I was extremely new to coding and Git. After two years of experience, I now know that Git doesn't allow to restrict READ access for any particular branch. But services like Bitbucket, GitLab, and GitHub allow you to put write and merge restrictions to branches.\nAlso, I shifted to GitLab six months back :)"}, {"role": "assistant", "content": "Git itself does not have such feature, but many hosting providers do. This is generally known as branch protection. There is no way to prevent read access as far as I know.\nUsing Bitbucket\nBitbucket allows a lot of customization for the actions to prevent by branch protection. To protect a branch:\n\nGo to a repository in a project.\n\nChoose Settings \u2192 Branch permissions.\n\nClick Add permission.\n\nIn the Branches field, select either Branch name, Branch pattern, or Branching model.\n\n\n\nBranch name - select an existing branch by name.\n\nBranch pattern - specify a branch using branch pattern syntax for matching branch names.\n\nBranching model - select the branch type to restrict access to.\n\n\n\nSelect the type of actions you want to prevent.\n\n\nBranch deletion - prevents branch and tag deletion.\n\nRewriting history - prevents history rewrites on the specified branch(es) - for example by a force push or rebase.\n\nChanges without a pull request - prevents pushing changes directly to the specified branch(es); changes are allowed only with a pull request.\n\nAll modifications - prevents pushes to the specified branch(es) and restricts creating new branches matching the specified branch(es) or pattern.\n\n\n\nOptional: Add exemptions for any of the selected restrictions. Adding a user or group as an exemption means that it will not apply to them. This is not required; not adding any exemptions means the restriction will apply to everyone.\n\nClick Create to finish.\n\n\nSource\nUsing GitHub\nA repository can have multiple protected branch rules that affect the same branches.\nProtected branches are available only in public repositories with GitHub Free.\nProtected branch in GitHub can be configured to require:\n\npushes to be made via pull requests and reviewed before being merged,\n\nother branches to pass status check before being merged,\n\ncommits to be signed,\n\nhistory to be linear,\n\nthat the above rules are enforced even for administrators,\n\nthat pushes come from specific people, teams or applications,\n\n\nForce pushes and deletions can be allowed independently.\nTo protect a branch:\n\nOn GitHub, navigate to the main page of the repository.\n\nUnder your repository name, click Settings.\n\nIn the left menu, click Branches.\n\nNext to \"Branch protection rules\", click Add rule.\n\nUnder \"Branch name pattern\", type the branch name or pattern you want to protect (Impacted branches are listed and counted).\n\nConfigure specific branch rule settings if needed.\n\nClick Create or Save changes.\n\n\nSource\nUsing GitLab\nIn GitLab, protecting a branch does the following:\n\nit prevents its creation, if not already created, from everybody except users with Master permission\nit prevents pushes from everybody except users with Master permission\nit prevents anyone from force pushing to the branch\nit prevents anyone from deleting the branch\n\nTo protect the branch:\n\nNavigate to the main page of the project.\n\nIn the upper right corner, click the settings wheel and select Protected branches.\n\nFrom the Branch dropdown menu, select the branch you want to protect and click Protect.\n\nOnce done, the protected branch will appear in the \"Already protected\" list.\n\n\nYou can then allow some access to users with developer rights by checking \"Developers can merge\" or \"Developers can push\"\nSource"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to use git commands after enable gitlab's second-factor authentication\n\nToday I've enabled Gitlab's 2nd-factor authentication. After that, since I logged in the Gitlab website, I need to use my cell phone to pass a 6-digits plus my password, that's good, it makes me feel safe.\nHowever, when I use the general operations, for example git clone some-repo.git, I got the error:\nCloning into 'some-repo'...\nremote: HTTP Basic: Access denied\nremote: You must use a personal access token with 'api' scope for Git over HTTP.\nremote: You can generate one at https://gitlab.com/profile/personal_access_tokens\nfatal: Authentication failed for 'some-repo.git'\n\nThen I try existing cloned local repo, using git pull, the same error occurs. Before I enabled the 2nd-factor authentication, all the above operation worked fine.\nFlowing the above error's instructions, I went to the mentioned address: https://gitlab.com/profile/personal_access_tokens. I created the following token, and save the token's key.\n\nHowever, I don't know what to do with this key. Can someone tell me how to use this key to enable the basic operations like git pull, git clone, git push etc...\nEdit\nI had many repos on local before I enabled the 2nd-factor authentication. I want these to work too."}, {"role": "assistant", "content": "As explained in using gitlab token to clone without authentication, you can clone a GitLab repo using your Personal Access Token like this:\ngit clone https://oauth2:[email\u00a0protected]/yourself/yourproject.git\n\nAs for how to update your existing clones to use the GitLab Personal Access Token, you should edit your .git/config file in each local git directory, which will have an entry something like this:\n[remote \"origin\"]\n    url = https://[email\u00a0protected]/yourself/yourproject.git\n\nChange the url:\n[remote \"origin\"]\n    url = https://oauth2:[email\u00a0protected]/yourself/yourproject.git\n\nNow you can continue using this existing git clone as you did before you enabled 2FA."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "\"Make sure you configure your 'user.email' and 'user.name' in git\" when trying to push to git lab\n\nI keep getting the same message when I try to push to my git lab account: \n\n\"Make sure you configure your 'user.email' and 'user.name' in git\".\n\nI've already done \ngit config --global user.name \"John Doe\"\n\ngit config --global user.email \"[email\u00a0protected]\"\n\nAnd I've checked w/\ngit remote -v\n\nAnyone have any ideas on what else I can do?"}, {"role": "assistant", "content": "Make sure you run this commands\ngit config --global user.name \"John Doe\"\n\ngit config --global user.email \"[email\u00a0protected]\"\n\nIn the terminal. In this directory -I\u00b4m a Windows user-: C:\\Program Files\\Git\\bin\nHad the same issue. Solved running those commands there"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to run a gitlab-ci.yml job only on a tagged branch?\n\nHow do I run a .gitlab-ci.yml job only on a tagged Master branch?\njob:\n  script:\n  - echo \"Do something\"\n  only:\n  - master\n  - tags\n\nThe above code will run if either condition exists: a Master branch or a tagged commit. \nMy goal is to have this run for a production deploy, but it would require that it be on the Master branch and that it be tagged (with a version). Otherwise, I'll have another job that will push to staging if its missing a tag."}, {"role": "assistant", "content": "This behavior will be introduced in version 12.\nOpen issue was recently update:\n\nJason Lenny @jlenny changed title from {-Update .gitlab-ci.yml to\nsupport conjunction logic for build conditions-} to Conjunction logic\nfor build conditions MVC \u00b7 2 days ago\nJason Lenny @jlenny changed milestone to 12.0 \u00b7 2 days ago\n\n(fingers crossed)\nA solution is to use the except keyword to exclude all the branches, in conjunction with only to run on tags, in this way you run your pipeline only on tag in master branch:\n  only:\n    - tags\n  except:\n    - branches\n\nI'm using version 11.3.4"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to access multiple repositories in CI build?\n\nWe have a project that is composed of multiple (non-public) repositories. \nTo build the whole project, the build system needs to have the files of all repositories (master branches).\nIs there a way I can configure GitLab CI to provide the repositories I need?\nI guess I could do a git fetch or similar during the CI build, but how to deal with authentication then?"}, {"role": "assistant", "content": "If you are running GitLab version 8.12 or later, the permissions model was reworked. Along with this new permission model comes the CI environment variable CI_JOB_TOKEN. The premium version of GitLab uses this environment variable for triggers, but you can use it to clone repos.\ndummy_stage:\n  script:\n    - git clone https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.instance/group/project.git"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How can I reference an image in GitLab markdown in the current directory with the path starting with ./ dot slash?\n\nI have stored a Markdown file and an image file in a Git repo as follows:\n\nreadme.markdown\nimages/\n\nimage.png\n\n\nI reference the image from readme.markdown like this:\n![](./images/image.png)\n\nThis renders as expected in ReText, but does not render when I push the repo to GitLab.\nHow can I reference the image from the Markdown file so that it renders when viewed in GitLab?"}, {"role": "assistant", "content": "![](images/image.png) without the ./ works for me: https://gitlab.com/cirosantilli/test/blob/bffbcc928282ede14dcb42768f10a7ef21a665f1/markdown.md#image\nI have opened a request for this to be allowed at: http://feedback.gitlab.com/forums/176466-general/suggestions/6746307-support-markdown-image-path-in-current-directory-s , but it entered into Internet void when GitLab dumped UserVoice."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to integrate UML diagrams into GitLab or GitHub\n\nI want to publish some programming documentation I have in a public available repository. This documentation has formatted text, some UML diagrams, and a lot of code examples. I think that GitHub or GitLab are good places to publish this.\nTo publish the UML diagrams, I would like to have some easy way to keep them updated into the repository and visible as images in the wiki. I don't want to keep the diagrams in my computer (or on the cloud), edit them, generate an image, and then publish it every time.\nIs there a way to put the diagrams in the repository (in PlantUML syntax would be ideal), link them in the markdown text, and make the images auto-update every time the diagram is updated?"}, {"role": "assistant", "content": "Edit: Alternative with Proxy service\nThis way is significantly different and simpler than the answer below; it uses the PlantUML proxy service:\nhttp://www.plantuml.com/plantuml/proxy?cache=no&src=https://raw.github.com/plantuml/plantuml-server/master/src/main/webapp/resource/test2diagrams.txt\n\nThe GitHub markdown for this would be:\n![alternative text](http://www.plantuml.com/plantuml/proxy?cache=no&src=https://raw.github.com/plantuml/plantuml-server/master/src/main/webapp/resource/test2diagrams.txt)\n\nThis method suffers from not being able to specify the SVG format (it defaults to PNG), and it is perhaps not possible to work-around the caching bug mentioned in the comments.\n\nAfter trying the other answer, I discovered the service to be slow and seemingly not up to the latest version of PlantUML.\nI've found a different way that's not quite as straightforward, but it works via  PlantUML.com's server (in the cloud). As such, it should work anywhere you can hotlink to an image.\nIt exploits the !includeurl function and is essentially an indirection. The markdown file links to a PlantUML source that includes the diagram's source. This method allows modifying the source in GitHub, and any images in the GitHub markdown files will automatically update. But it requires a tricky step to create the URL to the indirection.\n\n\nGet the URL to the raw PlantUML source, e.g., https://raw.githubusercontent.com/linux-china/plantuml-gist/master/src/main/uml/plantuml_gist.puml (using the example in the joanq's answer)\n\nGo to http://plantuml.com/plantuml/form (or PlantText.com) and create a one-line PlantUML source that uses the !includeurl URL-TO-RAW-PLANTUML-SOURCE-ON-GITHUB operation. Continuing with the example URL, the PlantUML (meta)source is:\n!includeurl https://raw.githubusercontent.com/linux-china/plantuml-gist/master/src/main/uml/plantuml_gist.puml\n\n\nCopy the image URL from PlantUML.com's image, e.g., http://plantuml.com:80/plantuml/png/FSfB2e0m303Hg-W1RFPUHceiDf36aWzwVEl6tOEPcGGvZXBAKtNljW9eljD9NcCFAugNU15FU3LWadWMh2GPEcVnQBoSP0ujcnS5KnmaWH7-O_kEr8TU and paste it into your GitHub markdown file. This URL won't change.\n![PlantUML model](http://plantuml.com:80/plantuml/png/3SNB4K8n2030LhI0XBlTy0YQpF394D2nUztBtfUHrE0AkStCVHu0WP_-MZdhgiD1RicMdLpXMJCK3TC3o2iEDwHSxvNVjWNDE43nv3zt731SSLbJ7onzbyeF)\n\n\n\nBonus: You can even get access to the SVG format by modifying the plantuml/png/ part of the URL to be plantuml/svg/ as follows\n![PlantUML model](http://plantuml.com:80/plantuml/svg/3SNB4K8n2030LhI0XBlTy0YQpF394D2nUztBtfUHrE0AkStCVHu0WP_-MZdhgiD1RicMdLpXMJCK3TC3o2iEDwHSxvNVjWNDE43nv3zt731SSLbJ7onzbyeF)\n\nExample on GitHub\nhttps://github.com/fuhrmanator/course-activity-planner/blob/master/ooad/overview.md\nCaveat with private repos\nAs davidbak pointed out in a comment, the raw file in a private repo will have a URL with token=<LONGSTRINGHERE> in it, and this token changes as the source file updates. Unfortunately, the markdown breaks when this happens, so you have to update the Readme file after you commit the file to GitHub, which is not a great solution."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Fingerprint has already been taken gitlab\n\nI formatted my Windows 7 laptop and in an attempt to have git setup working again, I installed git and source tree application.\nI deleted the SSH Key from gitlab and regenerated the key using ssh-keygen. But when I try to add the SSH Key at gitlab, it throws the following exception :\nKey is invalid\nFingerprint has already been taken\nFingerprint cannot be generated\n\nBecause of this I am unable to clone the git repository from the source tree application since gitlab is unable to authenticate the SSH key.I followed queries at google groups of gitlab but none of them seem to resolve my issue. Is there any workaround or steps to get the SSH key accepted by gitlab?"}, {"role": "assistant", "content": "In my case; the public key i was trying to add was already used with 'work' Gitlab account and i received the said error upon trying to use the same key with 'personal' Gitlab account.\nSolution - Add another public key on the same machine and use that with 'personal' gitlab account (both on same machine).\nnavigate to .ssh folder in your profile (even works on windows) and run command\nssh-keygen -t rsa\n\nwhen asked for file name give another filename id_rsa_2 (or any other).\nenter for no passphrase (or otherwise).\nYou will end up making id_rsa_2 and id_rsa_2.pub\nuse the command\ncat id_rsa_2.pub\n\ncopy and save key in 'personal' Gitlab account.\ncreate a file with no extension in .ssh folder named 'config'\nput this block of configuration in your config file\nHost           gitlab.com\nHostName       gitlab.com\nIdentityFile   C:\\Users\\<user name>\\.ssh\\id_rsa\nUser           <user name>\n\n\nHost           gitlab_2\nHostName       gitlab.com\nIdentityFile   C:\\Users\\<user name>\\.ssh\\id_rsa_2\nUser           <user name>\n\nnow whenever you want to use 'personal' gitlab account simply change alias in git URLs for action to remote servers.\nfor example\ninstead of using\ngit clone git@gitlab.com:..............\nsimply use\ngit clone git@gitlab_2:...............\ndoing that would use the second configuration with gitlab.com (from 'config' file) and will use the new id_rsa_2 key pair for authentication.\nFind more about above commands on this link\nhttps://clubmate.fi/how-to-setup-and-manage-multiple-ssh-keys/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Role of docker-in-docker (dind) service in gitlab ci\n\nAccording to the official gitlab documentation, one way to enable docker build within ci pipelines, is to make use of the dind service (in terms of gitlab-ci services).\nHowever, as it is always the case with ci jobs running on docker executors, the docker:latest image is also needed.\nCould someone explain:\n\nwhat is the difference between the docker:dind and the docker:latest images?\n(most importantly): why are both the service and the docker image needed (e.g. as indicated in this example, linked to from the github documentation) to perform e.g. a docker build whithin a ci job? doesn't the docker:latest image (within which the job will be executed!) incorporate the docker daemon (and I think the docker-compose also), which are the tools necessary for the commands we need (e.g. docker build, docker push etc)?\n\nUnless I am wrong, the question more or less becomes:\n\nWhy a docker client and a docker daemon cannot reside in the same docker (enabled) container"}, {"role": "assistant", "content": "what is the difference between the docker:dind and the docker:latest images?\n\n\ndocker:latest contains everything necessary to connect to a docker daemon, i.e., to run docker build, docker run and such. It also contains the docker daemon but it's not started as its entrypoint.\ndocker:dind builds on docker:latest and starts a docker daemon as its entrypoint.\n\nSo, their content is almost the same but through their entrypoints one is configured to connect to tcp://docker:2375 as a client while the other is meant to be used for a daemon.\n\nwhy are both the service and the docker image needed [\u2026]?\n\nYou don't need both. You can just use either of the two, start dockerd as a first step, and then run your docker build and docker run commands as usual like I did here; apparently this was the original approach in gitlab at some point. But I find it cleaner to just write services: docker:dind instead of having a before_script to setup dockerd. Also you don't have to figure out how to start & install dockerd properly in your base image (if you are not using docker:latest.)\nDeclaring the service in your .gitlab-ci.yml also lets you swap out the docker-in-docker easily if you know that your runner is mounting its /var/run/docker.sock into your image. You can set the protected variable DOCKER_HOST to unix:///var/run/docker.sock to get faster builds. Others who don't have access to such a runner can still fork your repository and fallback to the dind service without modifying your .gitlab-ci.yml."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "ssh : Permission denied (publickey,gssapi-with-mic)\n\ni'm use centos 5.9.\nafter installing gitlab by this link ssh not working.\nbefore install gitlab ssh correctly working.\ni'm using this server localy and other services such as elastix and apache,mysql installed on server.\nappeare this error :\nOpenSSH_6.9p1 Ubuntu-2ubuntu0.1, OpenSSL 1.0.2d 9 Jul 2015\ndebug1: Reading configuration data /etc/ssh/ssh_config\ndebug1: /etc/ssh/ssh_config line 19: Applying options for *\ndebug2: ssh_connect: needpriv 0\ndebug1: Connecting to 192.168.88.23 [192.168.88.23] port 22.\ndebug1: Connection established.\ndebug1: permanently_set_uid: 0/0\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_rsa type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_rsa-cert type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_dsa type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_dsa-cert type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_ecdsa type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_ecdsa-cert type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_ed25519 type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_ed25519-cert type -1\ndebug1: Enabling compatibility mode for protocol 2.0\n                                        debug1: Local version string SSH-2.0-OpenSSH_6.9p1 Ubuntu-2ubuntu0.1\ndebug1: Remote protocol version 2.0, remote software version OpenSSH_4.3\ndebug1: match: OpenSSH_4.3 pat OpenSSH_4* compat 0x00000000\ndebug2: fd 3 setting O_NONBLOCK\ndebug1: Authenticating to 192.168.88.23:22 as 'root'\ndebug1: SSH2_MSG_KEXINIT sent\ndebug1: SSH2_MSG_KEXINIT received\ndebug2: kex_parse_kexinit: [email\u00a0protected],ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group-exchange-sha1,diffie-hellman-group14-sha1,diffie-hellman-group1-sha1\ndebug2: kex_parse_kexinit: [email\u00a0protected],[email\u00a0protected],ssh-rsa,[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,ssh-ed25519,ssh-dss\ndebug2: kex_parse_kexinit: [email\u00a0protected],aes128-ctr,aes192-ctr,aes256-ctr,[email\u00a0protected],[email\u00a0protected],arcfour256,arcfour128,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,[email\u00a0protected]\ndebug2: kex_parse_kexinit: [email\u00a0protected],aes128-ctr,aes192-ctr,aes256-ctr,[email\u00a0protected],[email\u00a0protected],arcfour256,arcfour128,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,[email\u00a0protected]\ndebug2: kex_parse_kexinit: [email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],hmac-sha2-256,hmac-sha2-512,hmac-sha1,[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],hmac-md5,hmac-ripemd160,[email\u00a0protected],hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: [email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],hmac-sha2-256,hmac-sha2-512,hmac-sha1,[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],hmac-md5,hmac-ripemd160,[email\u00a0protected],hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: none,[email\u00a0protected],zlib\ndebug2: kex_parse_kexinit: none,[email\u00a0protected],zlib\ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: first_kex_follows 0 \ndebug2: kex_parse_kexinit: reserved 0 \ndebug2: kex_parse_kexinit: diffie-hellman-group-exchange-sha1,diffie-hellman-group14-sha1,diffie-hellman-group1-sha1\ndebug2: kex_parse_kexinit: ssh-rsa,ssh-dss\ndebug2: kex_parse_kexinit: aes128-ctr,aes192-ctr,aes256-ctr,arcfour256,arcfour128,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,[email\u00a0protected]\ndebug2: kex_parse_kexinit: aes128-ctr,aes192-ctr,aes256-ctr,arcfour256,arcfour128,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,[email\u00a0protected]\ndebug2: kex_parse_kexinit: hmac-md5,hmac-sha1,hmac-ripemd160,[email\u00a0protected],hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: hmac-md5,hmac-sha1,hmac-ripemd160,[email\u00a0protected],hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: none,[email\u00a0protected]\ndebug2: kex_parse_kexinit: none,[email\u00a0protected]\ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: first_kex_follows 0 \ndebug2: kex_parse_kexinit: reserved 0 \ndebug1: kex: server->client aes128-ctr hmac-sha1 none\ndebug1: kex: client->server aes128-ctr hmac-sha1 none\ndebug1: SSH2_MSG_KEX_DH_GEX_REQUEST(1024<7680<8192) sent\ndebug1: got SSH2_MSG_KEX_DH_GEX_GROUP\ndebug2: bits set: 3111/6144\ndebug1: SSH2_MSG_KEX_DH_GEX_INIT sent\ndebug1: got SSH2_MSG_KEX_DH_GEX_REPLY\ndebug1: Server host key: ssh-rsa SHA256:7J6JOe94H9PedNKlx6yG/wMy6ZYC8iB74WdOVGDgY7A\ndebug1: Host '192.168.88.23' is known and matches the RSA host key.\n    debug1: Found key in /root/.ssh/known_hosts:1\ndebug2: bits set: 3102/6144\ndebug2: set_newkeys: mode 1\ndebug1: SSH2_MSG_NEWKEYS sent\ndebug1: expecting SSH2_MSG_NEWKEYS\ndebug2: set_newkeys: mode 0\ndebug1: SSH2_MSG_NEWKEYS received\ndebug1: SSH2_MSG_SERVICE_REQUEST sent\ndebug2: service_accept: ssh-userauth\ndebug1: SSH2_MSG_SERVICE_ACCEPT received\ndebug2: key: /root/.ssh/id_rsa ((nil)),\ndebug2: key: /root/.ssh/id_dsa ((nil)),\ndebug2: key: /root/.ssh/id_ecdsa ((nil)),\ndebug2: key: /root/.ssh/id_ed25519 ((nil)),\ndebug1: Authentications that can continue: publickey,gssapi-with-mic\ndebug1: Next authentication method: gssapi-with-mic\ndebug1: Unspecified GSS failure.  Minor code may provide more information\nNo Kerberos credentials available\n\ndebug1: Unspecified GSS failure.  Minor code may provide more information\nNo Kerberos credentials available\n\ndebug1: Unspecified GSS failure.  Minor code may provide more information\n\n\ndebug1: Unspecified GSS failure.  Minor code may provide more information\nNo Kerberos credentials available\n\ndebug2: we did not send a packet, disable method\ndebug1: Next authentication method: publickey\ndebug1: Trying private key: /root/.ssh/id_rsa\ndebug1: Trying private key: /root/.ssh/id_dsa\ndebug1: Trying private key: /root/.ssh/id_ecdsa\ndebug1: Trying private key: /root/.ssh/id_ed25519\ndebug2: we did not send a packet, disable method\ndebug1: No more authentication methods to try.\nPermission denied (publickey,gssapi-with-mic)."}, {"role": "assistant", "content": "Setting 700 to .ssh and 600 to authorized_keys solved the issue.\nchmod 700 /root/.ssh\nchmod 600 /root/.ssh/authorized_keys"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to create a new gitlab repo from my existing local git repo, using CLI?\n\nI have many local git repos on my OSX. Using the command line I want to make new gitlab repositories on https://gitlab.companyname.com from existing local repositories.\nIs it possible to do that?"}, {"role": "assistant", "content": "2018 Solution: just use --set-upstream\nAssuming you'll take care of writing the script that would do the following for each of your local repo, it seems that as of Gitlab 10.5 you can simply use\n# To your own domain\ngit push --set-upstream address/your-project.git\n\n# To gitlab.com with SSH\ngit push --set-upstream [email\u00a0protected]:username/new-repo.git master\n\n# To gitlab.com with HTTP\ngit push --set-upstream https://gitlab.example.com/username/new-repo.git master\n\nThis will create a new project on Gitlab without you creating it manually on the server\n\nFrom the Documentation\nPush to create a new project\n\nWhen you create a new repository locally, instead of manually creating a new project in GitLab and then cloning the repository locally, you can directly push it to GitLab to create the new project, all without leaving your terminal. If you have access rights to the associated namespace, GitLab automatically creates a new project under that GitLab namespace with its visibility set to Private by default (you can later change it in the project's settings).\nThis can be done by using either SSH or HTTPS:\n\n## Git push using SSH\ngit push --set-upstream [email\u00a0protected]:namespace/nonexistent-project.git master\n\n## Git push using HTTPS\ngit push --set-upstream https://gitlab.example.com/namespace/nonexistent-project.git master\n\n\nYou can pass the flag --tags to the git push command to export existing repository tags.\nOnce the push finishes successfully, a remote message indicates the command to set the remote and the URL to the new project:\n\nremote:\nremote: The private project namespace/nonexistent-project was created.\nremote:\nremote: To configure the remote, run:\nremote:   git remote add origin https://gitlab.example.com/namespace/nonexistent-project.git\nremote:\nremote: To view the project, visit:\nremote:   https://gitlab.example.com/namespace/nonexistent-project\nremote:"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI/CD job's log exceeded limit\n\nWhen I run my job on Gitlab CI/CD, after a while I obtain the following error message:\nJob's log exceeded limit of 4194304 bytes.\n\nHow to change this limit?"}, {"role": "assistant", "content": "To change the build log size of your jobs in Gitlab CI/CD, you can edit your config.toml file and add a new limit in kilobytes:\n[[runners]]\n  output_limit = 10000\n\nAccording to the documentation\n\noutput_limit : Maximum build log size in kilobytes. Default is 4096 (4MB).\n\nFor this to take effect, you need to restart the gitlab runner:\nsudo gitlab-runner restart"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do we change the URL of a working GitLab install?\n\nI have set up and we are running a default install of GitLab v6.0.1 (we're about to upgrade as well). It was a \"Production\" setup, following this guide precisely to the letter:\nhttps://github.com/gitlabhq/gitlabhq/blob/master/doc/install/installation.md\nNow, how do we safely change the URL of a working install?\nApparently our URL is very long and we've come up with a new URL. I've edited a number of configuration files and the \"Application Status Checks\" report everything is OK. I've rebooted the server to ensure things are still working.\nI can access Nginx just fine, over our original SSL. I can browse the GitLab site, create a repository, etc. I can fork and commit just fine.\nIt all seems to be OK; but, since this is not a native environment for me, I wanted to double check that I have done everything to rename a GitLab site.\nThe files I've edited are:\n/etc/hosts\n  127.0.0.1  localhost\n  10.0.0.10  wake.domain.com    wake\n  10.0.0.10  git.domain.com     git\n\n/home/git/gitlab/config/gitlab.yml\n  production: &base\n    gitlab:\n      host: git.domain.com\n\n/home/git/gitlab-shell/config.yml\n  gitlab_url: \"https://git.domain.com\"\n  ^- yes, we are on SSL and that is working, even on a new URL\n\n/etc/nginx/sites-available/gitlab\n  server {\n    server_name git.domain.com"}, {"role": "assistant", "content": "GitLab Omnibus\nFor an Omnibus install, it is a little different.\nThe correct place in an Omnibus install is:\n/etc/gitlab/gitlab.rb\n    external_url 'http://gitlab.example.com'\n\nFinally, you'll need to execute sudo gitlab-ctl reconfigure and sudo gitlab-ctl restart so the changes apply.\n\nI was making changes in the wrong places and they were getting blown away.\nThe incorrect paths are:\n/opt/gitlab/embedded/service/gitlab-rails/config/gitlab.yml\n/var/opt/gitlab/.gitconfig\n/var/opt/gitlab/nginx/conf/gitlab-http.conf\n\nPay attention to those warnings that read:\n# This file is managed by gitlab-ctl. Manual changes will be\n# erased! To change the contents below, edit /etc/gitlab/gitlab.rb\n# and run `sudo gitlab-ctl reconfigure`."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Move repository from one group to another in GitLab\n\nIs it possible to move a GitLab repository from one group to another in GitLab?\nFor example, I have https://gitlab.com/my-user/my-repo. I'd like to move it to https://gitlab.com/my-group/another-group/my-repo.\nIdeally, I'd like to keep all the issues associated with it."}, {"role": "assistant", "content": "Yes, you can move your GitLab project from one namespace to another.\nYour project -> Settings -> General -> Advanced\n\nThen, almost at the end of the list.\nTransfer project"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab - Push to a repository using access_token\n\nI implemented the oauth2 web flow in order to get access_token from users of my app. With the access_token, I would like to do the following actions:  \n\nGet user informations  \nCreate a repo for this user  \nPush code to this repo (using git push  )\n\nI already successfully get the user information(1) and create a repo(2)\nThe problem is I can't push code (3), I got \"Unauthorized\" error.  \nThe command I run:\ngit remote add origin https://gitlab-ci-token<mytoken>@gitlab.com/myuser/myrepo.git  \ngit push origin master"}, {"role": "assistant", "content": "You should do\ngit remote add origin https://<access-token-name>:<access-token>@gitlab.com/myuser/myrepo.git\n\nNote that this stores the access token as plain text in the .git\\config file.  To avoid this you can use the git credential system, providing the access token name for \"username\" and the access token for \"password\".  This should store the credentials in the git credential system in a more secure way."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I push to a repo from within a gitlab CI pipeline?\n\nIn my CI pipeline I am generating an artifact public/graph.png that visualises some aspect of my code. In a later step I want to commit that to the repo from within the CI pipeline. Here's the pertinent part of .gitlab-ci.yml:\ncommit-graph:\n  stage: pages\n  script:\n    - git config user.email \"[email\u00a0protected]\"\n    - git config user.name \"CI Pipeline\"\n    - cd /group/project\n    - mv public/graph.png .\n    - git add graph.png\n    - git commit -m \"committing graph.png [ci skip]\"\n    - echo $CI_COMMIT_REF_NAME\n    - git push origin HEAD:$CI_COMMIT_REF_NAME\n\nWhen the pipeline runs within gitlab it fails with:\n\n$ git config user.email \"[email\u00a0protected]\"\n  $ git config user.name \"CI Pipeline\"\n  $ cd /group/project\n  $ mv public/graph.png .\n  $ git add graph.png\n  $ git commit -m \"committing graph.png [ci skip]\"\n  [detached HEAD 22a50d1] committing graph.png [ci skip]\n   1 file changed, 0 insertions(+), 0 deletions(-)\n   create mode 100644 graph.png\n  $ echo $CI_COMMIT_REF_NAME\n  jamiet/my-branch\n  $ git push origin HEAD:$CI_COMMIT_REF_NAME\n  fatal: unable to access 'https://gitlab-ci-token:[email\u00a0protected]/group/project/project.git/': server certificate verification failed. CAfile: /etc/ssl/certs/ca-certificates.crt CRLfile: none\n\nNot sure what I'm doing wrong and don't know enough about SSL to understand that error. Can anyone advise?\nWe are hosting gitlab ourselves by the way."}, {"role": "assistant", "content": "Nowadays there is a much cleaner way to solve this without using SSH but using a project scoped access token, also see this answer.\nIn the GitLab project create an project scoped access token so it is linked to the project, not to an individual. Next store this token as an GitLab CI/CD variable. You can now connect using the following:\npush-back-to-remote:\n  script:\n    - git config user.email \"[email\u00a0protected]\"\n    - git config user.name \"ci-bot\"\n    - git remote add gitlab_origin https://oauth2:[email\u00a0protected]/path-to-project.git\n    - git add .\n    - git commit -m \"push back from pipeline\"\n    - git push gitlab_origin HEAD:main -o ci.skip # prevent triggering pipeline again"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "An error occurred while installing rugged\n\nFollowing this tutorial [link] to install gitlab on a dedicated server. I need to :\nsudo -u git -H bundle install --deployment --without development test postgres aws\n\nBut an error occurred while installing rugged :\nGem::Installer::ExtensionBuildError: ERROR: Failed to build gem native extension.\n\n    /usr/local/bin/ruby extconf.rb\nchecking for cmake... no\nERROR: CMake is required to build Rugged.\n*** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of necessary\nlibraries and/or headers.  Check the mkmf.log file for more details.  You may\nneed configuration options.\n\nProvided configuration options:\n    --with-opt-dir\n    --without-opt-dir\n    --with-opt-include\n    --without-opt-include=${opt-dir}/include\n    --with-opt-lib\n    --without-opt-lib=${opt-dir}/lib\n    --with-make-prog\n    --without-make-prog\n    --srcdir=.\n    --curdir\n    --ruby=/usr/local/bin/ruby\n\n\n    Gem files will remain installed in /home/git/gitlab/vendor/bundle/ruby/2.0.0/gems/rugged-0.21.2 for inspection.\n    Results logged to /home/git/gitlab/vendor/bundle/ruby/2.0.0/gems/rugged-0.21.2/ext/rugged/gem_make.out\n    An error occurred while installing rugged (0.21.2), and Bundler cannot continue.\n    Make sure that `gem install rugged -v '0.21.2'` succeeds before bundling.\n\nSo I installed rugged -> I installed CMake & config-pkg :\n/home/git/gitlab$ sudo gem install rugged\nBuilding native extensions.  This could take a while...\nSuccessfully installed rugged-0.21.2\nParsing documentation for rugged-0.21.2\nunable to convert \"\\xC0\" from ASCII-8BIT to UTF-8 for lib/rugged/rugged.so, skipping\n1 gem installed\n\nBut it doesnt change anything : \nErrno::EACCES: Permission denied - /home/git/gitlab/vendor/bundle/ruby/2.0.0/gems/rugged-0.21.2/LICENSE\nAn error occurred while installing rugged (0.21.2), and Bundler cannot continue.\nMake sure that `gem install rugged -v '0.21.2'` succeeds before bundling.\n\nAny idea ?"}, {"role": "assistant", "content": "For OSX if you're using homebrew:  \nbrew install cmake \nbundle install"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Git - What is \"Refspec\"\n\nI've been following this guide on configuring GitLab continuous integration with Jenkins.\nAs part of the process, it is necessary to set the refspec as follows: +refs/heads/*:refs/remotes/origin/* +refs/merge-requests/*/head:refs/remotes/origin/merge-requests/*\nWhy this is necessary is not explained in the post, so I began looking online for an explanation and looked at the official documentation as well as some related StackOverflow questions like this one.\nIn spite of this, I'm still confused:\nWhat exactly is refspec? And why is the above refspec necessary \u2013 what does it do?"}, {"role": "assistant", "content": "A refspec tells git how to map references from a remote to the local repo.\nThe value you listed was +refs/heads/*:refs/remotes/origin/* +refs/merge-requests/*/head:refs/remotes/origin/merge-requests/*; so let's break that down.\nYou have two patterns with a space between them; this just means you're giving multiple rules.  (The pro git book refers to this as two refspecs; which is probably technically more correct. However, you just about always have the ability to list multiple refspecs if you need to, so in day to day life it likely makes little difference.)\nThe first pattern, then, is +refs/heads/*:refs/remotes/origin/* which has three parts:\n\nThe + means to apply the rule without failure even if doing so would move a target ref in a non-fast-forward manner.  I'll come back to that.\nThe part before the : (but after the + if there is one) is the \"source\" pattern.  That's refs/heads/*, meaning this rule applies to any remote reference under refs/heads (meaning, branches).\nThe part after the : is the \"destination\" pattern. That's refs/remotes/origin/*.\n\nSo if the origin has a branch master, represented as refs/heads/master, this will create a remote branch reference origin/master represented as refs/remotes/origin/master.  And so on for any branch name (*).\nSo back to that +... suppose the origin has\nA --- B <--(master)\n\nYou fetch and, applying that refspec you get\nA --- B <--(origin/master)\n\n(If you applied typical tracking rules and did a pull you also have master pointed at B.)  \nA --- B <--(origin/master)(master)\n\nNow some things happen on the remote.  Someone maybe did a reset that erased B, then committed C, then forced a push.  So the remote says\nA --- C <--(master)\n\nWhen you fetch, you get\nA --- B\n \\\n  C\n\nand git must decide whether to allow the move of origin/master from B to C.  By default it wouldn't allow this because it's not a fast-forward (it would tell you it rejected the pull for that ref), but because the rule starts with + it will accept it.  \nA --- B <--(master)\n \\\n  C <--(origin/master)\n\n(A pull will in this case result in a merge commit.)\nThe second pattern is similar, but for merge-requests refs (which I assume is related to your server's implementation of PR's; I'm not familiar with it).\nMore about refspecs:  https://git-scm.com/book/en/v2/Git-Internals-The-Refspec"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to give user level access to private GitLab repository?\n\nI have a private repository in GitLab. I have to give its access to members of my team. How can I do that using GitLab web-interface?\nI know, how to do this in GitHub, but in GitLab it's somehow different."}, {"role": "assistant", "content": "Update 2021: This answer is out of date, scroll down for the 2021 info.\nUPDATE: Gitlab has changed a bit in 2 years, so here is the updated flow.\n\nClick on the project that you want to share.\nClick on the Settings tab (the gear icon on the left).\nClick on the Members subtab.\nAdd member, and find the user if it exists on GitLab, or insert\nemail to send an invitation.\nSelect access level for the user, the possible levels are:\n\n\nGuest, can see wiki pages, view and create issues.\nReporter, can do what the guest can plus view the code.\nDeveloper, normal developer access, can develop, but cannot push or merge to procted branches by default.\nMaintainer, can do everything except managing the project.\n\n\nFor more info about the user access level refer to gitlab official help.\n(Optional) Set expiration date of the user access.\n\n\nOld instructions:\n\nClick on the project that you want to share.\nClick on members.\nAdd member, and find the user if it exists on GitLab, or insert\nemail to send an invitation."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "git push all branches from one remote to another remote\n\nI have two remote: upstream and origin. upstream is something I can't push to. origin is my own repo. How can I fetch all branches from upstream and then push them to origin?\nI tried:\ngit fetch upstream\ngit push --all origin\n\nBut it doesn't work."}, {"role": "assistant", "content": "I just needed to copy one repository from Bitbucket to GitHub, these are the steps assuming your remote is called origin, all branches and tags will be copied:\ngit remote add neworigin url-to-new-remote\ngit push neworigin --tags \"refs/remotes/origin/*:refs/heads/*\"\n\nGood thing about this is that files in your working copy won't be modified."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab-runner local build - login from non TTY device\n\nI'm trying to build my project locally using gitlab-runner on Linux. \ndocker-build:\n  stage: build\n  image: docker:latest\n  script:\n    - docker login -u \"gitlab-ci-token\" -p \"$CI_JOB_TOKEN\" $CI_REGISTRY # user \"gitlab-ci-token\" is automatically created by GitLab\n    - docker build -t \"$CI_REGISTRY_IMAGE:$CI_COMMIT_REF_NAME\" target/\n    - docker push \"$CI_REGISTRY_IMAGE:$CI_COMMIT_REF_NAME\"\n\nUnfortunately my attempts end with error about \"docker login\" not being able to perform interactive login from non-TTY device.\n$ gitlab-ci-multi-runner exec docker --docker-privileged docker-build\nRunning with gitlab-ci-multi-runner 1.11.1 (a67a225)\n  on  ()\nUsing Docker executor with image docker:latest ...\nStarting service docker:dind ...\nPulling docker image docker:dind ...\nWaiting for services to be up and running...\nPulling docker image docker:latest ...\nRunning on runner--project-1-concurrent-0 via vanqyard...\nCloning repository...\nCloning into '/builds/project-1'...\ndone.\nChecking out 70187b2d as docker-basic-conf...\nSkipping Git submodules setup\nChecking cache for docker-build/docker-basic-conf...\nSuccessfully extracted cache\n$ docker login -u \"gitlab-ci-token\" -p \"$CI_JOB_TOKEN\" $CI_REGISTRY\nError: Cannot perform an interactive login from a non TTY device\nERROR: Job failed: exit code 1\nFATAL: exit code 1 \n\nMy question is has anybody stumbled upon this issue and how to succesfunlly perform build?"}, {"role": "assistant", "content": "Probably not linked to the problem here, but some people might encounter the exact same message when trying a docker login from a Linux like terminal on Windows such as Git bash or Docker quickstart terminal or even Cygwin.\nThe trick here is to use winpty docker login"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to change the project owner in GitLab\n\nHow can I change the project owner in GitLab?\nThere are options in project settings, but in the \"transfer\" field, it does not recognize any username or anything. Is it possible to change the owner-permissions and root-privileges?"}, {"role": "assistant", "content": "TL;DR\nMove your project to a new group where both you and the other user are owners, then the other user must transfer it to his own namespace.\nBackground\nThe other answers obviously do not work to transfer a project to a different user, although the comments section of one is enough for someone to figure it out. Also there is this issue on GitLab itself that provides some insights.\nMy Situation\nI installed and now administer a few instances of GitLab for a few small developer teams as well as one for my personal projects. Resultingly, I have run into numerous questions about this. I keep coming back to this question only to realize that it was never actually answered correctly.\nThe Namespace Problem\nThe issue that you face when doing this is that there can only be one owner of a project, but to transfer a project you have to own the namespace that you are transferring it to. To my knowledge there is no other way to move a project. For completeness, I'll add that the namespace here is, e.g., \"gitlab.com/my-user-name/...\" or \"gitlab.com/my-group-name/...\".\n\nSolution\nBecause one user cannot \"own\" another namespace (not even admins), the only option to set up a scenario where two users own the same namespace is with a group. Perform the following steps to accomplish this.\n\nCreate a new group.\nAdd the user that you want to transfer your project to as an owner member of that group.\nTransfer your project to that group (a namespace you manage because you are an owner).\nLogin as the other user, then transfer the group project to the \"other user\" namespace.\n\nAt this point you will be left as a master in the project. You can now remove yourself from the project entirely if desired."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Does GitHub for Windows work with GitLab?\n\nWhile working on a project using GitHub I've fallen in love with GitHub for Windows as a client. Now a new project beckons where I'll be using GitLab instead of GitHub.\nWill I still be able to use GitHub for Windows as a client for GitLab? After all, they're both based on git, right? If not, what clients are available for GitLab?"}, {"role": "assistant", "content": "Yes, you can use the Windows GitHub client and the GitHub Desktop client with GitLab, BitBucket or any other hosted Git solution. \nWe only use it with HTTPS and you'll need a valid certificate if you do use HTTPS. It may work with HTTP as well. We never did get SSH to work completely right since it's a tough to inject your own SSH keys into the application.\nIf you want to clone a repository, you have to drag and drop the HTTP URL onto the GitHub application. \nI was unable to get the drag and drop trick to work on OS X. But you can add locally cloned repositories into the OSX version and then the application works like normal. And OSX supports SSH keys unlike the Windows version."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to set up a code review using Gitlab?\n\nHow does one set up a code review using Gitlab?  I see it listed as a feature on the Gitlab website, but I can't seem to find instructions on how to set one up (For that matter, any link to a Gitlab user manual would be most appreciated).  \nSome of my searching has indicated that 'Merge Requests' are the way to go... but I'm finding them limiting.  An issued merge request shows all of the commits between one branch and the other.  I seem to only be able to view diffs generated for each individual commit.  For example, let's say I have a file I want to review.  It is a new file but I've submitted changes to it over 10 commits on a dev branch.  If I issue a merge request for that dev branch from integration I see 10 commits each of which show the incremental changes made to the file... I want to review the entire thing.  It is new!  \nAm I barking up the wrong tree here?  Is there an actual code-review tool I can use in GitLab, or are merge requests the way to go, and if they are am I using them incorrectly?  what's the best way to set up a proper code review here?"}, {"role": "assistant", "content": "Note: since GitLab 6.4, side-by-side diff view is available: see \"pull request 5308\".\n(July 2013)There is no possibility yet to comment on each line though, only at the file level.\nDaniel Sokolowski mentions in the comments that Per line comments are now supported (09/2014):\n\nYour team members can comment on the merge request in general or on specific lines with line comments.\n\nThat still can help for code review activity.\n\n\n6 years later, for GitLab 13.1 (June 2020):\n\nMerge Request Reviews moved to Core\n\n\nOriginally introduced in GitLab 11.4 as a GitLab Premium feature, Merge Request Reviews allow merge request reviewers to:\n\nsubmit multiple comments at once,\ncutting down on notification noise for the merge request author, and\nallowing for a more cohesive and streamlined review process.\n\n\n\n\nSince its introduction, we\u2019ve re-evaluated its place in our buyer-based pricing model and as part of 13.1 we\u2019re excited to announce this feature has now moved to GitLab Core.\n\nSee Documentation and Issue\n\nWith GitLab 13.9 (February 2021), you also have:\n\nRequest a follow-up review from a Reviewer\nMerge request authors receive feedback from reviewers. Often, this feedback needs to be re-reviewed to make sure all issues have been appropriately addressed. As the author of the contribution, you need to communicate the need for a follow-up to your reviewer.\nFor reviewers who have already reviewed a merge request, you can now request a re-review. This request triggers a To-Do item and email notification to alert the user that you need a follow-up review of your contribution.\n\nSee Documentation and Issue.\n\n\nWith GitLab 13.11 (April 2021)\n\nAdd standalone comments to merge request reviews\nWhen you\u2019re reviewing changes, you may want to summarize your feedback, or comment on something unrelated to the specific changes. Reviews in GitLab only allowed commenting on the changes or replying to existing comments, which meant that other kinds of comments had to be made after submitting the review.\nAs part of your review process, you can now submit a general comment along with your replies or change-specific comments. General comments make it simple to provide feedback to the author and use quick actions to update items across the merge request.\nThanks to Lee Tickett for the contribution!\n\nSee Documentation and Issue."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to store releases/binaries in GitLab?\n\nI am building a workflow with Gitlab, Jenkins and - probably - Nexus (I need an artifact storage). I would like to have GitLab to store releases/binaries - is it possible in a convenient way?\nI would not like to have another service from which a release (and documentation) could be downloaded but to have it somehow integrated with repository manager, just like releases are handled in e.g. GitHub. Any clues?"}, {"role": "assistant", "content": "Update Oct. 2020:\nGitLab 13.5 now offers:\n\nAttach binary assets to Releases\nIf you aren\u2019t currently using GitLab for your releases because you can\u2019t attach binaries to releases, your workflow just got a lot simpler.\nYou now have the ability to attach binaries to a release tag from the gitlab.ci-yml. This extends support of Release Assets to include binaries, rather than just asset links or source code. This makes it even easier for your development teams to adopt GitLab and use it to automate your release process.\n\nSee Documentation and Issue.\n\n\nUpdate Nov. 2015: GitLab 8.2 now supports releases.\nWith its API, you now can create and update a relase associated to a tag.\nFor now, it is only the ability to add release notes (markdown text and attachments) to git tags (aka Releases).\n\nfirst upload the release binary\ncreate a new release and place a link to the uploaded binary in the description\n\nUpdate May 2019: GitLab 1.11 introduces an interesting \"Guest access to Releases\":\n\nIt is now possible for guest users of your projects to view releases that you have published on the Releases page.\nThey will be able to download your published artifacts, but are not allowed to download the source code nor see repository information such as tags and commits.\n\n\nOriginal answer March 2015\nThis is in progress, and suggested in suggestions 4156755:\n\nWe\u2019re accepting merge requests for the minimal proposal by Ciro:\n\n\n\nFor each repository tag under https://github.com/cirosantilli/test/releases/tag/3.0, allow to upload and download a list of files.\n2. The upload and download can be done directly from the tag list view.\n3. If a tag gets removed, the uploads are destroyed.\n(we\u2019re not accepting the tag message edit mentioned in recent comments)\n\n\n\nThe comments to that suggestion include:\n\nWhat makes it more interesting is the next step.\nI would really like a way to let public download artifacts from \"releases\" without being able to access source code (i.e. make sources private for project team only except anything else like wiki, \"releases\", issue tracker).\n\n\nHowever, such additional feature looks more generic and I submitted a separate feature request for that.\n\n\nNevertheless, I repeat my point here:\nWhile the simplistic version of \"releases\" is still nice to have, many people can easily set up external file server and point URLs in release/tag description to this server outside GitLab.\nIn other words, \"releases\" may not look attractive now without some future picture of integration."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab-ci SSH key invalid format\n\nI would like run deploy script with gitlab-ci, but step ssh-add $SSH_PRIVATE_KEY return an error :\necho \"$SSH_PRIVATE_KEY\" | ssh-add -\nError loading key \"(stdin)\": invalid format\n\nYou can see my .gitlab-ci.yml :\ndeploy:\n  image: node:9.11.1-alpine\n  stage: deploy\n  before_script:\n    # Install ssh-agent if not already installed, it is required by Docker.\n    # (change apt-get to yum if you use a CentOS-based image)\n    - 'which ssh-agent || ( apk add --update openssh )'\n\n    # Add bash\n    - apk add --update bash\n\n    # Add git\n    - apk add --update git\n\n    # Run ssh-agent (inside the build environment)\n    - eval $(ssh-agent -s)\n\n    # Add the SSH key stored in SSH_PRIVATE_KEY variable to the agent store\n    - echo \"$SSH_PRIVATE_KEY\"\n    - echo \"$SSH_PRIVATE_KEY\" | ssh-add -\n\n    # For Docker builds disable host key checking. Be aware that by adding that\n    # you are suspectible to man-in-the-middle attacks.\n    # WARNING: Use this only with the Docker executor, if you use it with shell\n    # you will overwrite your user's SSH config.\n    - mkdir -p ~/.ssh\n    - '[[ -f /.dockerenv ]] && echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" > ~/.ssh/config'\n    # In order to properly check the server's host key, assuming you created the\n    # SSH_SERVER_HOSTKEYS variable previously, uncomment the following two lines\n    # instead.\n    # - mkdir -p ~/.ssh\n    # - '[[ -f /.dockerenv ]] && echo \"$SSH_SERVER_HOSTKEYS\" > ~/.ssh/known_hosts'\n  script:\n    - npm i -g pm2\n    - pm2 deploy ecosystem.config.js production\n  # only:\n  # - master\n\nOn my project setting, i've been add SSH_PRIVATE_KEY variable, with the id_rsa from my production server cat ~/.ssh/id_rsa.pub.\nAnyone can help me ?"}, {"role": "assistant", "content": "In my case, it was because I had made my SSH_PRIVATE_KEY variable protected. When I disabled the Protected state, it worked without any error."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Moving an existing GitLab project into a new subgroup\n\nJust started out using self hosted GitLab... it looks like it's going to be really useful moving towards a DevOps workflow.\nAnyway, after migrating about 20 local Git repositories to the new GitLab server, neatly arranged into 4 groups. I then noticed you can actually have sub-groups within the groups. This would help organisation even further, but I'm struggling to work out how to move the existing projects I've spent a day importing and configuring into a newly created sub-group. Sure I could just create a new project and copy the files over and commit them into the new project, and spend the time reconfiguring the project.\nIs there an easy way of moving the existing configured Project from the group into the new subgroup?"}, {"role": "assistant", "content": "Turns out the \"slug\" for a project... the part of the URL after the GitLab server domain name is made up of the \"namespace\" and the project name. The name space is the group/subgroup path, so I was looking to transfer project to new namespace.\nSo for example if the group is \"important-group\" and project is called \"project\". Then the slug will be something like /important-group/project. To then move that to /important-group/sub-group/project, we need to create the new subgroup (down arrow next to the \"New project\" button). Then change the project namespace.\nTo do this, go to the project page, click the settings button (cog bottom left). Go to the Advanced settings section. And it's just below the rename project option.\nnote: you need to have \"owner\" privileges on the project otherwise the settings don't appear... maintainer or developer is not enough.\n\nJust select the new subgroup and your done!\nHere is the GitLab docs link with more info on managing projects in GitLab, in case that is useful to anyone."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to quickly disable / enable stages in Gitlab CI\n\nWhen you work on your .gitlab-ci.yml for a big project, for example having a time consuming testing stage causes a lot of delay. Is there an easy way to disable that stage, as just removing it from the stages definition, will make the YAML invalid from Gitlab's point of view (since there's a defined but unused stage), and in my case results in:\ntest job: chosen stage does not exist; available stages are .pre, build, deploy, .post\n\nSince YAML does not support block comments, you'd need to comment out every line of the offending stage.\nAre there quicker ways?"}, {"role": "assistant", "content": "You could disable all the jobs from your stage using this trick of starting the job name with a dot ('.'). See https://docs.gitlab.com/ee/ci/jobs/index.html#hide-jobs for more details.\n.hidden_job:\n  script:\n    - run test"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to create a GitLab merge request via command line\n\nWe are working on integrating GitLab (enterprise edition) in our tooling, but one thing that is still on our wishlist is to create a merge request in GitLab via a command line (or batchfile or similar, for that matter). We would like to integrate this in our tooling. Searching here and on the web lead me to believe that this is not possible with native GitLab, but that we need additional tooling for that. \nAm I correct? And what kind of tooling would I want to use for this?"}, {"role": "assistant", "content": "As of GitLab 11.10, if you're using git 2.10 or newer, you can automatically create a merge request from the command line like this:\ngit push -o merge_request.create\n\nMore information can be found in the docs."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Delete commit on gitlab\n\nHow can I delete a commit that I made on GitLab? This commit that I made is not the HEAD now. \nIf I can't delete it, can I edit? \nWhen it was the HEAD, I tried:\ngit reset  --soft HEAD\n\ngit reset  --soft HEAD^1\n\ngit revert HEAD\n\ngit rebase -i HEAD\n\ngit rebase -i HEAD~1\n\ngit reset --hard HEAD\n\ngit reset --hard Id-Code\n\nI already tried to rebase it, but it still stays on the branch. Now I just removed it from the HEAD, but it is still there.\nThere is another command?"}, {"role": "assistant", "content": "git reset --hard CommitId\ngit push -f origin master\n\n1st command will rest your head to commitid and 2nd command will delete all commit after that commit id on master branch.\n\nNote: Don't forget to add -f in push otherwise it will be rejected."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Mirroring from GitLab to GitHub\n\nI have been using a private GitLab instance to hold all my code. But since most of the staff that work with me now have a GitHub account, i would really like to get moving and mirror my Gitlab repo to Github.\nMy situation:\n\na server running Gitlab (Omnibus)\na Github account for which I'll create an organization for where me and my staff can be organized together.\n\nI know that there is the --mirror switch in git, but I am not really sure how this is ment to work. Documentation I found online was very wonky... So it would be nice if someone could help me out. :)"}, {"role": "assistant", "content": "GitLab has now an option to do this from the UI, go to the Settings->Repository of your repo:\nhttps://gitlab.com/yourUserNameInGitLab/yourRepoName/settings/repository\nThen find the option \"Mirror a repository\" and click on expand. What you want to do is choose the \"Push\" mirror direction and fill this URL:\nhttps://[email\u00a0protected]/yourUserNameInGitHub/yourRepoName.git\nIn the password field, you have to use a Personal Access Token (as GitHub has deprecated password access now), which you can generate here: https://github.com/settings/tokens (don't forget to enable the \"repo\" and \"workflow\" permissions when generating it)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to fix \"Filename too long error\" during git clone\n\nI am trying to take a git clone from a particular branch of my bitbucket repository using the below command:\ngit clone <url> --branch <branchname>.\nHowever, I am getting the below error while taking the clone:\n\nerror:unable to create file foldername/nodemodules/......: Filename\n  too long.\n\nI tried resolving this by running the below command in my git cmd\ngit config --system core.longpaths true.\nBut I am getting:\n\nerror: could not lock config file c://.gitconfig: Permission denied\n  error: could not lock config file c://.gitconfig: Invalid argument.\n\nHow do I solve these two errors?"}, {"role": "assistant", "content": "Start Git Bash as Administrator\nRun command git config --system core.longpaths true\n\nAnother way (only for this clone):\ngit clone -c core.longpaths=true <repo-url>"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI/CD: Run jobs only when files in a specific directory have changed\n\nI would like to run specific jobs on the .gitlab-ci.yaml if and only if files within specific directories of the repository have changed. Is there a way to do this with gilab's ci/cd tooling or would it be easier just to run a custom build script?"}, {"role": "assistant", "content": "Changes policy introduced in GitLab 11.4.\nFor example:\ndocker build:\n  script: docker build -t my-image:$CI_COMMIT_REF_SLUG .\n  only:\n    changes:\n      - Dockerfile\n      - docker/scripts/*\n      - dockerfiles/**/*\n      - more_scripts/*.{rb,py,sh}\n\nIn the scenario above, if you are pushing multiple commits to GitLab to an existing branch, GitLab creates and triggers the docker build job, provided that one of the commits contains changes to either:\n\nThe Dockerfile file.\nAny of the files inside docker/scripts/ directory.\nAny of the files and subdirectories inside the dockerfiles directory.\nAny of the files with rb, py, sh extensions inside the more_scripts directory.\n\nYou can read more in the documentation and with some more examples."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to checkout merge request locally, and create new local branch?\n\nI have GitLab repository there and I need to test every merge request locally, before merging to the target branch. \nHow can I pull/fetch merge request as a new branch?"}, {"role": "assistant", "content": "Pull merge request to new branch \ngit fetch origin merge-requests/REQUESTID/head:BRANCHNAME\ni.e \ngit fetch origin merge-requests/10/head:file_upload\nCheckout to newly created branch\ngit checkout BRANCHNAME\ni.e (git checkout file_upload)\n\nOR with single command \ngit fetch origin merge-requests/REQUESTID/head:BRANCHNAME && git checkout BRANCHNAME\ni.e \ngit fetch origin merge-requests/18/head:file_upload && git checkout file_upload"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI - How to trigger a build only if changes happen on particular set of files\n\nIn Gitlab CI, how do you trigger a build only if changes happen on particular set of files?\nIs there a way to either include or exclude certain files from triggering a build? For eg: updating README.md, .gitignore files should not cause a build to trigger."}, {"role": "assistant", "content": "UPDATE 2\nOnly/except seem to be an unstable feature. The doc recommends using rules:changes instead:\njob:\n  script:\n    - build # replace with your build command\n  rules:\n    - changes:\n      - /*.{java, py} # ... or whatever your file extension is\n      - dockerfiles/**/* # all files under folder 'dockerfiles'\n\nUPDATE 1:\nLike Gajus mentioned in the comments, it is now possible!\nMerge Request: https://gitlab.com/gitlab-org/gitlab-ce/merge_requests/21981\nDocumentation: https://docs.gitlab.com/ee/ci/yaml/#onlyexcept-basic (Thanks to Connor Shea for the tip in the comments)\nOriginal post:\nNo, it is not possible \u2013 not now!\nI think this is the issue you are looking for: https://gitlab.com/gitlab-org/gitlab-ce/issues/19232 \u2013 It is a very high rated issue (over 100 thumps-up).\nThe milestone has changed to Next 3-6 months, 4 months ago. (https://gitlab.com/gitlab-org/gitlab-ce/issues/19232#note_31943850)\nI hope we will see this function soon."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "change the data directory gitlab to store repos elsewhere\n\nmy basic disk is full for my gitlab installation, is it possible to move the repositories and their data to some other folder and make sure that the upcoming push's data is sent to those directories?\nI tried stopping the gitlab and copying over the entire folder, but to no avail.\nPS - I am not an IT guy, I am just pitching in to see how could we get out of this issue; so please be verbose when answering."}, {"role": "assistant", "content": "Just updating in case people still refer to this. From the GitLab documentation:\n\nBy default, omnibus-gitlab stores the Git repository data under\n  /var/opt/gitlab/git-data. The repositories are stored in a subfolder\n  repositories. You can change the location of the git-data parent\n  directory by adding the following line to /etc/gitlab/gitlab.rb.\ngit_data_dirs({\"default\" => \"/mnt/nas/git-data\"})\n\nStarting from GitLab 8.10 you can also add more than one git data\n  directory by adding the following lines to /etc/gitlab/gitlab.rb\n  instead.\ngit_data_dirs({\n  \"default\" => \"/var/opt/gitlab/git-data\",\n  \"alternative\" => \"/mnt/nas/git-data\"\n})\n\nNote that the target directories and any of its subpaths must not be a\n  symlink.\nRun sudo gitlab-ctl reconfigure for the changes to take effect.\nIf you already have existing Git repositories in\n  /var/opt/gitlab/git-data you can move them to the new location as\n  follows:\n# Prevent users from writing to the repositories while you move them.\nsudo gitlab-ctl stop\n\n# Note there is _no_ slash behind 'repositories', but there _is_ a\n# slash behind 'git-data'.\nsudo rsync -av /var/opt/gitlab/git-data/repositories /mnt/nas/git-data/\n\n# Fix permissions if necessary\nsudo gitlab-ctl reconfigure\n\n# Double-check directory layout in /mnt/nas/git-data. Expected output:\n# gitlab-satellites  repositories\nsudo ls /mnt/nas/git-data/\n\n# Done! Start GitLab and verify that you can browse through the repositories in\n# the web interface.\nsudo gitlab-ctl start"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Understanding Gitlab CI tags\n\nI've read documentation, some articles and you might call me dumb, but this is my first time working with a concept like this.\n\nI've registered runner with tag \"testing\"\ncreated tag \"testing\" in gitlab\nbinded this runner, with  particular project \nI've also added the same tag e.g. \"testing\"in my local repo. \n\nBUT how exactly is running my jobs dependent on those tags? Are all these operations necessary? If I push new code to repo, *.yml file is executed anyway as far as I tested.\nSo what if I want to run build only when I define a version in a commit?\nIDK...\n   git commit --tags \"v. 2.0\" -m \"this is version 2.0\" (probably not right)\n\nBut of course it should be universal, so I don't have to always tell, which tag to use to trigger the runner, but for example let him recognize numeric values.\nAs you can see, I'm fairly confused... If you could elaborate how exactly tags work, so I would be able to understand the concept, I would be really grateful."}, {"role": "assistant", "content": "Tags for GitLab CI and tags for Git are two different concepts.\nWhen you write your .gitlab-ci.yml, you can specify some jobs with the tag testing.  If a runner with this tag associated is available, it will pickup the job.\nIn Git, within your repository, tags are used to mark a specific commit.  It is often used to tag a version.\nThe two concepts can be mixed up when you use tags (in Git) to start your pipeline in GitLab CI.  In your .gitlab-ci.yml, you can specify the section only with tags.\nRefer to GitLab documentation for tags and only.\nAn example is when you push a tag with git:\n$ git tag -a 1.0.0 -m \"1.0.0\"\n$ git push origin 1.0.0\n\nAnd a job in .gitlab-ci.yml like this:\ncompile:\n    stage: build\n    only: [tags]\n    script:\n        - echo Working...\n    tags: [testing]    \n\nwould start using a runner with the testing tag.\nBy my understanding, what is missing in your steps is to specify the tag testing to your runner.  To do this, go in GitLab into your project.  Next to\nWiki, click on Settings.  Go to CI/CD Pipelines and there you have your runner(s).  Next to its Guid, click on the pen icon.  On next page the tags can be modified."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Getting GitLab CI to clone private repositories\n\nI have GitLab & GitLab CI set up to host and test some of my private repos. For my composer modules under this system, I have Satis set up to resolve my private packages.\nObviously these private packages require an ssh key to clone them, and I have this working in the terminal - I can run composer install and get these packages, so long as I have the key added with ssh-add in the shell.\nHowever, when running my tests in GitLab CI, if a project has any of these dependencies the tests will not complete as my GitLab instance needs authentication to get the deps (obviously), and the test fails saying Host key verification failed.\nMy question is how do I set this up so that when the runner runs the test it can authenticate to gitlab without a password? I have tried putting a password-less ssh-key in my runners ~/.ssh folder, however the build wont even add the key, \"eval ssh-agent -s\" followed by ssh-add seems to fail saying the agent isn't running..."}, {"role": "assistant", "content": "See also other solutions:\n\ngit submodule permission (see Marco A.'s answer)\njob token and override repo in git config (see a544jh's answer)\n\n\nHere a full howto with SSH keys:\nGeneral Design\n\ngenerating a pair of SSH keys\nadding the private one as a secure environment variable of your project\nmaking the private one available to your test scripts on GitLab-CI\nadding the public one as a deploy key on each of your private dependencies\n\nGenerating a pair of public and private SSH keys\nGenerate a pair of public and private SSH keys without passphrase:\nssh-keygen -b 4096 -C \"<name of your project>\" -N \"\" -f /tmp/name_of_your_project.key\n\nAdding the private SSH key to your project\nYou need to add the key as a secure environment variable to your project as\nfollowing:\n\nbrowse https://<gitlab_host>/<group>/<project_name>/variables\nclick on \"Add a variable\"\nfill the text field Key with SSH_PRIVATE_KEY\nfill the text field Value with the private SSH key itself\nclick on \"Save changes\"\n\nExposing the private SSH key to your test scripts\nIn order to make your private key available to your test scripts you need to add\nthe following to your .gitlab-ci.yml file:\nbefore_script:\n  # install ssh-agent\n  - 'which ssh-agent || ( apt-get update -y && apt-get install openssh-client -y )'\n  # run ssh-agent\n  - eval $(ssh-agent -s)\n  # add ssh key stored in SSH_PRIVATE_KEY variable to the agent store\n  - ssh-add <(echo \"$SSH_PRIVATE_KEY\")\n  # disable host key checking (NOTE: makes you susceptible to man-in-the-middle attacks)\n  # WARNING: use only in docker container, if you use it with shell you will overwrite your user's ssh config\n  - mkdir -p ~/.ssh\n  - echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" > ~/.ssh/config\n\nCode Snippet comes from GitLab documentation\nAdding the public SSH key as a deploy key to all your private dependencies\nYou need to register the public SSH key as deploy key to all your private\ndependencies as following:\n\nbrowse https://<gitlab_host>/<group>/<dependency_name>/deploy_keys\nclick on \"New deploy key\"\nfill the text field Title with the name of your project\nfill the text field Key with the public SSH key itself\nclick on \"Create deploy key\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to continue job even when script fails\n\nI have a job in my pipeline that has a script with two very important steps:\n\nmvn test to run JUnit tests against my code\njunit2html to convert the XML result of the tests to a HTML format (only possible way to see the results as my pipelines aren't done through MRs) that is uploaded to GitLab as an artifact\ndocker rm to destroy a container created earlier in the pipeline\n\nMy problem is that when my tests fail, the script stops immediately at mvn test, so the junit2html step is never reached, meaning the test results are never uploaded in the event of failure, and docker rm is never executed either, so the container remains and messes up subsequent pipelines as a result.\nWhat I want is to be able to keep a job going till the end even if the script fails at some point. Basically, the job should still count as failed in GitLab CI / CD, but its entire script should be executed. How can I configure this?"}, {"role": "assistant", "content": "In each step that you need to continue even if the step fails, you can add a flag to your .gitlab-ci.yml file in that step. For example:\n...\nUnit Tests:\n  stage: tests\n  only:\n    - branches\n  allow_failure: true\n  script:\n    - ...\n\nIt's that allow_failure: true flag that will continue the pipeline even if that specific step fails. Gitlab CI Documentation about allow_failure is here: https://docs.gitlab.com/ee/ci/yaml/#allow_failure\nUpdate from comments:\nIf you need the step to keep going after a failure, and be aware that something failed, this has worked well for me:\n./script_that_fails.sh || FAILED=true\n\nif [ $FAILED ]\n    then ./do_something.sh\nfi"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Fast-forward merge is not possible. To merge this request, first rebase locally\n\nRecently, I have created newbranch and created a merge request to Master branch. Before TeamLead accept merge request into Master branch another team member was committed another fix to the same branch(newbranch). After that I committed my local changes and pulled the changes in newbranch to local branch. And I pushed my local commit to newbranch\n\nMy TeamLead told me to rebase my branch to an earlier version.\nAnd resolve conflicts.\nI don't know what to do now. Any idea?"}, {"role": "assistant", "content": "Starting on your newBranch:\ngit checkout master to get back on the master branch\ngit pull origin master to get the most up-to-date version of the master branch\ngit checkout newBranch to get back on your newBranch\ngit rebase origin/master -i to perform an interactive rebase. The command will take you through and let you pick commits, rename them, squash them, etc. Assuming you will want to keep them all, it will pause when there are merge conflicts and then you'll have to resolve them in your text editor, it will tell you where (in your text editor) that the conflicts occur. You will have to add those files after fixing them then do git rebase --continue to proceed with the rebase.\nWhen you're done with the rebase your newBranch will be synced up with master and have any commits in master that weren't there when you started your work, and all merge conflicts will be resolved so that you can easily merge your newBranch."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Unable to push files to git due to: failed to push some refs\n\nI have a directory that i want to turn into a git project.\nI created a new project in gitlab and then i did the following:\ngit init\ngit remote add origin [email\u00a0protected]:a/b/c.git\ngit add .\ngit commit -m \"Initial commit\"\ngit push -u origin master\n\nIn addition, I created the following .gitignore file:\n*\n!*/scripts\n!*/jobs\n\nAfter running git push -u origin master i got the following error:\nCounting objects: 33165, done.\nDelta compression using up to 2 threads.\nCompressing objects: 100% (32577/32577), done.\nWriting objects: 100% (33165/33165), 359.84 MiB | 1.70 MiB/s, done.\nTotal 33165 (delta 21011), reused 0 (delta 0)\nremote: Resolving deltas: 100% (21011/21011), done.\nremote: GitLab: \nremote: A default branch (e.g. master) does not yet exist for a/b/c\nremote: Ask a project Owner or Maintainer to create a default branch:\nremote: \nremote:   https://gitlab.com/a/b/c/project_members\nremote: \nTo gitlab.com:a/b/c.git\n ! [remote rejected] master -> master (pre-receive hook declined)\nerror: failed to push some refs to '[email\u00a0protected]:a/b/c.git'\n\nWhat could be the issue?\nPlease advise"}, {"role": "assistant", "content": "This is linked to issue 27456 and merge request 6608:\n\ndocument the need to be owner or have the master permission level for the initial push \n\nSo it might be a permission level, not a branch issue.\nSee commit 81ee443:\n\nYou will need to be owner or have the master permission level for the initial push, as the master branch is automatically protected."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to connect local folder to Git repository and start making changes on branches?\n\nI'm new to source control; in the past, I've manually backed up copies of files and made changes on clones then transferred changes manually to master files once debugged. I realize this is similar to how branches work with Git repositories, however I've never used one.\nI downloaded Git and made an account on GitLab, and started a new project. My site is hosted on a local server and my files are saved locally. How do I connect these files to a Git repository and continue developing with branches?"}, {"role": "assistant", "content": "To register a project as a local Git repository the first thing you need to do is perform the following command at your project root:\ngit init\n\nThis will create a .git folder at your project root and will allow you to start using Git in that repository.\n\nIf you want to \"push\" your local Git repository to a remote Git server (in your case, to GitLab), you'll need to perform the following command first:\ngit remote add origin <Repository_Location>\n\nYou can call origin whatever you like, really, but origin is the standard name for Git remote repositories. <Repository_Location> is the URL to your remote repository. For example, if I had a new project called MyNewProject that I wanted to push to GitLab, I'd perform:\ngit remote add origin https://gitlab.com/Harmelodic/MyNewProject.git\n\nYou can then \"push\" your changes from your local machine to your remote repo using the following command:\ngit push origin <branch_name>\n\nwhere branch name is the name of the branch you want to push, e.g. master.\n\nYou can find a good beginners guide to Git here."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to use Go with a private GitLab repo\n\nGitLab is a free, open-source way to host private .git repositories but it does not seem to work with Go. When you create a project it generates a URL of the form:\n[email\u00a0protected]:private-developers/project.git\n\nwhere:\n\n1.2.3.4 is the IP address of the gitlab server\nprivate-developers is a user group which has access to the private repo\n\nGolang 1.2.1 doesn't seem to understand this syntax.\ngo get [email\u00a0protected]:private-developers/project.git\n\nresults in:\npackage [email\u00a0protected]/project.git: unrecognized import path \"[email\u00a0protected]/project.git\"\n\nIs there a way to get this to work?"}, {"role": "assistant", "content": "Run this command:\ngit config --global url.\"[email\u00a0protected]:\".insteadOf \"https://1.2.3.4/\"\n\nAssuming you have the correct privileges to git clone the repository, this will make go get work for all repos on server 1.2.3.4. \nI tested this with go version 1.6.2, 1.8, and 1.9.1."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to run Gitlab CI only for specific branches and tags?\n\nI would like to setup my project_dev CI only for 3 branches and specific kind of tags like: dev_1.0, dev_1.1, dev_1.2.\nHow can I achieve that?\nThis is what I have now:\n\nproject_dev:\n  stage: dev\n  script:\n    - export\n    - bundle exec pod repo update\n    - bundle exec pod install\n    - bundle exec fastlane crashlytics_project_dev\n  after_script:\n    - rm -rf ~/Library/Developer/Xcode/Archives || true\n  when: manual\n  only:\n    - develop\n    - release\n    - master\n    - //here I need to add condition to fire that stage additionally only for specific tags. How can I setup regexp here?\n  tags:\n    - iOS\n\nWhen I type it like:\n\n  only:\n    - branches\n    - /^dev_[0-9.]*$/\n\nIt also runs the CI for tags like: dev1.2 but it should not. Why? Is there a regexp for tags at all?"}, {"role": "assistant", "content": "Sounds like a regular expression question. I just created a project on gitlab.com for the regular expression.\nFile: .gitlab-ci.yml\nproject_dev:\n  # Irrelevant keys is skipped\n  script:\n    - echo \"Hello World\"\n  only:\n    - develop\n    - release\n    - master\n    - /^dev_[0-9]+(?:.[0-9]+)+$/ # regular expression\n\nI was pushed all of tags you mentioned to test this regular expression.\n\nAs you can see , It will match tags like dev_1.0, dev_1.1, but the job project_dev will not be triggered by tag dev1.2, You can check the result on pipeline pages"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Get Branch name in gitlab ci\n\nIn my Gitlab CI, I have a stage that triggers another stage by api call trigger and  I want to pass the current branch name as parameter to the other project holding the trigger. I used the CI_COMMIT_REF_NAME for this, it seemed to work, but now that I call the stage only when merging the branch to master, the CI_COMMIT_REF_NAME always says \"master\".\nIn the documentation it says \"The branch or tag name for which project is built\", do I understand it correctly that it kind of holds the target branch of my working branch?\nI tried to get the current branch in gitlab ci with git symbolic-ref HEAD | sed 's!refs\\/heads\\/!!' as well but it was empty.\nIs CI_COMMIT_REF_NAME the variable I am looking for and something is going wrong or do I need something else?\nThanks in advance."}, {"role": "assistant", "content": "I'm not sure what you mean by \u201ca stage that triggers another stage by api call trigger\u201d. But, generally speaking, GitLab CI jobs are part of a CI pipeline, and CI pipelines are created for a branch or tag.\nThe CI_COMMIT_REF_NAME variable contains the name of the branch or tag that the pipeline was created for.\nThe CI_MERGE_REQUEST_TARGET_BRANCH_NAME is \"The target branch name of the merge request.\"\nfrom GitLab Predefined Variables reference"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab git user password\n\nI have just installed GitLab.\nI created a project called project-x.\nI have created few users and assigned it to the project.\nNow I tried to clone:\n git clone [email\u00a0protected]:project-x.git\n\nIt prompted me for a password.\nWhat password should I use?"}, {"role": "assistant", "content": "Not strictly related to the current scenario. Sometimes when you are prompted for password, it is because you added the wrong* origin format (HTTPS instead of SSH)\nHTTP(S) protocol is commonly used for public repos with strong username+pass\nSSH authentication is more common for internal projects where you can authenticate with a ssh-key-file and simple pass-phrase\nGitLab users are more likely to use the SSH protocol\nView your remote info with \ngit remote -v\n\nIf you see HTTP(S) address, this is the command to change it to SSH:\ngit remote set-url origin [email\u00a0protected]_domain.com/example-project.git"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab repository mirroring\n\nIs it possible to have gitlab set up to automatically sync (mirror) a repository hosted at another location?\nAt the moment, the easiest way I know of doing this involves manually pushing to the two (gitlab and the other) repository, but this is time consuming and error prone.\nThe greatest problem is that a mirror can resynchronize if two users concurrently push changes to the two different repositories. The best method I can come up with to prevent this issue is to ensure users can only push to one of the repositories."}, {"role": "assistant", "content": "Update Dec 2016: Mirroring is suported with GitLAb EE 8.2+: see \"Repository mirroring\".\nAs commented by Xiaodong Qi:\n\nThis answer can be simplified without using any command lines (just set it up on Gitlab repo management interface)\n\n\nOriginal answer (January 2013)\nIf your remote mirror repo is a bare repo, then you can add a post-receive hook to your gitlab-managed repo, and push to your remote repo in it.\n#!/bin/bash\ngit push --mirror [email\u00a0protected]:/path/to/repo.git\n\nAs Gitolite (used by Gitlab) mentions:\n\nif you want to install a hook in only a few specific repositories, do it directly on the server.\n\nwhich would be in:\n~git/repositories/yourRepo.git/hook/post-receive\n\n\nCaveat (Update Ocotober 2014)\nCiro Santilli points out in the comments:\n\nToday (Q4 2014) this will fail because GitLab automatically symlinks github.com/gitlabhq/gitlab-shell/tree/\u2026 into every repository it manages.\n  So if you make this change, every repository you modify will try to push.\n  Not to mention possible conflicts when upgrading gitlab-shell, and that the current script is a ruby script, not bash (and you should not remove it!). \nYou could correct this by reading the current directory name and ensuring bijection between that and the remote, but I recommend people to stay far far away from those things\n\nSee (and vote for) feeadback \"Automatic push to remote mirror repo after push to GitLab Repo\".\n\nUpdate July 2016: I see this kind of feature added for GitLab EE (Enterprise Edition): MR 249\n\nAdd ability to enter remote push URL under Mirror Repository settings\nAdd implementation code to push to remote repository\nAdd new background worker\nShow latest update date and sync errors if they exists.\nSync remote mirror every hour.\n\nNote that the recent Remote Mirror Repository (issues 17940) can be tricky:\n\nI'm currently trying to shift main development of the Open Source npm modules of my company Lossless GmbH (https://www.npmjs.com/~lossless) from GitHub.com to GitLab.com\nI'm importing all the repos from GitHub, however when I try to switch off Mirror Repository and switch on Remote Mirror Repository with the original GitHub URL I get an error saying: \n\nRemote mirrors url is already in use\n\nHere is one of the repos this fails with: https://gitlab.com/pushrocks/npmts\nEdited 2 months ago\n\nturns out, it just requires multiple steps:\n\ndisable the Mirror Repository\npress save\nremove the URl\npress save\nthen add the Remote Mirror"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab ci: Run build job when manual or when master only\n\nIs it possible to have a gitlab-ci file wheres a build job defined with the following requirements:\n\nget executed when manual\nOR\nget executed by master push\n\nI thought of something like this, but this is poorly false:\nbuild_jar:\nstage: build\nscript:\n  - echo \"build jar\"\nartifacts:\n  paths:\n    - jar/path/*.jar\nonly:\n  - master\nwhen: manual\n\nOnly solution for me is to have two jobs, one for the master push and one a manual input. But the disadvantage is, that in gitlab it becomes confusingly"}, {"role": "assistant", "content": "I also did not find a way to do this in one block and had to use yaml anchors and split into two separate blocks: \n.deploy_common:\n# common config HERE\n\ndeploy_master_CD:\n  extends: .deploy_common\n  only:\n    refs:\n      - master\n\ndeploy_manual:\n  extends: .deploy_common\n  when: manual\n\nOR all in one since GitLab 12.3 using rules\ndeploy:\n  rules:\n    - if: '$CI_COMMIT_REF_NAME == \"master\"'\n    - when: manual"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Search for code or text in GitLab\n\nIs it possible to search for code or text in GitLab inside of files? I can search for files, issues, milestones, etc., but could not find a way to search for code in source files or text in the documentation i.e .doc files."}, {"role": "assistant", "content": "We have a paid gitlab account such that our domain is gitlab.ourcompany.com - so this answer might not apply to all. There have been a few occassions where I needed to search for a \"string\" across all files in a Gitlab project, but there is no clear 'search' button. The search bar only searches for matching project names - so not what I was looking for. This method below is the easiest to use and easiest to remember.\n\nhttps://gitlab.xxxxx.com/search"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Creating a branch from issue in GitLab\n\nI've just started using GitLab, and have created a set of issues, in order to keep an overview of what needs to be done for my application. I was wondering if it was possible to create a branch from these issues, such that the branch and issues are linked, similar as in jira and Stash from atlassian?"}, {"role": "assistant", "content": "If you create a branch with the name <issue-number>-issue-description and push that branch to gitlab, it will automatically be linked to that issue. For instance, if you have an issue with id 654 and you create a branch with name 654-some-feature and push it to gitlab, it will be linked to issue 654.\nGitlab will even ask you if you want to create a merge request and will automatically add Closes #654 to the merge request description which will close issue 654 when the merge request is accepted.\nAlso if you go to a given issue page on gitlab, you should see a New Branch button which will automatically create a branch with a name of the form <issue-number>-issue-description."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to integrate sourcetree for gitlab\n\nI worked on github and integrated it to sourcetree (MAC version) for one of my project. I would like to use sourcetree for GITLAB. But I am not able to add remote of gitlab to source tree. In Repository settings, Only I can see host type as \"unknown\", \"bitbucket\", \"github\" & \"stash\". I used unknown but it won't help me.\nSourcetree Version 2.0.4 (2.0.4)"}, {"role": "assistant", "content": "This worked for me,\nStep 1: Click on + New Repository> Clone from URL\nStep 2: In Source URL provide URL followed by your user name,\nExample:\n\nGitLab Repo URL : http://git.zaid-labs.info/zaid/iosapp.git\nGitLab User Name : zaid.pathan\n\nSo final URL should be http://[email\u00a0protected]/zaid/iosapp.git\nNote: zaid.pathan@ added before git.\nStep 3: Enjoy cloning :)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is the difference between GitHub Flow and GitLab Flow?\n\nRecently I've found three concepts of a workflow in Git:\n\nGitFlow\nGitHub Flow\nGitLab Flow\n\nI've read the nice articles about it but I don't understand GitLab Flow very well.\nBriefly.\nGitFlow\n\nWe've a master branch as a production branch. Also we have a develop branch where every developer merges his features. Sometimes we create a release branch to deploy our features in production. If we have a bug in the release branch, fix it and pull changes into the develop branch. If we have a critical bug in production, create new hotfix-branch, fix the bug and merge branch with production (master) and develop branches.\nThis approach works well if we seldom publish results of our work. (Maybe once every 2 weeks).\nGitHub Flow\n\nWe have a master branch as a production branch. And we (as developers) can  create branches for adding new features or fixing bugs and merge them with production (master) branch. It sounds very simple. This approach fits for extreme programming where the production branch is deployed several times in a day.\nGitLab Flow\n\n\n\nI've seen new terms like a pre-production, a production, a release (stable) branch and a staging environment, a pre-production environment, a production environment. What relationships do they have between them?\nI understand it this way: If we need to add a new feature we deploy a pre-production branch from the master branch. When we have finished the feature, we deploy a production branch from the pre-production branch. A pre-production branch is the intermediate stage. And then the master branch pulls all changes from the production branch.\nThe approach is good if we want to see each separate feature; we just checkout in the branch what we need to look at.\nBut if we need to show our work we create a release branch with a tag as late as possible. If later we fix bugs in the master branch we need to cherry-pick them to the last release branch. At the end we have the release branch with tags that can help us to move between versions.\nIs my understanding correct?\nWhat is the difference between pull and cherry-pick?"}, {"role": "assistant", "content": "It has been a year now since this post was raised, but considering future readers and the fact things have changed a bit I think it's worth refreshing.\nGitHub Flow as originally depicted by Scott Chacon in 2011 assumed each change once reviewed on a feature branch and merged into master should be deployed to production immediately. While this worked at the time and conformed to the only GitHub Flow rule, which is anything in the master branch is deployable, it was quickly discovered that in order to keep master a true record of known working production code the actual deployment to production should happen from the feature branch before merging it into master. Deploying from the feature branch makes perfect sense as in the case of any issue production can be instantaneously reverted by deploying master to it. Please take a look at a short visual introduction to GitHub Flow.\nGitLab Flow is kind of an extension to GitHub Flow accompanied by a set of guidelines and best practices that aim to further standardize the process. Aside from promoting ready to deploy master branch and feature branches (same as GitHub Flow) it introduces three other kinds of branches:\n\nProduction branch\nEnvironment branches: uat, pre-production, production\nRelease branches: 1-5-stable, 1-6-stable\n\nI believe above names and examples are self-descriptive, thus I won't elaborate further."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Connecting to GitLab repositories on Android Studio\n\nI'm trying to connect to a GitLab repository using the I/O preview of Android Studio. Does anyone know how to do this/if it is possible yet?"}, {"role": "assistant", "content": "How to add an Android Studio project to GitLab\nThis answer shows how to do it using the Android Studio GUI.\n1. Create a new project on GitLab\nChose the + button on the menu bar. Add a project name and then click \"Create project\".\n\nThis will give you a new project address. Choose the https version.\n\nIt will look something like this:\nhttps://gitlab.com/MyUserName/my-project.git\n\n2. Create a Git repository in Android Studio\nIn the Android Studio menu go to VCS > Import into Version Control > Create Git Repository...\n\nSelect the root directory of your project. (It will be automatically selected if you already have it highlighted in the Project view. Otherwise you will have to browse up to find it.)\n3. Add remote\nGo to VCS > Git > Remotes.... Then paste in the https address you got from GitLab in step one.\n\nYou may need to log in with your GitLab username and password.\n4. Add, commit, and push your files\nMake sure you have the top level of the project selected. If you are in the Android view you can switch it to the Project view.\n\n\nAdd: Go to VCS > Git > Add.\nCommit: After adding, do VCS > Git > Commit Directory. (You will need to write a commit message, something like initial commit.)\nPush: Finally, go to  VCS > Git > Push.\n\nFinished!\nYou should be able to view your files in GitLab now.\nSee also\nThere is a plugin that would probably streamline the process. Check it out here."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Is it possible to use GitHub and GitLab on one machine?\n\nI have accounts in GitHub and GitLab. I generated and added an RSA key to my account in GitLab, but now I need to work with GitHub on a second project. \nI know that GitLab and GitHub both use git. Please tell me if it's possible to use GitHub and GitLab on one machine?"}, {"role": "assistant", "content": "Yes you can, you can share the same key between them both (ssh key) or create a new one per git server.\nCreate a SSH config file\n\nWhen you have multiple identity files(in your case one for gitlab and one for github) , create a SSH config file to store your various identities.\n\n\nThe format for the alias entries use in this example is:\n\n\nHost alias \n\n\n  HostName github.com \n  IdentityFile ~/.ssh/identity\n\n\nTo create a config file for two identities (workid and personalid), you would do the following:\n\nOpen a terminal window.\nEdit the ~/.ssh/config file. \n\nIf you don't have a config file, create one.\nAdd an alias for each identity combination for example:\nHost github\nHostName github.com \nIdentityFile ~/.ssh/github\n\nHost gitlab\nHostName gitlab.com \nIdentityFile ~/.ssh/gitlab\n\nThis way you can have as many accounts as you wish each one with a different ssh key attached to it."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "ssh: Could not resolve hostname git: Name or service not known fatal: Could not read from remote repository\n\nAfter I switched from HTTPS to SSH for my repo then I received this error when pushing to origin master:\nssh: Could not resolve hostname git: Name or service not known\nfatal: Could not read from remote repository.\n\nPlease make sure you have the correct access rights\nand the repository exists.\n\nI also add my ssh in the gitlab. What should I do?"}, {"role": "assistant", "content": "I was getting the same error.\n\nThis error typically occurs when there is an issue with the SSH configuration or the Git remote repository's hostname cannot be resolved.\n\nHere, you can check your remote by running:\ngit remote -v\n\nThere are few reasons why this error occurs:\n\nIncorrect Hostname\nSSH Configuration\nNetwork Connection\nDNS Resolution\nFirewall or Proxy\n\nTypically, you can solve this by Change the [remote \"origin\"] URL value in .gitconfig or .config/git/config file\nPreviously:\nhttps://[email\u00a0protected]:userName/repo.git\n\nOR\nssh://[email\u00a0protected]:userName/repo.git\n\nNew:\n[email\u00a0protected]:userName/repo.git"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "HTTP Basic: Access denied fatal: Authentication failed\n\nI use GitLab Community Edition 9.1.3 2e4e522 on Windows 10 Pro x64. With Git client.\nError\nCloning into 'project_name'...\nremote: HTTP Basic: Access denied\nfatal: Authentication failed for 'http://[email\u00a0protected]/my_user_name/project_name.git/'\n\nHow to fix it?"}, {"role": "assistant", "content": "Open CMD (Run as administrator)\ntype command:\ngit config --system --unset credential.helper\n\nthen enter new password for Git remote server."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I add a .env file in gitlab ci during deployment stage?\n\nSo I have a react/typescript app in my repo that I'm working on and in my repo I have a .env file that I'm ignoring so that my secrets don't get exposed and a .env-example file of important environment variables to configure. My problem is, since I'm not pushing the .env file to my repo, when I deploy my app through the google app engine(this is done in the deployment stage in my gitlab-ci.yml file), these environment variables will not be present in production and I need them for my app to work as I do something like this in my webpack.config.js file.\nconst dotenv = require('dotenv').config({ path: __dirname + '/.env' });\n\nand then\nnew webpack.DefinePlugin({\n  'process.env': dotenv.parsed\n})\n\nHere is my .gitlab-ci file for reference in case anyone here wants to see.\ncache:\n  paths:\n    - node_modules/\n\nstages:\n  - build\n  - test\n  - deploy\n\nBuild_Site:\n  image: node:8-alpine\n  stage: build\n  script:\n    - npm install --progress=false\n    - npm run-script build\n  artifacts:\n    expire_in: 1 week\n    paths:\n      - build\n\nRun_Tests:\n  image: node:8-alpine\n  stage: test\n  script:\n    - npm install --progress=false\n    - npm run-script test\n\nDeploy_Production:\n  image: google/cloud-sdk:latest\n  stage: deploy\n  environment: Production\n  only:\n    - master\n  script:\n    - echo $DEPLOY_KEY_FILE_PRODUCTION > /tmp/$CI_PIPELINE_ID.json\n    - gcloud auth activate-service-account --key-file /tmp/$CI_PIPELINE_ID.json\n    - gcloud config set project $PROJECT_ID_PRODUCTION\n    - gcloud info\n    - gcloud --quiet app deploy\n  after_script:\n    - rm /tmp/$CI_PIPELINE_ID.json\n\nAlso, feel free to critique my gitlab-ci.yml file so I can make it better."}, {"role": "assistant", "content": "I don't know if you still need this, but this is how I achieved, what you wanted to.\n\nCreate your environment variables in your gitlab repo config\nCreate setup_env.sh:\n\n#!/bin/bash\n\necho API_URL=$API_URL >> .env\necho NODE_ENV=$NODE_ENV >> .env\n\n\nModify your .gitlab-ci.yml. Upsert below to your before_script: section\n\n  - chmod +x ./setup_env.sh\n  - ./setup_env.sh\n\n\nIn webpack.config.js make use of https://www.npmjs.com/package/dotenv\n\nrequire('dotenv').config();\n\nThis passes your .env variables available in webpack.config.js file.\nAdd this to your plugins array (add those variables you need):\n    new webpack.DefinePlugin({\n      'process.env.API_URL': JSON.stringify(process.env.API_URL),\n      'process.env.NODE_ENV': JSON.stringify(process.env.NODE_ENV),\n      ...\n    })\n\nNow your deployment should use your environment variables specified in you gitlab settings."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Reference an issue from a commit message in gitlab\n\nIs it possible to make a reference to an issue in Gitlab from a commit message?\nI haven't found anything on the web."}, {"role": "assistant", "content": "There should be a way to reference a GitLab issue from a commit message, simply with #xx (id of the issue).\nConsider \"Default closing pattern value \"\n\nFor example the following commit message:\nAwesome commit message\n\nFix #20, Fixes #21 and Closes group/otherproject#22.\nThis commit is also related to #17 and fixes #18, #19\nand https://gitlab.example.com/group/otherproject/issues/23.\n\nwill close #18, #19, #20, and #21 in the project this commit is pushed to, as well as #22 and #23 in group/otherproject.\n#17 won't be closed as it does not match the pattern.\nIt works with multi-line commit messages as well as one-liners when used with git commit -m.\n\nSee also \"Tutorial: It's all connected in GitLab\"\n\nAdd references in issue or merge request descriptions or in comments.\nThis will update the issue with info about anything related.\n\nTo reference an issue: #123\nTo reference a MR: !123\nTo reference a snippet $123\n\n\n\npierreb adds in the comments:\n\nAlthough this is not specifically asked in the original question, it may be worth adding that one can also cross-reference a previous commit in a new commit message in Gitlab.\nYou do it by copying the hash from the commit message you want to reference and simply pasting it in the new commit message.\nSomething along these lines:\nThis is related with commit 7as7b101\n\n\nYou can see (much) more in:\n\n\"gitlab-ce issue 13345 'ability to reference a commit'\"\n\"Tutorial: It's all connected in GitLab\".\n\nandrybak adds in the comments:\n\n\n\"You do it by copying the hash from the commit message you want to reference and simply pasting it in the new commit message.\"\n\nThere is also a special, more human-readable format:\ngit log -1 --format=reference\n\n<abbrev-hash> (<title-line>, <short-author-date>)\n\nSee git log PRETTY FORMATS\n\n\nThis format is used to refer to another commit in a commit message and is the same as --pretty='format:%C(auto)%h (%s, %ad)'.\nBy default, the date is formatted with --date=short unless another --date option is explicitly specified.\nAs with any format: with format placeholders, its output is not affected by other options like --decorate and --walk-reflogs.\n\n\nFr0zenFyr adds in the comments:\n\nSimilarly, even a closed issue can be referenced like Related to #78 and #93."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is Gitlab's instance domain?\n\nI am trying to test to see if my SSH key was added correctly by following the instructions which are found halfway down the page here. \n\nTo test whether your SSH key was added correctly, run the following\n  command in your terminal (replacing gitlab.com with your GitLab's\n  instance domain):\n\nssh -T [email\u00a0protected]\n\nHowever, I have no idea what my \"Gitlab's instance domain\" is referring to. I have searched other online but I cannot find anything relevant."}, {"role": "assistant", "content": "If you're using Gitlab on gitlab.com then the domain is\u00a0gitlab.com, so you should run\u00a0 ssh -T [email\u00a0protected]"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI Pipeline on specific branch only\n\nI'm trying to implement GitLab CI Pipelines to build and deploy an Angular app. In our project we have two general branches: master (for production only) and develop. For development we create feature/some-feature branches from develop branch. When development finished, we create merge request from feature/some-feature to develop. When merge request approved and merged into develop branch I want to run a Pipeline in order to build application and deploy the build on some environment.\nI use the following setup in .gitlab-ci.yml:\nimage: node:7.5-configured\n\nstages:\n    - build\n    - deploy\n\nbuild_job:\n    stage: build\n    only:\n        - develop\n    script:\n        - /bin/bash <some script here>\n\n...\n\nThe problem is that Pipeline executed every time I push into any feature/some-feature branch. What's wrong with my setup? How can I force the Pipeline to be executed only when push performed into develop branch directly?\nSolution\nIt was my mistake - I had two different .gitlab-ci.yml files in develop branch and feature/some-feature branch."}, {"role": "assistant", "content": "Although it has been passed much time on this discussion I would like to suggest an opinion, which I am using most of the time.\nrules:\n    - if: '$CI_PIPELINE_SOURCE == \"push\" && $CI_COMMIT_BRANCH == \"master\"'\n      when: on_success\n      changes:\n        - folder/some_folder/**/* \n    - if: '$CI_PIPELINE_SOURCE == \"web\" && $CI_COMMIT_BRANCH == \"development\"'\n      when: manual\n      changes:\n        - folder/some_other_folder/**/* \n\nThis structure solved my various problems, I hope it helps you to!\nRegards."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Updating pull request after review changes commit doesn't show up in the pull request\n\nI forked a GitHub repository and made some changes on my fork and submited a pull request but the owners of the original GitHub repository asked for some changes which they asked me for in the pull request. I assumed that adding additional changes to my fork will cause them to show up in the current pull request but to my surprise I can't see my changes in the pull request.\nThis is what I did after generating the original pull request:\n\nmade code changes\nadd the files 1git add -A`\ncommit the files git commit -m \"these are my suggested changes in pull request\"\nsubmit my changes with git push\n\nI can see changes on my own fork but I don't understand why I can't see any changes in the pull request.\nDoes anyone know what I need to do for my changes to show up in the current pull request?\nI'd really appreciate your help."}, {"role": "assistant", "content": "First, make sure that you did push to the right branch and that the commit still doesn't show up in the PR. For me, the commit showed up when I viewed the specific branch in the repo, but didn't show in the PR and didn't trigger CI.\nThis is what fixed the issue for me:\n\nClick on Edit in the top right corner.\nClick on the base selector and choose the same base branch.\nGitHub will ask you whether you want to change base, confirm.\nThe PR should update and the commit should show up."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How can I clone a private GitLab repository?\n\nWhen I do this:\ngit clone https://example.com/root/test.git\n\nI am getting this error:\n\nfatal: HTTP request failed\n\nWhen I use SSH:\ngit clone username [email\u00a0protected]:root/test.git\n\nI am getting this error:\n\nInitialized empty Git repository in /server/user/[email\u00a0protected]:root/test.git/.git/ \n     fatal: 'user' does not appear to be a git repository \n     fatal: The remote end hung up unexpectedly\n\nIt's a private repository, and I have added my SSH keys."}, {"role": "assistant", "content": "It looks like there's not a straightforward solution for HTTPS-based cloning regarding GitLab. Therefore if you want a SSH-based cloning, you should take account these three forthcoming steps:\n\nCreate properly an SSH key using your email used to sign up. I would use the default filename to key for Windows. Don't forget to introduce a password! (tip: you can skip this step if you already have one ssh key here)\n $ ssh-keygen -t rsa -C \"[email\u00a0protected]\" -b 4096\n\n Generating public/private rsa key pair.\n Enter file in which to save the key ($PWD/.ssh/id_rsa): [\\n]\n Enter passphrase (empty for no passphrase):[your password]\n Enter same passphrase again: [your password]\n Your identification has been saved in $PWD/.ssh/id_rsa.\n Your public key has been saved in $PWD/.ssh/id_rsa.pub.\n\n\nCopy and paste all content from the recently id_rsa.pub generated into Setting>SSH keys>Key from your GitLab profile.\n # Copy to clipboard\n pbcopy < ~/.ssh/id_rsa.pub\n\n\nGet locally connected:\n $ ssh -i $PWD/.ssh/id_rsa [email\u00a0protected]\n\n Enter passphrase for key \"$PWD/.ssh/id_rsa\": [your password]\n PTY allocation request failed on channel 0\n Welcome to GitLab, you!\n Connection to gitlab.com closed.\n\n\n\nFinally, clone any private or internal GitLab repository!\n$ git clone https://git.metabarcoding.org/obitools/ROBIBarcodes.git\n\nCloning into 'ROBIBarcodes'...\nremote: Counting objects: 69, done.\nremote: Compressing objects: 100% (65/65), done.\nremote: Total 69 (delta 14), reused 0 (delta 0)\nUnpacking objects: 100% (69/69), done."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "java.lang.IllegalStateException: Dex archives: setting .DEX extension only for .CLASS files\n\nI build the project at gitlab ci \n./gradlew assembleDebug --stacktrace\n\nand sometimes it throws an error:\nFAILURE: Build failed with an exception.\n* What went wrong:\nExecution failed for task ':app:transformClassesWithDexBuilderForDebug'.\n> com.android.build.api.transform.TransformException: java.lang.IllegalStateException: Dex archives: setting .DEX extension only for .CLASS files\n\nAt my local pc it works correctly.\nkotlin version is 1.2\nmultidex is enabled\nWhat is the reason of this error?"}, {"role": "assistant", "content": "./gradlew clean fixed the same error for me."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Git with large files\n\nSituation\nI have two servers, Production and Development. On Production server, there are two applications and multiple (6) databases (MySQL) which I need to distribute to developers for testing. All source codes are stored in GitLab on Development server and developers are working only with this server and don't have access to production server. When we release an application, master logs into production and pulls new version from Git. The databases are large (over 500M each and counting) and I need to distribute them as easy as possible to developers for testing.\nPossible solutions\n\nAfter a backup script which dumps databases, each to a single file, execute a script which pushes each database to its own branch. A developer pulls one of these branches if he wants to update his local copy.\nThis one was found non working.\nCron on production server saves binary logs every day and pushes them into the branch of that database. So, in the branch, there are files with daily changes and developer pulls the files he doesn't have. The current SQL dump will be sent to the developer another way. And when the size of the repository becomes too large, we will send full dump to the developers and flush all data in the repository and start from the beginning.\n\nQuestions\n\nIs the solution possible?\nIf git is pushing/pulling to/from repository, does it upload/download whole files, or just changes in them (i.e. adds new lines or edits the current ones)?\nCan Git manage so large files? No.\nHow to set how many revisions are preserved in a repository? Doesn't matter with the new solution.\nIs there any better solution? I don't want to force the developers to download such large files over FTP or anything similar."}, {"role": "assistant", "content": "Update 2017:\nMicrosoft is contributing to Microsoft/GVFS: a Git Virtual File System which allows Git to handle \"the largest repo on the planet\"\n(ie: the Windows code base, which is approximately 3.5M files and, when checked in to a Git repo, results in a repo of about 300GB, and produces 1,760 daily \u201clab builds\u201d across 440 branches in addition to thousands of pull request validation builds)\n\nGVFS virtualizes the file system beneath your git repo so that git and all tools see what appears to be a normal repo, but GVFS only downloads objects as they are needed.\n\nSome parts of GVFS might be contributed upstream (to Git itself).\nBut in the meantime, all new Windows development is now (August 2017) on Git.\n\nUpdate April 2015: GitHub proposes: Announcing Git Large File Storage (LFS)\nUsing git-lfs (see git-lfs.github.com) and a server supporting it: lfs-test-server, you can store metadata only in the git repo, and the large file elsewhere. Maximum of 2 Gb per commit.\n\nSee git-lfs/wiki/Tutorial:\ngit lfs track '*.bin'\ngit add .gitattributes \"*.bin\"\ngit commit -m \"Track .bin files\"\n\n\nOriginal answer:\nRegarding what the git limitations with large files are, you can consider bup (presented in details in GitMinutes #24)\nThe design of bup highlights the three issues that limits a git repo:\n\nhuge files (the xdelta for packfile is in memory only, which isn't good with large files)\nhuge number of file, which means, one file per blob, and slow git gc to generate one packfile at a time.\nhuge packfiles, with a packfile index inefficient to retrieve data from the (huge) packfile.\n\n\nHandling huge files and xdelta\n\nThe primary reason git can't handle huge files is that it runs them through xdelta, which generally means it tries to load the entire contents of a file into memory at once.\nIf it didn't do this, it would have to store the entire contents of every single revision of every single file, even if you only changed a few bytes of that file.\nThat would be a terribly inefficient use of disk space, and git is well known for its amazingly efficient repository format.\n\n\nUnfortunately, xdelta works great for small files and gets amazingly slow and memory-hungry for large files.\nFor git's main purpose, ie. managing your source code, this isn't a problem.\n\n\nWhat bup does instead of xdelta is what we call \"hashsplitting.\"\nWe wanted a general-purpose way to efficiently back up any large file that might change in small ways, without storing the entire file every time.\nWe read through the file one byte at a time, calculating a rolling checksum of the last 128\nbytes.\n\n\nrollsum seems to do pretty well at its job. You can find it in bupsplit.c.\nBasically, it converts the last 128 bytes read into a 32-bit integer. What we then do is take the lowest 13 bits of the rollsum, and if they're all 1's, we consider that to be the end of a chunk.\nThis happens on average once every 2^13 = 8192 bytes, so the average chunk size is 8192 bytes.\nWe're dividing up those files into chunks based on the rolling checksum.\nThen we store each chunk separately (indexed by its sha1sum) as a git blob.\n\n\nWith hashsplitting, no matter how much data you add, modify, or remove in the middle of the file, all the chunks before and after the affected chunk are absolutely the same.\nAll that matters to the hashsplitting algorithm is the 32-byte \"separator\" sequence, and a single change can only affect, at most, one separator sequence or the bytes between two separator sequences.\nLike magic, the hashsplit chunking algorithm will chunk your file the same way every time, even without knowing how it had chunked it previously.\n\n\nThe next problem is less obvious: after you store your series of chunks as git blobs, how do you store their sequence?  Each blob has a 20-byte sha1 identifier, which means the simple list of blobs is going to be 20/8192 = 0.25% of the file length.\nFor a 200GB file, that's 488 megs of just sequence data.\n\n\nWe extend the hashsplit algorithm a little further using what we call \"fanout.\" Instead of checking just the last 13 bits of the checksum, we use additional checksum bits to produce additional splits.\nWhat you end up with is an actual tree of blobs - which git 'tree' objects are ideal to represent.\n\nHandling huge numbers of files and git gc\n\ngit is designed for handling reasonably-sized repositories that change relatively infrequently.  You might think you change your source code \"frequently\" and that git handles much more frequent changes than, say, svn can handle.\nBut that's not the same kind of \"frequently\" we're talking about.\n\n\nThe #1 killer is the way it adds new objects to the repository: it creates one file per blob.  Then you later run 'git gc' and combine those files into a single file (using highly efficient xdelta compression, and ignoring any files that are no longer relevant).\n\n\n'git gc' is slow, but for source code repositories, the resulting super-efficient storage (and associated really fast access to the stored files) is worth it.\n\n\nbup doesn't do that.  It just writes packfiles directly.\nLuckily, these packfiles are still git-formatted, so git can happily access them once\nthey're written.\n\nHandling huge repository (meaning huge numbers of huge packfiles)\n\nGit isn't actually designed to handle super-huge repositories.\nMost git repositories are small enough that it's reasonable to merge them all into a single packfile, which 'git gc' usually does eventually.\n\n\nThe problematic part of large packfiles isn't the packfiles themselves - git is designed to expect the total size of all packs to be larger than available memory, and once it can handle that, it can handle virtually any amount of data about equally efficiently.\nThe problem is the packfile indexes (.idx) files.\n\n\neach packfile (*.pack) in git has an associated idx (*.idx) that's a sorted list of git object hashes and file offsets.\nIf you're looking for a particular object based on its sha1, you open the idx, binary search it to find the right hash, then take the associated file offset, seek to that offset in the packfile, and read the object contents.\n\n\nThe performance of the binary search is about O(log n) with the number of hashes in the pack, with an optimized first step (you can read about it elsewhere) that somewhat improves it to O(log(n)-7).\nUnfortunately, this breaks down a bit when you have lots of packs.\n\n\nTo improve performance of this sort of operation, bup introduces midx (pronounced \"midix\" and short for \"multi-idx\") files.\nAs the name implies, they index multiple packs at a time."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Which is the best git hosting sw? - Gitolite vs. Gitlab vs. Gitorius [closed]\n\nClosed. This question is opinion-based. It is not currently accepting answers.\n                                \n                            \n\n\n\n\n\n\n\n\n\n\n\nWant to improve this question? Update the question so it can be answered with facts and citations by editing this post.\n\n\nClosed 10 years ago.\n\n\n\n\n\n\n\n                        Improve this question\n                    \n\n\n\nI am looking for a git hosting environment for several users. Therefore i've searched for comparisons between Gitolite, Gitlab and Gitorius. But i get nothing what could be useful.\nIs there anybody, who has experiences with different hosting tools and could provide an advice?"}, {"role": "assistant", "content": "Gitolite is not a git hosting environment: it is an authorization layer, which grants or denies access to a git repo.\nIt is the https or ssh layer which allows the authentication of a user, and the git repo hosting itself.\nSee \"How do programs like gitolite work?\"\nGitLab and Gitorious both provide git hosting, with (to my opinion) an easier installation process and more features for GitLab.\n\nWhen comparing GitLab features and Gitorious features, the issue tracker is more complete, the fork and authorization levels are present, GitLab has teams and groups, webhooks, and API.\nThe development is more active (one release every month) on GitLab. \nUpdate: GitLab has acquired Gitorious"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Change Gitlab CI Runner user\n\nCurrently when I start a build in GitlabCI it is running under gitlab-runner user. I want to change it the company's internal user. I didn't find any parameter to the /etc/gitlab-runner/config.toml which is solve that.\nMy current configuration: \nconcurrent = 1\n[[runners]]\n  name = \"deploy\"\n  url = \"\"\n  token = \"\"\n  executor = \"shell\""}, {"role": "assistant", "content": "Running ps aux | grep gitlab you can see:\n/usr/bin/gitlab-ci-multi-runner run --working-directory /home/gitlab-runner --config /etc/gitlab-runner/config.toml --service gitlab-runner --syslog --user gitlab-runner\n\nService is running with option --user.\nSo let's change this, it depends on what distro. you are running it. If systemd, there is a file:\n/etc/systemd/system/gitlab-runner.service:\n[Service]\nStartLimitInterval=5\nStartLimitBurst=10\nExecStart=/usr/bin/gitlab-ci-multi-runner \"run\" \"--working-directory\" \"/home/gitlab-runner\" \"--config\" \"/etc/gitlab-runner/config.toml\" \"--se\n\nBingo, let's change this file now:\ngitlab-runner uninstall\n\ngitlab-runner install --working-directory /home/ubuntu --user ubuntu\n\nreboot the machine or reload the service (i.e. systemctl daemon-reload), et voil\u00e0!"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to force push to Gitlab\n\ngit push --force gitlab master                                                                                  \nEnumerating objects: 50, done.\nCounting objects: 100% (50/50), done.\nDelta compression using up to 8 threads\nCompressing objects: 100% (29/29), done.\nWriting objects: 100% (40/40), 12.22 KiB | 4.07 MiB/s, done.\nTotal 40 (delta 26), reused 18 (delta 11)\nremote: GitLab: You are not allowed to force push code to a protected branch on this project.\nTo gitlab.com:xxx/yyyy.git\n ! [remote rejected]     master -> master (pre-receive hook declined)\nerror: failed to push some refs to '[email\u00a0protected]:xxx/yyyy.git'\n\nWhat should I do to push my commits to Gitlab? I use several remotes, and other remotes are OK and I was able to finish\ngit push --force some_other_remote master"}, {"role": "assistant", "content": "From the official documentation on dealing with Protected Branches:\n\nNavigate to your project\u2019s Settings \u2794 Repository\nScroll to find the Protected branches section.\nFrom the Branch dropdown menu, select the branch you want to protect and click Protect.\n\nFollowing the steps above, you should be greeted with a box similar to this one below.\n\nThere, you can click either:\n\n\"Allowed to force push\" toggle button, or\nthe orange Unprotect button\n\nfor the branch you want to force push to, e.g., master.\nIf you don't want to navigate through the navigation bars, you can also fill out this URL template:\nhttps://gitlab.com/<USERNAME>/<PROJECTNAME>/settings/repository#js-protected-branches-settings\n\nand replace <USERNAME> and <PROJECTNAME> with your specific username and project name, respectively.\nNote, the \"Allowed to force push\" button is probably favored over un-selecting the Unprotect button because branch protection gives you additional safety from accidentally deleting your branch. But either option appears to work.\nMore help:\n\nCommunity discussion on force pushing on branch https://gitlab.com/gitlab-com/support-forum/issues/93\nOfficial documentation to do so https://docs.gitlab.com/ee/user/project/protected_branches.html"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab Checking pipeline status - running forever\n\nI've enabled the option - Settings/General/Merge Requests/Merge Checks - Pipelines must succeed.\nSince then every merge requests automatically starts execution of the pipeline which is actually what i want. The problem is that this is running forever , i'm receiving message : Checking pipeline status\nIf i run the pipeline manually from CI/CD Pipelines - Run pipeline finish immediately. I don't understand what is wrong and why it stuck , can i check logs somewhere or something ?\nFor testing , the pipeline is really simple , just exit 1 .. but still not working ..\nAt this stage , \"running pipeline\" is not listed in pipeline list even if the status in merge request is\n\nChecking pipeline status"}, {"role": "assistant", "content": "We ran into a case where a merge request does not contain the .gitlab-ci.yml file. The fix is simply to do a rebase\nFor troubleshooting purposes, pipelines can be run manually on particular branches at CI/CD -> Pipelines -> Run Pipeline"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to remove merge request from GitLab server\n\nI created a merge request on gitlab (local) server. Now whenever I click on the merge request, the request times out with error 500. Before that I used to get an error code 504 and I applied the change mentioned in this gitlab support topic.\nAll I want to do is remove the merge request. Is there a manual way of doing this?"}, {"role": "assistant", "content": "Web UI Option\nToday I discovered a way to do this with the Web UI.\nSo for Merge Request 14\nhttps://gitlab.example.com/MyGroup/MyProject/merge_requests/14/edit\nOn the bottom Right you should see a red Delete button.\n\nPowerShell Option\nInvoke-RestMethod -Method Delete -Uri 'https://gitlab.example.com/api/v4/projects/PROJECT_ID_GOES_HERE/merge_requests/14' -Headers @{'PRIVATE-TOKEN'='PRIVATE_TOKEN_GOES_HERE'}"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to fail a build on Gitlab CI shell runner\n\nI have a Gitlab CI runner running on windows 10:\nbefore_script:\n  - \"echo off\"\n  - 'call \"%VS120COMNTOOLS%\\vsvars32.bat\"'\n  - echo.\n  - set\n  - echo.\n\nstages:\n  - build\n\nbuild:\n  stage: build\n  script:\n  - 'StatusTest.exe'\n  #- msbuild...\n\nI am trying to fail the build with StatusText.exe (I tried returning status codes -1,0,1; throwing an exception, etc.) But Runner only logs the exception and continues with following steps.\nWhat determines that CI shell runner should fail the build and not proceed to next step?\nOutput:\n...\nwindows_tracing_logfile=C:\\BVTBin\\Tests\\installpackage\\csilogfile.log\n$ echo.\n\n$ StatusTest.exe\n\nUnhandled Exception: System.Exception: tralala\n   at StatusTest.Program.Main(String[] args)\n$ echo \"Restoring NuGet Packages...\"\n..."}, {"role": "assistant", "content": "What determines that CI shell runner should fail the build and not\nproceed to next step?\n\nIf a pipeline job exits with the code other than 0 then that job fails causing all the following jobs in the pipeline to be skipped.\nThis behaviour can be changed on a per job basis with allow_failure job keyword.\nTo make a job to fail forcefully you need to artificially exit from a job with code other than 0. Here is an gitlab-ci.yml job example :\nsome-example-job:\n  script:\n    - # ....\n    - exit 1\n\n\nSee the GitLab CI UI sreeenshot example. The third job has failed.\n\nOn the opposite remove exit 0 and your job would succeed if the remaining script section commands do not exit with code other than 0.\nNow see all the jobs & the entire pipeline finished successfully."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab-ci.yml jobs:build-production config key may not be used with `rules`: only\n\nI am having a syntax error when I test my gitlab-ci.yml in CI Lint.  Can someone suggest a solution to this problem?\nbuild-production:\n  stage: build\n  only:\n    - master\n  image:\n    name: gcr.io/kaniko-project/executor:debug\n    entrypoint: [\"\"]\n  script:\n    - mkdir -p /kaniko/.docker\n    - echo \"{\\\"auths\\\":{\\\"$CI_REGISTRY\\\":{\\\"username\\\":\\\"$CI_REGISTRY_USER\\\",\\\"password\\\":\\\"$CI_REGISTRY_PASSWORD\\\"}}}\" > /kaniko/.docker/config.json\n    - /kaniko/executor --context $CI_PROJECT_DIR --dockerfile $CI_PROJECT_DIR/Dockerfile --destination $CI_REGISTRY_IMAGE:$CI_COMMIT_TAG\n  rules:\n    - if: $CI_COMMIT_TAG\n\nStatus: syntax is incorrect \n\njobs:build-production config key may not be used with `rules`: only"}, {"role": "assistant", "content": "Documentation is pretty clear :\n\nrules replaces only/except and they can\u2019t be used together in the same job. If you configure one job to use both keywords, the linter returns a key may not be used with rules error.\n\nI suggest to use rules: for both of your conditions :\nrules:\n  - if: '$CI_COMMIT_REF_NAME == \"master\" && $CI_COMMIT_TAG'"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Whole team gets 'too many unreachable loose objects' messages\n\nNot long ago, we have made the switch from SVN to Git.\nA few days ago, I realized that all of our team gets those messages when they push :\n$ git push\nCounting objects: 32, done.\nDelta compression using up to 8 threads.\nCompressing objects: 100% (19/19), done.\nWriting objects: 100% (32/32), 2.94 KiB | 0 bytes/s, done.\nTotal 32 (delta 14), reused 0 (delta 0)\nerror: The last gc run reported the following. Please correct the root cause\nand remove gc.log.\nAutomatic cleanup will not be performed until the file is removed.\n\nwarning: There are too many unreachable loose objects; run 'git prune' to remove them.\n\nTo [email\u00a0protected]:root/xxx.git\n   15c3bbb..69e6d8b  xxxx -> xxx\n\nI thought it was coming from my computer for a while, until I realize that everybody has the same issues.\nNeedless to say, there is no gc.log in my .git folder, and using 'git gc' or 'git prune' has no effect.\nSo my question is : Could it be that the repository hosted on the server is somehow not clean? If so, how to I actually clean it?\nAll of the solutions I have found so far relate to local copies of repositories.\nAlso, we use Gitlab to host our repos.\nEDIT : It is worth saying that I have since I posted this question also tried  \"Housecleaning\" the repository using Gitlab but with no result so far."}, {"role": "assistant", "content": "This is followed by issue 14357 (GitLab 8.6- or less)\nThe manual fix was:\n\nSSH into worker1\ncd into the gitlab-org/gitlab-ce directory\nran rm gc.log, this just contained the line \" warning: There are too many unreachable loose objects; run 'git prune' to remove them.\"\nran git prune and prayed it didn't break things (which it thankfully didn't)\n\nBut it looks like, starting GitLab 8.7, auto gc is disabled.\nThis is also done in the context of (still opened) issue 13524:\n\nTypically after a rebase, amend or other action that requires a force push we can have dangled commits.\nSuch \"dereferenced\" commits are getting lost due to git gc that may be executed internally or by using GitLab Housekeeping features.\nIf it happens that there was a discussion attached to a specific commit - it is not available after dereferenced commit has been garbage-collected.\nCommits are being recorded in push events and are available through system notes added to merge request, and currently this produces error 500 in GitLab.\n\nUpdate: that issue was closed a month later (July 2016) with:\n\nMR 5062: Don't garbage collect commits that have related DB records like comments\n\n\nMakes sure a commit is kept around when Git garbage collection runs.\nGit GC will delete commits from the repository that are no longer in any branches or tags, but we want to keep some of these commits around, for example if they have comments or CI builds.\n\n\nMR 4101: Refactor: Convert existing array-based diff refs to the DiffRefs model"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to create new local branch in Git\n\nI am working on a project which I cloned from a remote repository hosted on GitLab. I made some changes to the project, but I didn\u2019t create any branch and want to now start work on some other new features, but without first pushing my existing work to the remote repository.\nI might discard the changes in the new feature or might need to push both the new feature as well as the earlier changes to the remote repository, at a later stage.\nFrom what I know about Git, I think I need to create a new local branch, which I can do using git checkout -b NEW_BRANCH_NAME. Is this the correct way to accomplish what I am trying to do?  When I use this command, it creates a new branch. How do I switch back and forth between working on this new branch and the earlier one?"}, {"role": "assistant", "content": "You switch back and forth between branches using git checkout <branch name>.\nAnd yes, git checkout -b NEW_BRANCH_NAME is the correct way to create a new branch and switching to it. At the same time, the command you used is a shorthand to git branch <branch name> and git checkout <branch name>."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to create repository badges in gitlab?\n\nHow do I create badges for my project in gitlab?\nI know there is a webpage for it here https://docs.gitlab.com/ee/user/project/badges.html\nbut I have no idea what they are saying.\nsuppose my project is here\nhttps://gitlab.com/username/userproject\nwhat should be the link and the badge image link?"}, {"role": "assistant", "content": "There are two default badges: Pipeline and Coverage.\nThe example URLs would be:\nhttps://gitlab.com/username/userproject/badges/master/pipeline.svg\nhttps://gitlab.com/username/userproject/badges/master/coverage.svg\n\n\nFor pipeline you have to set up a buildserver pipeline (.gitlab-ci.yml).\nFor coverage you have to enter a regex parsing expression in the settings for CI.\n\nBut you can also set up custom badges. But you have to create them on your own.\nFor public repos you can use an service like Shields.io or private repos you can use AnyBadge (needs an python interpreter in build chain.\nHere is an example how to set up a custom badge: Adding Custom badges to Gitlab\nWhen you look at bigger repositories (for example this), you can have a look at the path of the images and see where they are created."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "NPM install resulting in 401 Unauthorized for private repo\n\nI have the following line in my dependencies in package.json:\n\"log\": \"https://git.mydomain.com/myproject/myrepo/repository/archive.tar.gz?ref=0.1.0\",\n\nI get the following:\nkm@Karls-MBP ~/dev/vertica (km/ref) $ npm install\nnpm ERR! code E401\nnpm ERR! 404 401 Unauthorized: log@https://git.mydomain.com/myproject/myrepo/repository/archive.tar.gz?ref=0.5.0\n\nnpm ERR! A complete log of this run can be found in:\nnpm ERR!     /Users/km/.npm/_logs/2018-02-16T08_49_38_669Y-debug.log\n\nI don't know if the issue is GitLab (where the repo exists) or NPM.\n\nNode v8.9.4\nNPM v5.6.0"}, {"role": "assistant", "content": "Remove .npmrc from the Home Directory, it should be able to work. I did the same and it works for me."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Using GitLabCI with C#\n\nI've been working on a C# application and wanted to try the GitLab CI out. All I can see is Ruby and can't find any information on how to build a C# application using it.\nWhen I run the test settings, I make the commit, but I don't have my build.\n\nHow should I make a simple build? Which command could I use for that? I don't mind if I get a failed build (but a build)."}, {"role": "assistant", "content": "I just wanted to share my .gitlab-ci.yml complete with unit testing. You will have to adjust your nuget and possibly other paths. This is for a single project in a solution of the same name.\nvariables:\n  PROJECT_NAME: \"ProjectNameGoesHere\"\nbefore_script:\n  - echo \"starting build for %PROJECT_NAME%\"\n  - echo \"Restoring NuGet Packages...\"\n  - d:\\tools\\nuget restore \"%PROJECT_NAME%.sln\"\nstages:\n  - build\n  - test\nbuild:\n  stage: build\n  script:\n  - echo \"Release build...\"\n  - '\"C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319\\msbuild.exe\" /consoleloggerparameters:ErrorsOnly /maxcpucount /nologo /property:Configuration=Release /verbosity:quiet \"%PROJECT_NAME%.sln\"'\n  artifacts:\n    untracked: true\ntest:\n  stage: test\n  script:\n  - echo \"starting tests\"\n  - cd %PROJECT_NAME%Tests/bin/Release\n  - '\"C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE\\MSTest.exe\" /testcontainer:%PROJECT_NAME%Tests.dll'\n  dependencies:\n  - build"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "`docker pull` returns `denied: access forbidden` from private gitlab registry\n\nI have a Dockerfile which is going to be implemented FROM a private registry's image. I build this file without any problem with Docker version 1.12.6, build 78d1802 and docker-compose version 1.8.0, build unknown, but in another machine which has Docker version 17.06.1-ce, build 874a737 and docker-compose version 1.16.1, build 6d1ac21, the docker-compose build returns:\nFROM my.private.gitlab.registry:port/image:tag\nhttp://my.private.gitlab.registry:port/v2/docker/image/manifests/tag: denied: access forbidden\n\ndocker pull my.private.gitlab.registry:port/image:tag returns the same. \nNotice that I tried to get my.private.registry:port/image:tag and http://my.private.registry:port/v2/docker/image/manifests/tag has been catched."}, {"role": "assistant", "content": "If this is an authenticated registry, then you need to run docker login <registryurl> on the machine where you are building this.\nThis only needs to be done once per host. The command then caches the auth in a file\n$ cat ~/.docker/config.json\n{\n    \"auths\": {\n        \"https://index.docker.io/v1/\": {\n            \"auth\": \"......=\"\n        }\n    }\n}"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How gitlab runner concurrency works?\n\nQ1: Whats the difference between\nconcurrent = 3\n\n[[runners]]\n  ..\n  executor = \"shell\"\n\nand\nconcurrent = 3\n\n[[runners]]\n  ...\n  executor = \"shell\"\n\n[[runners]]\n  ...\n  executor = \"shell\"\n\n[[runners]]\n  ...\n  executor = \"shell\"\n\nQ2: Does it makes sense, to...\nhave 3 executors (workers) of same type on a single runner with global concurrent = 3? Or can single executor with global concurrent = 3 do multiple jobs in parallel safely?\nQ3: How they're related...\nrunners.limit with runners.request_concurrency and concurrent\nThanks"}, {"role": "assistant", "content": "Gitlab's documentation on runners describes them as:\n\n(...) isolated (virtual) machines that pick up jobs through the coordinator API of GitLab CI\n\nTherefore, each runner is an isolated process responsible for picking up requests for job executions and for dealing with them according to pre-defined configurations. As an isolated process, each runner have the capability of creating 'sub-processes' (also called machines) in order to run jobs.\nWhen you define in your config.toml a [[runner]] section, you're configuring a runner and setting how it should deal with job execution requests.\nIn your questions, you mentioned two of those \"how to deal with job execution request\"' settings:\n\nlimit: \"Limit how many jobs can be handled concurrently\". In other words, how many 'sub-processes' can be created by a runner in order to execute jobs simultaneously;\nrequest_concurrency: \"Limit number of concurrent requests for new jobs from GitLab\". In other words, how many job execution requests can a runner take from GitLab CI job queue simultaneously.\n\nAlso, there are some settings that apply to a machine globally. In your question you mentioned one of them:\n\nconcurrent: \"Limit how many jobs globally can be run concurrently. This is the most upper limit of number of jobs using all defined runners\". In other words, it limits the maximum amount of 'sub-processes' that can run jobs simultaneously.\n\nThus, keeping in mind the difference between a runner its sub-processes and also the difference between specific runner settings and global machine settings:\nQ1:\nThe difference is that in your 1st example you have one runner and in your 2nd example you have three runners. It's worth mentioning that in both examples your machine would only allow running 3 jobs simultaneously.\nQ2:\nNot only a single runner can run multiple jobs concurrently safely but also is possible to control how many jobs you want it to handle (using the aforementioned limit setting).\nAlso, there is no problem to have similar runners running in the same machine. How you're going to define your runner's configurations is up to you and your infrastructure capabilities.\nAlso, please notice that an executor only defines how to run your job. It isn't the only thing that defines a runner and it isn't a synonymous for \"worker\". The ones working are your runners and their sub-processes.\nQ3:\nTo summarize: You can define one or many workers at the same machine. Each one is an isolated process. A runner's limit is how many sub-processes of a runner process can be created to run jobs concurrently. A runner's request_concurrency is how many requests can a runner handle from the Gitlab CI job queue. Finally, setting a value to concurrent will limit how many jobs can be executed at your machine at the same time in the one or more runners running in the machine.\nReferences\nFor better understanding, I really recommend you read about Autoscaling algorithm and parameters. \nFinally, I think you might find this question on how to run runners in parallel on the same server useful."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab-ci: extend script section\n\nI have an unity ci-project.\n .gitlab-ci.yml contains base .build job with one script command. Also I have multiple specified jobs for build each platform which extended base .build. I want to execute some platform-specific commands for android, so I have created separated job generate-android-apk. But if it's failing the pipeline will be failed too.(I know about allow_failure). Is it possible to extend script section between jobs without copy-pasting?"}, {"role": "assistant", "content": "UPDATE:\nsince gitlab 13.9 it is possible to use !reference tags from other jobs or \"templates\" (which are commented jobs - using dot as prefix)\nactual_job:\n  script:\n    - echo doing something\n\n.template_job:\n  after_script:\n    - echo done with something\n\njob_using_references_from_other_jobs:\n  script:\n    - !reference [actual_job, script]\n  after_script:\n    - !reference [.template_job, after_script]\n\nThanks to @amine-zaine for the update\n\nFIRST APPROACH:\nYou can achieve modular script sections by utilizing 'literal blocks' (using |) like so:\n.template1: &template1 |\n  echo install\n\n.template2: &template2 |\n  echo bundle\n\ntestJob:\n  script:\n  - *template1\n  - *template2\n\nSee Source\n\nANOTHER SOLUTION:\nSince GitLab 11.3 it is possible to use extend which could also work for you.\n.template:\n  script: echo test template\n  stage: testStage\n  only:\n    refs:\n      - branches\n\nrspec:\n  extends: .template1\n  after_script:\n    - echo test job\n  only:\n    variables:\n      - $TestVar\n\nSee Docs\nMore Examples"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Export a repository from a Gitlab server to another Gitlab server\n\nJust installed a fresh new 6.8 Gitlab on a brand new high performance server.\nBefore considering to forget my repositories history (comments, issues, etc...), do one know of a way to export a repository data from a Gitlab server to another Gitlab Server ?\nI just failed to found anything on the documentation for exporting/migrating the whole project data (not just the git repository and its wiki)."}, {"role": "assistant", "content": "For GitLab versions >= 8.9 (released in June 2016) you can use the built-in export and import project feature.\nPlease not that for the existing installations of GitLab, this option has to be enabled in the application settings (URL: /admin/application_settings) under 'Import sources'. You have to be a GitLab admin user to enable and use the import functionality.\nHere is the feature complete documentation: https://gitlab.com/help/user/project/settings/import_export.md"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What's the difference between \"Submit review\" and \"Add comment now\" in GitLab's merge request discussions?\n\nFirst time GitLab user and I'm a bit confused when reviewing someone's merge request. Whenever I add a comment I get prompted with two options: Submit review and Add comment now.\n\nWhat's the difference between the two? Why is there a need for two options?"}, {"role": "assistant", "content": "Just heard this from my colleagues, so not sure if this is 100% accurate:\nAdd comment now: instantly adds the comment to the review and notifies the reviewer that a comment has been added. So if you choose this option X times, the reviewer receives X notifications.\nSubmit review: You can add as many comments as you want in as many files as you want. If you choose this option at the end of your review, the reviewer will receive only 1 notification containing all of your comments."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to delete gitlab CI jobs pipelines logs/builds and history\n\nHow can we configure gitlab to keep only the last 10 CI jobs/builds and keep deleting the rest? \nFor example , in Jenkins , we can configure the job to keep only last X builds."}, {"role": "assistant", "content": "UPDATE\nAs of Gitlab Release 12.6, deleting a pipeline is now an option in the GUI for users in role Owner:\n\nClick the pipeline you want to remove in the pipelines list\nHit the red Delete button in the upper right of the pipeline details page.\n\nAs of Gitlab Release 11.6, deleting a pipeline is now an option, for users in Owner role only, via the API.\nYou need:\n\nAn API token\nThe id of the project\nThe pipeline_id of the pipeline you wish to remove.\n\nExample using curl from the docs for project id: 1 and pipeline_id: 4:\ncurl --header \"PRIVATE-TOKEN: <your_access_token>\" --request \"DELETE\" \"https://gitlab.example.com/api/v4/projects/1/pipelines/46\"\n\nDocumentation is here"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab with non-standard SSH port (on VM with Iptable forwarding)\n\nMy gitlab is on a virtual machine on a host server. I reach the VM with a non-standard SSH port (i.e. 766) which an iptable rule then forward from host:766 to vm:22.\nSo when I create a new repo, the instruction to add a remote provide a mal-formed URL (as it doesn't use the 766 port. For instance, the web interface give me this:\nMalformed\n\ngit remote add origin [email\u00a0protected]:group/project.git\n\nInstead of an URL containing :766/ before the group.\nWellformed\n\ngit remote add origin [email\u00a0protected]:766/group/project.git  \n\nSo it time I create a repo, I have to do the modification manually, same for my collaborator. \nHow can I fix that ?"}, {"role": "assistant", "content": "In Omnibus-packaged versions you can modify that property in the /etc/gitlab/gitlab.rb file:\ngitlab_rails['gitlab_shell_ssh_port'] = 766\n\nThen, you'll need to reconfigure GitLab:\n# gitlab-ctl reconfigure\n\nYour URIs will then be correctly displayed as ssh://[email\u00a0protected]:766/group/project.git in the web interface."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI: npm doesn't like the cached node_modules\n\nThe internet is full of complains about Gitlab not caching, but in my case I think, that Gitlab CI indeed caches correctly. The thing is, that npm seems to install everything again anyway.  \ncache:\n  key: ${CI_COMMIT_REF_SLUG}\n  paths:\n    - vendor/\n    - bootstrap/\n    - node_modules/\n\nbuild-dependencies:\n  image: ...\n  stage: build\n  script:\n  - cp .env.gitlab-testing .env\n  - composer install --no-progress --no-interaction\n  - php artisan key:generate\n  - npm install\n  - npm run prod\n  - npm run prod\n  artifacts:\n    paths:\n    - vendor/\n    - bootstrap/\n    - node_modules/\n    - .env\n    - public/mix-manifest.json\n  tags:\n  - docker\n\nThis is my gitlab-ci.yml file (well.. the relevant part). While the cached composer dependencies are used, the node_modules aren't. I even added everything to cache and artifacts out of desperation.."}, {"role": "assistant", "content": "Updated Answer (Dec 2, 2023, GitLab@^15.12 & >13)\nJust like the comments received, the use of artifacts is not ideal in the original answer, but was the cleanest approach that worked reliably. Now, that GitLab's documentation has been updated around the use of cache and it was also expanded to support multiple cache keys per job (4 maximum unfortunately), there is a better way to handle node_modules across a pipeline.\nThe rationale for implementation is based on understand the quirks of both GitLab and how npm works. These are the fundamentals:\n\nNPM recommends the use of npm ci instead of npm install when running in a CI/CD environment.  FYI, this will require the existence of package-lock.json, which is used to ensure 0 packages are automatically version bumped while running in a CI environment (npm i by default will not create the same deterministic build every time, such as on a job re-run).\n\nnpm ci deliberately removes the entirety of node_modules first before re-installing all packages listed in package-lock.json.  Therefore, it is best to only configure GitLab to run npm ci once and ensure the resulting node_modules is passed to other jobs.\n\nNPM has its own cache that it stores at ~/.npm/ in case of offline builds and overall speed.  You can specify a different cache location with the --cache <dir> option (you will need this). (variation of @Amityo's answer)\n\nGitLab cannot cache any directory outside of the repository! This means the default cache directory ~/.npm cannot be cached.\n\nGitLab's global cache configuration is applied to every job by default. Jobs will need to explicit override the cache config if it doesn't need the globally cached files. Using YAML anchors, the global cache config can be copied & modified.\n\nTo run additional npx or npm run <script> without re-running an install, you should cache node_modules/ folder(s) across the pipeline.\n\nGitLab's expectation is for users to use the cache feature to handle dependencies and only use artifacts for dynamically generated build results. This answer now supports this desire better than possible before. There is the restriction that artifacts should be less than the maximum artifact size or 1GB (compressed) on GitLab.com. And artifacts uses your storage usage quota\n\nThe use of the needs or dependencies directives will influence if artifacts from a previous job will be downloaded (or deleted) automatically on the next job.\n\nGitLab cache's can monitor the hash value of a file and use that as the key so its possible the cache will only update when the package-lock.json updates. You could use package.json but you would invalidate your deterministic builds as it does not update when minor or patches are available.\n\nIf you have a mono-repo and have more than 2 separate packages, you will hit the cache entry limit of 4 during the install job. You will not have the ideal setup but you can combine some cache definitions together. It is also worth noting, GitLab cache.key.files supports a maximum of 2 files to use for the key hash so you likely will need to use another method to determine a useful key. One likely solution will be to use a non-file related key and cache all node_modules/ folders under that key. That way you have only 2 cache entries for the install job and 1 for each subsequent job.\n\nGitLab's cache list unfortunately prepends the index value to the cache key it uses (this is very unintuitive!) which can affect whether or not your cache is matched between jobs. Thank you to @deanharber for bringing this up. As of 3 Dec 2023, this example has been updated to reflect the new order in the install job. The global cache entry must be first in the install job since the global cache key is actually 0_[CACHE_KEY_FOR_NODE_MODULES], and the npm cache second as it will have a key of 1_[CACHE_KEY_FOR_NPM_TARBALLS].\n\n\nSolution\n\nRun a single install job as .pre stage, using cached downloaded packages (tar.gz's) across entire repository.\nCache all node_modules/ folders to following jobs for that pipeline execution. Do not allow any jobs except install to upload cache (lowers pipeline run time & prevents unintended consequences)\nPass the build/ directory via artifacts on to other jobs only when needed\n\n# .gitlab-ci.yml\n\nstages:\n  - build\n  - test\n  - deploy\n\n\n# global cache settings for all jobs\n# Ensure compatibility with the install job\n# goal: the install job loads the cache and\n# all other jobs can only use it\ncache:\n    # most npm libraries will only have 1 entry for the base project deps\n    - &global_cache_node_mods\n      key:\n          files:\n              - package-lock.json\n      paths:\n          - node_modules/\n      policy: pull  # prevent subsequent jobs from modifying cache\n\n#   # ATTN mono-repo users: with only additional node_modules, \n#   # add up to 2 additional cache entries. \n#   # See limitations in #10. \n#   - key:\n#         files:\n#             - core/pkg1/package-lock.json\n#     paths:\n#         - core/pkg1/node_modules/\n#     policy: pull # prevent jobs from modifying cache\n\n\ninstall:\n  image: ...\n  stage: .pre   # always first, no matter if it is listed in stages\n  cache:\n    # Mimic &global_cache_node_mods config but override policy\n    # to allow this job to update the cache at the end of the job\n    # and only update if it was a successful job (#5)\n    - <<: *global_cache_node_mods\n       when: on_success\n       policy: pull-push\n\n#   # ATTN Monorepo Users: add additional key entries from \n#   # the global cache and override the policy as above but\n#   # realize the limitations (read #10).\n#   - key:\n#      files:\n#        - core/pkg1/package-lock.json\n#      paths:\n#        - core/client/node_modules/\n#      when: on_success\n#      policy: pull-push\n\n    # store npm cache for all branches (stores download pkg.tar.gz's)\n    # will not be necessary for any other job\n    - key: ${CI_JOB_NAME}\n       # must be inside $CI_PROJECT_DIR for gitlab-runner caching (#3)\n       paths:\n         - .npm/\n       when: on_success\n       policy: pull-push\n\n# before_script:\n#   - ...\n  script:\n    # define cache dir & use it npm!\n    - npm ci --cache .npm --prefer-offline\n#   # monorepo users: run secondary install actions\n#   - npx lerna bootstrap -- --cache .npm/ --prefer-offline\n\n\nbuild:\n  stage: build\n  # global cache settings are inherited to grab `node_modules`\n  script:\n    - npm run build\n  artifacts:\n    paths:\n      - dist/           # where ever your build results are stored\n\n\ntest:\n  stage: test\n  # global cache settings are inherited to grab `node_modules`\n  needs:\n    # install job is not \"needed\" unless it creates artifacts\n    # install job also occurs in the previous stage `.pre` so it\n    # is implicitly required since `when: on_success` is the default\n    # for subsequent jobs in subsequent stages\n    - job: build\n      artifacts: true      # grabs built files\n  # dependencies: could also be used instead of needs\n  script:\n    - npm test\n\n\ndeploy:\n  stage: deploy\n  when: on_success # only if previous stages' jobs all succeeded\n  # override inherited cache settings since node_modules is not needed\n  cache: {}\n  needs:\n    - job: build\n      artifacts: true      # grabs dist/\n  script:\n    - npm publish\n\nGitLab's recommendation for npm can be found in the GitLab Docs.\n\n[DEPRECATED] Original Answer (Oct 27, 2021, GitLab<13.12)\nAll the answers I see so far give only half answers but don't actually fully accomplish the task of caching IMO.\nIn order to fully cache with npm & GitLab, you must be aware of the following:\n\nSee #1 above\n\nnpm ci deliberately removes the entirety of node_modules first before re-installing all packages listed in package-lock.json. Therefore, configuring GitLab to cache the node_modules directory between build jobs is useless. The point is to ensure no preparation hooks or anything else modified node_modules from a previous run. IMO, this is not really valid for a CI environment but you can't change it and maintain the fully deterministic builds.\n\nSee #3-#4 above\n\nIf you have multiple stages, global cache will be downloaded every job.  This likely is not what you want!\n\nTo run additional npx commands without re-running an install, you should pass the node_modules/ folder as an artifact to other jobs.\n\n\n[DEPRECATED] Solution\n\nRun a single install job as .pre stage, using cached downloaded packages (tar.gz's) across entire repository.\nPass node_modules & the build directory on to other jobs only when needed\n\n\nstages:\n  - build\n  - test\n  - deploy\n\ninstall:\n  image: ...\n  stage: .pre         # always first, no matter if it is listed in stages\n  cache:\n    key: NPM_DOWNLOAD_CACHE  # a single-key-4-all-branches for install jobs\n    paths:\n      - .npm/\n  before_script:\n    - cp .env.gitlab-testing .env\n    - composer install --no-progress --no-interaction\n    - php artisan key:generate\n  script:\n    # define cache dir & use it npm!\n    - npm ci --cache .npm --prefer-offline\n  artifacts:\n    paths:\n    - vendor/\n    - bootstrap/\n    - node_modules/\n    - .env\n    - public/mix-manifest.json\n\nbuild:\n  stage: build\n  needs:\n    - job: install         \n      artifacts: true       # true by default, grabs `node_modules`\n  script:\n    - npm run build\n  artifacts:\n    paths:\n      - dist/               # whereever your build results are stored\n\ntest:\n  stage: test\n  needs:\n    - job: install\n      artifacts: true      # grabs node_modules\n    - job: build\n      artifacts: true      # grabs built files\n  script:\n    - npm test\n\ndeploy:\n  stage: deploy\n  needs:\n      # does not need node_modules so don't state install as a need\n    - job: build\n      artifacts: true      # grabs dist/\n    - job: test            # must succeed\n      artifacts: false     # not needed\n  script:\n    - npm publish"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Deploying GitLab pages for different branches\n\nI am deploying my React app using GitLab Pages, and it works well.\nHere is my gitlab-ci.yml:\n# Using the node alpine image to build the React app\nimage: node:alpine\n\n# Announce the URL as per CRA docs\n# https://github.com/facebook/create-react-app/blob/master/packages/react-scripts/template/README.md#advanced-configuration\nvariables:\n  PUBLIC_URL: /\n# Cache node modules - speeds up future builds\ncache:\n  paths:\n  - client/node_modules\n\n# Name the stages involved in the pipeline\nstages:\n  - deploy\n\n# Job name for gitlab to recognise this results in assets for Gitlab Pages\n# https://docs.gitlab.com/ee/user/project/pages/introduction.html#gitlab-pages-requirements\npages:\n  stage: deploy\n  script:\n    - cd client\n    - npm install # Install all dependencies\n    - npm run build --prod # Build for prod\n    - cp public/index.html public/404.html # Not necessary, but helps with https://medium.com/@pshrmn/demystifying-single-page-applications-3068d0555d46\n    - mv public _public # CRA and gitlab pages both use the public folder. Only do this in a build pipeline.\n    - mv build ../public # Move build files to public dir for Gitlab Pages\n  artifacts:\n    paths:\n    - public # The built files for Gitlab Pages to serve\n  only:\n    - master # Only run on master branch\n\nNow, I just created a dev version, based on my branch develop\nI would like to have 2 versions of my React app with 2 different URLs. How can I do that?\nFor example right now, I have:\nmy-react-app.com linked to master branch\nHow should I have\ndev.my-react-app.com or even my-react-app.gitlab.io linked to develop branch?<"}, {"role": "assistant", "content": "I've had success using the browsable artifacts for this purpose. In your example, you would create a job for your develop branch and set the PUBLIC_URL to the path on gitlab.io where the job's artifacts are published:\ndevelop:\n    artifacts:\n        paths:\n          - public\n\n    environment:\n        name: Develop\n        url: \"https://$CI_PROJECT_NAMESPACE.gitlab.io/-/$CI_PROJECT_NAME/-/jobs/$CI_JOB_ID/artifacts/public/index.html\"\n\n    script: |\n        # whatever\n\n    stage: deploy\n\n    variables:\n        PUBLIC_URL: \"/-/$CI_PROJECT_NAME/-/jobs/$CI_JOB_ID/artifacts/public\"\n\nSetting the environment as indicated produces a \u00bbReview app\u00ab link in relevant merge requests, allowing you to get to the artifacts with a single click.\nNote: if your repository is in a subgroup, you need to insert the subgroup name in two places above above between /-/ and $CI_PROJECT_NAME for the resulting URLs to work."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do you center text in Gitlab markdown?\n\nAfter Gitlab switched its markdown engine to CommonMark it's no longer as easy to add things like custom styling to your markdown files.\nI've used Gitlab for some time and for the longest time I've liked how nicely I could make my README.md file look, having a centered icon, title and description for my project. When they switched the engine all my markdown files that relied on having such stylings look really bad.\nHow do I center text in Gitlab after the transition to CommonMark?"}, {"role": "assistant", "content": "Update\nI checked out an old project of mine and noticed that it was already centered. It turns out that CommonMark allows you to set align=\"center\" on <div> tags as well!\nSo, the simplest solution for centering is currently (note the empty line after the opening <div>:\n<div align=\"center\">\n\n# This is gonna be centered!\n</div>\n\nOriginal\nThe only CommonMark html object that supports centering (as far as I know) is when you center a table cell. First you might've thought about just making a table and then using align=\"center\", but the table won't take up the entire width of the page, so you'd get a small table on the left hand side of the page, which wouldn't solve our problem of wanting to center stuff relative to the page rather than the table.\nTo get around this we set the table width (not using CSS with an inline style tag since it's not supported in CommonMark at the time of writing) to a large value that will take up way more than the total width of the page. Since the max-width: CSS property of tables in Gitlab markdown is 100% it means that by setting a ridiculously high width=\"\" we're essentially setting the table width: to 100% by using only the allowed pure html width=\"\" property.\nThe markdown below if placed in e.g. README.md in your Gitlab project will result in a 100% width table with a centered image, title and description. The most notable part is that we're setting width=\"9999\" on the <td> element in the table.\n<table align=\"center\"><tr><td align=\"center\" width=\"9999\">\n<img src=\"/icon.png\" align=\"center\" width=\"150\" alt=\"Project icon\">\n\n# MyProject\n\nDescription for my awesome project\n</td></tr></table>\n\n... More content\n\nBelow you can see an example of how your README.md file could look on Gitlab using the above markdown."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to add icon to my repository?\n\nI have found that Gitlab and SourceTree support icons for every repositories which make them more specific and easy to find at one glance.\nHow is this possible?"}, {"role": "assistant", "content": "We as a developer sometimes need a change to make our tools look different.\nYou can add a small(I prefer 96px x 96px) logo.png image file to the root of your repository.\n\nWhich makes your project more specific and easy to find with gitlab or SourceTree git client. Unfortunately github does not support this feature.\n\nIt is very simple but it works!\n\nUpdate: Thanks to your comments I have found another way within Gitlab repository settings:\n\nhope you enjoy this trick and make your tools more fun :)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Is it possible to delete issues on GitLab?\n\nI recently installed GitLab to try it out and I am really enjoying it. It's very easy to install and use, still, I found an annoying \"problem\". I haven't yet found a way to delete Issues associated to projects. \nI know that it's not a good practice to remove Issues from the system, but there are some specific occasions where this is really useful, such as when you create an Issue that makes no sense and don't want to be in the system, even after being closed.\nSo, my question, really simple: Is it possible to delete Issues on GitLab? If so, how can I do it?\nI am using GitLab 7.2.1, on Debian wheezy.\nMany thanks"}, {"role": "assistant", "content": "It is now possible to delete issues starting with GitLab 8.6:\nGitLab 8.6 released with Deploy to Kubernetes and Subscribe to Label\n\nDelete Issues\nSometimes, simply closing an issue or merge request is not sufficient. For those times, we are now making it possible to delete issues and merge requests.\nOnly owners can delete issues by editing the issue or merge request and clicking, you guessed it, Delete."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Disable pipeline for every commit in Gitlab and only run it on open merge request\n\nThe CI pipeline runs on every commit in my Gitlab repository at work. Is there way to disable that and only run the CI pipeline on an open merge request to the master branch?"}, {"role": "assistant", "content": "There is currently no configuration option to do that. Here are some things that can be used to \"disable\" a pipeline build.\n\nAdding [ci skip] inside the commit message will not trigger a pipeline on push.\nUsing except and only options on all jobs inside the pipeline. To avoid duplication in this case, you can use Anchors.\n\nUpdate: GitLab 11.7\nWhen pushing to GitLab you can skip triggering a pipeline by passing ci.skip option to the push command: git push -o ci.skip"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "remote: GitLab: You are not allowed to push code to protected branches on this project\n\nI am trying to push to master branch of a repo and I am failing to do so, since it is protected.\nI tried to look into the project settings and do not see any option for protected branches. The only option I could see is members.   \nremote: GitLab: You are not allowed to push code to protected branches on this project.\nTo [email\u00a0protected]:cmd/release.git\n ! [remote rejected] master -> master (pre-receive hook declined)\nerror: failed to push some refs to '[email\u00a0protected]:cmd/release.git'\n\nMy repo has only one branch, with no contents in it so far.\nI do see protected branches options of my other Repos but not for this specific one.\nIt is a new repo with no contents and with only default branch.\nI have the master permission.\nUnfortunately I am not able to upload the image here somehow. \nPlease suggest how to push code to master branch."}, {"role": "assistant", "content": "12/17/2018\n1. git push: \"error: failed to push some refs to\"\n\ngit push -f: \"remote rejected\"\n\n2. the branch is in a protected state and cannot be forced to operate.\nGitlab - Repository - Branches\n\n3. temporarily remove branch protection.\nGitlab - Settings - Repository - Protected Branches - Unprotect\n\n4. try pushing again\ngit push -f\n\n5. may add protection"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Exporting environment variables from one stage to the next in GitLab CI\n\nIs there a way to export environment variables from one stage to the next in GitLab CI? I'm looking for something similar to the job artifacts feature, only for environment variables instead of files.\nLet's say I'm configuring the build in a configure stage and want to store the results as (secret, protected) environment variables for the next stages to use. I could safe the configuration in files and store them as job artifacts but I'm concerned about secrets being made available in files than can be downloaded by everyone."}, {"role": "assistant", "content": "Since Gitlab 13 you can inherit environment variables like this:\nbuild:\n  stage: build\n  script:\n    - echo \"BUILD_VERSION=hello\" >> build.env\n  artifacts:\n    reports:\n      dotenv: build.env\n\ndeploy:\n  stage: deploy\n  script:\n    - echo $BUILD_VERSION # => hello\n  dependencies:\n    - build\n\nNote: for GitLab < 13.1 you should enable this first in Gitlab Rails console:\nFeature.enable(:ci_dependency_variables)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I remove Tag in GitLab repository\n\nI am using GitLab 7.7.2 and tried to remove Tag in a repository in GitLab.\nI could remove tag in a local repository but cannot remove tag in origin.\nHow do I remove tag in GitLab repository?\n$ git tag -d Tag_AAA\nDeleted tag 'Tag_AAA' (was d10bff2)\n\n$ git push --delete origin Tag_AAA\nremote: GitLab: You don't have permission\nTo [email\u00a0protected]:root/Repository.git\n ! [remote rejected] Tag_AAA (pre-receive hook declined)\nerror: failed to push some refs to '[email\u00a0protected]:root/Repository.git'"}, {"role": "assistant", "content": "# delete locally:\ngit tag -d <tag>\n\n# delete remotely:\ngit push origin :refs/tags/<tag>\n\n# another way to delete remotely:\ngit push --delete origin <tag>"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to reset git authentication?\n\nI typed wrong ID (my mistake) and I think my computer's IP is permanently banned. I'd like to un-ban my IP so that I can git clone to my desired git repository. But when I tried to git clone my git repository, it says\nremote: HTTP Basic: Access denied\nfatal: Authentication failed for \"~~my repository\"\nHow can I access my git repository again? Or how can I reset my banned state? I think typing a wrong ID only once and be permanently banned is somewhat harsh."}, {"role": "assistant", "content": "It seems that your credential manager stored wrong authentication and reuses it. Reset it.\ngit config --system --unset credential.helper\n\nMore information:\nRemove credentials from Git\nGitLab remote: HTTP Basic: Access denied and fatal Authentication"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "List all the projects and all the groups\n\nWhat is the easiest method to list all the projects and groups in GitLab using my private token?"}, {"role": "assistant", "content": "If only your private token is available, you can only use the API:\nPROJECTS\nUse the following command to request projects:\ncurl \"https://<host>/api/v4/projects?private_token=<your private token>\"\n\nThis will return you the first 20 entries. To get more you can add the paramater per_page\ncurl \"https://<host>/api/v4/projects?private_token=<your private token>&per_page=100\"\n\nwith this parameter you can request between 20and 100 entries (see REST API Pagination documentation).\nIf you now want all projects, you have to loop through the pages. To get to another page add the parameter page.\ncurl \"https://<host>/api/v4/projects?private_token=<your private token>&per_page=100&page=<page_number>\"\n\nNow you may want to know how many pages there are. For that, add the curl parameter --head. This will not return the payload, but the header.\nThe result should look like this:\nHTTP/1.1 200 OK\nServer: nginx\nDate: Thu, 13 Jul 2017 17:43:24 GMT\nContent-Type: application/json\nContent-Length: 29428\nCache-Control: no-cache\nLink: <request link>\nVary: Origin\nX-Frame-Options: SAMEORIGIN\nX-Next-Page: 2\nX-Page: 1\nX-Per-Page: 20\nX-Prev-Page:\nX-Request-Id: 80ecc167-4f3f-4c99-b09d-261e240e7fe9\nX-Runtime: 4.117558\nX-Total: 312257\nX-Total-Pages: 15613\nStrict-Transport-Security: max-age=31536000\n\nThe two interesting parts here are X-Totaland X-Total-Pages. The first is the count of available entries and the second the count of total pages.\nI suggest to use python or some other kind of script to handle the requests and concat the results at the end.\nIf you want to refine the search, consult this wiki page:\nhttps://docs.gitlab.com/ce/api/projects.html#projects-api\nGROUPS\nFor groups simply replace projects with groups in the curls.\nhttps://docs.gitlab.com/ce/api/groups.html#list-groups\n\nUPDATE:\nHere is the official list of Gitlab API clients/wrappers: https://docs.gitlab.com/ee/api/rest/#third-party-clients\nI highly recommend using one of these."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to use sudo in build script for gitlab ci?\n\nWhen I would like to do something that requiers sudo privelegies, the build process stucks and when ps aux for that command, it hanging in the list but doing nothing.\nE.g.:\nin the buildscript:\n# stop nginx\necho \"INFO: stopping nginx. pid [$(cat /opt/nginx/logs/nginx.pid)]\"\nsudo kill $(cat /opt/nginx/logs/nginx.pid)\n\nin the gitlab ci output console:\nINFO: stopping nginx. pid [2741]\n\nkill $(cat /opt/nginx/logs/nginx.pid) # with a spinning wheel\n\nin the bash:\n> ps aux | grep nginx\n\nroot      6698  0.0  0.1  37628  1264 ?        Ss   19:25   0:00 nginx: master process /opt/nginx/sbin/nginx\nnobody    6700  0.3  0.3  41776  3832 ?        S    19:25   0:00 nginx: worker process\nkai   7015  0.0  0.0   4176   580 pts/0    S+   19:27   0:00 sh -c sudo kill $(cat /opt/nginx/logs/nginx.pid)\nkai   7039  0.0  0.0   7828   844 pts/2    S+   19:27   0:00 grep nginx\n\nSo:\n\nnot the sudo kill $(cat /opt/nginx/logs/nginx.pid) is going to execute, but sh -c sudo kill $(cat /opt/nginx/logs/nginx.pid)\nit is hanging up, without response (sounds for me like it asks for a password interactively)"}, {"role": "assistant", "content": "There are a couple of ways to resolve this.\nGrant sudo permissions\nYou can grant sudo permissions to the gitlab-runner user as this is who is executing the build script.\n$ sudo usermod -a -G sudo gitlab-runner\n\nYou now have to remove the password restriction for sudo for the gitlab-runner user.\nStart the sudo editor with\n$ sudo visudo\n\nNow add the following to the bottom of the file\ngitlab-runner ALL=(ALL) NOPASSWD: ALL\n\n\nDo not do this for gitlab runners that can be executed by untrusted users.\n\nSSH Runner\nYou can configure the gitlab-ci-runner to connect to a remote host using SSH. You configure this to use a user remotely that has sudo permissions, and perform the build using that user. The remote host can be the same machine that the gitlab runner is executing on, or it can be another host.\nThis build user account will still need to have sudo and passwordless permissions. Follow the instruction below, except replace gitlab-runner with the build user."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": ".gitlab-ci.yml after_script section: how can I tell whether the task succeeded or failed?\n\nI'm using Gitlab CI, and so have been working on a fairly complex .gitlab-ci.yml file. The file has an after_script section which runs when the main task is complete, or the main task has failed somehow. Problem: I need to do different cleanup based on whether the main task succeeded or failed, but I can't find any Gitlab CI variable that indicates the result of the main task.\nHow can I tell, inside the after_script section, whether the main task has succeeded or failed?"}, {"role": "assistant", "content": "Since gitlab-runner 13.5, you can use the CI_JOB_STATUS variable.\ntest_job:\n  # ...\n  after_script:\n    - >\n      if [ $CI_JOB_STATUS == 'success' ]; then\n        echo 'This will only run on success'\n      else\n        echo 'This will only run when job failed or is cancelled'\n      fi\n\nSee GitLab's documentation on predefined_variables: https://docs.gitlab.com/ee/ci/variables/predefined_variables.html"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Artifacts for failed builds in Gitlab\n\nI would like to know how to generate artifacts for failed builds in gitlab continuous integration, to view the html report generated by the build.\nI tried like this:\n artifacts:\n    when: on_failure\n      paths:\n        - SmokeTestResults/\n        - package.json\n\nbut it does not work unfortunately. I am using Gitlab 8.11.4 community edition."}, {"role": "assistant", "content": "Using when: on_failure will upload the artifact only when there is a failure.\nTo always upload the artifact despite a failure, use when: always.\nhttps://docs.gitlab.com/ce/ci/yaml/index.html#artifactswhen"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to use multiple auths/ logins for same docker registry\n\nI'm using latest gitlab and the integrated docker registry. For each project I create an individual deploy token. On the host where I want to deploy the images I do docker login https://registry.example.com/project1, enter the deploy token and get success. Pulling the image just works fine.\nOn the same host I need to deploy another image from the same registry. So I do docker login https://registry.example.com/project2, the the deploy token (which is differrent to token 1, because each project has its own deploy tokens) and get success.\nHowever looking in the .docker/config.json I can see docker just stores the domain, not the full url, and so replaces the old auth token with the new one. So I can only pull image 2 now, but not image 1 anymore.\nIs this a bug in docker? How to use more than one auth/ deploy token for the same registry?"}, {"role": "assistant", "content": "You can use the --config option of the Docker client to store multiple credentials into different paths:\ndocker --config ~/.project1 login registry.example.com -u <username> -p <deploy_token>\ndocker --config ~/.project2 login registry.example.com -u <username> -p <deploy_token> \n\nThen you are able to call Docker commands by selecting your credential:\ndocker --config ~/.project1 pull registry.example.com/project1\ndocker --config ~/.project2 pull registry.example.com/project2"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Cannot connect to the Docker daemon at tcp://localhost:2375/. Is the docker daemon running. On GitLab\n\nI'm trying to build the CI pipeline in GitLab. I'd like to ask about making the docker work in GitLab CI.\nFrom this issue: https://gitlab.com/gitlab-org/gitlab-runner/issues/4501#note_195033385\nI'm follow the instruction for both ways. With TLS and not used TLS.\nBut It's still stuck. Which in same error\nCannot connect to the Docker daemon at tcp://localhost:2375/. Is the docker daemon running\n\nI've try to troubleshooting this problem. follow by below,\n\nenable TLS\n\nWhich used .gitlab-ci.yml and config.toml for enable TLS in Runner.\nThis my .gitlab-ci.yml:\nimage: docker:19.03\nvariables:\n  DOCKER_HOST: tcp://localhost:2375/\n  DOCKER_DRIVER: overlay2\n  DOCKER_TLS_CERTDIR: \"/certs\"\n  IMAGE_NAME: image_name\n\nservices:\n  - docker:19.03-dind\n\nstages:\n  - build\n\npublish:\n  stage: build\n  script:\n    - docker build -t$IMAGE_NAME:$(echo $CI_COMMIT_SHA | cut -c1-10) .\n    - docker push $IMAGE_NAME:$(echo $CI_COMMIT_SHA | cut -c1-10)\n  only:\n    - master   \n\nAnd this my config.toml:\n[[runners]]\n  name = MY_RUNNER\n  url = MY_HOST\n  token = MY_TOKEN_RUNNER\n  executor = \"docker\"\n  [runners.custom_build_dir]\n  [runners.docker]\n    tls_verify = false\n    image = \"docker:stable\"\n    privileged = true\n    disable_entrypoint_overwrite = false\n    oom_kill_disable = false\n    disable_cache = false\n    volumes = [\"/certs/client\", \"/cache\"]                      \n    shm_size = 0\n\n\nDisable TLS\n\n.gitlab-ci.yml:\nimage: docker:18.09\nvariables:\n  DOCKER_HOST: tcp://localhost:2375/\n  DOCKER_DRIVER: overlay2\n  DOCKER_TLS_CERTDIR: \"\"\n  IMAGE_NAME: image_name\n\nservices:\n  - docker:18.09-dind\n\nstages:\n  - build\n\npublish:\n  stage: build\n  script:\n    - docker build -t$IMAGE_NAME:$(echo $CI_COMMIT_SHA | cut -c1-10) .\n    - docker push $IMAGE_NAME:$(echo $CI_COMMIT_SHA | cut -c1-10)\n  only:\n    - master   \n\nAnd this my config.toml:\n[[runners]]\n  environment = [\"DOCKER_TLS_CERTDIR=\"]\n\nAnyone have idea?\n\nSolution\nYou can see at the accepted answer.     Moreover, In my case and\nanother one. Looks like the root cause it from the Linux server that\nGitLab hosted doesn't has permission to connect Docker. Let's check\nthe permission connectivity between GitLab and Docker on your server."}, {"role": "assistant", "content": "You want to set DOCKER_HOST to tcp://docker:2375. It's a \"service\", i.e. running in a separate container, by default named after the image name, rather than localhost.\nHere's a .gitlab-ci.yml snippet that should work:\n# Build and push the Docker image off of merges to master; based off\n# of Gitlab CI support in https://pythonspeed.com/products/pythoncontainer/\ndocker-build:\n  stage: build\n\n  image:\n    # An alpine-based image with the `docker` CLI installed.\n    name: docker:stable\n\n  # This will run a Docker daemon in a container (Docker-In-Docker), which will\n  # be available at thedockerhost:2375. If you make e.g. port 5000 public in Docker\n  # (`docker run -p 5000:5000 yourimage`) it will be exposed at thedockerhost:5000.\n  services:\n   - name: docker:dind\n     alias: thedockerhost\n\n  variables:\n    # Tell docker CLI how to talk to Docker daemon; see\n    # https://docs.gitlab.com/ee/ci/docker/using_docker_build.html#use-docker-in-docker-executor\n    DOCKER_HOST: tcp://thedockerhost:2375/\n    # Use the overlayfs driver for improved performance:\n    DOCKER_DRIVER: overlay2\n    DOCKER_TLS_CERTDIR: \"\"\n\n  script:\n    # Download bash:\n    - apk add --no-cache bash python3\n    # GitLab has a built-in Docker image registry, whose parameters are set automatically.\n    # See https://docs.gitlab.com/ee/ci/docker/using_docker_build.html#using-the-gitlab-contai\n    #\n    # CHANGEME: You can use some other Docker registry though by changing the\n    # login and image name.\n    - docker login -u \"$CI_REGISTRY_USER\" -p \"$CI_REGISTRY_PASSWORD\" \"$CI_REGISTRY\"\n    - docker build -t \"$CI_REGISTRY_IMAGE\" .\n    - docker push \"$CI_REGISTRY_IMAGE\"\n\n  # Only build off of master branch:\n  only:\n    - master"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to change the default target branch for merges in Gitlab\n\nwe are using Gitlab 8.10.1 with many groups and projects. Many of the projects happen to be forks of other projects.\nOur problem is that whenever somebody opens a merge request for a project the default target branch is NOT the default branch of the project but from one very specific other project. Is there a way to override this setting somehow?\nJust to make it clear, I know how to set the default branch of a project and those settings appear to be correct, however gitlab doesn't seem to use them when creating merge requests.\nThis issue is very annoying and has led to weird situations when people didn't pay attention and made merge requests with a completely different \"master\" as target."}, {"role": "assistant", "content": "The default MR target depends on whether or not the repository is a GitLab fork.\nForks\nIf the repository is a GitLab fork, then the default MR target will be the default branch of the upstream repository. This relationship can be removed via the \"Remove fork relationship\" option on the Project settings page, after which the default MR target will be determined as normal for a non-fork repository (described below).\nAt time of writing, it is not possible to override the default MR target without removing the fork relationship, but that functionality has been requested in gitlab issue #14522.\nNon-Forks\nIf the repository has no fork relationship, then the Default Branch setting on the Project settings page sets both (1) the default MR target, and (2) the HEAD reference of the repo on the GitLab server (which determines the branch that's checked out when the repo is cloned). Note that, due to a bug/quirk in git, problems can occur if a branch that was once the Default Branch is later deleted from GitLab.\nAt time of writing, it is not possible to change the default MR target independently of the Default Branch, but this functionality has been requested in gitlab issue #17909."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Git push failed with error: \u201cGitLab: Author not member of team\u201d\n\ngit push failed with the following message:\nremote: GitLab: Author '`[email\u00a0protected]`' is not a member of team\n\nMy #git config user.name and #git config user.email are set as:\n#git config user.name\nSam Logan \n\n#git config user.email\n[email\u00a0protected]\n\nMy hostname is logath-T460.\nI am not sure why git push uses my localhostname with the Author.  Any clue how to resolve this issue?"}, {"role": "assistant", "content": "It's not git push that's using your username + hostname, it's git commit.\nBy default, if you did not set user.name and user.email BEFORE making a commit, git will get it from your computer name and hostname. It would also have shown you a warning like this:\nCommitter: user1234 <[email\u00a0protected]>\nYour name and email address were configured automatically based\non your username and hostname. Please check that they are accurate.\nYou can suppress this message by setting them explicitly:\n\n    git config --global user.name \"Your Name\"\n    git config --global user.email [email\u00a0protected]\n\nAfter doing this, you may fix the identity used for this commit with:\n\n    git commit --amend --reset-author\n\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 file1.txt\n\nWhen you do git push, it would just use whatever was set as the commit author and push it to the remote repo.\nWhat I think happened, is that you already committed BEFORE you set the correct user.name and user.email settings. So those commits you're trying to push already has that invalid user details \"[email\u00a0protected]\" saved as the commit author.\nWhat you need to do then is to update the author of the previous commits.\nFirst, make sure to properly set the user.name and user.email config (--global or --local to the repo), otherwise known as your Git identity.\ngit config --global user.name \"yourname\"\ngit config --global user.email \"[email\u00a0protected]\"\n\nSet it now to the correct identity that matches the user account of your Gitlab repo.\nThen use --reset-author on those commits.\n\nTo modify the author of only the most recent commit:\ngit commit --amend --reset-author --no-edit\n\n\nTo modify the author of multiple past commits:\n(reference: How to amend several commits in Git to change author)\ngit rebase -i HEAD~N -x \"git commit --amend --reset-author --no-edit\"\n\nwhere N is the number of previous commits you need to update. The rebase -i will show a command line editor to show you the changes, and --reset-author will use your current user.* settings. Just save and quit to apply to changes.\n\nAfter that, git push should now work."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Move .git repo to parent directory [duplicate]\n\nThis question already has answers here:\n                                \n                            \n\n\n\n\nMy Git repository is in the wrong root directory. Can I move it? (../ instead of ./)\n\n                                (10 answers)\n                            \n\nClosed 7 years ago.\n\n\n\nI have a subdirectory named \"www\" that is a repo:\nsite\n|-- www/\n|    |-- .git/\n|    |-- index.html\n|-- design/\n|    |-- images.jpg\n\nI'd like to change the repo to the parent directory so that the repo structure mirrors the original file structure as follows:\nsite\n|-- .git/\n|-- www/\n|    |-- index.html\n|-- design/\n|    |-- images.jpg\n\nCan this be done? Are there implications with then pushing the changes up to Gitlab?"}, {"role": "assistant", "content": "Create a www directory in your repo.\ngit mv the HTML files to that directory. Optionally commit this step.\nmv the design directory into your repo, and git add .\nCommit.\nRename/move your whole repo."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I create a GitLab webhook?\n\nI've read that GitLab is capable of sending messages to other servers via \"web hooks\" but I can't find where one would create one.\nCan someone point me in the right direction?"}, {"role": "assistant", "content": "All the answers I've found in official documentation and on Stack Overflow for finding web hooks are incorrect. The admin area > hooks page does NOT contain web hooks. It contains system hooks, which fire when you create/delete projects and users and things like that. This is not what you want.\nTo find your web hooks, go to the specific project > settings > web hooks (on sidebar in GitLab 6.1.0) page. These will fire on post-receive for the project in question. You can use a service like RequestBin to see what the payload looks like and to ensure you're firing these off correctly for debugging purposes."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to merge branch to master?\n\nI do have a local branch with some changes, and I want to merge it to remote master. When I run: git merge master I get: \n\nAlready up-to-date\n\nbut I still can see that the master doesn't contain the new changes. \nI checked the following issue Git merge reports \u201cAlready up-to-date\u201d though there is a difference Ask, but it seems in one hand to be outdated, and on the other hand, none of the hints there were helpful.\nAny idea or hint?"}, {"role": "assistant", "content": "If you want to merge your branch to master on remote, follow the below steps:\n\npush your branch say 'br-1' to remote using git push origin br-1.\nswitch to master branch on your local repository using git checkout master.\nupdate local master with remote master using git pull origin master.\nmerge br-1 into local master using git merge br-1. This may give you conflicts which need to be resolved and changes committed before moving further.\nOnce merge of br-1 to master on local is committed, push local master to remote master using git push origin master."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do you find your GitLab host name (to test your SSH key)?\n\nI just created a personal GitLab account and am trying to follow the steps on \nhttps://gitlab.com/help/ssh/README\nto deploy my SSH key to GitLab. I've completed up to step 5, and see my SSH key among 'Your SSH keys' in my User Settings -> SSH keys:\n\nI'm trying to now complete the optional 6th step, testing the key:\n\nMy GitLab username is khpeek, so I guessed my 'GitLab domain' is gitlab.com/khpeek. However, the test command\nssh -T [email\u00a0protected]/khpeek\n\nyields an error message:\nssh: Could not resolve hostname gitlab.com/khpeek: Name or service not known\n\nApparently this is the wrong hostname. What would be the right one?"}, {"role": "assistant", "content": "If you're using Gitlab on gitlab.com then the domain is simply gitlab.com so you should run ssh -T [email\u00a0protected]"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to prevent Gitlab from creating extra merge commit on branch merge\n\nI use GitLab in my project. I'm exploring Merge Requests feature. \n\nI created a topic_branch from master.\nMade a bunch of commits on topic_branch. \nPushed topic_branch to remote. \nCreated a merge request on master to pull changes from topic_branch. \nOn accept merge in Gitlab, master pulled all the commits and also created a merge commit which is horrible to see duplication of code. \n\nI should have created a squash of commits on branch and then created merge request. But still master would have two new commits, one from the branch and another one would be merge commit. I'm assuming, if I do this from command line i.e,\n\ncheckout master\nmerge topic_branch into master\ncommit / push master\nIn this case, there would be only 1 commit on master.\n\nHow to achieve this from GitLab ?"}, {"role": "assistant", "content": "TL;DR\nYour Project > Settings > General > Merge Request Settings > Fast-Forward Merge.\nNote: in recent Gitlab versions the Merge Request Settings are not located under General anymore, they're directly located under Settings: Your Project > Settings > Merge Requests > Merge Method > Fast-Forward Merge.\nPersonally, I also prefer to do squash commits on every merge.\n\nI think GitLab supports this now.\nSteps\n\nGo to your project\nNavigate to project settings (Note: This is NOT the profile settings available on the top right)\nGo to General tab.\nNavigate to Merge Request Settings section\nChoose Fast-Forward Merge."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab-CI runner: ignore self-signed certificate\n\ngitlab-ci-multi-runner register\n\ngave me\ncouldn't execute POST against https://xxxx/ci/api/v1/runners/register.json:\nPost https://xxxx/ci/api/v1/runners/register.json: \nx509: cannot validate certificate for xxxx because it doesn't contain any IP SANs\n\nIs there a way to disable certification validation?\nI'm using Gitlab 8.13.1 and gitlab-ci-multi-runner 1.11.2."}, {"role": "assistant", "content": "Based on Wassim's answer, and gitlab documentation about tls-self-signed and custom CA-signed certificates, here's to save some time if you're not the admin of the gitlab server but just of the server with the runners (and if the runner is run as root):\nSERVER=gitlab.example.com\nPORT=443\nCERTIFICATE=/etc/gitlab-runner/certs/${SERVER}.crt\n\n# Create the certificates hierarchy expected by gitlab\nsudo mkdir -p $(dirname \"$CERTIFICATE\")\n\n# Get the certificate in PEM format and store it\nopenssl s_client -connect ${SERVER}:${PORT} -showcerts </dev/null 2>/dev/null | sed -e '/-----BEGIN/,/-----END/!d' | sudo tee \"$CERTIFICATE\" >/dev/null\n\n# Register your runner\ngitlab-runner register --tls-ca-file=\"$CERTIFICATE\" [your other options]\n\nUpdate 1: CERTIFICATE must be an absolute path to the certificate file.\nUpdate 2: it might still fail with custom CA-signed because of gitlab-runner bug #2675"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Can't find out base GitLab API base url\n\nI've created project and repo on my gitlab.com account, generated private key, now I'm trying to do API call to get list of commits.\nNow I want to get list of projects via API, from documentation\nhttps://docs.gitlab.com/ce/api/projects.html#list-projects\nGET /projects\n\nSo I'm doing:\ncurl --header \"PRIVATE-TOKEN: XXXXXXX -c\" \"https://gitlab.com/projects\"\n\nAnd getting 404.\nI've tried several combinations and can't find correct base URL.\nSame for repository commits, documentation https://docs.gitlab.com/ce/api/commits.html says\nhttps://gitlab.example.com/api/v3/projects/5/repository/commits\n\nfine, I'm trying (with myusername/projectname as project id)\nhttps://gitlab.com/api/v3/projects/myusername/projectname/repository/commits\nAnd got 404 as well"}, {"role": "assistant", "content": "The correct base url for the hosted GitLab is https://gitlab.com/api/v4/ so your request to\nGET /projects would be\ncurl --header \"PRIVATE-TOKEN: XXXXXX\" \"https://gitlab.com/api/v4/projects\"\n\nThat would return all projects that are visible to you, including other user's public projects.\nIf you wish to view just your projects, then you should use the GET /users/:user_id/projects endpoint, where :user_id is your user ID that can be found on your GitLab profile page or in the response to your request to GET /user if you're authenticated.\n# Get :user_id from this request\ncurl --header \"PRIVATE-TOKEN: XXXXXX\" \"https://gitlab.com/api/v4/user\"\n\n# See your projects by replacing :user_id with id value from previous request\ncurl --header \"PRIVATE-TOKEN: XXXXXX\" \"https://gitlab.com/api/v4/users/:user_id/projects\"\n\nAlso, the project ID is not the same as the project name. You can retrieve the project ID from the response of your request to GET /users/:user_id/projects, or from the project's settings page."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Why can't I delete a branch in a remote GitLab repository?\n\nI'm trying to delete a branch both locally and in a remote GitLab repository. Its name is origin/feat. I tried git push --delete origin feat. Git complains:\nremote: error: By default, deleting the current branch is denied, because the next\nremote: 'git clone' won't result in any file checked out, causing confusion.\nremote: \nremote: You can set 'receive.denyDeleteCurrent' configuration variable to\nremote: 'warn' or 'ignore' in the remote repository to allow deleting the\nremote: current branch, with or without a warning message.\nremote: \nremote: To squelch this message, you can set it to 'refuse'.\nremote: error: refusing to delete the current branch: refs/heads/feat\n\nOK makes sense, so I tried switching to origin/master with git checkout master and it tells me: Already on 'master'. Does the current branch also need to be set in the remote directory? How would I do that?"}, {"role": "assistant", "content": "Try\ngit push origin --delete <branch-name>"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Remove releases in GitLab\n\nI have a problem with my releases in GitLab.\nI created them in my project with tags. Now I want to remove them, so I deleted the associated tags but my releases are always displayed. I searched on Google and Stack Overflow but I can't find any solutions.\nHow can I remove these releases without their tags?"}, {"role": "assistant", "content": "Go to Project Overview -> Releases\nClick the release you want to delete\nScroll to the bottom. Find the tag icon. Click on the tag.\nThere is a trash can button for the tag. Deleting the tag will delete the release as well."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI builds remains pending\n\nWe recently started to use GitLab-CI on the gitlab.com free service.\nAt first everything went fine, but now, seems like we can't build our project anymore. The builds are shown as pending and doesn't do anything.\nHere's what we have in our builds list:\n\nAnd if we check the details of a build:\n\nAs you might notice, in the list, each build is assigned to a runner id, but in the details page, the runner section is blank.\nAt first, we thought it was just latency caused by gitlab.com ingrastructure, but it's really just stuck there...\nEDIT\nIt's more than 1 year ago but I keep having notifications about this question. If I recall properly, the problem was due to GitLab itself. Follow the GitLab docs and make sure your setup is valid, and hope for the best !"}, {"role": "assistant", "content": "If you are working with local gitlab-runner, like macOS or custom runner that you have been made, you should start running jobs manually.\nBased on this topic on gitlab documentation you should start manually in user-mode or system-mode based on where you executing this command\nRun in terminal\nIf you did not started gitlab-runner yet\ngitlab-runner start \n\nsystem-mode execution\nsudo gitlab-runner run \n\nuser-mode execution\ngitlab-runner run"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Git push results in fatal: protocol error: bad line length character: This\n\nI am trying to get GitLab working on my server (running CentOS 6.5). I followed the gitlab-receipe to the line, but I just can't get it working. I am able to access the web interface, create new projects but pushing to the master branch returns the following error : \nfatal: protocol error: bad line length character: This\n\nI have done checks on the production environment, here are the results : \nChecking Environment ...\n\nGit configured for git user? ... yes\n\nChecking Environment ... Finished\n\nChecking GitLab Shell ...\n\nGitLab Shell version >= 1.7.9 ? ... OK (1.8.0)\nRepo base directory exists? ... yes\nRepo base directory is a symlink? ... no\nRepo base owned by git:git? ... yes\nRepo base access is drwxrws---? ... yes\nupdate hook up-to-date? ... yes\nupdate hooks in repos are links: ... \nASC / Wiki ... repository is empty\nRunning /home/git/gitlab-shell/bin/check\nCheck GitLab API access: OK\nCheck directories and files: \n    /home/git/repositories: OK\n    /home/git/.ssh/authorized_keys: OK\nTest redis-cli executable: redis-cli 2.4.10\nSend ping to redis server: PONG\ngitlab-shell self-check successful\n\nChecking GitLab Shell ... Finished\n\nChecking Sidekiq ...\n\nRunning? ... yes\nNumber of Sidekiq processes ... 1\n\nChecking Sidekiq ... Finished\n\nChecking LDAP ...\n\nLDAP is disabled in config/gitlab.yml\n\nChecking LDAP ... Finished\n\nChecking GitLab ...\n\nDatabase config exists? ... yes\nDatabase is SQLite ... no\nAll migrations up? ... yes\nGitLab config exists? ... yes\nGitLab config outdated? ... no\nLog directory writable? ... yes\nTmp directory writable? ... yes\nInit script exists? ... yes\nInit script up-to-date? ... no\n  Try fixing it:\n  Redownload the init script\n  For more information see:\n  doc/install/installation.md in section \"Install Init Script\"\n  Please fix the error above and rerun the checks.\nprojects have namespace: ... \nASC / Wiki ... yes\nProjects have satellites? ... \nASC / Wiki ... can't create, repository is empty\nRedis version >= 2.0.0? ... yes\nYour git bin path is \"/usr/bin/git\"\nGit version >= 1.7.10 ? ... yes (1.8.3)\n\nChecking GitLab ... Finished\n\nFor the init script error, the receipt says \n\nDo not mind about that error if you are sure that you have downloaded\n  the up-to-date\n\nso as I have downloaded the latest one, I can't really do much about it.\nI've been banging my head for the past week, and can not figure out why this error is occurring, any help would appreciated!!"}, {"role": "assistant", "content": "If anyone else has this problem, the solution is to change the login shell of the user 'git' (or whatever your user is called) to /bin/bash. This can be done via the command : usermod -s /bin/bash git (Link). The reason for changing the login shell is because the default shell for the git user is /sbin/nologin (or similar, depending on environment), which prevents the git application from logging in as the git user on the git server."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab pipeline - reports config contains unknown keys: cobertura\n\nI'm not able run the gitlab pipeline due to this error\nInvalid CI config YAML file\njobs:run tests:artifacts:reports config contains unknown keys: cobertura"}, {"role": "assistant", "content": "Check the latest correct doc here: https://docs.gitlab.com/ee/ci/yaml/artifacts_reports.html#artifactsreportscoverage_report\nSome of the docs are in somewhat of a messy state right now, due to the new release as mentioned.\nThis was the fix for me:\n  artifacts:\n    expire_in: 2 days\n    reports:\n      coverage_report:\n        coverage_format: cobertura\n        path: python_app/coverage.xml"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab rename branch and start over on another\n\nI just started on a new project and I'm using GitLab with SourceTree. I had created a branch (origin\\master) but I did the mistake of using this branch for my development, so I pushed my first few changes to this branch. Now I learned that this branch should actually have the production version and that an origin\\develop branch should be used for development.\nIs there any way I can rename the master branch to origin\\develop and somehow create a new origin\\master branch with the original version of the application?\nI'm the only developer in the project so it won't affect anyone. If possible, if you can explain how to do it in SourceTree since I don't use the command line git. I'm more familiar with SourceTree."}, {"role": "assistant", "content": "You could try something like this. Answer modified from this great answer, to suit OP's needs.\ngit branch -m master develop    # rename master on local\ngit push origin :master         # delete master on remote\ngit push origin develop         # create develop on remote\ngit checkout -b master develop  # create a new local master on top of develop\ngit push origin master          # create master on remote"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab-Runner \"listen_address not defined\" error\n\nI'm running a Laravel api on my server, and I wanted to use Gitlab-runner for CD. The first two runs were good, but then I started to see this problem listen_address not defined, session endpoints disabled  builds=0\nI'm running a linux server on a web shared hosting, so I can access a terminal and get some priviliges but I can't do some sudo stuff like installing a service. That's why I've been running gitlab-runner in user-mode\nError info\nConfiguration loaded                                builds=0\nlisten_address not defined, metrics & debug endpoints disabled  builds=0\n[session_server].listen_address not defined, session endpoints disabled  builds=0\n\n.gitlab-runner/config.toml\nconcurrent = 1\ncheck_interval = 0\n\n[session_server]\n  session_timeout = 1800\n\n[[runners]]\n  name = \"CD API REST Sistema SIGO\"\n  url = \"https://gitlab.com/\"\n  token = \"blablabla\"\n  executor = \"shell\"\n  listen_address=\"my.server.ip.address:8043\"\n  [runners.custom_build_dir]\n  [runners.cache]\n    [runners.cache.s3]\n    [runners.cache.gcs]"}, {"role": "assistant", "content": "I have literally wasted 2 days on this subject. I have followed the below steps to get the runners configured and execute jobs successfully.\nI am using Mac OS X 10.13 and Git Lab 12. However, people with other OS also can check this out.\nI have stopped the runners and uninstalled them. Now deleted all references and files to gitlab runner, including the gitlab executable also.\nI got to know GitLab Runner executable paths from https://docs.gitlab.com/runner/configuration/advanced-configuration.html\nI have installed them again using the gitlab official documentation.\nThen the runners shows online in the gitlab portal. However, the jobs are not getting executed. It shows simply stuck. It tried to get information from logs using \n\ngitlab-runner -debug run\n\nThen I got to know that listen_address not defined. After a long try I got to know that simply enabling Run Untagged jobs did the trick. The jobs started and completed successfully. Still the I see the listen_address not defined from debug. So that misled me.\n\nThough it seems that last one task has solved my problem, but doing all the tasks in a batch did the trick."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to NOT download artifacts from previous stages for build configuration?\n\nI have a gitlab CI build process with 4 steps, in which artifacts produced in first step are packaged into docker image in 2nd step, then the output image is given as the artifact to 3rd step, and there is a 4th step afterwards, that notifies external service.\nThe 2nd step needs artifacts from step 1, the 3rd step need artifacts from step 2. This is done with 'dependencies'parameter and it works fine.\nWhat is not working is the step 4, that need no artifacts. I've skipped the 'dependencies' block, then I've declared dependencies: [], but in both cases the both artifacts are downloaded!\nHow do I correct inform gitlab CI that the step has no dependencies? Or is it some bug in Gitlab CI?"}, {"role": "assistant", "content": "As per the gitlab-ci documentation: \nTo disable artifact passing, define the job with empty dependencies:\n\njob:\n  stage: build\n  script: make build\n  dependencies: []\n\nI've found the same issue here: https://gitlab.com/gitlab-org/gitlab-runner/issues/228\nThis seems to be fixed in: https://gitlab.com/gitlab-org/gitlab-ce/merge_requests/10359\nPlease update your CI Runner to a newer version as that should fix it."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Code coverage report using gitlab-ci.yml file\n\nI need to see code coverage report for a java maven project in Gitlab.\nAccording to this, this and some other sources:\n\nI added jacoco to the list of plugins in pom.xml.\nAdded pages job to my .gitlab-ci.yml file.\nAdded Total.*?([0-9]{1,3})% to code coverage parsing in project setting.\n\nbut there isn't any coverage report or at least I can't see it. There is no coverage percentage or coverage report page.\nContent of .gitlab-ci.yml file:\nimage: maven:latest\n\nvariables:\n  MAVEN_CLI_OPTS: \"--batch-mode --errors --fail-at-end --show-version -DinstallAtEnd=true -DdeployAtEnd=true\"\n  MAVEN_OPTS: \"-Dmaven.repo.local=.m2/repository -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=WARN -Dorg.slf4j.simpleLogger.showDateTime=true -Djava.awt.headless=true\"\n\ncache:\n  paths:\n    - .m2/repository/\n\nbuild:\n  stage: build\n  script:\n    - mvn $MAVEN_CLI_OPTS compile\n\ntest:\n  stage: test\n  script:\n    - mvn $MAVEN_CLI_OPTS test\n  artifacts:\n    paths:\n      - target/site/jacoco/\npages:\n  stage: deploy\n  dependencies:\n    - test\n  script:\n   - mkdir public\n   - mv target/site/jacoco/index.html public\n  artifacts:\n    paths:\n      - public\n\ndeploy:\n  stage: deploy\n  script:\n    - mvn $MAVEN_CLI_OPTS verify\n  only:\n    - master\n\njacoco plugin in pom.xml:\n<plugin>\n    <groupId>org.jacoco</groupId>\n    <artifactId>jacoco-maven-plugin</artifactId>\n    <version>0.7.5.201505241946</version>\n    <executions>\n        <execution>\n            <id>pre-unit-test</id>\n            <goals>\n                <goal>prepare-agent</goal>\n            </goals>\n        </execution>\n        <execution>\n            <id>post-unit-test</id>\n            <phase>test</phase>\n            <goals>\n                <goal>report</goal>\n            </goals>\n        </execution>\n    </executions>\n</plugin>\n\nMy Project is a private project on gitlab.com.\nPipeline and its all 4 jobs passed successfully.\nHow can I see the coverage reports?"}, {"role": "assistant", "content": "It seems you forgot to add the calls to cat in your .gitlab-ci.yml file.\nYou should have something like that:\nscript:\n    - mvn $MAVEN_CLI_OPTS test\n    - cat target/site/jacoco/index.html\n\nThat being said, I don't think this is the best way of doing this, as you need to pollute your output with raw HTML in order to retreive the desired coverage value.\nI would recommend using the method described in this pull request instead: https://github.com/jacoco/jacoco/pull/488\n\nKeep the jacoco parts in your build.xml\nUse this awk instruction to print the correct code coverage total:\nawk -F\",\" '{ instructions += $4 + $5; covered += $5 } END { print covered, \"/\", \ninstructions, \"instructions covered\"; print 100*covered/instructions, \"% \ncovered\" }' target/site/jacoco/jacoco.csv\n\nReplace the Gitlab CI regexp with what the instruction returns: \\d+.\\d+ \\% covered\n\nEdit:\nAs of Gitlab 8.17, you can define the regexp directly inside the .gitlab-ci.yml file, as stated in the documentation.\nIt may seem superfluous, but if this regexp is now part of your repository history, you can change it alongside the other tools used to compute it."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is a GitLab instance URL, and how can I get it?\n\nI have tried searching for it everywhere, but I can\u2019t find anything.\nIt would be really awesome if someone could define it straight out of the box.\nI don\u2019t know what an instance of GitLab URL is. I\u2019m asking if someone could clarify what it is, and where can I get it. I am currently trying to add it in Visual Studio Code extension GitLab Workflow. The extension is asking for my GitLab instance URL, and I don\u2019t know where to get it."}, {"role": "assistant", "content": "The instance URL of any GitLab install is basically the link to the GitLab you're trying to connect to.\nFor example, if your project is hosted on gitlab.example.com/yourname/yourproject then for the instance URL enter https://gitlab.example.com.\nAnother example, if your project is hosted on gitlab.com/username/project then the instance URL is https://gitlab.com. Though note that in the VS Code extension specifically, gitlab.com is the default so you can leave it blank in this case."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Clearing the pipeline cache with Gitlab CI\n\nIs it possible to invalidate or clear a pipeline cache with the Gitlab CI after a pipeline completes?\nMy .gitlab-ci.yml file has the following global cache definition\ncache:\n  key: \"%CI_PIPELINE_ID%\"\n  paths:\n    - './msvc/Project1`/bin/Debug'\n    - './msvc/Project2`/bin/Debug'\n    - './msvc/Project3`/bin/Debug'\n\nThe cache-key value specifies that each pipeline should maintain it's own cache, which is working fine, but the cache file continues to exist after the pipeline completes. With hundreds of pipelines being run, the size starts to add up and manually deleting the cache folder on our machine isn't a great solution.\nI tried adding a cleanup job at the end of the pipeline\ncleanup:\n  stage: cleanup\n  script:\n  - rm -rf './msvc/Project1/bin'\n  - rm -rf './msvc/Project2/bin'\n  - rm -rf './msvc/Project3/bin'\n  when: always\n\nWhich deletes the local files, but won't delete them from the cache.\nAm I missing something here?\nCurrently running Gitlab-EE 10.3.3"}, {"role": "assistant", "content": "Artifacts are the solution as mentioned in the comments. However there is an option to clear caches in the Pipelines page as shown in the image below."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to set variable within 'script' section of gitlab-ci.yml file\n\nI am trying to set an environment variable for my GitLab Runner based on the branch that the commit originated from.\nI have 4 kubernetes clusters: staging, integration, production, and qa. Essentially I want to deploy my application to the proper cluster based on the branch I am pushing to.\nimage: google/cloud-sdk:latest\nvariables:\nDOCKER_HOST: tcp://docker:2375/\nDOCKER_DRIVER: overlay2\nservices:\n  - docker:dind\nbefore_script:\n  - docker info\nstages:\n  - publish\npublish:\nstage: publish\nscript:\n  - if [ \"$CI_COMMIT_REF_NAME\" = \"master\" ]; then $ENVIRONMENT=\"production\"; else $ENVIRONMENT=\"$CI_COMMIT_REF_NAME\"; fi\n  - echo $ENVIRONMENT\n   .\n   .\n   .\n  - kubectl apply -f cfg/${ENVIRONMENT}/web-deployment.yaml\nonly:\n - master\n - integration\n - qa\n - staging\n\nAny time I run my script with a different form of the if statement I get the following error:\n/bin/bash: line 83: =integration: command not found\nERROR: Job failed: exit code 1\n\nSo from what I can tell the variable is being set, but the script exits. I've seen several SO questions related to this problem, but nothing about how to set a variable and then continue a script. How can I fix this issue?"}, {"role": "assistant", "content": "The comment above helped me figure it out. So I use a VERSION file that right now contains 0.0.0 which I manipulate to create other variables\n  # determine what branch I am on\n  - if [ \"$CI_COMMIT_REF_NAME\" = \"master\" ]; then ENVIRONMENT=\"qa\"; else ENVIRONMENT=\"$CI_COMMIT_REF_NAME\"; fi\n\n  # determine patch number for semver\n  - PATCH=`git log --pretty=oneline | wc -l | sed -e 's/^[[:space:]]*//'`\n  - VERSION=`cat VERSION`\n\n  # drop trailing 0 from VERSION\n  - VERSION=${VERSION%?}\n\n  # set all env variables\n  - TAG=\"${VERSION}${PATCH}\"\n  - IMAGE=\"${TAG}-${ENVIRONMENT}\" # used for Kubernetes\n  - API_HOST=\"https://api.${ENVIRONMENT}.my-app.com/\"\n  - WEB_HOST=\"https://www.${ENVIRONMENT}.my-app.com/\"\n\n  # pass enviornment variables to make \n  - ENVIRONMENT=\"$ENVIRONMENT\" IMAGE=\"$IMAGE\" API_HOST=\"$API_HOST\" WEB_HOST=\"$WEB_HOST\" make\n\n  # make has a step that calls sed and replaces text inline in this file to prepare Kubernetes\n  - kubectl apply -f cfg/web-deployment.yaml\n\n  # create a tag in the repo after deployment is done\n  - curl -X POST --silent --insecure --show-error --fail \"https://gitlab.com/api/v4/projects/${CI_PROJECT_ID}/repository/tags?tag_name=${TAG}&ref=${CI_COMMIT_SHA}&private_token=${GITLAB_TOKEN}\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How can I let the gitlab-ci-runner DinD image cache intermediate images?\n\nI have a Dockerfile that starts with installing the texlive-full package, which is huge and takes a long time. If I docker build it locally, the intermedate image created after installation is cached, and subsequent builds are fast.\nHowever, if I push to my own GitLab install and the GitLab-CI build runner starts, this always seems to start from scratch, redownloading the FROM image, and doing the apt-get install again. This seems like a huge waste to me, so I'm trying to figure out how to get the GitLab DinD image to cache the intermediate images between builds, without luck so far.\nI have tried using the --cache-dir and --docker-cache-dir for the gitlab-runner register command, to no avail.\nIs this even something the gitlab-runner DinD image is supposed to be able to do?\nMy .gitlab-ci.yml:\nbuild_job:\n    script:\n    - docker build --tag=example/foo .\n\nMy Dockerfile:\nFROM php:5.6-fpm\nMAINTAINER Roel Harbers <[email\u00a0protected]>\nRUN apt-get update && apt-get install -qq -y --fix-missing --no-install-recommends texlive-full\nRUN echo Do other stuff that has to be done every build.\n\nI use GitLab CE 8.4.0 and gitlab/gitlab-runner:latest as runner, started as\ndocker run -d --name gitlab-runner --restart always \\\n    -v /var/run/docker.sock:/var/run/docker.sock \\\n    -v /usr/local/gitlab-ci-runner/config:/etc/gitlab-runner \\\n    gitlab/gitlab-runner:latest \\\n; \\\n\nThe runner is registered using:\ndocker exec -it gitlab-runner gitlab-runner register \\\n    --name foo.example.com \\\n    --url https://gitlab.example.com/ci \\\n    --cache-dir /cache/build/ \\\n    --executor docker \\\n    --docker-image gitlab/dind:latest \\\n    --docker-privileged \\\n    --docker-disable-cache false \\\n    --docker-cache-dir /cache/docker/ \\\n; \\\n\nThis creates the following config.toml:\nconcurrent = 1\n[[runners]]\n    name = \"foo.example.com\"\n    url = \"https://gitlab.example.com/ci\"\n    token = \"foobarsldkflkdsjfkldsj\"\n    tls-ca-file = \"\"\n    executor = \"docker\"\n    cache_dir = \"/cache/build/\"\n    [runners.docker]\n        image = \"gitlab/dind:latest\"\n        privileged = true\n        disable_cache = false\n        volumes = [\"/cache\"]\n        cache_dir = \"/cache/docker/\"\n\n(I have experimented with different values for cache_dir, docker_cache_dir and disable_cache, all with the same result: no caching whatsoever)"}, {"role": "assistant", "content": "I suppose there's no simple answer to your question. Before adding some details, I strongly suggest to read this blog article from the maintainer of DinD, which was originally named \"do not use Docker in Docker for CI\".\nWhat you might try is declaring /var/lib/docker as a volume for your GitLab runner. But be warned, depending on your file-system drivers you may use AUFS in the container on an AUFS filesystem on your host, which is very likely to cause problems.\nWhat I'd suggest to you is creating a separate Docker-VM, only for the runner(s), and bind-mount docker.sock from the VM into your runner-container.\nWe are using this setup with GitLab with great success (>27.000 builds in about 12 months).\nYou can take a look at our runner with docker-compose support which is actually based on the shell-executor of GitLab's runner."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "FATAL: Failed to start gitlab-runner: \"launchctl\" failed with stderr: Load failed: 5: Input/output error\n\nAfter installing and registering gitlab-runner, when I'm running gitlab-runner start I get this error message. What will be the reason for this ?\nRuntime platform                                    arch=amd64 os=darwin pid=65915 revision=c1edb478 version=14.0.1\nFATAL: Failed to start gitlab-runner: \"launchctl\" failed with stderr: Load failed: 5: Input/output error"}, {"role": "assistant", "content": "I edited the /Users/$USER/Library/LaunchAgents/gitlab-runner.plist file and changed the location of the log files to a location writeable by my user:\n<key>StandardOutPath</key>\n    <string>/Users/USERNAME/.gitlab-runner/gitlab-runner.out.log</string>\n<key>StandardErrorPath</key>\n    <string>/Users/USERNAME/.gitlab-runner/gitlab-runner.err.log</string>\n\nThen issued a\nlaunchctl unload /Users/$USER/Library/LaunchAgents/gitlab-runner.plist\nlaunchctl load -w /Users/$USER/Library/LaunchAgents/gitlab-runner.plist\ngitlab-runner stop\ngitlab-runner start\ngitlab-runner status\n\nAnd the service is up and running\nFor more info: https://gitlab.com/gitlab-org/gitlab-runner/-/issues/28136\nEDIT:\nSee also GitLab Issue #29383 where Brad King wrote a single sed command to edit the file for you:\ngitlab-runner install\nsed -i '' \"s|/usr/local/var/log/|$HOME/.gitlab-runner/|\" ~/Library/LaunchAgents/gitlab-runner.plist\ngitlab-runner start"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How can you execute Gitlab stages conditionally?\n\nThere are 3 stages - build, test and deploy in .gitlab-ci.yml.\nA nightly regression test stage needs to be run nightly.\nHere's the relevant .gitlab-ci.yml code:\nstages:\n  - build\n  - test\n  - deploy\n\nbuild_project:\n  stage: build\n  script:\n    - cd ./some-dir\n    - build-script.sh\n  except:\n  - tags\n\n#Run this only when say variable 'NIGHTLY_TEST == True'. But HOW?\nnightly_regression_test_project:\n  stage: test\n  script:\n    - cd ./some-dir\n    - execute test-script\n\nTagging daily to only run the test stage is not preferable.\nAny other ideas?"}, {"role": "assistant", "content": "except and only can specify variables that will trigger them.\nYou can use the following in your .gitlab-ci.yml:\nbuild1:\n  stage: build\n  script:\n    - echo \"Only when NIGHTLY_TEST is false\"\n  except:\n    variables:\n      - $NIGHTLY_TEST \n    \ntest1:\n  stage: test\n  script: \n    - echo \"Only when NIGHTLY_TEST is true\"\n  only:\n    variables:\n      - $NIGHTLY_TEST"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I establish manual stages in Gitlab CI?\n\nI'd can't seem to find any documentation of manual staging in Gitlab CI in version 8.9. How do I do a manual stage such as \"Deploy to Test\"? \nI'd like Gitlab CI to deploy a successful RPM to dev, and then once I've reviewed it, push to Test, and from there generate a release. Is this possible with Gitlab CI currently?"}, {"role": "assistant", "content": "You can set tasks to be manual by using when: manual in the job (documentation).\nSo for example, if you want to want the deployment to happen at every push but give the option to manually tear down the infrastructure, this is how you would do it:\nstages:\n  - deploy\n  - destroy\n\ndeploy:\n  stage: deploy\n  script:\n    - [STEPS TO DEPLOY]\n\ndestroy:\n  stage: destroy\n  script:\n    - [STEPS TO DESTROY]\n  when: manual\n\nWith the above config, if you go to the GitLab project > Pipelines, you should see a play button next to the last commit. When you click the play button you can see the destroy option."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Creating pull requests in gitlab\n\nI have a GitLab installation running, and I have a repository that I want to share with my friends. I can't understand the flow of sending pull requests in GitLab.\nA user can't fork my repository or access my project (unless he is my on team). A merge request can be from one branch to another in my repository.\nHow do pull requests work in GitLab?"}, {"role": "assistant", "content": "GitLab.com co-founder here. Forking should work fine in recent versions of GitLab (6.x). You can fork a repo belonging to someone else and then create a merge request (the properly named version of the GitHub pull request)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI - docker: command not found\n\nI am trying to build my docker image within the gitlab ci pipeline.\nHowever it is not able to find the docker command.\n\n/bin/bash: line 69: docker: command not found ERROR: Job failed: error\n  executing remote command: command terminated with non-zero exit code:\n  Error executing in Docker Container: 1\n\n.gitlab-ci.yml\nstages:\n  - quality\n  - test\n  - build\n  - deploy\n\nimage: node:8.11.3\n\nservices:\n  - mongo\n  - docker:dind\n\nbefore_script:\n- npm install\n\nquality:\n  stage: quality\n  script:\n  - npm run-script lint\n\ntest:\n  stage: test\n  script:\n  - npm run-script test\n\nbuild:\n  stage: build\n  script:\n  - docker build -t server .\n\ndeploy:\n  stage: deploy\n  script:\n  - echo \"TODO deploy push docker image\""}, {"role": "assistant", "content": "you need to choose an image including docker binaries\nimage: gitlab/dind\n\nservices:\n  - docker:dind"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitKraken won't let me open my Private Repository on GitLab\n\nSo, in addition to GitKraken won't let me clone from a private repo on GitHub\nI get this screen when opening my GitLab Repo:\n\nAnyone got a solution of how to make my Repo 'non-private' or how to make GitKraken let me open this without the Pro Plan?\nAlready tried:\n\nGenerating new SSH Key in GitKraken\nRemoving Repo, Generate new GitLab connection, Clone Repo\nChecked GitLab: GitKraken is an Authorized applications\nGit Pull via command line gives no trouble, so no permission issue\n..."}, {"role": "assistant", "content": "6.5.1 is the last version to support private repo. You can see the release details at this link https://blog.axosoft.com/gitkraken-v6-0/#pricing-changes OR https://support.gitkraken.com/release-notes/6x/\nAnd you can also download it (Mac version) from Axosoft https://release.axocdn.com/darwin/GitKraken-v6.5.1.zip OR https://release.gitkraken.com/darwin/GitKraken-v6.5.1.zip\nI not sure how to turn off the automatic update function, so if you turn off GitKraken completely and reopen it, it will update to the latest version.\n=======\nUpdated\nBlock IP Address for updating\nFor MacOS\necho \"127.0.0.1 release.gitkraken.com\" >> /private/etc/hosts\n\n\nWindows 10 \u2013 \u201cC:\\Windows\\System32\\drivers\\etc\\hosts\u201d\nLinux \u2013 \u201c/etc/hosts\u201d\nMac OS X \u2013 \u201c/private/etc/hosts\u201d"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab: Runner is offline, last contact was about some hours ago\n\nrecently my runners have been stopped and I don't know why?\nI've just upgraded nodejs on the server and it did happen.\nafter this problem, I've tried to update gitlab to the latest version and check the runner status but the problem still persists and in the title of grey icon shows: \n\nRunner is offline, the last contact was about 22 hours ago.\n\n\nWhat should I do?\nand when I try to Retry stuck jobs, see this error:\n\nThis job is stuck, because you don't have any active runners online with any of these tags assigned to them: 'my label'.\n\nAny Help is appreciated!"}, {"role": "assistant", "content": "To me, the following solved the problem:\ngitlab-runner restart\n\nWhere gitlab-runner is a symlink to gitlab-ci-multi-runner:\n\nGitLab Runner is the open source project that is used to run your jobs and send the results back to GitLab. It is used in conjunction with GitLab CI, the open-source continuous integration service included with GitLab that coordinates the jobs."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Access GitLab repo with project access token\n\nAccording to the documentation, it should be possible to access GitLab repos with project access tokens:\n\nThe username is set to project_{project_id}_bot, such as project_123_bot.\n\nNever mind that that's a lie -- the actual user is called project_4194_bot1 in my case; apparently they increment a number for subsequent tokens.\nEither way -- and I have tried both with and without the trailing 1 -- I would expect\ngit clone \"https://project_4194_bot1:[email\u00a0protected]/my-group/my-project.git\"\n\nto succeed, same as with my.username:$PERSONAL_TOKEN (which works perfectly). However, I get\nremote: HTTP Basic: Access denied\nfatal: Authentication failed for '<snip>'\n\nWhat may be going on here? How can I access GitLab repositories using project access tokens?\n\nIt's not as if we'd get that far, but FWIW, the token seems to have sufficient permissions:"}, {"role": "assistant", "content": "It seems that using the project name as username works. In your case replacing project_4194_bot1 with my-project should work:\ngit clone \"https://my-project:[email\u00a0protected]/my-group/my-project.git\"\n\nEDIT: One can actually use any non-blank value as a username (see docs), as others correctly pointed out."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "502 Whoops, GitLab is taking too much time to respond\n\nI installed Gitlab on Raspberry Pi2, and it had worked well for a couple of months. But since shutting down the power of RPi, it doesn't work anymore. The webpage returns 502 error.\n\n502 Whoops, GitLab is taking too much time to respond.\n\nSo I tried reconfigure (sudo gitlab-ctl reconfigure) but, it failed with the error message:\nFATAL: Errono::EAFNOSUPPORT: Address family not supported by protocol - socket(2)\n\nI don't know how to resolve this problem."}, {"role": "assistant", "content": "I saw issue like this several times.\nIf GitLab has been worked fine please do not touch anything. Just wait. It seems GitLab has not been started properly :(\nI mean that after booting system you have to wait 1-2 minutes before using GitLab. GitLab needs some time for starting."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab signup users without email confirmation\n\nI want to setup a gitlab instance for internal use. Since the instance can only be reached over a local network I haven't setup the email setup. Unfortunately gitlab still wants to sent new users confirmation emails with a temporary password, but they never receive this email.\nIs there a way to configure gitlab so that it doesn't send these confirmation mails? I already tried to set email_enabled: false in gitlab.yml but it didn't work.\nUpdate:\nIt should work without me having to interfere manually in the signup process."}, {"role": "assistant", "content": "Admin can confirm user manually!\n\nLogin gitlab with admin account and create a new user (Mini), ignore password.\nAdmin area ---> users ---> edit Mini user ---> set password.\nUser Mini can login gitlab."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "High memory usage for Gitlab CE\n\nLook at this picture showing gitlab ce memory consumption.\n\nI really dont need all of those workers, sidekiq or unicorn or all of those daemon. This is on IDLE. I mean, I installed this to manage 1 project, with like 4 people, I dont need all those daemon. Is there any way to reduce this ?"}, {"role": "assistant", "content": "I also had problems with gitlab's high memory consumption. So I ran the linux tool htop.\nIn my case I found out that the postgresl service used most of the memory.\nWith postgres service running 14.5G of 16G were used\nI stopped one gitlab service after the other and found out that when I stop postgres a lot of memory was freed.\n\nYou can try it\ngitlab-ctl stop postgresql\n\nand start the service again with\ngitlab-ctl start postgresql\n\nFinally I came across the following configuration in /etc/gitlab/gitlab.rb\n##! **recommend value is 1/4 of total RAM, up to 14GB.**\n# postgresql['shared_buffers'] = \"256MB\"\n\nI just set the shared buffers to 256MB by removing the comment #, because 256MB is sufficient for me.\npostgresql['shared_buffers'] = \"256MB\"\n\nand executed gitlab-ctl reconfigure. gitlab-ctl restarts the affected services and the memory consumption is now very moderate.\n\nHopefully that helps someone else."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to deploy to Heroku directly from my Gitlab repository\n\nIn my team, we use Gitlab as a remote repository, so we are looking for a solution to auto deploy our apps to Heroku. We found Codeship for auto deploying apps to Heroku from Github.\nAny tips? Tricks?"}, {"role": "assistant", "content": "If you are not prepared to use Ruby/dpl you can deploy to Heroku as follows:\nLook up your Heroku API key (Account settings -> API Key on the Heroku web console) and make it available as a Gitlab secret variable e.g. HEROKU_API_KEY  (Please note the values is not the same as what heroku auth:token returns...)\nThen add two script lines in your .gitlab-ci.yml config file at the relevant job:\ngit remote add heroku https://heroku:[email\u00a0protected]/<name of your heroku app>.git\n\ngit push -f heroku HEAD:master\n\nYou can see detailed explanation at http://blog.thecodewhisperer.com/permalink/deploying-jekyll-to-heroku-using-gitlab-ci"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to manage signing keystore in Gitlab CI for android\n\nDear stackoverflow community, once more I turn to you :)\nI've recently come across the wonder of Gitlab and their very nice bundled CI/CD solution. It works gallantly however, we all need to sign our binaries don't we and I've found no way to upload a key as I would to a Jenkins server for doing this.\nSo, how can I, without checking in my keys and secrets sign my android (actually flutter) application when building a release?\nFrom what I see, most people define the build job with signing settings referring to a non-committed key.properties file specifying a local keystore.jks. This works fine when building APKs locally but if I would like to build and archive them as a part of the CI/CD job, how do I?\nFor secret keys, for example the passwords to the keystore itself, I've found that I can simply store them as protected variables but the actual keystore file itself. What can I do about that?\nAny ideas, suggestions are dearly welcome.\nCheers\nEdit:\nI apologise for never marking a right answer here and as @IvanP proposed the solution of writing individual values to a file was what I used for a long time. But as @VonC added later, Gitlab now has the capability to data as actual files which simplifies this so I am marking that as the correct answer."}, {"role": "assistant", "content": "Usually I store keystore file (as base64 string), alias and passwords to Gitlab's secrets variables.\nIn the .gitlab-ci.yml do something like:\ncreate_property_files:\n  stage: prepare\n  only:\n    - master\n  script:\n    - echo $KEYSTORE | base64 -d > my.keystore\n    - echo \"keystorePath=my.keystore\" > signing.properties\n    - echo \"keystorePassword=$KEYSTORE_PASSWORD\" >> signing.properties\n    - echo \"keyAlias=$ALIAS\" >> signing.properties\n    - echo \"keyPassword=$KEY_PASSWORD\" >> signing.properties\n  artifacts:\n    paths:\n      - my.keystore\n      - signing.properties\n    expire_in: 10 mins\n\nAnd, finally, in your build gradle:\nsigningConfigs {\n    release {\n        file(\"../signing.properties\").with { propFile ->\n            if (propFile.canRead()) {\n                def properties = new Properties()\n                properties.load(new FileInputStream(propFile))\n\n                storeFile file(properties['keystorePath'])\n                storePassword properties['keystorePassword']\n                keyAlias properties['keyAlias']\n                keyPassword properties['keyPassword']\n            } else {\n                println 'Unable to read signing.properties'\n            }\n        }\n    }\n}"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab prompts for password while push for git user\n\nI installed gitlab on my servers at linode. All services of gitlab are working fantastic. I am able to login, create users, repos etc.\nBut the problem I am facing is when I try to push a repo it prompts a password for the git user as follows:\n[email\u00a0protected]'s password\n\nI have followed the instructions of installing gitlab at: https://github.com/gitlabhq/gitlabhq/blob/master/doc/install/installation.md and have disable the login got the user git using the following line mentioned in the installation guide:\n\nsudo adduser --disabled-login --gecos 'GitLab' git\n\nI am using gitlab version 6. What could be the problem?\nThe output of: ssh -Tvvv [email\u00a0protected] is as follows:\nOpenSSH_5.9p1 Debian-5ubuntu1.1, OpenSSL 1.0.1 14 Mar 2012\ndebug1: Reading configuration data /etc/ssh/ssh_config\ndebug1: /etc/ssh/ssh_config line 19: Applying options for *\ndebug2: ssh_connect: needpriv 0\ndebug1: Connecting to gitlab.myserver.com [MY_IP] port 22.\ndebug1: Connection established.\ndebug3: Incorrect RSA1 identifier\ndebug3: Could not load \"/home/swaroop/.ssh/id_rsa\" as a RSA1 public key\ndebug1: identity file /home/swaroop/.ssh/id_rsa type 1\ndebug1: Checking blacklist file /usr/share/ssh/blacklist.RSA-2048\ndebug1: Checking blacklist file /etc/ssh/blacklist.RSA-2048\ndebug1: identity file /home/swaroop/.ssh/id_rsa-cert type -1\ndebug1: identity file /home/swaroop/.ssh/id_dsa type -1\ndebug1: identity file /home/swaroop/.ssh/id_dsa-cert type -1\ndebug1: identity file /home/swaroop/.ssh/id_ecdsa type -1\ndebug1: identity file /home/swaroop/.ssh/id_ecdsa-cert type -1\ndebug1: Remote protocol version 2.0, remote software version OpenSSH_5.9p1 Debian-5ubuntu1.1\ndebug1: match: OpenSSH_5.9p1 Debian-5ubuntu1.1 pat OpenSSH*\ndebug1: Enabling compatibility mode for protocol 2.0\ndebug1: Local version string SSH-2.0-OpenSSH_5.9p1 Debian-5ubuntu1.1\ndebug2: fd 3 setting O_NONBLOCK\ndebug3: load_hostkeys: loading entries for host \"gitlab.myserver.com\" from file \"/home/swaroop/.ssh/known_hosts\"\ndebug3: load_hostkeys: found key type ECDSA in file /home/swaroop/.ssh/known_hosts:92\ndebug3: load_hostkeys: loaded 1 keys\ndebug3: order_hostkeyalgs: prefer hostkeyalgs: [email\u00a0protected],[email\u00a0protected],[email\u00a0protected],ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521\ndebug1: SSH2_MSG_KEXINIT sent\ndebug1: SSH2_MSG_KEXINIT received\ndebug2: kex_parse_kexinit: ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group-exchange-sha1,diffie-hellman-group14-sha1,diffie-hellman-group1-sha1\ndebug2: kex_parse_kexinit: [email\u00a0protected],[email\u00a0protected],[email\u00a0protected],ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],ssh-rsa,ssh-dss\ndebug2: kex_parse_kexinit: aes128-ctr,aes192-ctr,aes256-ctr,arcfour256,arcfour128,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,[email\u00a0protected]\ndebug2: kex_parse_kexinit: aes128-ctr,aes192-ctr,aes256-ctr,arcfour256,arcfour128,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,[email\u00a0protected]\ndebug2: kex_parse_kexinit: hmac-md5,hmac-sha1,[email\u00a0protected],hmac-sha2-256,hmac-sha2-256-96,hmac-sha2-512,hmac-sha2-512-96,hmac-ripemd160,[email\u00a0protected],hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: hmac-md5,hmac-sha1,[email\u00a0protected],hmac-sha2-256,hmac-sha2-256-96,hmac-sha2-512,hmac-sha2-512-96,hmac-ripemd160,[email\u00a0protected],hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: none,[email\u00a0protected],zlib\ndebug2: kex_parse_kexinit: none,[email\u00a0protected],zlib\ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: first_kex_follows 0 \ndebug2: kex_parse_kexinit: reserved 0 \ndebug2: kex_parse_kexinit: ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group-exchange-sha1,diffie-hellman-group14-sha1,diffie-hellman-group1-sha1\ndebug2: kex_parse_kexinit: ssh-rsa,ssh-dss,ecdsa-sha2-nistp256\ndebug2: kex_parse_kexinit: aes128-ctr,aes192-ctr,aes256-ctr,arcfour256,arcfour128,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,[email\u00a0protected]\ndebug2: kex_parse_kexinit: aes128-ctr,aes192-ctr,aes256-ctr,arcfour256,arcfour128,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,[email\u00a0protected]\ndebug2: kex_parse_kexinit: hmac-md5,hmac-sha1,[email\u00a0protected],hmac-sha2-256,hmac-sha2-256-96,hmac-sha2-512,hmac-sha2-512-96,hmac-ripemd160,[email\u00a0protected],hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: hmac-md5,hmac-sha1,[email\u00a0protected],hmac-sha2-256,hmac-sha2-256-96,hmac-sha2-512,hmac-sha2-512-96,hmac-ripemd160,[email\u00a0protected],hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: none,[email\u00a0protected]\ndebug2: kex_parse_kexinit: none,[email\u00a0protected]\ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: first_kex_follows 0 \ndebug2: kex_parse_kexinit: reserved 0 \ndebug2: mac_setup: found hmac-md5\ndebug1: kex: server->client aes128-ctr hmac-md5 none\ndebug2: mac_setup: found hmac-md5\ndebug1: kex: client->server aes128-ctr hmac-md5 none\ndebug1: sending SSH2_MSG_KEX_ECDH_INIT\ndebug1: expecting SSH2_MSG_KEX_ECDH_REPLY\ndebug1: Server host key: ECDSA 92:57:61:35:b1:e2:16:3b:7f:ae:e7:8a:dc:0c:98:83\ndebug3: load_hostkeys: loading entries for host \"gitlab.myserver.com\" from file \"/home/swaroop/.ssh/known_hosts\"\ndebug3: load_hostkeys: found key type ECDSA in file /home/swaroop/.ssh/known_hosts:92\ndebug3: load_hostkeys: loaded 1 keys\ndebug3: load_hostkeys: loading entries for host \"MY_IP\" from file \"/home/swaroop/.ssh/known_hosts\"\ndebug3: load_hostkeys: found key type ECDSA in file /home/swaroop/.ssh/known_hosts:93\ndebug3: load_hostkeys: loaded 1 keys\ndebug1: Host 'gitlab.myserver.com' is known and matches the ECDSA host key.\ndebug1: Found key in /home/swaroop/.ssh/known_hosts:92\ndebug1: ssh_ecdsa_verify: signature correct\ndebug2: kex_derive_keys\ndebug2: set_newkeys: mode 1\ndebug1: SSH2_MSG_NEWKEYS sent\ndebug1: expecting SSH2_MSG_NEWKEYS\ndebug2: set_newkeys: mode 0\ndebug1: SSH2_MSG_NEWKEYS received\ndebug1: Roaming not allowed by server\ndebug1: SSH2_MSG_SERVICE_REQUEST sent\ndebug2: service_accept: ssh-userauth\ndebug1: SSH2_MSG_SERVICE_ACCEPT received\ndebug2: key: /home/swaroop/.ssh/id_rsa (0x7fd470589410)\ndebug2: key: /home/swaroop/.ssh/id_dsa ((nil))\ndebug2: key: /home/swaroop/.ssh/id_ecdsa ((nil))\ndebug1: Authentications that can continue: publickey,password\ndebug3: start over, passed a different list publickey,password\ndebug3: preferred gssapi-keyex,gssapi-with-mic,publickey,keyboard-interactive,password\ndebug3: authmethod_lookup publickey\ndebug3: remaining preferred: keyboard-interactive,password\ndebug3: authmethod_is_enabled publickey\ndebug1: Next authentication method: publickey\ndebug1: Offering RSA public key: /home/swaroop/.ssh/id_rsa\ndebug3: send_pubkey_test\ndebug2: we sent a publickey packet, wait for reply\ndebug1: Authentications that can continue: publickey,password\ndebug1: Trying private key: /home/swaroop/.ssh/id_dsa\ndebug3: no such identity: /home/swaroop/.ssh/id_dsa\ndebug1: Trying private key: /home/swaroop/.ssh/id_ecdsa\ndebug3: no such identity: /home/swaroop/.ssh/id_ecdsa\ndebug2: we did not send a packet, disable method\ndebug3: authmethod_lookup password\ndebug3: remaining preferred: ,password\ndebug3: authmethod_is_enabled password\ndebug1: Next authentication method: password\n[email\u00a0protected]'s password: \n\nAlso following is the output when I run: rvmsudo -u git -H  bundle exec rake gitlab:env:info RAILS_ENV=production\nSystem information\nSystem:     Ubuntu 12.04\nCurrent User:   git\nUsing RVM:  yes\nRVM Version:    1.22.3\nRuby Version:   2.0.0p247\nGem Version:    2.0.7\nBundler Version:1.3.5\nRake Version:   10.1.0\n\nGitLab information\nVersion:    6.0.0\nRevision:   6c1c284\nDirectory:  /home/git/gitlab\nDB Adapter: mysql2\nURL:        http://gitlab.myserver.com\nHTTP Clone URL: http://gitlab.myserver.com/some-project.git\nSSH Clone URL:  [email\u00a0protected]:some-project.git\nUsing LDAP: no\nUsing Omniauth: no\n\nGitLab Shell\nVersion:    1.7.0\nRepositories:   /home/git/repositories/\nHooks:      /home/git/gitlab-shell/hooks/\nGit:        /usr/bin/git"}, {"role": "assistant", "content": "I had the same problem but it was because my server only accept ssh login from users of \"sshusers\".\nOn /etc/ssh/sshd_config I had the following line : \nAllowGroups sshusers\n\nIn order to fix this issue, I added git to sshusers group: \n$ sudo adduser git sshusers \n\nAnd then it's working."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Getting \"Repositroy test has failed\" error while cloning repository from Gitlab in Android Studio?\n\nI will like to clone my android code from gitlab repository in Android Studio 0.8.1.I checked into VCS >> Checked out from Version Control >> Git >> Added HTTP url here.It prompts me that \"Repositroy test has failed\".Kindly help me to sort out the issue.I have checked the plugins as well.Thanks a lot."}, {"role": "assistant", "content": "You need to download and install git from http://git-scm.com/downloads\nThen you need to track the git.exe on AndroidStudio:\n\nGo to Settings > Project Settings > Version Control > VCSs > Git > Path to Git executable\nSelect (or type) executable path, eg: D:\\Program Files (x86)\\Git\\cmd\\git.exe\n\nIf you installed GitHub Desktop for Windows\nIn case you have GitHub Desktop for Windows, git.exe will be found at C:\\Users\\YOUR_USER_NAME\\AppData\\Local\\GitHub\\PortableGit_c7e0cbde92ba565zz218z5214zzz0e854zzza28\\cmd."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "private repo - go 1.13 - `go mod ..` failed: ping \"sum.golang.org/lookup\" .. verifying package .. 410 gone\n\nI am using golang 1.13 . \nI have a project that depends on a private gitlab project. \nI have the ssh keys for the same. \nWhen I try to retrieve the dependencies for a newly created module, I am getting the following error: \n$ go version\ngo version go1.13 linux/amd64\n\n$ go mod why\ngo: downloading gitlab.com/mycompany/myproject v0.0.145\nverifying gitlab.com/mycompany/[email\u00a0protected]: gitlab.com/mycompany/[email\u00a0protected]: reading https://sum.golang.org/lookup/gitlab.com/mycompany/[email\u00a0protected]: 410 Gone\n\nI have no idea why it is trying to ping sum.golang.org/lookup since it is a private gitlab project. \nMy ~/.gitconfig contains the following (based on my looking up in google search for similar errors)\n# Enforce SSH\n[url \"ssh://[email\u00a0protected]/\"]\n  insteadOf = https://github.com/\n[url \"ssh://[email\u00a0protected]/\"]\n        insteadOf = https://gitlab.com/\n[url \"ssh://[email\u00a0protected]/\"]\n  insteadOf = https://bitbucket.org/\n[url \"[email\u00a0protected]:\"]\n        insteadOf = https://gitlab.com/\n\nThe error still persists. \nI would expect the package to be downloaded from my private gitlab project repository to the current project. \nIs there anything I need to do in my private gitlab project repository to make it ready for 'go get' ? \nThe private gitlab project repository already contains the go.sum and go.mod for the project as well. \nAnything that I am missing ?\nedit: 1) The private repo name and the company name contains no asterisks or any other special characters. only alphabets and not even numeric characters."}, {"role": "assistant", "content": "Answering my own question after looking up, \nSetting the GOPRIVATE variable seems to help.\nGOPRIVATE=gitlab.com/mycompany/*  go mod why\n\n\"\nThe new GOPRIVATE environment variable indicates module paths that are not publicly available. It serves as the default value for the lower-level GONOPROXY and GONOSUMDB variables, which provide finer-grained control over which modules are fetched via proxy and verified using the checksum database.\n\" from https://golang.org/doc/go1.13 \nAliter:\nSetting the env variable GONOSUMDB also seems to work. \nSpecifically, invoking the following command seems to help.\n    GONOSUMDB=gitlab.com/mycompany/* go mod why\n\nThe above env variable prevents the ping to sum.golang.org/lookup for a checksum match. It also prevents leaking the names of private repos to a public checksum db. [ Source - https://docs.gomods.io/configuration/sumdb/ ]\nAlso - here at\n  * GONOSUMDB=prefix1,prefix2,prefix3 sets a list of module path prefixes, again possibly containing globs, that should not be looked up using the database.\n\nsource: https://go.googlesource.com/proposal/+/master/design/25530-sumdb.md\nRelated Issues:\n\nhttps://github.com/golang/go/issues/32291 \nhttps://github.com/golang/go/issues/33985 \n[\"Go 1.13 has been released, and this issue was filed well after the freeze window. The proposed changes will not happen in 1.13, but don't assume they will necessarily happen in 1.14 either.\" from issue 33985 above. ]"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Configure runner to run multiple jobs at the same time\n\nWhen having one gitlab runner serving multiple projects, it can only run one CI pipeline while the other project pipelines have to queue.\nIs it possible to make a gitlab runner run pipelines from all projects in parallel?\nI don't seem to find anywhere a configuration explanation for this."}, {"role": "assistant", "content": "I believe the configuration options you are looking for is concurrent and limit, which you'd change in the GitLab Runners config.toml file.\nFrom the documentation:\n\nconcurrent: limits how many jobs globally can be run concurrently. The most upper limit of jobs using all defined runners. 0 does not mean unlimited\n\nlimit:  limit how many jobs can be handled concurrently by this token.\n\n\nThe location for the config.toml file:\n\n\n/etc/gitlab-runner/config.toml on *nix systems when GitLab Runner is\nexecuted as root (this is also path for service configuration)\n~/.gitlab-runner/config.toml on *nix systems when GitLab Runner is\nexecuted as non-root\n./config.toml on other systems\n\n\nUseful issue as well."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How can I debug e-mail sending on Gitlab?\n\nMy Gitlab (version 5) is not sending any e-mails and I am lost trying to figure out what is happening. The logs give no useful information. I configured it to used sendmail.\nI wrote a small script that sends e-mail through ActionMailer (I guess it is what gitlab uses to send e-mail, right?). And it sends the e-mail correctly.\nBut, on my Gitlab, I can guarantee that sendmail is not even being called.\nDo I need to enable something to get e-mail notifications? How can I debug my issue?\nUpdate\nThe problem is that I can not find any information anywhere. The thing just fails silently. Where can I find some kind of log? The logs in the log dir provide no useful information.\nMy question is, how can I make Gitlab be more verbose? How can I make it tell me what is going on?\nUpdate 2\nI just found a lot of mails scheduled on the Background jobs section. A lot of unprocessed Sidekiq::Extensions::DelayedMailer. What does it mean? Why were these jobs not processed?"}, {"role": "assistant", "content": "Stumbled upon this issue today, here's my research:\nDebugging SMTP connections in the GitLab GUI is not supported yet. However there is a pending feature request and a command line solution.\nSet the desired SMTP settings /etc/gitlab/gitlab.rb and run gitlab-ctl reconfigure (see https://docs.gitlab.com/omnibus/settings/smtp.html).\nStart the console running gitlab-rails console -e production.\nShow the configured delivery method (should be :smtp) running the command ActionMailer::Base.delivery_method. Show all configured SMTP settings running ActionMailer::Base.smtp_settings.\nTo send a test mail run\nNotify.test_email('[email\u00a0protected]', 'Hello World', 'This is a test message').deliver_now\n\nOn the admin page in GitLab, the section \u00bbBackground jobs\u00ab shows information about all jobs. Failing SMTP connections are listed there as well.\nPlease note, you may need to restart the GitLab instance in order to use the newly configured SMTP settings (on my instance the console was able to send mails, the GUI required a restart). Run gitlab-ctl restart to restart your instance."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is gitlab runner\n\nI think I'm fundamentally missing something. I'm new to CI/CD and trying to set up my first pipeline ever with gitlab.\nThe project is a pre-existing PHP project.\nI don't want to clean it up just yet, at the moment I've pushed the whole thing into a docker container and it's running fine talking to google cloud's mysql databases etc as it should locally and also on a remote google cloud testing VM.\nThe dream is to be able to push to the development branch, and then merge the dev banch into the test branch which then TRIGGERS automated tests (easy part), and also causes the remote test VM (hosted on google cloud), to PULL the newest changes, rebuild the image from the latest docker file (or pull the latest image from gitlab image register)... and then rebuild the container with the newest image.\nI'm playing around with gitlab's runner but I'm not understanding what it's actually for, despite looking through almost all the online content for it.\nDo I just install it in the google cloud VM, and then when I push to gitlab from my development machine.. the repo will 'signal' the runner (which is running on the VM, to execute a bunch of scripts (which might include git pull on the newest changes?).\nBecause I already pre-package my app into a container locally (and push the image to the image registry) do I need to use docker as my executor on the runner? or can i just use shell and shell the commands in?\nWhat am I missing?\nTLDR and extra:\nQuestions:\n\nWhat is runner actually for,\nwhere is it meant to be installed?\nDoes it care which directory it is run in?\nIf it doesn't care which directory it's run,\nwhere does it execute it's script commands? At root?\nIf I am locally building my own images and uploading them to gitlab's registry,\n\nDo I need to set my executor to docker? Shouldn't I just set it to shell, pull the image, and build it? (Assuming the runner is runing on the remote VM)."}, {"role": "assistant", "content": "What is runner actually for?\n\nYou have your project along with a .gitlab-ci.yml file. .gitlab-ci.yml defines what stages your CI/CD pipeline has and what to do in each stage. This typically consists of a build,test,deploy stages. Within each stage you can define multiple job. For example in build stage you may have 3 jobs to build on debian, centos and windows (in GitLab glossary build:debian, build:centos, build:windows). A GitLab runner clones the project read the gitlab-ci.yaml file and do what he is instructed to do. So basically GitLab runner is a Golang process that executes some instructed tasks.\n\nwhere is it meant to be installed?\n\nYou can install a runner in your desired environment listed here. https://docs.gitlab.com/runner/install/\nor\nyou can use a shared runner that is already installed on GitLab's infrastructure.\n\nDoes it care which directory it is run in?\n\nYes. Every task executed by runner is relativly to CI_PROJECT_DIR defined in https://gitlab.com/help/ci/variables/README. But you can alter this behaviour.\n\nwhere does it execute it's script commands? At root?\nDo I need to set my executor to docker? Shouldn't I just set it to shell, pull the image, and build it?\n\nA runner can have mutiple executors such as docker, shell, virtualbox etc but docker being the most common one. If you use docker as the executor you can pull any image from docker hub or your configured registry and you can do loads of stff with docker images. In a docker environment normally you run them as the root user.\nhttps://docs.gitlab.com/runner/executors/README.html"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to duplicate a git repository on gitlab/github without forking?\n\nI've an existing repository on Gitlab / Github. I want a duplicate of that under the same group with a different repo name.\nNote: Thought the answers might be similar to another question, I was not able to find the said another question by googling, I'm guessing other users might be unable to do so either."}, {"role": "assistant", "content": "In gitlab there is functionality out of the box:\n\nGo to Settings -> General of existing project\nLast expanded panel Advanced contains Export button. Click it and then on the top of this page you can see info message Project export started. A download link will be sent by email.\nCheck email. There is following message:\n\n\nProject NAME_OF_YOUR_EXISTING_PROJECT was exported successfully.\nThe project export can be downloaded from: SOME_LINK\nThe download link will expire in 24 hours.\n\n\nClick SOME_LINK and then check the Downloads folder\nIn the UI, click the + button at the top of the left sidebar and select `New project/repository\nClick the Import project box\nClick the button Gitlab export\nClick Choose file and select previously downloaded file *.tar.gz\nClick the button Import project\nThen you will see Import in progress label.\nDEAL"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to transfer project from one group to a user in gitlab CE 9?\n\nI want to transfer a project from a group to another user. For e.g from https://gitlab.local/groupname/projectname to https://gitlab.local/userA/projectname\nHow can I achieve this? I have gitadmin permissions."}, {"role": "assistant", "content": "Go to\nSettings \u25b6 General \u25b6 Advanced \u25b6 Transfer project\n\u25b6 Select a new namespace"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to create a Gitlab webhook to update a mirror repo on Github?\n\nI would like to create a webhook within Gitlab to automatically update a mirror repository on Github, whenever a push event happens. I've checked this page, but I didn't understand how it is done.\nMy Gitlab version is 6.5. Here is the configuration page:\n\nWhat should I put in URL? Where do I need to place the script to update the repository?"}, {"role": "assistant", "content": "You don't need a webhook for that. A regular post-receive hook will work very well.\nTo create and use such a hook you just have to login on the server where your gitlab is installed and create an ssh key for git user.\nsudo -u git ssh-keygen -f /home/git/.ssh/reponame_key\n\n(do not type any passphrase when prompted)\nGo to your github account and add the public key (it's been created as /home/git/ssh/reponame_key.pub) to your project as a deploy key.\nhave a look at https://help.github.com/articles/managing-deploy-keys if you need help with that.\nOnce that is done, you just have to configure the connection between your git server and github's:\nadd an alias to git user's ssh configuration (add following lines to /home/git/.ssh/config - create it if it's not present)\nHost reponame  \nIdentityFile /home/git/.ssh/reponame_key  \nHostName github.com  \nUser git \n\nNow add the new remote (using the alias you just created) to your repository:\ncd /home/git/repositories/namespace/reponame.git\n\ngit remote add --mirror github reponame:youruser/reponame.git\n\nNow that everything is in place you'll have to create the actual hook:\ncd /home/git/repositories/namespace/reponame.git/hooks\n\necho \"exec git push --quiet github &\" >> post-receive\n\nchmod 755 post-receive\n\nThe lastcommand is very important because git will check if a hook is executable before running it.\nThat's it!\n(Replace reponame, namespace and youruser according to your real accounts and enjoy).\nLast note: if you want your name andavatar near commits on github, make sure that the email address you are using on gitlab is one of the addresses inked to your github account as well. You'll see your gitlab username otherwise."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI how to deploy an application via SSH\n\nI'm using Hosted Gitlab to host my Git repositories, and more recently I've been using it to build/deploy PHP and Java applications to servers.\nWhat I'd like to do is once a build is complete, deploy the application using SSH. Sometimes this might just be uploading the contents of the final build (PHP files) to a server via SSH, or other times it may be uploading a compiled .jar file and then executing a command on the remote server to restart a service.\nI've set up my own Docker container as a build environment, this includes things such as Java, PHP, Composer, and Maven all that I need for builds to complete. I'm using this image to run builds.\nWhat I'd like to know is, how can I SSH into an external server in order to perform deployment commands that I can specify in my gitlab-ci.yaml file?"}, {"role": "assistant", "content": "You can store your SSH key as a secret variable within gitlab-ci.yaml and use it during your build to execute SSH commands, for more details please see our documentation here.\nOnce you have SSH access you can then use commands such as rsync and scp to copy files onto your server.  I found an example of this in another post here which you can use as a reference."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I add an SSH key in gitlab?\n\nHere is what my dashboard looks like: \n\nNot really sure where to add an SSH key. Anyone have any idea?"}, {"role": "assistant", "content": "Go to your GitLab account: https://gitlab.com/\nClick on Settings on the top right drop-down, which will appear once you select the icon(white-fox image [specific to my profile]).\n\nClick on Settings on the top right drop-down, which will appear once you select the icon(white-fox image).  \nClick on SSH Keys:\n\nAdd/Paste the SSH Key.\nHow to generate the ssh key: Download gitbash or putty: \nAfter downloading gitbash/putty follow the steps:  \n\nOpen a terminal on Linux or macOS, or Git Bash / WSL on Windows.  \nGenerate a new ED25519 SSH key pair:  \nssh-keygen -t ed25519 -C \"[email\u00a0protected]\"  \n\nOr, if you want to use RSA:  \nssh-keygen -t rsa -b 4096 -C \"[email\u00a0protected]\"  \n\nIt will generate the key in => C:\\Users\\yourname.ssh directory.\nCopy the public key and paste in the gitlab location:  \n\n\nCommand to run on gitbash to clone the repository:  \nssh-agent $(ssh-add C:\\Users\\youname\\.ssh\\id_rsa; git clone [email\u00a0protected]:xyz/SpringBootStarter.git)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "In gitlab, is it possible to create two or more repositories into only one project?\n\nI'm running GitLab in a container of Docker but it's okay so far, no problem with that at all. I'm just in doubt about the creation of repositories in projects. I've created my first project in GitLab then after it creation i'd been redirected to a page with some commands to use in terminal. There were three sections, one of them were \"Create a repository\", i've used those commands and so i could create my repository of my project. However, after this, that page with commands went out and i could just see it again when i created a new project. After all,here goes my question again, is it possible to create two or more repositories into only one project?"}, {"role": "assistant", "content": "I only have time to give a short answer right now, but I hope it helps:\n\nIn short: NO\nBut also: YES, after a fashion\n\nThere is a one-to-one correspondence between repositories and projects (which would perhaps better be called repositories as well). \nOne Solution: Gitlab supports the creation of groups of projects/repos, which can be managed as a project consisting of multiple repos.\n\nGit-based/local Options\nIf you are interested in git-based solutions to including a repository inside of another repository check out my answer here. If you use either the subtree merge method (at least a variant of it that tracks history) or subrepository method in this answer, your subprojects will appear in your master project in Gitlab, but the master project will also track changes in the subprojects. \nAlternative Solution: Create a dummy repo that contains all of your desired repos as subrepos. This master repo will then track all subrepo changes. However; there are a few logistical issues, the .git files for the subrepos will not exist on Gitlab, so you might want a dedicated client with these files to pull the master repo from Gitlab (probably one commit at a time, if you want the subrepo histories to match the main repo history) and update the corresponding local subrepos (these could also be stored independently on GitLab)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I use let\u2019s encrypt with gitlab?\n\nI started to look in to ssl certificates when I stumbled upon let's encrypt, and I wanted to use it with gitlab, however being that it is running on a raspberry pi 2 and its running quite perfectly now (so I dont want to mess anything up), he would I go about installing a lets encrypt ssl certificate properly?\nPS: My installation is omnibus"}, {"role": "assistant", "content": "The by far best solution I was able to find for now is described in this blog post. I won't recite everything, but the key points are:\n\nUse the webroot authenticator for Let's Encrypt\nCreate the folder /var/www/letsencrypt and use this directory as webroot-path for Let's Encrypt\nChange the following config values in /etc/gitlab/gitlab.rb and run gitlab-ctl reconfigure after that:\nnginx['redirect_http_to_https'] = true\nnginx['ssl_certificate']= \"/etc/letsencrypt/live/gitlab.yourdomain.com/fullchain.pem\"\nnginx['ssl_certificate_key'] = \"/etc/letsencrypt/live/gitlab.yourdomain.com/privkey.pem\"\nnginx['custom_gitlab_server_config']=\"location ^~ /.well-known {\\n alias /var/www/letsencrypt/.well-known;\\n}\\n\"\n\nIf you are using Mattermost which is shipped with the Omnibus package then you can additionally set these options in /etc/gitlab/gitlab.rb:\nmattermost_nginx['redirect_http_to_https'] = true\nmattermost_nginx['ssl_certificate']= \"/etc/letsencrypt/live/gitlab.yourdomain.com/fullchain.pem\"\nmattermost_nginx['ssl_certificate_key'] = \"/etc/letsencrypt/live/gitlab.yourdomain.com/privkey.pem\"\nmattermost_nginx['custom_gitlab_mattermost_server_config']=\"location ^~ /.well-known {\\n alias /var/www/letsencrypt/.well-known;\\n}\\n\"\n\nAfter requesting your first certificate remember to change the external_url to https://... and again run gitlab-ctl reconfigure\n\nThis method is very elegant since it just mounts the directory /var/www/letsencrypt/.well-known used by the Let's Encrypt authenticator into the Gitlab web-root via a custom Nginx configuration and authentication is always possible when Gitlab is running. This means that you can automatically renew the Let's Encrypt certificates."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Use gitlab's https link when logged in with Google Account\n\nI've signed up to Gitlab using the connection they have with Google Accounts. Once that is made and I have permission to clone from a git repository, I try to clone using the https:// link (not the git: SSH one)\nNow to complete this process, I am asked my username and password, but what is that in this scenario? Please don't recommend using SSH link instead as ssh is not straightforward on a Windows OS."}, {"role": "assistant", "content": "You can actually use the https link if you login using a Google, Twitter or GitHub link but you have to have an actual GitLab password. If you've already created your account by logging in with a social network, all you have to do is use the Forgot Password feature. \n\nlog out and then use the \"Forgot your password?\" button and put in the email address of the social network you logged in with. \nOnce you get the email, \"change\" your password which will have actually set your GitLab password\nYou should now be able to use the https: clone url with your username and the password you just set."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Installing non-public packages from Gitlab using devtools::install_git\n\nMy institution recently installed GitLab for us.  I've figured out how to install R packages from the GitLab server using devtools::install_git and it works as long as the project is public.\n#* When modeltable project has Public status\ndevtools::install_git('https://mini-me2.lerner.ccf.org/nutterb/modeltable.git')\n\nHowever, if I have a package that is listed as either \"Internal\" or \"Private,\" I can't install the package without some form of authentication.  As of yet, I haven't figured out how to pass authentication via the URL.  Does anyone have experience with downloading packages from GitLab?\n#* After changing the 'modeltable' project to Private status\ndevtools::install_git('https://mini-me2.lerner.ccf.org/nutterb/modeltable.git')\nPreparing installation of modeltable using the Git-URL: https://mini-me2.lerner.ccf.org/nutterb/modeltable.git\n'/usr/bin/git'clone --depth 1 --no-hardlinks https://mini-me2.lerner.ccf.org/nutterb/modeltable.git /tmp/Rtmp5aj1cU/file24493dc03a32\nError: There seems to be a problem retrieving this Git-URL."}, {"role": "assistant", "content": "I'd highly recommend going the SSH route, and the below works for that.  I found making the leap to SSH was easy, especially with R and RStudio.  I'm using Windows in the below example.  Edits from code I use in practice are in all caps.\ncreds = git2r::cred_ssh_key(\"C:\\\\Users\\\\MYSELF\\\\.ssh\\\\id_rsa.pub\",\n                            \"C:\\\\Users\\\\MYSELF\\\\.ssh\\\\id_rsa\")\ndevtools::install_git(\"[email\u00a0protected]:GITLABGROUP/PACKAGE.git\",\n                      credentials = creds)\n\nTwo quick additional comments:    \n\ngit2r is imported with devtools, you shouldn't need to install it separately.\nAlso I don't think this should need mentioning, but passwords in plaintext in your script is a very bad idea."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab: team member project access levels\n\nGitLab offers the project access levels:\n\n\"Guest\"\n\"Reporter\"\n\"Developer\"\n\"Master\"\n\nfor \"team members\" co-operating with a specific project.\n\"Master\" and \"Guest\" are self-explanatory, but the others aren't quite clear to me, in their extents as well as in their granularity.\nWhat is the difference between these levels?"}, {"role": "assistant", "content": "2013: The project_security_spec.rb test each profile capabilities, which are listed in ability.rb:\n(2017 GitLab 10.x: this would be more likely in app/policies/project_policy.rb)\nSee also, as noted in jdhao's answer: \"Project members permissions\"\nThose rules are quite explicit:\ndef public_project_rules\n  [\n    :download_code,\n    :fork_project,\n    :read_project,\n    :read_wiki,\n    :read_issue,\n    :read_milestone,\n    :read_project_snippet,\n    :read_team_member,\n    :read_merge_request,\n    :read_note,\n    :write_issue,\n    :write_note\n  ]\nend\n\ndef project_guest_rules\n  [\n    :read_project,\n    :read_wiki,\n    :read_issue,\n    :read_milestone,\n    :read_project_snippet,\n    :read_team_member,\n    :read_merge_request,\n    :read_note,\n    :write_project,\n    :write_issue,\n    :write_note\n  ]\nend\n\ndef project_report_rules\n  project_guest_rules + [\n    :download_code,\n    :fork_project,\n    :write_project_snippet\n  ]\nend\n\ndef project_dev_rules\n  project_report_rules + [\n    :write_merge_request,\n    :write_wiki,\n    :push_code\n  ]\nend\n\nThat means:\n\na reporter is a guest who can also:\n\ndownload code,\nfork a project,\nwrite project snippet\n\n\na developer is a reporter who can also:\n\nwrite merge request,\nwrite wiki pages,\npush code\n\n\n\n\nNote: with GitLab 15.0 (May 2022):\n\nUsers with the Reporter role can manage iterations and milestones\nWe\u2019ve changed the permissions necessary to create, edit, and delete milestones and iterations from the Developer to Reporter role.\nThis change better reflects the typical day-to-day Reporter responsibilities of managing and tracking planning timeboxes.\nSee Documentation and Issue.\n\n\nAnd GitLab 17.0 (May 2024) adds, still for the Reporter role:\n\nDesign Management features extended to Product teams\nGitLab is expanding collaboration by updating our permissions. Now, users with the Reporter role can access Design Management features, enabling product teams to engage more directly in the design process. This change simplifies workflows and accelerates innovation by inviting broader participation from across your organization.\nSee Documentation and Issue.\n\nAnd, still with GitLab 17.0 (May 2024)\n\nGuests in groups can link issues\nWe reduced the minimum role required to relate issues and tasks from Reporter to Guest, giving you more flexibility to organize work across your GitLab instance while maintaining permissions.\nSee Documentation and Epic."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "SourceTree gives me a login Error when I try to add my gitlab account\n\nI would like to add my gitlab account to sourcetree.  Inside Preferences -> Accounts, I tried the 'add' button\nhost: GitLab.com\nAuth type: greyed out\nusername xxxxxx\npassword: xxxxxx\nprotocol: https\n\nwhen I go to save.  I get a pop up screen that says: \"We couldn't connect to GitLab with your (XXXXXX) credentials. Check your username and try the password again.\"\nI've double checked both username and password."}, {"role": "assistant", "content": "Someone on the GitLab forum had a similar issue recently, and they documented the steps to solve it:\n\nI eventually noticed that for github and bitbucket the credentials are through \"Oauth\", and for GitLab \"Personal access token\". I had generated yesterday a toke, but hadn't used anywhere. \nSteps to add a repo from GitLab on SourceTree:\n\nOn your browser, go to your account and > User settings > Personal Access Tokens (https://gitlab.com/profile/personal_access_tokens)\nGenerate and copy the token\nOn Sourcetree, \na) leave https as preferred protocol \nb) click on Refresh Personal Access Token\nc) type your username \nd) use the copied token as password\n\n\nRefer below image"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "fatal: unable to access \".....\": gnutls_handshake() failed: Handshake failed\n\nI've been using Git for the past few months. Recently when I try to clone or to push, I keep on getting this error. I've researched on the internet but so far no solution has worked for me. Does anyone have an idea?\nExternal note : Now I moved to different country, it was working perfectly where I was before.\nGit Version : 2.11.0   , OS : Debian GNU/Linux 9.11 (stretch)\nError :\ngit push\nfatal: unable to access 'https://**************/': gnutls_handshake() failed: Handshake failed"}, {"role": "assistant", "content": "This is solution fix this issue on ubuntu server 14.04.x\n1, Edit file:\nsudo nano  /etc/apt/sources.list\n\n2, Add to file sources.list\ndeb http://security.ubuntu.com/ubuntu xenial-security main\ndeb http://cz.archive.ubuntu.com/ubuntu xenial main universe\n\n3, Run command update and update CURL to new version\napt-get update && apt-get install curl\n\n4, Check version (Optional):\ncurl -V\nResponse :\n\ncurl 7.47.0 (x86_64-pc-linux-gnu) libcurl/7.47.0 GnuTLS/3.4.10 zlib/1.2.8 libidn/1.28 librtmp/2.3\nProtocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtmp rtsp smb smbs smtp smtps telnet tftp \nFeatures: AsynchDNS IDN IPv6 Largefile GSS-API Kerberos SPNEGO NTLM NTLM_WB SSL libz TLS-SRP UnixSockets \n\n5, Test connect with bitbucket (Optional)\nGIT_CURL_VERBOSE=1 git ls-remote https://bitbucket.org/\nResponse:\n\n\n* Closing connection 0\nfatal: repository 'https://bitbucket.org/' not found\n\nThis done."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to sync gitlab with github\n\nI have several developers working on a local Gitlab instance. The client requires that their Github repo is kept updated. So our Gitlab repo should push any commits directly to Github. Any commits to Github should likewise be pulled into Gitlab.  \nI could do the first part (dev --> gitlab --> github) with jenkins or something, but am stuck on the reverse. Our Gitlab and Jenkins run inside our firewall.   \nAny hints or pointers (or drop in solutions!) would be very appreciated."}, {"role": "assistant", "content": "It's only in the enterprise edition and on GitLab.com, but GitLab has introduced this feature directly, without any workarounds.\nThey've documented pulling/pushing from/to a remote repository in GitLab Docs \u2192 User Docs \u2192 Projects \u2192 Repositories \u2192 Mirroring.\nIt's in the same section of configuration that you can push, too:\n\nFrom within a project use the gear icon to select Mirror Repository\nScroll down to Push to a remote repository\nCheckmark Remote mirror repository: Automatically update the remote mirror's branches, tags, and commits from this repository every hour.\nEnter the repository you want to update; for GitHub you can include your username and password in the URL, like so: https://yourgithubusername:[email\u00a0protected]/agaric/guts_discuss_resource.git\n\nNote that I haven't tried it, but you should be able to push to and pull from the same repository.  It's working great for me pulling from a remote repository (drupal.org), and pushing to a different remote repository (gitlab.com)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab: How to use artifacts in subsequent jobs after build\n\nI've been trying to make a GitLab CI/CD pipeline for deploying my MEAN application. I have three stages:\n1. test\n2. build \n3. deploy\nThe build stage has a build_angular job which generates an artifact. Now I want to use this artifacts in the next stage i.e deploy. \nThe deploy job tells me that it has downloaded the artifact(image has been attached), but now I want to extract this artifact, but I don't know where the artifact is being downloaded. \nThe path where the artifact is being downloaded is not mentioned anywhere in the docs."}, {"role": "assistant", "content": "GitLab is cleaning the working directory between two subsequent jobs. That's why you have to use artifacts and dependencies to pass files between jobs.\nWhen the \"deploy\" job says that the build artifact have been downloaded, it simply means that they have been recreated as they were before. The location of the downloaded artifacts matches the location of the artifact paths (as declared in the .yml file).\nExample\nbuild_job:\n  stage: build\n  script:\n  - echo \"create bin/ directory\"\n  - make\n  artifacts:\n    paths:\n      - bin/\n\ndeploy_job:\n  stage: deploy\n  script:\n  - ls bin/\n  dependencies:\n  - build_job\n\nDirectory bin/ is passed to deploy_job from build_job."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab Account 2FA lost\n\nI have lost my Phone and do not have the recovery code for my 2FA for GitLab.  \nSo I am locked out of my account.\nWhat are my options?"}, {"role": "assistant", "content": "I know this is an old question, but the following, which I have tested only with gitlab.com free hosted accounts, may be useful for others with GitLab 2fa problems.\nIF\n\nyou have set up 2fa but then lost access to your 2fa device for some reason, and\nyou have lost (or never saved) your recovery codes, and\nyou had previously configured your ssh key in your gitlab.com account\n\nTHEN ...\nYou can create a brand new list of recovery codes via ssh:\nssh [email\u00a0protected] 2fa_recovery_codes\n\nAnswer the questions and save the list of recovery codes somewhere safe this time! I'm guilty of all of the above and this solution provided by GitLab is both simple and elegant.\nSource: https://gitlab.com/gitlab-org/gitlab-ce/issues/3765"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Git Update Local Branch with remote Master\n\nI see two possibilities of doing this:\n\nDo a replace of the local branch with the changes from remote master\nFollow the work flow that I get using Gitlab by creating a merge request and merge the changes from master branch into the branch that I wish to update to the latest from master\n\nWhat are the advantages and disadvantages of both these approaches? I'm leaning more towards the first approach. What do you guys say?"}, {"role": "assistant", "content": "The simple answer - there are plenty of more complicated ones - is to just do a merge, so:\ngit checkout master\ngit pull\ngit checkout <your-branch>\ngit merge master\n\n(This is effectively the same as you describe in option 2)\nDepending on your settings, you might not need all of those steps (but doing them all won't hurt) - I'd recommend reading up on each of the commands to find the precise workflow that fits you best.\nThis will merge the changes from master into your branch and probably create a new commit, with a comment making it clear that it's a merge.\nThe alternative, and slightly more advanced option would be to rebase, instead of merge, which will effectively rewind time to the point at which your branch diverged from master, then pull in the changes on master, bringing your branch in-line with master, but without your commits, and finally apply your commits at the end. The advantage of this is that it keeps the history more simple - you just get a straight line of changes, with the changes from your branch right at the end, rather than two separate branches that join at the point of the merge.\nTo do that, you'd do:\ngit checkout <your-branch>\ngit rebase master\n\nI'd recommend reading the docs on rebase, because there are lots of cases where it gets difficult, and if you're new to git, definitely go for merge, but come back to rebase when you're more confident - it's a very powerful feature, and more like what I think you're describing in your option 1."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI - Specifying stages in before_script\n\ni want to run a script that is needed for my test_integration and build stage. Is there a way to specify this in the before script so i don't have to write it out twice.\nbefore_script:\n  stage: ['test_integration', 'build']\n\nthis does not seem to work i get the following error in gitlab ci linter.\n\nStatus: syntax is incorrect \nError: before_script config should be an array of strings\n\n.gitlab-ci.yml\nstages:\n  - security\n  - quality\n  - test\n  - build\n  - deploy\n\nimage: node:10.15.0\n\nbefore_script:\n  stage: ['test_integration', 'build']\n  script:\n  - apt-get update\n  - apt-get -y install apt-transport-https ca-certificates curl gnupg2 software-properties-common\n  - curl -fsSL https://download.docker.com/linux/debian/gpg | apt-key add -\n  - add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable\"\n  - apt-get update\n  - apt-get -y install docker-ce\n  - curl -L \"https://github.com/docker/compose/releases/download/1.23.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n  - chmod +x /usr/local/bin/docker-compose\n  - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY\n\n\nservices:\n  - mongo\n  - docker:dind\n\nsecurity:\n  stage: security\n  script:\n  - npm audit\n\nquality:\n  stage: quality\n  script:\n  - npm install\n  - npm run-script lint\n\ntest_unit:\n  stage: test\n  script:\n  - npm install\n  - npm run-script unit-test\n\ntest_integration:\n  stage: test\n  script:\n  - docker-compose -f CI/backend-service/docker-compose.yml up -d\n  - npm install\n  - npm run-script integration-test\n\nbuild:\n  stage: build\n  script:\n  - npm install\n  - export VERSION=`git describe --tags --always`\n  - docker build -t $CI_REGISTRY_IMAGE:$VERSION .\n  - docker push $CI_REGISTRY_IMAGE\n\ndeploy:\n  stage: deploy\n  script: echo 'deploy'"}, {"role": "assistant", "content": "The before_script syntax does not support a stages section. You could use before_script as you have done without the stages section, however the before_script stage would run for every single job in the pipeline.\nInstead, what you could do is use YAML's anchor's feature (supported by Gitlab), which allows you to duplicate content across the .gitlab-ci file.\nSo in your scenario, it would look something like:\nstages:\n  - security\n  - quality\n  - test\n  - build\n  - deploy\n\nimage: node:10.15.0\n\n.before_script_template: &build_test-integration\n  before_script:\n    - apt-get update\n    - apt-get -y install apt-transport-https ca-certificates curl gnupg2 software-properties-common\n    - curl -fsSL https://download.docker.com/linux/debian/gpg | apt-key add -\n    - add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable\"\n    - apt-get update\n    - apt-get -y install docker-ce\n    - curl -L \"https://github.com/docker/compose/releases/download/1.23.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n    - chmod +x /usr/local/bin/docker-compose\n    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY\n\n\nservices:\n  - mongo\n  - docker:dind\n\nsecurity:\n  stage: security\n  script:\n  - npm audit\n\nquality:\n  stage: quality\n  script:\n  - npm install\n  - npm run-script lint\n\ntest_unit:\n  stage: test\n  script:\n  - npm install\n  - npm run-script unit-test\n\ntest_integration:\n  stage: test\n  <<: *build_test-integration\n  script:\n  - docker-compose -f CI/backend-service/docker-compose.yml up -d\n  - npm install\n  - npm run-script integration-test\n\nbuild:\n  stage: build\n  <<: *build_test-integration\n  script:\n  - npm install\n  - export VERSION=`git describe --tags --always`\n  - docker build -t $CI_REGISTRY_IMAGE:$VERSION .\n  - docker push $CI_REGISTRY_IMAGE\n\ndeploy:\n  stage: deploy\n  script: echo 'deploy'\n\n\nEdit: there is another way, instead of using anchors, you could also use extends syntax:\n.before_script_template:\n  before_script:\n    - apt-get update\n    - apt-get -y install apt-transport-https ca-certificates curl gnupg2 software-properties-common\n    - curl -fsSL https://download.docker.com/linux/debian/gpg | apt-key add -\n    - add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable\"\n    - apt-get update\n    - apt-get -y install docker-ce\n    - curl -L \"https://github.com/docker/compose/releases/download/1.23.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n    - chmod +x /usr/local/bin/docker-compose\n    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY\n\ntest_integration:\n  extends: .before_script_template\n  stage: test \n  script:\n    - docker-compose -f CI/backend-service/docker-compose.yml up -d\n    - npm install\n    - npm run-script integration-test\n    \nbuild:\n  extends: .before_script_template\n  stage: build\n  script:\n    - npm install\n    - export VERSION=`git describe --tags --always`\n    - docker build -t $CI_REGISTRY_IMAGE:$VERSION .\n    - docker push $CI_REGISTRY_IMAGE\n\netc"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "git clone works; git submodule fails \"Permission denied\"\n\nOn a private repository from gitlab, when I run git clone [email\u00a0protected]:group/project-submodule.git the clone completes successfully.\nAs part of the cloning process, I'm asked for the passphrase of my private key.\nWhen I run\nsubmodule update --init \"group/project-submodule\"\nIt fails with:  \n\nPermission denied, please try again.\n  Permission denied, please try again.\n  Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\n  fatal: Could not read from remote repository.\n\nWhile trying to process the submodule getting, I'm not asked for the passphrase for my private key.\n(I had to anonymize it)\n\nfatal: clone of '[email\u00a0protected]:group/project-submodule.git' into submodule path 'C:/Users/user/repos/project-module/project-submodule' failed\n\nI've checked the .gitmodules file and it contains the right data (I think it can be confirmed by the error message).\nThe main element that calls my attention is that I'm not asked for my private key passphrase. Even weirder because, when I use git clone directly, it runs as expected.\nI also already diagnosed by accessing with ssh and it asks me for the passphrase just like it happens when I execute a pull or a clone\nUsing git for windows \"git version 2.16.2.windows.1\""}, {"role": "assistant", "content": "Git tries to clone the submodule using ssh and not https.\nIf you haven't configured your ssh key this will fail.\nYou can setup ssh-agent to cache the password for the ssh key and get git to use that. Or change to https.\nGit is a bit confusing regarding submodules. They are configured in the .gitmodules file in the directory, but changing the url here from ssh to https won't help. Git uses the url that is configured in .git/config.\nOpen this file and you will find something like this.\n[submodule \"project-submodule\"]\n    url = [email\u00a0protected]:project-submodule.git\n\nChange this url to the https equivalent and try again."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab runner The requested URL returned error: 403\n\nI'm currently using gitlab.com (not local installation) with their multi-runner for CI integration.  This works great on one of my projects but fails for another.\nI'm using 2012R2 for my host with MSBuild version 14.0.23107.0.  I know the error below shows 403 which is an access denied message.  My problem is finding the permission setting to change.\nError message:\n\nRunning with gitlab-ci-multi-runner 1.5.3 (fb49c47) Using Shell\n  executor... Running on WIN-E0ORPCQUFHS...\nFetching changes...\nHEAD is now at 6a70d96 update runner file remote: Access denied fatal:\n  unable to access\n  'https://gitlab-ci-token:[email\u00a0protected]/##REDACTED##/ADInactiveObjectCleanup.git/':\n  The requested URL returned error: 403 Checking out 60ea1410 as\n  Production...\nfatal: reference is not a tree:\n  60ea1410dd7586f6ed9535d058f07c5bea2ba9c7 ERROR: Build failed: exit\n  status 128\n\ngitlab-ci.yml file:\nvariables:\n  Solution: ADInactiveObjectCleanup.sln\n\nbefore_script:\n  #- \"echo off\"\n  #- 'call \"%VS120COMNTOOLS%\\vsvars32.bat\"'\n  ## output environment variables (usefull for debugging, propably not what you want to do if your ci server is public)\n  #- echo.\n  #- set\n  #- echo.\n\nstages:\n  - build\n  #- test\n  #- deploy\n\nbuild:\n  stage: build\n  script:\n  - echo building...\n  - '\"%ProgramFiles(x86)%\\MSBuild\\14.0\\Bin\\msbuild.exe\" \"%Solution%\" /p:Configuration=Release'\n  except:\n  #- tags"}, {"role": "assistant", "content": "To resolve this issue I had to add myself as a project member.  This is a private repo.  I'm not sure if that caused the runner to fail with the different permission setup or not, but it is highly possible. \nThis help article at gitlab outlines this issue. \n\nWith the new permission model in place, there may be times that your\n  build will fail. This is most likely because your project tries to\n  access other project's sources, and you don't have the appropriate\n  permissions. In the build log look for information about 403 or\n  forbidden access messages. \nAs an Administrator, you can verify that the\n  user is a member of the group or project they're trying to have access\n  to, and you can impersonate the user to retry the failing build in\n  order to verify that everything is correct.\n\nFrom the project page click the settings gear and then click members.  Add yourself (or user generating builds) as a member to the project.  I used the \"Master\" Role, but based off of this document you can probably use the \"Reporter\" role as a minimum.  The reporter role is the least privilege that still has access to \"Pull project code.\"  This removed my 403 error and allowed me to continue on."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI Start job manually (deployment)\n\nIs it possible to mark gitlab ci jobs to start manually?\nI need it for deploying application but I want to decide if it's going to be deployed"}, {"role": "assistant", "content": "This has changed since the first answer has been posted. Here's the link to the original Gitlab Issue. It is now supported to do something like\nproduction:\n  stage: deploy\n  script: run-deployment $OMNIBUS_GITLAB_PACKAGE\n  environment: production\n  when: manual\n\nNote the when: manual attribute. The UI updates itself to provide a way for users to trigger the job."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GIT push, HTTP code = 502 error\n\nMy project size is 1,63 GB (Magento Project)\nI had followed this tutorial\nwhen I do this command : git push -u origin master , it is starting to write objects and after that I getting this error in git console: \nerror: RPC failed, result=22, HTTP code = 502\nfatal: The remote end hung up unexpectedly\nfatal: The remote end hung up unexpectedly\n\nWhat should I do to make this work ? \nThe result of the git remote -v is :"}, {"role": "assistant", "content": "The remote end hangs up because the pack size you are trying to transmit exceeds the maximum HTTP post size. Try to limit this pack size with\ngit config --local http.postBuffer 157286400\n\nto 150MB."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab run pipeline only manually and not automatically\n\nMy GitLab pipelines execute automatically on every push, I want to manually run pipeline and not on every push.\nPipeline docs: https://docs.gitlab.com/ee/ci/yaml/#workflowrules\nI tried this in\n.gitlab-ci.yml\nworkflow:\n  rules:\n    - when: manual    # Error: workflow:rules:rule when unknown value: manual"}, {"role": "assistant", "content": "You should specify a condition that tells Gitlab to not run the pipeline specifically on push events like so:\nworkflow:\n  rules:\n    - if: '$CI_PIPELINE_SOURCE == \"push\"'\n      when: never  # Prevent pipeline run for push event\n    - when: always # Run pipeline for all other cases"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Can a deleted GitLab branch be restored?\n\nThere is a Git branch which was deleted by GitLab when closing a merge request.  I would like to restore (undelete) that branch; however, I'm not seeing an option in the UI to do so.\nIn GitHub it is possible to restore a branch deleted by a pull request after the fact (via the \"Restore branch\" button on the pull request).  I'm wondering if GitLab has an  analogous feature for closed merge requests.\nI can of course do this manually through the Git command line, checking out the last commit hash for the deleted branch, and pushing it back up to the deleted branch name.  However, I would rather use the UI for something like this if it exists.\nHow can I restore a branch which GitLab deleted when closing a merge request?"}, {"role": "assistant", "content": "Restoring a deleted branch is an open issue, so GitLab has not implemented this feature at the time of this writing.\nHowever, if you know the commit ID (and it hasn't been pruned), you can create a new branch from that commit:\n\nFrom the Web UI, go to Repository > Commits\nFind the commit you want and copy the SHA to your clipboard\nGo to Repository > Branches\nClick \"New Branch\"\nEnter a branch name\nClick the \"Create from\" drop-down menu and enter the commit SHA. Press enter to apply it.\nClick \"Create Branch\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Can't connect IntelliJ-IDEA to GitLab with SSH\n\nI am trying to connect my GitLab repository with IntelliJ-IDEA, and it still cant connect to the repo. I have tried the next things:\n\nI have msysgit installed correctly\nGenerated the SSH keys (https://help.github.com/articles/generating-ssh-keys/)\nAdded the key on GitLab keys\nDefine the enviroment variables HOME USERPROFILE point to C:\\Users\\sebastian.garces.ssh. %USERPROFILE$/.ssh %HOME$/.ssh\nIn IntelliJ changed SSH executable to Native\n\nI did  a lot of things from this links:\n\nHow do I connect IntelliJ to GitHub using SSH\nHow to store SSH host key in IntelliJ IDEA\n\nAnd many other google searchs\nI dont know what else to do nothing is working.\nUPDATE: When i try to Clone the repository and press the Test Button it loads and loads and nothing happen after a while it give me this error: repository test has failed"}, {"role": "assistant", "content": "Try to install plugin:\nSettings -> Plugins -> Browse repositories -> type GitLab Projects Plugin  minimum version 1.3.0\nand go to Settings -> Other Settings -> GitLab Settings\nFill GitLab Server Url with https://gitlab.com/ (ensure slash at the end) \nand \nGitLab API Key with string (private token which is shown as the first thing on: https://gitlab.com/profile/account)\n\nAnd then the test in IntelliJ IDEA will pass and you will be able to use ssh or https for each repository...\nUPDATE: GitLab UI changed, so private tokens are created at https://gitlab.com/profile/personal_access_tokens"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to serve other vhosts next to Gitlab Omnibus server? [Full step-by-step solution]\n\nI installed Gitlab CE on a dedicated Ubuntu 14.04 server edition with Omnibus package.\nNow I would want to install three other virtual hosts next to gitlab. \nTwo are node.js web applications launched by a non-root user running on two distinct ports > 1024, the third is a PHP web application that need a web server to be launched from.\nThere are:\n\na private bower registry running on 8081 (node.js)\na private npm registry running on 8082 (node.js)\na private composer registry (PHP)\n\nBut Omnibus listen 80 and doesn't seem to use neither Apache2 or Nginx, thus I can't use them to serve my PHP app and reverse-proxy my two other node apps.\n\nWhat serving mechanics Gitlab Omnibus uses to listen 80 ?\n  How should I create the three other virtual hosts to be able to provide the following vHosts ?\n\ngitlab.mycompany.com (:80) -- already in use\nbower.mycompany.com (:80)\nnpm.mycompany.com (:80)\npackagist.mycompany.com (:80)"}, {"role": "assistant", "content": "About these\n\nBut Omnibus listen 80 and doesn't seem to use neither Apache2 or Nginx [, thus ...].\n\nand @stdob comment :\n\nDid omnibus not use nginx as a web server ??? \u2013 \n\nWich I responded \n\nI guess not because nginx package isn't installed in the system ...\n\nIn facts\nFrom Gitlab official docs :\n\nBy default, omnibus-gitlab installs GitLab with bundled Nginx.\n\nSo yes! \n\nOmnibus package actually uses Nginx ! \n\nbut it was bundled, explaining why it doesn't require to be installed as dependency from the host OS.\nThus YES! Nginx can, and should be used to serve my PHP app and reverse-proxy my two other node apps.\nThen now\nOmnibus-gitlab allows webserver access through user gitlab-www which resides\nin the group with the same name. To allow an external webserver access to\nGitLab, external webserver user needs to be added gitlab-www group.\nTo use another web server like Apache or an existing Nginx installation you will have to do\nthe following steps:\nDisable bundled Nginx by specifying in /etc/gitlab/gitlab.rb\nnginx['enable'] = false\n# For GitLab CI, use the following:\nci_nginx['enable'] = false\n\nCheck the username of the non-bundled web-server user. By default, omnibus-gitlab has no default setting for external webserver user.\nYou have to specify the external webserver user username in the configuration!\nLet's say for example that webserver user is www-data.\nIn /etc/gitlab/gitlab.rb set\nweb_server['external_users'] = ['www-data']\n\nThis setting is an array so you can specify more than one user to be added to gitlab-www group.\nRun sudo gitlab-ctl reconfigure for the change to take effect.\nSetting the NGINX listen address or addresses\nBy default NGINX will accept incoming connections on all local IPv4 addresses.\nYou can change the list of addresses in /etc/gitlab/gitlab.rb.\nnginx['listen_addresses'] = [\"0.0.0.0\", \"[::]\"] # listen on all IPv4 and IPv6 addresses\n\nFor GitLab CI, use the ci_nginx['listen_addresses'] setting.\nSetting the NGINX listen port\nBy default NGINX will listen on the port specified in external_url or\nimplicitly use the right port (80 for HTTP, 443 for HTTPS). If you are running\nGitLab behind a reverse proxy, you may want to override the listen port to\nsomething else.  For example, to use port 8080:\nnginx['listen_port'] = 8080\n\nSimilarly, for GitLab CI:\nci_nginx['listen_port'] = 8081\n\nSupporting proxied SSL\nBy default NGINX will auto-detect whether to use SSL if external_url\ncontains https://.  If you are running GitLab behind a reverse proxy, you\nmay wish to keep the external_url as an HTTPS address but communicate with\nthe GitLab NGINX internally over HTTP. To do this, you can disable HTTPS using\nthe listen_https option:\nnginx['listen_https'] = false\n\nSimilarly, for GitLab CI:\nci_nginx['listen_https'] = false\n\nNote that you may need to configure your reverse proxy to forward certain\nheaders (e.g. Host, X-Forwarded-Ssl, X-Forwarded-For, X-Forwarded-Port) to GitLab.\nYou may see improper redirections or errors (e.g. \"422 Unprocessable Entity\",\n\"Can't verify CSRF token authenticity\") if you forget this step. For more\ninformation, see:\n\nWhat's the de facto standard for a Reverse Proxy to tell the backend SSL is used?\nhttps://wiki.apache.org/couchdb/Nginx_As_a_Reverse_Proxy\n\n\nTo go further you can follow the official docs at https://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/doc/settings/nginx.md#using-a-non-bundled-web-server\n\nConfiguring our gitlab virtual host\nInstalling Phusion Passenger\nWe need to install ruby (gitlab run in omnibus with a bundled ruby) globally in the OS\n$ sudo apt-get update \n$ sudo apt-get install ruby\n$ sudo gem install passenger\n\nRecompile nginx with the passenger module\nInstead of Apache2 for example, nginx isn't able to be plugged with binary modules on-the-fly. It must be recompiled for each new plugin you want to add.\nPhusion passenger developer team worked hard to provide saying, \"a bundled nginx version of passenger\" : nginx bins compiled with passenger plugin.\nSo, lets use it:\n\nrequirement: we need to open our TCP port 11371 (the APT key port).\n\n$ sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 561F9B9CAC40B2F7\n$ sudo apt-get install apt-transport-https ca-certificates\n\n\ncreating passenger.list\n$ sudo nano /etc/apt/sources.list.d/passenger.list\n\nwith these lignes\n# Ubuntu 14.04\ndeb https://oss-binaries.phusionpassenger.com/apt/passenger trusty main\n\n\nuse the right repo for your ubuntu version. For Ubuntu 15.04 for example: \n     deb https://oss-binaries.phusionpassenger.com/apt/passenger vivid main\n\nEdit permissions: \n$ sudo chown root: /etc/apt/sources.list.d/passenger.list\n$ sudo chmod 600 /etc/apt/sources.list.d/passenger.list\n\nUpdating package list:\n$ sudo apt-get update\n\nAllowing it as unattended-upgrades\n$ sudo nano /etc/apt/apt.conf.d/50unattended-upgrades\n\nFind or create this config block on top of the file:\n// Automatically upgrade packages from these (origin:archive) pairs\nUnattended-Upgrade::Allowed-Origins {\n\n  // you may have some instructions here\n\n};\n\nAdd the following:\n// Automatically upgrade packages from these (origin:archive) pairs\nUnattended-Upgrade::Allowed-Origins {\n\n  // you may have some instructions here\n\n  // To check \"Origin:\" and \"Suite:\", you could use e.g.:\n  // grep \"Origin\\|Suite\" /var/lib/apt/lists/oss-binaries.phusionpassenger.com*\n    \"Phusion:stable\";\n\n};\n\nNow (re)install nginx-extra and passenger:\n$ sudo cp /etc/nginx/nginx.conf /etc/nginx/nginx.conf.bak_\"$(date +%Y-%m-%d_%H:%M)\"\n$ sudo apt-get install nginx-extras passenger\n\nconfigure it\nUncomment the passenger_root and passenger_ruby directives in the /etc/nginx/nginx.conf file:\n$ sudo nano /etc/nginx/nginx.conf\n\n... to obtain something like:\n##\n# Phusion Passenger config\n##\n# Uncomment it if you installed passenger or passenger-enterprise\n##\n\npassenger_root /usr/lib/ruby/vendor_ruby/phusion_passenger/locations.ini;\npassenger_ruby /usr/bin/passenger_free_ruby;\n\ncreate the nginx site configuration (the virtual host conf)\n$ nano /etc/nginx/sites-available/gitlab.conf\n\nserver {\n  listen *:80;\n  server_name gitlab.mycompany.com;\n  server_tokens off;\n  root /opt/gitlab/embedded/service/gitlab-rails/public;\n\n  client_max_body_size 250m;\n  access_log  /var/log/gitlab/nginx/gitlab_access.log;\n  error_log   /var/log/gitlab/nginx/gitlab_error.log;\n\n  # Ensure Passenger uses the bundled Ruby version\n  passenger_ruby /opt/gitlab/embedded/bin/ruby;\n\n  # Correct the $PATH variable to included packaged executables\n  passenger_env_var PATH \"/opt/gitlab/bin:/opt/gitlab/embedded/bin:/usr/local/bin:/usr/bin:/bin\";\n\n  # Make sure Passenger runs as the correct user and group to\n  # prevent permission issues\n  passenger_user git;\n  passenger_group git;\n\n  # Enable Passenger & keep at least one instance running at all times\n  passenger_enabled on;\n  passenger_min_instances 1;\n\n  error_page 502 /502.html;\n}\n\nNow we can enable it:\n$ sudo ln -s /etc/nginx/sites-available/gitlab.cong /etc/nginx/sites-enabled/\n\n\nThere is no a2ensite equivalent coming natively with nginx, so we use ln, but if you want, there is a project on github:\n  nginx_ensite:\n  nginx_ensite and nginx_dissite for quick virtual host enabling and disabling\nThis is a shell (Bash) script that replicates for nginx the Debian a2ensite and a2dissite for enabling and disabling sites as virtual hosts in Apache 2.2/2.4.\n\nIt' done :-). Finally, restart nginx\n$ sudo service nginx restart\n\nWith this new configuration, you are able to run other virtual hosts next to gitlab to serve what you want\nJust create new configs in /etc/nginx/sites-available. \n\nIn my case, I made running and serving this way on the same host :\n\n\ngitlab.mycompany.com - the awesome git platform written in ruby\nci.mycompany.com - the gitlab continuous integration server written in ruby\nnpm.mycompany.com - a private npm registry written in node.js\nbower.mycompany.com - a private bower registry written in node.js\npackagist.mycompany.com -  a private packagist for composer registry written in php\n\nFor example, to serve npm.mycompany.com :\nCreate a directory for logs:\n$ sudo mkdir -p /var/log/private-npm/nginx/\n\nAnd fill a new vhost config file:\n$ sudo nano /etc/nginx/sites-available/npm.conf\n\nWith this config\nserver {\n  listen *:80;\n  server_name npm.mycompany.com\n\n  client_max_body_size 5m;\n  access_log  /var/log/private-npm/nginx/npm_access.log;\n  error_log   /var/log/private-npm/nginx/npm_error.log;\n\n  location / {\n    proxy_pass http://localhost:8082;\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection 'upgrade';\n    proxy_set_header Host $host;\n    proxy_cache_bypass $http_upgrade;\n  }\n}\n\nThen enable it and restart it:\n$ sudo ln -s /etc/nginx/sites-available/npm.conf /etc/nginx/sites-enabled/\n$ sudo service nginx restart"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab - Project cannot be transferred, because tags are present in its container registry\n\nProject cannot be transferred, because tags are present in its container registry\n\nI am encountering the above error when I try to transfer my git repository to a group.\nI have checked in Repository/Tags but there are none. I have also checked in CI/CD tabs and there's nothing outstanding there either. So I'm wondering what tags is it referring to.\nI am currently using Netlify for my frontend hosting and Heroku for my backend hosting.\nCould either of these be applying some tags that I can't see/find?\nIs my only option to export the project?"}, {"role": "assistant", "content": "Issue 33301 mentions:\n\nthe only way to move a project with containers in the registry is to first delete them all.\n\nMeaning delete the container tags in the registry (not the repository or CI/CD)\n\nNavigate to sidebar menu Package->Container Registry on a project where Container registry is enabled\nClick on the button \"Remove Tag\"\n\n(since GitLab 12.3, Sept. 2019, you can delete the tags you want)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to trigger Jenkins Multibranch Pipeline with Gitlab Webhook\n\nI currently set up a Jenkins Multibranch Pipeline job that is based on a Git repository hosted on our GitLab server. Jenkins can read the branches in the repository and creates a job for every branch in the repository. But I can't figure out how to trigger the jobs with webhooks in GitLab.\nMy questions are:\n\nHow can I trigger the creation of a new branch job in Jenkins from our GitLab server? I can't see a webhook for a new branch being pushed.\n\nHow do I trigger the actual build job for a single branch? I can only add a webhook for push events but then I would have to add the branch name which I don't know how to do.\n\nHow can I make sure that GitLab always triggers the \"creation of the branch job\" before a push to a branch triggers the build job itself.\n\n\nWhat I tried so far is triggering the multi-branch job, but this has no effect and following this post does not work at all."}, {"role": "assistant", "content": "You need to install the GitLab Plugin on Jenkins.\nThis will add a /project endpoint on Jenkins. (See it in Jenkins => Manage Jenkins => Configure System => GitLab)\nNow add a webhook to your GitLab project => Settings => Integrations. (or in older GitLab versions: GitLab project => Wheel icon => Integrations, it seems you need to be owner of the project in this case)\nSet the URL to http://*yourjenkins.com*/**project**(/*foldername*)?/*yourprojectname* then click \"Add webhook\".\nWhen you click \"Test\" on your webhook it should trigger your Jenkins pipeline build (you should get a 200 HTTP response).\nIt works without authentication in the GitLab plugin, configuration with authentication are welcome."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Why am I getting \"Pipeline failed due to the user not being verified\" & \"Detached merge request pipeline\" on a Gitlab merge request?\n\nWhen a non-owner dev pushes a branch to our Gitlab repo, it returns a \"pipeline failed\" message, with the detail \"Pipeline failed due to the user not being verified\". On the dev's account, he's getting a prompt to add a credit card to verify him to be eligible for free pipeline minutes.\nBut I haven't set up any pipelines - I don't have a gitlab-ci.yml file in my repo, neither does the new branch. There are no jobs or schedules under the CI/CD tab of the project on Gitlab. So why is there a marker saying the branch failed in the pipeline?"}, {"role": "assistant", "content": "In my case, I was using my own runner for my project. In that case also, I got this error.\nI fixed the error by disabling the shared runner in my project.\nUnder\nSetting -> CICD -> Runner (Expand) -> Under the shared runner section, disable Shared runner."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is the special gitlab-ci-token user?\n\nThe docs for gitlab's container registry (https://gitlab.com/help/container_registry/README.md) provide a config example with this instruction:\n- docker login -u gitlab-ci-token -p $CI_BUILD_TOKEN registry.example.com\nand this explanation:\nYou have to use the credentials of the special gitlab-ci-token user with its password stored in $CI_BUILD_TOKEN in order to push to the Registry connected to your project. This allows you to automated building and deployment of your Docker images.\nI cannot find any documentation about this special gitlab-ci-token user, nor about the $CI_BUILD_TOKEN var.\nWhat is this special user? Is it automatically available? Does it have to be defined somewhere? What value should be given to the $CI_BUILD_TOKEN var?"}, {"role": "assistant", "content": "Gitlab acts as an authentication provider for the registry.\ngitlab-ci-token is a user automatically created for you.\nCI_BUILD_TOKEN is set automatically for each build by Gitlab-CI"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Retrieve the commit hash\n\nI'm currently working on a deployment script to run as part of my GitLab CI setup. What I want is to copy a file from one location to another and rename it.\nNow I want to be able to find what commit that file was generated with, so I'd like to add the hash of the commit to it.\nFor that to work I'd like to use something like this:\ncp myLogFile.log /var/log/gitlab-runs/$COMMITHASH.log\n\nThe output should be a file named eg.\n/var/log/gitlab-runs/9b43adf.log\n\nHow is this possible to achieve using GitLab CI?"}, {"role": "assistant", "content": "In your example you used the short git hash that you would get with the predefined variable CI_COMMIT_SHA by building a substring like this:\n${CI_COMMIT_SHA:0:8}\n\nor by using the short sha directly\n$CI_COMMIT_SHORT_SHA"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Adds needs relations to GitLab CI yaml but got an error: the job was not added to the pipeline\n\nI am trying to add needs between jobs in the Gitlab CI yaml configuration file.\n\nstages:\n  - build\n  - test\n  - package\n  - deploy\n\nmaven-build:\n  stage: build\n  only:\n    - merge_requests\n    - master\n    - branches\n  ...\ntest:\n  stage: test\n  needs: [ \"maven-build\" ]\n  only:\n    - merge_requests\n    - master\n  ...\ndocker-build:\n  stage: package\n  needs: [ \"test\" ]\n  only:\n    - master\n  ...\ndeploy-stage:\n  stage: deploy\n  needs: [ \"docker-build\" ]\n  only:\n    - master\n  ...\ndeploy-prod:\n  stage: deploy\n  needs: [ \"docker-build\" ]\n  only:\n    - master\n  when: manual\n  ...\n\n\nI have used the GitLab CI online lint tools to check my syntax, it is correct.\nBut when I pushed the codes, it always complains:\n\n    'test' job needs 'maven-build' job\n    but it was not added to the pipeline\n\nYou can also test your .gitlab-ci.yml in CI Lint\n\nThe GitLab CI did not run at all.\nUpdate: Finally I made it. I think the needs position is sensitive, move all needs under the stage, it works. My original scripts included some other configuration between them."}, {"role": "assistant", "content": "CI-jobs that depend on each other need to have the same limitations!\nIn your case that would mean to share the same only targets:\nstages:\n  - build\n  - test\n\nmaven-build:\n  stage: build\n  only:\n    - merge_requests\n    - master\n    - branches\n\ntest:\n  stage: test\n  needs: [ \"maven-build\" ]\n  only:\n    - merge_requests\n    - master\n    - branches\n\nthat should work from my experience^^"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How does one retrieve an arbritrary user's ssh public keys from GitLab?\n\nHow does one retrieve an arbritrary user's ssh public keys from GitLab?\nGitHub provides this feature. For example: https://github.com/winny-.keys\nThe GitLab API exposes public keys, however it looks like it requires:\n\nSeparate authentication\nQuery a given user name for its UID\nFinally get the public keys"}, {"role": "assistant", "content": "GitHub style ssh public key access was added in GitLab 6.6.0 using the following scheme: http://__HOST__/__USERNAME__.keys (thanks @bastelflp).\nCurrently we are running 6.2.3, and we will upgrade."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI syntax to write FOR loop statement?\n\nBelow is the script mentioned in the gitlab-ci.yml file. This GitLab CI configuration is valid. But, when the CI/CD build is run, the job fails. Is it something to do with the FOR loop syntax? \ndeploy_dv:\n  stage: deploy_dv\n  variables:\n    GIT_STRATEGY: none\nscript:\n  - echo \"Deploying Artifacts...\"\n  - echo \"Configure JFrog CLI with parameters of your Artifactory instance\"\n  - 'c:\\build-tools\\JFROG-CLI\\jfrog rt config --url  %ARTIFACTORY_WEBSITE% --user %ARTIFACTORY_USER% --apikey %APIKEY%'\n  - 'cd ..\\artifacts'\n  - 'SETLOCAL ENABLEDELAYEDEXPANSION'\n  - FOR %%i in (*) do (\n        'c:\\build-tools\\curl\\bin\\curl.exe --header \"PRIVATE-TOKEN:%HCA_ACCESS_TOKEN%\" --insecure https://code.example.com/api/repository/tags/%CI_COMMIT_TAG% | c:\\build-tools\\jq\\jq-win64.exe \".release.description\" > temp.txt'\n         'set /p releasenote=<temp.txt'\n         'rem del temp.txt'\n         'set mydate=%DATE:~6,4%-%DATE:~3,2%-%DATE:~0,2%'\n         'c:\\build-tools\\JFROG-CLI\\jfrog rt u \"%%i\" %ARTIFACTORY_ROOT_PATH%/%PROJECT_NAME%/%%i --build-name=%%i --build-number=%BUILDVERSION%  --props releasenote=%releasenote%;releaseversion=%BUILDVERSION%;releasedate=%mydate% --flat=false'\n     )\n\n    - '%CURL% -X POST -F token=%REPOSITORY_TOKEN% -F ref=master  -F \"variables[RELEASE]=false\" -F \"variables[PROGRAM]=test\" --insecure https://code.example.com/api/repository/trigger'\n\n  only:\n  - /^(dv-)(\\d+\\.)(\\d+\\.)(\\d+)$/\n\nI get this below error:\n  $ echo \"Deploying Artifacts...\"\n\"Deploying Artifacts...\"\n$ echo \"Configure JFrog CLI with parameters of your Artifactory instance\"\n\"Configure JFrog CLI with parameters of your Artifactory instance\"\n$ c:\\build-tools\\JFROG-CLI\\jfrog rt config --url  %ARTIFACTORY_WEBSITE% --user %ARTIFACTORY_USER% --apikey %APIKEY%\nArtifactory server ID [Default-Server]: $ cd ..\\artifacts\n$ SETLOCAL ENABLEDELAYEDEXPANSION\n$ FOR %%i in (*) do ( 'c:\\build-tools\\curl\\bin\\curl.exe --header \"PRIVATE-TOKEN:%HCA_ACCESS_TOKEN%\" --insecure  https://code.example.com/api/repository/tags/%CI_COMMIT_TAG% | c:\\build-tools\\jq\\jq-win64.exe \".release.description\" > temp.txt' 'set /p releasenote=<temp.txt' 'rem del temp.txt' 'set mydate=%DATE:~6,4%-%DATE:~3,2%-%DATE:~0,2%' 'c:\\build-tools\\JFROG-CLI\\jfrog rt u \"%%i\" %ARTIFACTORY_ROOT_PATH%/%PROJECT_NAME%/%%i --build-name=%%i --build-number=%BUILDVERSION%  --props releasenote=%releasenote%;releaseversion=%BUILDVERSION%;releasedate=%mydate% --flat=false' )\nThe filename, directory name, or volume label syntax is incorrect.\nERROR: Job failed: exit status 255"}, {"role": "assistant", "content": "Since there is still no good answer to this question, I will give it a try. I used this snippet to start multiple Docker builds for every directory in my repository. Notice the |+ and the > characters, which lets you put multi-line commands in YAML and are part of GitLab syntax.\nLinux example:\nbuild:\n  stage: loop\n  script:\n    - |+\n      for i in $(seq 1 3)\n      do\n        echo \"Hello $i\"\n      done\n\nWindows example:\nbuild:\n  stage: loop\n  script:\n    - >\n      setlocal enabledelayedexpansion\n      for %%a in (\"C:\\Test\\*.txt\") do (\n        set FileName=%%~a\n        echo Filename is: !FileName!\n      )\n      endlocal"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI runner can't connect to unix:///var/run/docker.sock in kubernetes\n\nGitLab's running in kubernetes cluster. Runner can't build docker image with build artifacts. I've already tried several approaches to fix this, but no luck. Here are some configs snippets:\n.gitlab-ci.yml\nimage: docker:latest\nservices:\n  - docker:dind\n\nvariables:\n  DOCKER_DRIVER: overlay\n\nstages:\n  - build\n  - package\n  - deploy\n\nmaven-build:\n  image: maven:3-jdk-8\n  stage: build\n  script: \"mvn package -B --settings settings.xml\"\n  artifacts:\n    paths:\n      - target/*.jar\n\ndocker-build:\n  stage: package\n  script:\n  - docker build -t gitlab.my.com/group/app .\n  - docker login -u gitlab-ci-token -p $CI_BUILD_TOKEN gitlab.my.com/group/app\n  - docker push gitlab.my.com/group/app\n\nconfig.toml\nconcurrent = 1\ncheck_interval = 0\n\n[[runners]]\n  name = \"app\"\n  url = \"https://gitlab.my.com/ci\"\n  token = \"xxxxxxxx\"\n  executor = \"kubernetes\"\n  [runners.kubernetes]\n    privileged = true\n    disable_cache = true\n\nPackage stage log:\nrunning with gitlab-ci-multi-runner 1.11.1 (a67a225)\n  on app runner (6265c5)\nUsing Kubernetes namespace: default\nUsing Kubernetes executor with image docker:latest ...\nWaiting for pod default/runner-6265c5-project-4-concurrent-0h9lg9 to be running, status is Pending\nWaiting for pod default/runner-6265c5-project-4-concurrent-0h9lg9 to be running, status is Pending\nRunning on runner-6265c5-project-4-concurrent-0h9lg9 via gitlab-runner-3748496643-k31tf...\nCloning repository...\nCloning into '/group/app'...\nChecking out 10d5a680 as master...\nSkipping Git submodules setup\nDownloading artifacts for maven-build (61)...\nDownloading artifacts from coordinator... ok        id=61 responseStatus=200 OK token=ciihgfd3W\n$ docker build -t gitlab.my.com/group/app .\nCannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\nERROR: Job failed: error executing remote command: command terminated with non-zero exit code: Error executing in Docker Container: 1\n\nWhat am I doing wrong?"}, {"role": "assistant", "content": "Don't need to use this: \nDOCKER_DRIVER: overlay\n\ncause it seems like OVERLAY isn't supported, so svc-0 container is unable to start with it:\n$ kubectl logs -f `kubectl get pod |awk '/^runner/{print $1}'` -c svc-0\ntime=\"2017-03-20T11:19:01.954769661Z\" level=warning msg=\"[!] DON'T BIND ON ANY IP ADDRESS WITHOUT setting -tlsverify IF YOU DON'T KNOW WHAT YOU'RE DOING [!]\"\ntime=\"2017-03-20T11:19:01.955720778Z\" level=info msg=\"libcontainerd: new containerd process, pid: 20\"\ntime=\"2017-03-20T11:19:02.958659668Z\" level=error msg=\"'overlay' not found as a supported filesystem on this host. Please ensure kernel is new enough and has overlay support loaded.\"\n\nAlso, add export DOCKER_HOST=\"tcp://localhost:2375\" to the docker-build:\n docker-build:\n  stage: package\n  script:\n  - export DOCKER_HOST=\"tcp://localhost:2375\"\n  - docker build -t gitlab.my.com/group/app .\n  - docker login -u gitlab-ci-token -p $CI_BUILD_TOKEN gitlab.my.com/group/app\n  - docker push gitlab.my.com/group/app"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Using gitlab's nginx to serve another app\n\nHello I have installed Gitlab using this\nhttps://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/README.md#installation\nNow I want to use nginx to serve another content other than gitlab application\nhow can I do this \n\nWhere are the config files that I need to modify\nHow can I point a directory like /var/www so that nginx knows that is the root for another app.\n\nUpdate(forgot to mention I'm running this under Red Hat 6.5, Debian/Ubuntu solution welcome)"}, {"role": "assistant", "content": "Here I am using \n- gitlab.example.com to serve gitlab.example.com over https.\n- example.com over http to serve another content other than gitlab application.\n\nGitlab installed from deb package is using chef to provision ngnix, so you have to modify chef recipies and add new vhost template into chef cookbooks directory\nYou can find all chef cookbooks here:\n/opt/gitlab/embedded/cookbooks/gitlab/\nopen \n/opt/gitlab/embedded/cookbooks/gitlab/recipes/nginx.rb\nchange:\nnginx_vars = node['gitlab']['nginx'].to_hash.merge({\n  :gitlab_http_config => File.join(nginx_etc_dir, \"gitlab-http.conf\"),\n})\n\nto:\nnginx_vars = node['gitlab']['nginx'].to_hash.merge({\n  :gitlab_http_config => File.join(nginx_etc_dir, \"gitlab-http.conf\"),\n  :examplecom_http_config => File.join(nginx_etc_dir, \"examplecom-http.conf\"),\n})\n\nadd this to the same file:\ntemplate nginx_vars[:examplecom_http_config] do\n  source \"nginx-examplecom-http.conf.erb\"\n  owner \"root\"\n  group \"root\"\n  mode \"0644\"\n  variables(nginx_vars.merge(\n    {\n      :fqdn => \"example.com\",\n      :port => 80,\n    }\n  ))\n  notifies :restart, 'service[nginx]' if OmnibusHelper.should_notify?(\"nginx\")\nend\n\nthen in template directory(/opt/gitlab/embedded/cookbooks/gitlab/templates/default), create nginx vhost template file( nginx-examplecom-http.conf.erb) and add this there:\nserver {\n  listen <%= @listen_address %>:<%= @port %>;\n  server_name <%= @fqdn %>;\n  root /var/www/example.com;\n\n  access_log  <%= @log_directory %>/examplecom_access.log;\n  error_log   <%= @log_directory %>/examplecom_error.log;\n\n  location /var/www/example.com {\n    # serve static files from defined root folder;.\n    # @gitlab is a named location for the upstream fallback, see below\n    try_files $uri $uri/index.html $uri.html;\n  }\n\n  error_page 502 /502.html;\n}\n\nyou have to set nginx['redirect_http_to_https'] = false in(/etc/gitlab/gitlab.rb):\nexternal_url \"https://gitlab.example.com\"\ngitlab_rails['gitlab_email_from'] = \"[email\u00a0protected]\"\ngitlab_rails['gitlab_support_email'] = \"[email\u00a0protected]\"\n\n\n\nnginx['redirect_http_to_https'] = false\nnginx['ssl_certificate'] = \"/etc/gitlab/ssl/ssl-unified.crt\"\nnginx['ssl_certificate_key'] = \"/etc/gitlab/ssl/ssl.key\"\n\n\ngitlab_rails['gitlab_default_projects_limit'] = 10\n\nadd include <%= @examplecom_http_config %>; into /opt/gitlab/embedded/cookbooks/gitlab/templates/default/nginx.conf.erb  :\nhttp {\n  sendfile <%= @sendfile %>;\n  tcp_nopush <%= @tcp_nopush %>;\n  tcp_nodelay <%= @tcp_nodelay %>;\n\n  keepalive_timeout <%= @keepalive_timeout %>;\n\n  gzip <%= @gzip %>;\n  gzip_http_version <%= @gzip_http_version %>;\n  gzip_comp_level <%= @gzip_comp_level %>;\n  gzip_proxied <%= @gzip_proxied %>;\n  gzip_types <%= @gzip_types.join(' ') %>;\n\n  include /opt/gitlab/embedded/conf/mime.types;\n\n  include <%= @gitlab_http_config %>;\n  include <%= @examplecom_http_config %>;\n}\n\nafter all those changes run:\ngitlab-ctl reconfigure\ngitlab-ctl restart"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI/CD Pass artifacts/variables between pipelines\n\ntl;dr\nHow do I pass data, e.g. the $BUILD_VERSION variable, between jobs in different pipelines in Gitlab CI?\nSo (in my case) this:\nPipeline 1 on push ect.            Pipeline 2 after merge\n\n    `building` job ...                `deploying` job\n          \u2502                                \u25b2\n          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500 $BUILD_VERSION \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\nBackground\nConsider the following example (full yml below):\nbuilding:\n    stage: staging\n    # only on merge requests\n    rules:\n        # execute when a merge request is open\n        - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n          when: always\n        - when: never\n    script:\n        - echo \"BUILD_VERSION=1.2.3\" > build.env\n    artifacts:\n        reports:\n            dotenv: build.env\n\ndeploying:\n    stage: deploy\n    # after merge request is merged\n    rules:\n        # execute when a branch was merged to staging\n        - if: $CI_COMMIT_BRANCH == $STAGING_BRANCH\n          when: always\n        - when: never\n    dependencies: \n        - building\n    script:\n        - echo $BUILD_VERSION\n\nI have two stages, staging and deploy. The building job in staging builds the app and creates a \"Review App\" (no separate build stage for simplicity). The deploying job in deploy then uploads the new app.\nThe pipeline containing the building job runs whenever a merge request is opened. This way the app is built and the developer can click on the \"Review App\" icon in the merge request. The deploying job is run right after the merge request is merged. The idea is the following:\n                      *staging* stage (pipeline 1)        *deploy* stage (pipeline 2)\n\n<open merge request> -> `building` job (and show)   ...   <merge> -> `deploying` job\n                             \u2502                                            \u25b2\n                             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 $BUILD_VERSION \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nThe problem for me is, that the staging/building creates some data, e.g. a $BUILD_VERSION. I want to have this $BUILD_VERSION in the deploy/deploying, e.g. for creating a new release via the Gitlab API.\nSo my question is: How do I pass the $BUILD_VERSION (and other data) from staging/building to deploy/deploying?\n\nWhat I've tried so far\nartifacts.reports.dotenv\nThe described case is more less handled in the gitlab docs in Pass an environment variable to another job. Also the yml file shown below is heavily inspired by this example. Still, it does not work.\nThe build.env artifact is created in building, but whenever the deploying job is executed, the build.env file gets removed as shown below in line 15: \"Removing build.env\". I tried to add build.env to the .gitignore but it still gets removed.\n\nAfter hours of searching I found in this gitlab issue comment and this stackoverflow post that the artifacts.reports.dotenv doesn't work with the dependencies or the needs keywords.\nRemoving dependencies doesn't work. Using needs only doesn't work either. Using both is not allowed.\nDoes anyone know a way how to get this to work? I feel like this is the way it should work.\nGetting the artifacts as a file\nThis answer of the stackoverflow post Gitlab ci cd removes artifact for merge requests suggests to use the build.env as a normal file. I also tried this. The (relevant) yml is the following:\nbuilding:\n    # ...\n    artifacts:\n        paths:\n            - build.env\n\ndeploying:\n    # ...\n    before_script:\n        - source build.env\n\nThe result is the same as above. The build.env gets removed. Then the source build.env command fails because build.env does not exist. (Doesn't matter if build.env is in the .gitignore or not, tested both)\nGetting the artifacts from the API\nI also found the answer of the stackoverflow post Use artifacts from merge request job in GitLab CI which suggests to use the API together with $CI_JOB_TOKEN. But since I need the artifacts in a non-merge-request pipeline, I cannot use the suggested CI_MERGE_REQUEST_REF_PATH.\nI tried to use $CI_COMMIT_REF_NAME. The (important section of the) yml is then:\ndeploying:\n    # ...\n    script:\n        - url=$CI_API_V4_URL/projects/jobs/artifacts/$CI_COMMIT_REF_NAME/download?job=building\n        - echo \"Downloading $url\"\n        - 'curl --header \"JOB-TOKEN: ${CI_JOB_TOKEN}\" --output $url'\n        # ...\n\nBut this the API request gets rejected with \"404 Not Found\". Since commit SHAs are not supported, $CI_COMMIT_BEFORE_SHA or $CI_COMMIT_SHA do not work either.\nUsing needs\nUpdate: I found the section Artifact downloads between pipelines in the same project in the gitlab docs which is exactly what I want. But: I can't get it to work.\nThe yml looks like the following after more less copying from the docs:\nbuilding:\n    # ...\n    artifacts:\n        paths:\n            - version\n        expire_in: never\n\ndeploying:\n    # ...\n    needs:\n        - project: $CI_PROJECT_PATH\n          job: building\n          ref: staging # building runs on staging branch, main doesn't work either\n          artifacts: true\n\nNow the deploying job instantly fails and I get the following error banner:\n\nI tried to set artifacts.expire_in = never (as shown) but I still get the same error. Also in Settings > CI/CD > Artifacts \"Keep artifacts from most recent successful jobs\" is selected. So the artifact should be present. What did I miss here? This should work according to the docs!\n\nI hope somebody can help me on getting the $BUILD_VERSION to the deploying job. If there are other ways than the ones I've tried, I'm very happy to hear them. Thanks in advance.\n\nThe example .gitlab-ci.yml:\nstages:\n    - staging\n    - deploy\n\nbuilding:\n    tags: \n        - docker\n    image: bash\n    stage: staging\n    rules:\n        - if: ($CI_PIPELINE_SOURCE == \"merge_request_event\") && $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == \"staging\"\n          when: always\n        - when: never\n    script:\n        - echo \"BUILD_VERSION=1.2.3\" > build.env\n    artifacts:\n        reports:\n            dotenv: build.env\n    environment:\n        name: Example\n        url: https://example.com\n\ndeploying:\n    tags: \n        - docker\n    image: bash\n    stage: deploy\n    rules:\n        - if: $CI_COMMIT_BRANCH == \"staging\"\n          when: always\n        - when: never\n    dependencies:\n        - building\n    script:\n        echo $BUILD_VERSION"}, {"role": "assistant", "content": "Going by the Gitlab docs, it should be possible to download any job's artifact by URL, if it hasn't expired yet.\nIn addition, you can use the Gitlab API to download (unexpired) artifacts from other projects, too; and you can use the Gitlab API to mark a job's artifacts for keeping-regardless-of-expiry-policy, or to delete an artifact.\nBut I have not tried this myself.\nFor your case, assuming the 'building' and 'deploying' jobs both run on the main branch, you can hopefully pass the artifact like so.\nIf you have some other way of finding out in the deploying job what branch name X the building job ran on, then you can download the artefact from branch X instead of always from main like I do below.\n# Assuming\n# domain: example.com\n# namespace: mygroup\n# project: myproject\n\nbuilding:\n    # on latest commit on `main`, because we need a predictable\n    # branch name to save/retrieve the artifact.\n    stage: staging\n    script:\n        - echo \"BUILD_VERSION=1.2.3\" > build.env\n    artifacts:\n        # 'paths', not 'reports'\n        paths:\n            - build.env\n\ndeploying:\n    # after merge request is merged\n    stage: deploy\n    dependencies: \n        - building\n    script:\n        # could use ${CI_PROJECT_URL} to get https://example.com/mygroup/myproj\n        - curl https://${CI_SERVER_HOST}/${CI_PROJECT_NAMESPACE}/${CI_PROJECT_NAME}/-/jobs/artifacts/main/raw/build.env?job=building > build.env\n        - source build.env\n        - echo $BUILD_VERSION  # should print '1.2.3'.\n\n\nThe relevant parts of the docs, with links and excerpts:\nAccess a branch or tag's latest job artifacts by URL\nTo browse or download the latest artifacts of a branch, use one of these two urls. [I think the /file/ variant is used for Gitlab Pages artifacts, but I'm not sure. --Esteis]\n\nBrowse artifacts:\nhttps://example.com/<namespace>/<project>/-/jobs/artifacts/<ref>/browse?job=<job_name>\nDownload zip of all artifacts:\nhttps://example.com/<namespace>/<project>/-/jobs/artifacts/<ref>/download?job=<job_name>\nDownload one artifact file:\nhttps://example.com/<namespace>/<project>/-/jobs/artifacts/<ref>/raw/<path/to/file>?job=<job_name>\nDownload one artifact file (Gitlab Pages-related?):\nhttps://example.com/<namespace>/<project>/-/jobs/artifacts/<ref>/file/<path>?job=<job_name>\n\nFor example, to download an artifact with domain gitlab.com, namespace gitlab-org, project gitlab, latest commit on main branch, job coverage, file path review/index.html:\nhttps://gitlab.com/gitlab-org/gitlab/-/jobs/artifacts/main/raw/review/index.html?job=coverage\nConfig setting: Keep artifacts from each branch's most recent succesful jobs\n\nThis option is on by default\nAFAICT it keeps the most recent artifact for\n\nevery active branch or tag (a.k.a. a 'ref');\nif multiple pipelines are run on that ref, last pipeline's artifacts overwrite those produced by earlier pipelines.\n\n\nAll other artifacts are still governed by the expire_in setting in the .gitlab-ci.yml that produced them.\n\nGitlab API for job artifacts\nAdvantage of using the Gitlab API is that if you can get the right tokens, you can also download artifacts from other projects. You'll need the numeric project ID -- that's $CI_PROJECT_ID, if your script is running in Gitlab CI.\nTo download an artifact archive:\n\ncurl --header \"PRIVATE-TOKEN: <your_access_token>\" \"https://gitlab.example.com/api/v4/projects/${CI_PROJECT_ID}/jobs/artifacts/main/download?job=test\"\n\nTo download a single artifact file:\n\ncurl --location --header \"PRIVATE-TOKEN: <your_access_token>\" \"https://gitlab.example.com/api/v4/projects/${CI_PROJECT_ID}/jobs/artifacts/main/raw/some/release/file.pdf?job=pdf\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Git init: fatal: could not set 'core.filemode' to 'false'\n\nUsing Team City to check out from a Git Repo. (Gitlabs if it matters)\nStart with Empty build directory.  Get this error:\nfatal: could not set 'core.filemode' to 'false'\n(Running on a Windows machine, if that matters)\nThe user that Team City is running on was changed to an Admin just in case.\nThe .Git directory is not a valid Repo when this command exits.\nWiping the entire 'work' directory doesn't help.\nIt randomly comes and goes... \nAND this: \ngit config --global --replace-all core.fileMode false\nDoes nothing useful - with or without the --replace-all, and run as admin, or another user (if you change 'false' to 'true' you get the same error, if you change it to 'falseCD' it changes the error to that being an invalid value - so clearly, it is changing it.\nAnyone got any ideas?"}, {"role": "assistant", "content": "In my case using \"sudo\" worked for me. For example: \nasif@asif-vm:/mnt/prog/protobuf_tut$ git clone https://github.com/protocolbuffers/protobuf.git\nCloning into 'protobuf'...\nerror: chmod on /mnt/prog/protobuf_tut/protobuf/.git/config.lock failed: Operation not permitted\nfatal: could not set 'core.filemode' to 'false'\n\nAfter doing a \"sudo\" I could get it working:\nasif@asif-vm:/mnt/prog/protobuf_tut$ sudo git clone https://github.com/protocolbuffers/protobuf.git\nCloning into 'protobuf'...\nremote: Enumerating objects: 5, done.\nremote: Counting objects: 100% (5/5), done.\nremote: Compressing objects: 100% (5/5), done.\nremote: Total 66782 (delta 0), reused 0 (delta 0), pack-reused 66777\nReceiving objects: 100% (66782/66782), 55.83 MiB | 2.04 MiB/s, done.\nResolving deltas: 100% (45472/45472), done.\nChecking out files: 100% (2221/2221), done."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab email setup: sending via another mail server\n\nBy default gitlab has the next configuration in gitlab.yml :\nemail:\n  from: [email\u00a0protected]\n  host: gitlabhq.com\n\nbut, I need to specify other variables (host, port, user, password, etc) to use another mail server.\nHow I do that?"}, {"role": "assistant", "content": "Now it is totally different in Gitlab 5.2+.\nIt is in \"/home/git/gitlab/config/initializers/smtp_settings.rb.sample\" and we just need to follow the instructions in that."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab initial root password\n\nIm trying to do an automated deployment of gitlab that has everything pre-configured. I need to specify an initial root password so first-time logins are not prompted with the password reset screen. I see the omnibus config option in the template: https://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/files/gitlab-config-template/gitlab.rb.template#L509\n506 #### Change the initial default admin password and shared runner registration tokens.\n507 ####! **Only applicable on initial setup, changing these settings after database\n508 ####!   is created and seeded won't yield any change.**\n509 # gitlab_rails['initial_root_password'] = \"password\"\n\nHowever, as the documentation says, this option will not take affect after installation. So, using gitlab-ctl reconfigure does not deploy these changes, as I have tested.\nWhen I try the solution from this this post:\n$ sudo gitlab-rake gitlab:setup RAILS_ENV=production GITLAB_ROOT_PASSWORD=\"Pa$$w0rd!\" GITLAB_ROOT_EMAIL=\"[email\u00a0protected]\" DISABLE_DATABASE_ENVIRONMENT_CHECK=1\nThis will create the necessary database tables and seed the database.\nYou will lose any previous data stored in the database.\nDo you want to continue (yes/no)? yes\n\nPG::ObjectInUse: ERROR:  database \"gitlabhq_production\" is being accessed by other users\nDETAIL:  There are 10 other sessions using the database.\n: DROP DATABASE IF EXISTS \"gitlabhq_production\"\nCouldn't drop database 'gitlabhq_production'\nrake aborted!\nActiveRecord::StatementInvalid: PG::ObjectInUse: ERROR:  database \"gitlabhq_production\" is being accessed by other users\nDETAIL:  There are 10 other sessions using the database.\n: DROP DATABASE IF EXISTS \"gitlabhq_production\"\n/opt/gitlab/embedded/service/gitlab-rails/lib/tasks/gitlab/setup.rake:33:in `setup_db'\n/opt/gitlab/embedded/service/gitlab-rails/lib/tasks/gitlab/setup.rake:5:in `block (2 levels) in <top (required)>'\n/opt/gitlab/embedded/bin/bundle:23:in `load'\n/opt/gitlab/embedded/bin/bundle:23:in `<main>'\n\nCaused by:\nPG::ObjectInUse: ERROR:  database \"gitlabhq_production\" is being accessed by other users\nDETAIL:  There are 10 other sessions using the database.\n/opt/gitlab/embedded/service/gitlab-rails/lib/tasks/gitlab/setup.rake:33:in `setup_db'\n/opt/gitlab/embedded/service/gitlab-rails/lib/tasks/gitlab/setup.rake:5:in `block (2 levels) in <top (required)>'\n/opt/gitlab/embedded/bin/bundle:23:in `load'\n/opt/gitlab/embedded/bin/bundle:23:in `<main>'\nTasks: TOP => db:drop:_unsafe\n(See full trace by running task with --trace)\n\nWhen I try to stop gitlab so no users are accessing it with gitlab-ctl stop, it fails with the following error:\n$ sudo gitlab-rake gitlab:setup RAILS_ENV=production GITLAB_ROOT_PASSWORD=\"Pa$$w0rd!\" GITLAB_ROOT_EMAIL=\"[email\u00a0protected]\" DISABLE_DATABASE_ENVIRONMENT_CHECK=1\nrake aborted!\nPG::ConnectionBad: could not connect to server: No such file or directory\n        Is the server running locally and accepting\n        connections on Unix domain socket \"/var/opt/gitlab/postgresql/.s.PGSQL.5432\"?\n/opt/gitlab/embedded/service/gitlab-rails/ee/app/models/license.rb:261:in `load_license'\n/opt/gitlab/embedded/service/gitlab-rails/ee/app/models/license.rb:250:in `current'\n/opt/gitlab/embedded/service/gitlab-rails/ee/app/models/license.rb:254:in `feature_available?'\n/opt/gitlab/embedded/service/gitlab-rails/ee/lib/ee/gitlab/auth/ldap/config.rb:19:in `_available_servers'\n/opt/gitlab/embedded/service/gitlab-rails/lib/gitlab/auth/ldap/config.rb:39:in `available_servers'\n/opt/gitlab/embedded/service/gitlab-rails/config/initializers/omniauth.rb:3:in `<module:Strategies>'\n/opt/gitlab/embedded/service/gitlab-rails/config/initializers/omniauth.rb:2:in `<top (required)>'\n/opt/gitlab/embedded/service/gitlab-rails/config/environment.rb:6:in `<top (required)>'\n/opt/gitlab/embedded/bin/bundle:23:in `load'\n/opt/gitlab/embedded/bin/bundle:23:in `<main>'\nTasks: TOP => gitlab:setup => gitlab_environment => environment\n(See full trace by running task with --trace)\n\n\nHow do I set an initial root password for gitlab with the omnibus install?"}, {"role": "assistant", "content": "I had a similar problem. Even if I set the environment variable, it seems that my gitlab ce still can't login. So I reset the password with the \"root\" user.\n# dir: /etc/gitlab\ngitlab-rake \"gitlab:password:reset[root]\"\n\nWait 10 minutes.\nAnd result\nEnter password:\nConfirm password:\nPassword successfully updated for user with username root.\n\nThen all works as usual."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Installing gitLab missing modernizer?\n\nI try to install gitlab on debian with this turotial: https://github.com/gitlabhq/gitlabhq/blob/master/doc/install/installation.md \nI'm at step \"Install Gems\" and try to run: \nsudo -u git -H bundle install --deployment --without development test postgres aws\n\ni get this echo: \nFetching source index from https://rubygems.org/\nCould not find modernizr-2.6.2 in any of the sources\n\nI don't find a solution for this error I run it as root as well.\nThanks for help."}, {"role": "assistant", "content": "I ran into this same problem a few minutes ago. Looks like the classy folks behind Modernizr's Rubygem yanked the most recent versions. You can download the latest gem (Modernizr-2.5.2 as required in the docs there) running the following command inside your /home/git/gitlab directory:\nwget http://rubygems.org/downloads/modernizr-2.6.2.gem\n\nThen, go ahead and run gem install modernizr (without changing directories) and the utility will search in the local directory for the gem file before trying to fetch it remotely. This is the gem we're looking for.\nNOTE: It looks like some people are still having problems with this solution, so something else we can do is replace a few lines in Gemfile and Gemfile.lock (both on /home/git/gitlab), switching modernizr for modernizr-rails:\n\nin Gemfile, line 164, change \"modernizr\", \"2.6.2\" to \"modernizr-rails\", \"2.7.1\" \nin Gemfile.lock, line 292, change modernizr (2.6.2) to modernizr-rails (2.7.1) \nin Gemfile.lock, line 626, change modernizr (= 2.6.2) to modernizr-rails (= 2.7.1)\n\nThis second solution is thanks to csj4032 on Github."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Download a GitLab private repository\n\nI want to use curl to download my private repo in GitLab. I know I can use the Gitlab API, but for some reason, It doesn't work.\nIs this possible? When I try to do it this way, it always returns the login page."}, {"role": "assistant", "content": "This is possible, just follow these steps:\n\nFirst, you have to create a \"Personal Access Token\":\n\nGo to Your Profile > Settings > Access Tokens.\n\nEnter a name for your \"Personal Access Token\".\n\nCheck \"api Access the authenticated user's API\"\n\n\nClick \"Create personal access token\"\n\nThe page will reload and save your new token.\n\nMake sure you save the token somewhere safe, you won't be able to view it again.\n\n\n\n\nNow that you have your \"Personal Access Token\", you need to get your project id to use the API:\n\nGo to https://gitlab.com/api/v4/projects?private_token=XXXXXXXXXXXXXXXXXXXX (replace the Xs with your new token)\n\nGet your project's id from the json.\n\n\n\n(alternatively you can just copy Project ID from its web page)\n\n\nNow you can call:\n wget -O your_project.tar.gz https://gitlab.com/api/v4/projects/0000000/repository/archive?private_token=XXXXXXXXXXXXXXXXXXXX\n\n\n\nAnd that'll download your project as a .tar.gz file.\nEdit: you can get tarball for specific commit/tag by adding &sha=... parameter to URL, like:\nhttps://gitlab.com/api/v4/projects/24470128/repository/archive?private_token=XXXXXXXXXXXXX&sha=606e81c69eff27eccbbc59a0546a9439780dff55"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Push files to gitlab-ci via CI runner\n\nI am using gitlab CI runner to test my code and generating some files. I just want to push the generated files to gitlab repository via CI runner. Is there any way to do that ?"}, {"role": "assistant", "content": "I have resolved this issue by doing this:\nNote: If you want to git push to a non protected branch do not set the runner variable as protected\n\nGenerate new gitlab access token with api scope: User Settings > Access Tokens\nAdd a protected CI variable into your project settings with the new token: Your project > Settings > Secret variable using variable name CI_PUSH_TOKEN\nAdd another protected CI variable with your username using variable name CI_USERNAME\n\nThen you can use this token instead of the default in you gitlab-ci script. for example:\nbefore_script:\n  - git remote set-url origin https://${CI_USERNAME}:${CI_PUSH_TOKEN}@gitlab.com/${CI_PROJECT_NAME}.git\n  - git config --global user.email '${GITLAB_USER_EMAIL}'\n  - git config --global user.name '${GITLAB_USER_ID}'\n\n...\n\n- git checkout -B branch\n- # do the file changes here\n- git commit -m '[skip ci] commit from CI runner'\n- git push --follow-tags origin branch"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Can I submit a pull request from GitLab.com to GitHub?\n\nMost of our work occurs on GitLab.com (i.e. not a local GitLab installation). If the upstream repo resides on GitHub, is there a way to submit a pull request to upstream? (If forking the upstream repo in a particular way is part of solution, that's ok.)"}, {"role": "assistant", "content": "No. The correct workflow would be forking the upstream project on GitHub to your own namespace. Then use your fork as upstream in your GitLab repository not the origin of your fork.\nFrom your GitLab repository you are then pushing changes to your fork (upstream). Then on GitHub you can submit a pull request from your GitHub fork to the origin."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Displaying latex equation in gitlab wiki using the markdown editor\n\nI am interested in building a wiki for my scientific computing code on gitlab which needs me to write equations and render them in the wiki in gitlab.\nHow to do this.\nI tried to paste the mathjax rendering script but it doesn't work. \nCan KaTeX be used anyhow ?\n$$\n  \\partial_t \\int_{\\Omega} \\mathbf{q} d \\Omega =\n  \\int_{\\partial \\Omega} \\mathbf{f} (\n  \\mathbf{q}) \\cdot \\mathbf{n}d \\partial\n  \\Omega - \\int_{\\Omega} hg \\nabla z_b\n$$"}, {"role": "assistant", "content": "GitLab supports KaTex from GitLab CE 8.15 using code backticks. \nDocumentation is here and the \nRelevant discussion are on merge request 8003.\nHere is the current way to use equations in GitLab"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Kubernetes - Container image already present on machine\n\nSo I have 2 similar deployments on k8s that pulls the same image from GitLab. Apparently this resulted in my second deployment to go on a CrashLoopBackOff error and I can't seem to connect to the port to check on the /healthz of my pod. Logging the pod shows that the pod received an interrupt signal while describing the pod shows the following message.\n FirstSeen  LastSeen    Count   From            SubObjectPath                   Type        Reason          Message\n  --------- --------    -----   ----            -------------                   --------    ------          -------\n  29m       29m     1   default-scheduler                           Normal      Scheduled       Successfully assigned java-kafka-rest-kafka-data-2-development-5c6f7f597-5t2mr to 172.18.14.110\n  29m       29m     1   kubelet, 172.18.14.110                          Normal      SuccessfulMountVolume   MountVolume.SetUp succeeded for volume \"default-token-m4m55\" \n  29m       29m     1   kubelet, 172.18.14.110  spec.containers{consul}             Normal      Pulled          Container image \"..../consul-image:0.0.10\" already present on machine\n  29m       29m     1   kubelet, 172.18.14.110  spec.containers{consul}             Normal      Created         Created container\n  29m       29m     1   kubelet, 172.18.14.110  spec.containers{consul}             Normal      Started         Started container\n  28m       28m     1   kubelet, 172.18.14.110  spec.containers{java-kafka-rest-development}    Normal      Killing         Killing container with id docker://java-kafka-rest-development:Container failed liveness probe.. Container will be killed and recreated.\n  29m       28m     2   kubelet, 172.18.14.110  spec.containers{java-kafka-rest-development}    Normal      Created         Created container\n  29m       28m     2   kubelet, 172.18.14.110  spec.containers{java-kafka-rest-development}    Normal      Started         Started container\n  29m       27m     10  kubelet, 172.18.14.110  spec.containers{java-kafka-rest-development}    Warning     Unhealthy       Readiness probe failed: Get http://10.5.59.35:7533/healthz: dial tcp 10.5.59.35:7533: getsockopt: connection refused\n  28m       24m     13  kubelet, 172.18.14.110  spec.containers{java-kafka-rest-development}    Warning     Unhealthy       Liveness probe failed: Get http://10.5.59.35:7533/healthz: dial tcp 10.5.59.35:7533: getsockopt: connection refused\n  29m       19m     8   kubelet, 172.18.14.110  spec.containers{java-kafka-rest-development}    Normal      Pulled          Container image \"r..../java-kafka-rest:0.3.2-dev\" already present on machine\n  24m       4m      73  kubelet, 172.18.14.110  spec.containers{java-kafka-rest-development}    Warning     BackOff         Back-off restarting failed container\n\nI have tried to redeploy the deployments under different images and it seems to work just fine. However I don't think this will be efficient as the images are the same throughout. How do I go on about this?\nHere's what my deployment file looks like:\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: \"java-kafka-rest-kafka-data-2-development\"\n  labels:\n    repository: \"java-kafka-rest\"\n    project: \"java-kafka-rest\"\n    service: \"java-kafka-rest-kafka-data-2\"\n    env: \"development\"\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      repository: \"java-kafka-rest\"\n      project: \"java-kafka-rest\"\n      service: \"java-kafka-rest-kafka-data-2\"\n      env: \"development\"\n  template:\n    metadata:\n      labels:\n        repository: \"java-kafka-rest\"\n        project: \"java-kafka-rest\"\n        service: \"java-kafka-rest-kafka-data-2\"\n        env: \"development\"\n        release: \"0.3.2-dev\"\n    spec:\n      imagePullSecrets:\n      - name: ...\n      containers:\n      - name: java-kafka-rest-development\n        image: registry...../java-kafka-rest:0.3.2-dev\n        env:\n        - name: DEPLOYMENT_COMMIT_HASH\n          value: \"0.3.2-dev\"\n        - name: DEPLOYMENT_PORT\n          value: \"7533\"\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 7533\n          initialDelaySeconds: 30\n          timeoutSeconds: 1\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 7533\n          timeoutSeconds: 1\n        ports:\n        - containerPort: 7533\n        resources:\n          requests:\n            cpu: 0.5\n            memory: 6Gi\n          limits:\n            cpu: 3\n            memory: 10Gi\n        command:\n          - /envconsul\n          - -consul=127.0.0.1:8500\n          - -sanitize\n          - -upcase\n          - -prefix=java-kafka-rest/\n          - -prefix=java-kafka-rest/kafka-data-2\n          - java\n          - -jar\n          - /build/libs/java-kafka-rest-0.3.2-dev.jar\n        securityContext:\n          readOnlyRootFilesystem: true\n      - name: consul\n        image: registry.../consul-image:0.0.10\n        env:\n        - name: SERVICE_NAME\n          value: java-kafka-rest-kafka-data-2\n        - name: SERVICE_ENVIRONMENT\n          value: development\n        - name: SERVICE_PORT\n          value: \"7533\"\n        - name: CONSUL1\n          valueFrom:\n            configMapKeyRef:\n              name: consul-config-...\n              key: node1\n        - name: CONSUL2\n          valueFrom:\n            configMapKeyRef:\n              name: consul-config-...\n              key: node2\n        - name: CONSUL3\n          valueFrom:\n            configMapKeyRef:\n              name: consul-config-...\n              key: node3\n        - name: CONSUL_ENCRYPT\n          valueFrom:\n            configMapKeyRef:\n              name: consul-config-...\n              key: encrypt\n        ports:\n        - containerPort: 8300\n        - containerPort: 8301\n        - containerPort: 8302\n        - containerPort: 8400\n        - containerPort: 8500\n        - containerPort: 8600\n        command: [ entrypoint, agent, -config-dir=/config, -join=$(CONSUL1), -join=$(CONSUL2), -join=$(CONSUL3), -encrypt=$(CONSUL_ENCRYPT) ]\n      terminationGracePeriodSeconds: 30\n      nodeSelector:\n        env: ..."}, {"role": "assistant", "content": "To those having this problem, I've discovered the problem and solution to my question. Apparently the problem lies with my service.yml where my targetPort was aimed to a port different than the one I opened in my docker image. Make sure the port that's opened in the docker image connects to the right port.\nHope this helps."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Fatal: Not a gitflow-enabled repo yet. Please run 'git flow init' first\n\nI cloned a project and ran git checkout -b develop. When I run git flow feature start feature_name it gives me the following error:\n\nFatal: Not a gitflow-enabled repo yet. Please run 'git flow init' first.\n\ncan any one help me?"}, {"role": "assistant", "content": "I got it working by doing the steps mentioned by jpfl @ answers.atlassian.com:\n\nAlthough this is an old post, just wanted to add to this since I've\n  gotten stuck on this same error. Was able to resolve by doing the\n  following:\n\nOpen the .git\\config file OR Repository -> Repository Settings -> Remotes -> Edit Config File (Sourcetree 2.7.6)\nRemove all the [gitflow * entries and save\n  the file \nClose and re-open SourceTree \nIn the main menu, go to\n  Repository > Git Flow > Initialise Repository (should be enabled\n  now)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Docker login: access denied you must use a personal access token\n\nTrying to login from docker to gitlab using the command:\nsudo docker login registry.gitlab.com?private_token=XXX\n\nBut I still have the following error message:\nError response from daemon: Get https://registry.gitlab.com/v2/: unauthorized: HTTP Basic: Access denied\\nYou must use a personal access token with 'api' scope for Git over HTTP.\\nYou can generate one at https://gitlab.com/-/profile/personal_access_tokens\n\nThe token has the right access I doubled checked... I am rather new to docker, any hint/help? thanks!"}, {"role": "assistant", "content": "The correct command line (that works in my case at least) was:\ndocker login registry.example.com -u <your_username> -p <your_personal_access_token>"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab-CI: Specify that Job C should run after Job B if Job A fails\n\nImagine you have the following Pipeline:\nJob A (deploy) -> Job B (test) -> Job C (remove test deployment)\n\nThe pipeline should deploy a test image and test it after a successful deployment. After the test I want to run a cleanup script regardless of the test output, but only if the test image (Job A) was deployed.\nTo summarize this:  I want Gitlab to execute Job C only if Job A succeeds, but after Job B.\nThings that won't work:\n\nwhen: on-failure (Job A or Job B could failed, but only Job A is important)\nwhen: always (maybe Job A failed which causes Job C to fail)\nwhen: on-success (requires all jobs to succeed)\n\nI know that GitLab has a feature called DAG Pipelines which allow you to specify multiple dependencies on other jobs with the needs keyword, but sadly the when keyword is always scoped to all prior jobs. So you are not able to say something like:\nwhen:\n    on-success: job-a\n    always: job-b\n\nDo I miss something or is there no way to achieve such a behaviour?"}, {"role": "assistant", "content": "The needs DAG field can be used to conditionally execute the cleanup (Job C), if Job B fails or succeeds, but NOT when it is skipped because Job A failed.\nCreate 2 cleanup jobs that match the following boolean conditions:\n\n(Job A succeeds and Job B succeeds): If all previous tasks succeed (Job A and Job B), we can run the cleanup with when: on_success. However, this will not trigger if Job A succeeds and Job B fails.\n(Job A succeeds and Job B fails): To circumvent the previous scenario with an untriggered cleanup (Job C), we make use of the fact that if Job B fails, this implies that Job A succeeded in the pipeline. By creating a duplicate cleanup task and specifying a needs tag on Job B and when: on_failure, the cleanup task will only run if Job A succeeds and Job B fails.\n\nTo reiterate: a cleanup job will run if (Job A succeeds and Job B succeeds) or (Job A succeeds and Job B fails), which by boolean expression reduction is equivalent to (Job A succeeds).\nAn obvious caveat here is that there are now 2 cleanup jobs that are displayed in the pipeline; however, they are mutually exclusive and only one could ever be executed.\nHere is a sample configuration:\nstages:\n  - deploy\n  - test\n  - cleanup\n\ndeploy_job:\n  stage: deploy\n  script:\n    - echo Deployed\n    - \"true\"\n  when: always\n\ntest_job:\n  stage: test\n  script:\n    - echo Executing tests\n    - \"true\"\n  when: on_success\n\n# a YAML anchor reduces repetition\n.cleanup_job: &cleanup_job\n  stage: cleanup\n  script:\n    - echo Cleaned up deployment\n\ncleanup_deployment_success:\n  when: on_success\n  <<: *cleanup_job\n\ncleanup_deployment_failure:\n  needs: [\"test_job\"]\n  when: on_failure\n  <<: *cleanup_job\n\n\nWith various intentional fail conditions, the following pipeline states are produced:\n\nfailed pipeline: \nfailed pipeline: \npassed pipeline: \n\nLogically, this indicates that regardless of whether Job B succeeded or failed, Job C runs if Job A succeeded. Furthermore, the failure state is preserved in the overall pipeline."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab DOCKER_AUTH_CONFIG not working\n\nThe following are in my .gitlab-ci.yml\nstages:\n  - build\n\nvariables:\n  DOCKER_HOST: tcp://docker:2375/\n  DOCKER_DRIVER: overlay2\n\nservices:\n  - docker:dind\n\nbuild-image:\n  image: docker:stable\n  stage: build\n  script:\n    - docker build --no-cache -t repo/myimage:$CI_JOB_ID .\n    - docker push repo/myimage:$CI_JOB_ID\n\nI've setup the DOCKER_AUTH_CONFIG in Gitlab like following (to contain all possibilities of matching)\n{\n    \"auths\": {\n        \"https://index.docker.io\": {\n            \"auth\": \"....\"\n        },\n        \"https://index.docker.io/v1/\": {\n            \"auth\": \"...\"\n        },\n        \"https://index.docker.io/v2/\": {\n            \"auth\": \"...\"\n        },\n        \"index.docker.io/v1/\": {\n            \"auth\": \"...\"\n        },\n        \"index.docker.io/v2/\": {\n            \"auth\": \"...\"\n        },\n        \"docker.io/repo/myimage\": {\n            \"auth\": \"...\"\n        }\n\n    }\n}\n\nHowever, whenever trying to push the image, the following error occurred\n$ docker push repo/myimage:$CI_JOB_ID\nThe push refers to repository [docker.io/repo/myimage]\nce6466f43b11: Preparing\n719d45669b35: Preparing\n3b10514a95be: Preparing\n63dcf81c7ca7: Waiting\n3b10514a95be: Waiting\ndenied: requested access to the resource is denied\nERROR: Job failed: exit code 1\n\nIt worked when I use docker login with username/password. Anyone please show me what I did wrong to get it to work with DOCKER_AUTH_CONFIG?\nThanks heaps\nRegards\nTin"}, {"role": "assistant", "content": "To use the content of DOCKER_AUTH_CONFIG as docker login, just store it in $HOME/.docker/config.json, e.g. as follows:\nbefore_script:\n  - mkdir -p $HOME/.docker\n  - echo $DOCKER_AUTH_CONFIG > $HOME/.docker/config.json\n\nRef: https://docs.gitlab.com/ee/ci/docker/using_docker_build.html#option-3-use-docker_auth_config\nThis allows to use a single config to load images for build containers and to access the registry inside the build from the same configuration source.\nnote: this replaces an execution of docker login\nsee also: https://docs.docker.com/engine/reference/commandline/login/#privileged-user-requirement"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "how to change gitlab-ci runner build path\n\nHow to change the gitlab multi runner build path.\nin my server it have /home/gitlab-runner/builds.\nI want to change this path to my secondary HDD that is mounted in the same server."}, {"role": "assistant", "content": "You can change your runners build path by adjusting the config.toml. In the [[runners]] section add or change the builds_dir directory.\nFor further reference on runner configuration you can check out the documentation here."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab 8.2.1, How to use cache in .gitlab-ci.yml\n\nI'm trying to use 'cache' in .gitlab-ci.yml (http://doc.gitlab.com/ce/ci/yaml/README.html#cache). My gitlab version is 8.2.1 and my Runner is: \n$ docker exec -it gitlab-runner gitlab-runner -v \ngitlab-runner version 0.7.2 (998cf5d)\n\nSo according to the doc, everything is up to date, but I'm unable to use the cache ;-(. All my files are always deleted. Am I doing something wrong?\nA cache archive is created, but not passed to the next jobs.\nHere is my .gitlab-ci.yml\n$ cat .gitlab-ci.yml\n    stages:\n    - createcache\n    - testcache\n\n    createcache:\n      type: createcache\n      cache:\n        untracked: true\n        paths:\n          - doc/\n      script:\n        - touch doc/cache.txt\n\n    testcache:\n      type: testcache\n      cache:\n        untracked: true\n        paths:\n          - doc/\n      script:\n        - find .\n        - ls doc/cache.txt\n\nOutput of the job 'createcache'\nRunning on runner-141d90d4-project-2-concurrent-0 via 849d416b5994...\nFetching changes...\nHEAD is now at 2ffbadb MUST BE REVERTED\n[...]\n$ touch doc/cache.txt\n[...]\nArchiving cache...\nINFO[0000] Creating archive cache.tgz ...              \nINFO[0000] Done!                                        \n\nBuild succeeded.\n\nOutput of the job 'testcache'\nRunning on runner-141d90d4-project-2-concurrent-0 via 849d416b5994...\nFetching changes...\nRemoving doc/cache.txt\n[...]\n$ ls doc/cache.txt\nls: cannot access doc/cache.txt: No such file or directory\n\nERROR: Build failed with: exit code 1\n\nMy workaround\nMy workaround is to manually untar what's in the /cache directory ... I'm pretty sure that's not the correct way to use cache ...\n$ cat .gitlab-ci.yml\n    stages:\n    - build\n    - test\n    - deploy\n\n    image: ubuntu:latest\n\n    before_script:\n      - export CACHE_FILE=`echo ${CI_PROJECT_DIR}/createcache/${CI_BUILD_REF_NAME}/cache.tgz | sed -e \"s|/builds|/cache|\"`\n\n    createcache:\n      type: build\n      cache:\n        untracked: true\n        paths:\n          - doc/\n      script:\n        - find . | grep -v \".git\"\n        - mkdir -p doc\n        - touch doc/cache.txt\n\n    testcache:\n      type: test\n      script:\n        - env\n        - find . | grep -v \".git\"\n        - tar xvzf ${CACHE_FILE}\n        - ls doc/cache.txt"}, {"role": "assistant", "content": "https://gitlab.com/gitlab-org/gitlab-ci-multi-runner/issues/327\nimage: java:openjdk-8-jdk\n\nbefore_script:\n    - export GRADLE_USER_HOME=`pwd`/.gradle\n\ncache:\n  paths:\n    - .gradle/wrapper\n    - .gradle/caches\n\nbuild:\n  stage: build\n  script:\n     - ./gradlew assemble\n\ntest:\n  stage: test\n  script:\n     - ./gradlew check"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab-Ci: How could I share data between jobs\n\nI want to share a file between two jobs and modify it if there are changed files. The python script compare the cache.json file with changes and modify the cahce file sometimes.\n.gitlab-ci.yaml:\nimage: ubuntu\n\nstages:\n  - test\n\ncache:\n  key: one-cache\n  paths:\n    - cache.json\n\n job1:\n   stage: test\n\nscript:\n  # - touch cache.json\n  - cat cache.json\n  - python3 modify_json_file.py\n  - cat cache.json\n\nThe problem is that it the cache.json file not exist at the next job run. I get the error message: cat: cache.json: No such file or directory. I did also insert once the touch command, but this doesn't change anything for the next run without the touch command.\nDo I something wrong or don't I understand the cache at gitlab wrong."}, {"role": "assistant", "content": "I think you need artifacts and not cache.\nFrom cache vs artifact:\n\ncache - Use for temporary storage for project dependencies. Not useful for keeping intermediate build results, like jar or apk files. Cache was designed to be used to speed up invocations of subsequent runs of a given job, by keeping things like dependencies (e.g., npm packages, Go vendor packages, etc.) so they don't have to be re-fetched from the public internet. While the cache can be abused to pass intermediate build results between stages, there may be cases where artifacts are a better fit.\nartifacts - Use for stage results that will be passed between stages. Artifacts were designed to upload some compiled/generated bits of the build, and they can be fetched by any number of concurrent Runners. They are guaranteed to be available and are there to pass data between jobs. They are also exposed to be downloaded from the UI."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab run a pipeline job when a merge request is merged\n\nI have a gitlab pipeline where there are two stages, one is build and the other one is deploy. The build stage is run when a commit is made. I want a way to run the deploy job when the merge request is merged to master. I tried several things but no luck. Can anyone help?\nstages:\n  - build\n  - deploy\n\ndotnet:\nscript: \"echo This builds!\"\nstage: build\n\n\nproduction:\nscript: \"echo This deploys!\"\nstage: deploy\n\nonly:\n  refs:\n    - master"}, {"role": "assistant", "content": "Try using the gitlab-ci.yml \"rules\" feature to check for the merge request event.\nYour current gitlab-ci.yml will run your \"dotnet\" job every commit, merge request, schedule, and manually triggered pipeline.\nhttps://docs.gitlab.com/ee/ci/yaml/#workflowrules\ndotnet:\n  script: \"echo This builds!\"\n  stage: build\n  rules:\n    - if: '$CI_COMMIT_REF_NAME != \"master\" && $CI_PIPELINE_SOURCE == \"push\" || $CI_PIPELINE_SOURCE == \"merge_request_event\"'\n\nproduction:\n  script: \"echo This deploys!\"\n  stage: deploy\n  rules:\n    - if: '$CI_PIPELINE_SOURCE == \"push\" && $CI_COMMIT_REF_NAME == \"master\"'"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I add image to README file on GitLab?\n\nThe title says it all. I took a look into GitLab docs but couldn't find clear-cut solution to this.\nHow do I add image to readme on GitLab ? Image that's within the repo."}, {"role": "assistant", "content": "You can use ![image info](images/image.png) where images could be a directory in your project structure."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to connect Visual Studio 2015 to an existing Gitlab project?\n\nThere is an on-premise instance of gitlab installed. There are Visual Studio projects in this instance. What is the easiest way of connecting Visual Studio 2015 to one of the projects?\nWith GitHub, you can do it by selecting \"Connect to GitHub\" as on the following picture:\n\nand then pasting the repository url. There is no GitLab option in the drop down. What is the easiest way of configuring Visual Studio 2015 to work with a solution from gitlab repository? By work I mean to have your usual source control bindings to the repository.\nNote, that this question is probably useful in more general context of connecting to any git repository that is not GitHub, and does not have direct support with built-in Visual Studio menu, not just to GitLab repository."}, {"role": "assistant", "content": "First, get the clone using command line:\ngit clone <repository url>\n\nThen in Visual Studio, in the Team Explorer pane, select the connect button and look for Local Git Repositories \"tab\":\n\nPress Add, as indicated on the picture, and select the folder you cloned your repository too. \nWhen the process finishes, you can double-click the added repo to \"connect\" to it, and then select and open a solution it contains. After that follow your usual Visual Studio git workflow."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do we use the 'variables' keyword in gitlab-ci.yml?\n\nI am trying to make use of the variables: keyword documented in the Gitlab CI Documentation here:\nFROM: https://docs.gitlab.com/ce/ci/yaml/README.html\n\nvariables\nThis feature requires gitlab-runner with version equal or greater than\n  0.5.0.\nGitLab CI allows you to add to .gitlab-ci.yml variables that are set\n  in build environment. The variables are stored in repository and are\n  meant to store non-sensitive project configuration, ie. RAILS_ENV or\n  DATABASE_URL.\nvariables:   \n  DATABASE_URL: \"postgres://postgres@postgres/my_database\"\n\nThese variables can be later used in all executed commands and\n  scripts.\nThe YAML-defined variables are also set to all created service\n  containers, thus allowing to fine tune them.\n\nWhen I attempt to use it, my builds do not run any stages and are marked successful anyway, a good sign of bad YAML. I pasted my gitlab-ci.yml contents into the LINT tool in the settings area and the output error is:\n\nStatus: syntax is incorrect\nError: variables job: unknown parameter PACKAGE_NAME\n\nI'm using my YAML syntax the same as the docs, however it will not work. I'm unable to find any open bugs related to this. Below are my current versions and a sanitized version of my gitlab-ci.yml.\nGitlab Version:  7.13.2 Omnibus\nGitlab Runner Version: 0.5.2\ngitlab-ci.yml (Sanitized)\ntypes:\n  - test\n  - build\n\nvariables:\n  PACKAGE_NAME: \"awesome-django-app\"\n  PACKAGE_SUMMARY: \"Awesome webapp backend.\"\n  MAJOR_RELEASE: \"1\"\n  MINOR_RELEASE: \"0\"\n  PATCH_LEVEL: \"0dev\"\n  DEV_DB_URL: \"db\"\n  DEV_SERVER: \"pydev.example.com\"\n  PROD_SERVER: \"pyprod.example.com\"\n  TEST_SERVER: \"pytest.example.com\"\n\nenvtest:\n  type: test\n  script:\n  - \". ./testbuild.sh\"\n  tags:\n  - python2.7\n  - postgres\n  - linux\n  except:\n  - tags\n\nbuildrpm:\n  type: build\n  script:\n  - mkdir -p ~/rpmbuild/SOURCES\n  - mkdir -p ~/rpmbuild/SPECS\n  - mkdir -p ~/tarbuild/$PACKAGE_NAME-$MAJOR_RELEASE.$MINOR_RELEASE.$PATCH_LEVEL\n  - cp $PACKAGE_NAME.spec ~/rpmbuild/SPECS/.\n  - cp -r * ~/tarbuild/$PACKAGE_NAME-$MAJOR_RELEASE.$MINOR_RELEASE.$PATCH_LEVEL/.\n  - cd ~/tarbuild\n  - tar -zcf ~/rpmbuild/SOURCES/$PACKAGE_NAME-$MAJOR_RELEASE.$MINOR_RELEASE.$PATCH_LEVEL.tar.gz *\n  - cd ~\n  - rm -Rf ~/tarbuild\n  - rpmlint -i ~/rpmbuild/SPECS/$PACKAGE_NAME.spec\n  - echo $CI_BUILD_ID\n  - 'rpmbuild -ba ~/rpmbuild/SPECS/$PACKAGE_NAME.spec \\\n                    --define=\"_build_number $CI_BUILD_ID\" \\\n                    --define=\"_python_version_min 2.7\" \\\n                    --define=\"_version $MAJOR_RELEASE.$MINOR_RELEASE.$PATCH_LEVEL\" \\\n                    --define=\"_package_name $PACKAGE_NAME\" \\\n                    --define=\"_summary $SUMMARY\"'\n  - scp rpmbuild/RPMS/noarch/$PACKAGE_NAME-$MAJOR_RELEASE.$MINOR_RELEASE.$PATCH_LEVEL-$CI_BUILD_ID.noarch.rpm $DEV_SERVER:~/.\n  tags:\n  - python2.7\n  - postgres\n  - linux\n  - rpm\n  except:\n  - tags\n\nQuestion: \nHow do I use this value properly?\nAdditional Info:\nRemoving this section from the YAML file causes everything to work so the rest of the file is in working order. (Of course undefined variables lead to script errors...)\nEven just reducing the variables for testing down to just PACKAGE_NAME causes the same break."}, {"role": "assistant", "content": "The original answer is no longer correct. \nThe original documentation now stands, Now there are more ways as well. Variables can be created from the GUI, API, or by being defined in the .gitlab-ci.yml as well.\nhttps://docs.gitlab.com/ce/ci/variables/README.html"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Auto-merging package-lock.json\n\ngit merge --no-ff account-creation\n\nAuto-merging package-lock.json\nCONFLICT (content): Merge conflict in package-lock.json\nAutomatic merge failed; fix conflicts and then commit the result.\nAny idea regarding this issue ?"}, {"role": "assistant", "content": "As per the docs:\n\nResolving lockfile conflicts\nOccasionally, two separate npm install will create package locks that\ncause merge conflicts in source control systems. As of [email\u00a0protected],\nthese conflicts can be resolved by manually fixing any package.json\nconflicts, and then running npm install [--package-lock-only] again.\nnpm will automatically resolve any conflicts for you and write a\nmerged package lock that includes all the dependencies from both\nbranches in a reasonable tree. If --package-lock-only is provided,\nit will do this without also modifying your local node_modules/.\nTo make this process seamless on git, consider installing\nnpm-merge-driver, which will\nteach git how to do this itself without any user interaction. In\nshort: $ npx npm-merge-driver install -g will let you do this, and\neven works with pre-[email\u00a0protected] versions of npm 5, albeit a bit more\nnoisily. Note that if package.json itself conflicts, you will have\nto resolve that by hand and run npm install manually, even with the\nmerge driver."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "why I have HTTP 403 from repo spring?\n\nI have a jhipster project which deploy on heroku with gitlab since several months\nSince yesterday, I can not deploy new version because I have this error\nFAILURE: Build failed with an exception.\n32 * What went wrong:\n33 A problem occurred configuring root project 'yvidya'.\n34 > Could not resolve all artifacts for configuration ':classpath'.\n35    > Could not resolve io.spring.gradle:propdeps-plugin:0.0.10.RELEASE.\n36      Required by:\n37          project :\n38       > Could not resolve io.spring.gradle:propdeps-plugin:0.0.10.RELEASE.\n39          > Could not get resource 'http://repo.spring.io/plugins-    release/io/spring/gradle/propdeps-plugin/0.0.10.RELEASE/propdeps-plugin-0.0.10.RELEASE.pom'.\n40             > Could not GET 'http://repo.spring.io/plugins-release/io/spring/gradle/propdeps-plugin/0.0.10.RELEASE/propdeps-plugin-0.0.10.RELEASE.pom'. Received status code 403 from server:     Forbidden\n\nAnyone know why this error? and how solve it?"}, {"role": "assistant", "content": "Open your build.gradle file and replace the spring maven repository URL from http with https"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to git clone with username and password in gitlab?\n\nI am using gitlab . I want to write a .bat file which contains all the steps so that I can automate all the process , which are as follows:\n\nopen cmd.exe /k\ngit init\ngit clone https://username:[email\u00a0protected]/board.git  ////// not working \ngit status\n\n\nThe 3rd point that is git clone https.... is not working in gitBash anymore. I tried using git clone SSH ... and it  is working which asked for the passphrase and after logging in it was about to clone the repo. As I want to automate the process by providing the login credentials by-default , how can it be achieved using SSH. Thank you."}, {"role": "assistant", "content": "Adding username before gitlab worked for me. It will ask password afterwards.\ngit clone https://[email\u00a0protected]/project.git"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "git push gives fatal: unable to update url base from redirection:\n\nI did commit successfully in my local repository. When I try to do:\ngit push https://gitlab.com/priceinsight/jmt4manager/compare/develop...2-retrieve-list-userrecord# 2-retrieve-list-userrecord -v\n\nI got this error:\nPushing to https://gitlab.com/priceinsight/jmt4manager/compare/develop...2-retrieve-list-userrecord#\nfatal: unable to update url base from redirection:\n  asked for: https://gitlab.com/priceinsight/jmt4manager/compare/develop...2-retrieve-list-userrecord#/info/refs?service=git-receive-pack\n   redirect: https://gitlab.com/users/sign_in"}, {"role": "assistant", "content": "The URL you try to push to is not correct. You are trying to push to the URL https://gitlab.com/priceinsight/jmt4manager/compare/develop...2-retrieve-list-userrecord# which is a webpage that compares two branches and not the URL of a repository. The repository would be https://gitlab.com/priceinsight/jmt4manager."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Create a repo in Gitlab using CLI\n\nWe have a gitlab setup at our office, and we have somewhat around 100-150 project each week to create over there, while Admin wants to keep the control of creating repos and assigning teams to it, it seems quite a bit of task for anyone to create that many repos every week.\nIs there a way to create repo on Gitlab using CLI - I won't mind if i have to use ssh for it."}, {"role": "assistant", "content": "gitlab-cli is no longer maintained, the author references the Gitlab module to be used instead - it also includes a CLI tool.\nFor your specific request - namely creating a project on the command line, use the following command:\ngitlab create_project \"YOUR_PROJECT_NAME\" \"{namespace_id: 'YOUR_NUMERIC_GROUP_ID'}\"\nBe sure to use the option namespace_id and not group_id! If you are not sure what your GROUP_ID is, you can use\ngitlab groups | grep YOUR_GROUP_NAME\nto find out.\nThe parameters for each command can be inferred from the API documentation. Any non-scalar valued parameter has to be encoded in an inline YAML syntax (as above)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to cause a job to finish with warning in Gitlab\n\nI mean to get this status:\n\nI can finish my job with failure, by \"exit 1\" , but can't do the same with warning"}, {"role": "assistant", "content": "This is possible since 13.8:\ntest_job:\n  script:\n    - execute_script_that_will_fail \n  # if the script exit code is 137 or 255 the job will allow to be \n  # failed and the pipeline will continue to run\n  allow_failure:\n    exit_codes: # User defined exit code\n      - 137\n      - 255"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to pass GitLab CI file variable to Dockerfile and docker container?\n\nGitLab CI allows adding custom variables to a project. \nIt allows to use a secret variable of type file where I specify a Key that is the variable name and Value that is the content of a file(e.g. content of certificate)\nThen during execution of the pipeline the content will be saved as a temporary file and calling the variable name will return the path to the created file.\nUltimately I need to copy this file to a Docker container that is created when building the project. (docker build ... in the yml)\nWhen testing if the variable works, I tried echo $VARIABLE in .gitlab-ci.yml and it works, returns path of temp file. But when doing RUN echo $VARIABLE in the Dockerfile, it is empty. Therefore I also cannot use ADD $VARIABLE /tmp/ which is my goal.\nIs there a way to solve this and make this file available to the Dockerfile? I am new to Docker and GitLab and not sure where else to look."}, {"role": "assistant", "content": "Had to use .yml file docker build argument --build-arg VARIABLE_NAME=variable_value and in Dockerfile use ARG VARIABLE_NAME so the Dockerfile knows it needs to use variable from environment."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI runner not able to expose ports of nested Docker containers\n\nWhen using GitLab CI, as well as the gitlab-ci-multi-runner, I'm unable to get internally-started Docker containers to expose their ports to the \"host\", which is the Docker image in which the build is running.\nMy .gitlab-ci.yml file:\ntest:\n  image: docker\n  stage: test\n  services:\n    - docker:dind\n  script:\n    - APP_CONTAINER_ID=`docker run -d --privileged -p \"9143:9143\" appropriate/nc nc -l 9143`\n    - netstat -a\n    - docker exec $APP_CONTAINER_ID netstat -a\n    - nc -v localhost 9143\n\nMy command:\ngitlab-ci-multi-runner exec docker --docker-privileged test\n\nThe output:\n$ netstat -a\nActive Internet connections (servers and established)\nProto Recv-Q Send-Q Local Address           Foreign Address         State\ntcp        0      0 runner--project-1-concurrent-0:54664 docker:2375             TIME_WAIT\ntcp        0      0 runner--project-1-concurrent-0:54666 docker:2375             TIME_WAIT\nActive UNIX domain sockets (servers and established)\nProto RefCnt Flags       Type       State         I-Node Path\n\n$ docker exec $APP_CONTAINER_ID netstat -a\nActive Internet connections (servers and established)\nProto Recv-Q Send-Q Local Address           Foreign Address         State\ntcp        0      0 0.0.0.0:9143            0.0.0.0:*               LISTEN\nActive UNIX domain sockets (servers and established)\nProto RefCnt Flags       Type       State         I-Node Path\n\n$ nc -v localhost 9143\nERROR: Build failed: exit code 1\nFATAL: exit code 1\n\nWhat am I doing wrong here?\nOriginal Question Follows - above is a shorter, easier-to-test example\nI have an application image that listens on port 9143. Its startup and config is managed via docker-compose.yml, and works great on my local machine with docker-compose up - I can access localhost:9143 without issue.\nHowever, when running on GitLab CI (the gitlab.com version) via a shared runner, the port doesn't seem to be exposed.\nThe relevant portion of my .gitlab-ci.yml:\ntest:\n  image: craigotis/buildtools:v1\n  stage: test\n  script:\n    - docker login -u gitlab-ci-token -p $CI_BUILD_TOKEN registry.gitlab.com/craigotis/myapp\n    - docker-compose up -d\n    - sleep 60 # a temporary hack to get the logs\n    - docker-compose logs\n    - docker-machine env\n    - docker-compose port app 9143\n    - netstat -a\n    - docker-compose ps\n    - /usr/local/bin/wait-for-it.sh -h localhost -p 9143 -t 60\n    - cd mocha\n    - npm i\n    - npm test\n    - docker-compose down\n\nThe output is:\n$ docker-compose logs\n...\napp_1  | [Thread-1] INFO spark.webserver.SparkServer - == Spark has ignited ...\napp_1  | [Thread-1] INFO spark.webserver.SparkServer - >> Listening on 0.0.0.0:9143\napp_1  | [Thread-1] INFO org.eclipse.jetty.server.Server - jetty-9.0.z-SNAPSHOT\napp_1  | [Thread-1] INFO org.eclipse.jetty.server.ServerConnector - Started ServerConnector@6919dc5{HTTP/1.1}{0.0.0.0:9143}\n...\n\n$ docker-compose port app 9143\n0.0.0.0:9143\n\n$ netstat -a\nActive Internet connections (servers and established)\nProto Recv-Q Send-Q Local Address           Foreign Address         State       \ntcp        0      0 runner-e11ae361-project-1925166-concurrent-0:53646 docker:2375             TIME_WAIT   \ntcp        0      0 runner-e11ae361-project-1925166-concurrent-0:53644 docker:2375             TIME_WAIT   \ntcp        0      0 runner-e11ae361-project-1925166-concurrent-0:53642 docker:2375             TIME_WAIT   \nActive UNIX domain sockets (servers and established)\nProto RefCnt Flags       Type       State         I-Node Path\n\n$ docker-compose ps\nstty: standard input: Not a tty\n    Name                  Command               State                Ports               \n----------------------------------------------------------------------------------------\nmy_app_1   wait-for-it.sh mysql_serve ...   Up      8080/tcp, 0.0.0.0:9143->9143/tcp \nmysql_server   docker-entrypoint.sh --cha ...   Up      3306/tcp     \n\n$ /usr/local/bin/wait-for-it.sh -h localhost -p 9143 -t 60\nwait-for-it.sh: waiting 60 seconds for localhost:9143\nwait-for-it.sh: timeout occurred after waiting 60 seconds for localhost:9143\n\nThe contents of my docker-compose.yml:\nversion: '2'\n\nnetworks:\n    app_net:\n        driver: bridge\n\nservices:\n    app:\n        image: registry.gitlab.com/craigotis/myapp:latest\n        depends_on:\n        - \"db\"\n        networks:\n        - app_net\n        command: wait-for-it.sh mysql_server:3306 -t 60 -- java -jar /opt/app*.jar\n        ports:\n        - \"9143:9143\"\n\n    db:\n        image: mysql:latest\n        networks:\n        - app_net\n        container_name: mysql_server\n        environment:\n        - MYSQL_ALLOW_EMPTY_PASSWORD=true\n\nIt seems like my application container is listening on 9143, and it's properly exposed to the shared GitLab runner, but it doesn't seem to actually be exposed. It works fine on my local machine - is there some special workaround/tweak I need to make this work inside a Docker container running on GitLab?"}, {"role": "assistant", "content": "When using docker:dind a container is created and your docker-compose containers get setup within it. It exposes the ports to localhost within the docker:dind container. You cannot access this as localhost from the environment that your code is executing in.\nA hostname of docker is setup for you to reference this docker:dind container. You can check by using cat /etc/hosts.\nInstead of referencing localhost:9143 you should use docker:9143."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is the purpose of \"workflow:rules\" in Gitlab-ci pipelines?\n\nI am a bit confused between Gitlab CI pipeline workflow:rules and job:rules\nworkflow:\n  rules:\n    - if: '$CI_PIPELINE_SOURCE == \"push\"'\n    - if: '$CI_PIPELINE_SOURCE != \"schedule\"'\n\n\nand\ntest:\n  stage: test\n  image: image\n  script:\n    - echo \"Hello world!\"\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"schedule\"\n\nWhat happens if both of them were used in the same GitLab-ci YAML file."}, {"role": "assistant", "content": "With workflow you configure when a pipeline is created while with rules you configure when a job is created.\nSo in your example pipelines are created for pushes but cannot be scheduled while your test job will only run when scheduled.\nBut as workflow rules take precedence over job rules, no pipeline will be created in your example as your rules for workflow and job are mutually exclusive."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I enable cloning over SSH for a Gitlab runner?\n\nI am having some trouble cloning large repositories over HTTP on my Windows Gitlab runner. I've tried several methods to do shallow clones or disable clone compression. Still no luck.\nCloning the same repository over SSH works great as a temporary solution and I would like to get this working on our Gitlab CI process.\nThe issue now stands where I have no idea how to use SSH as a clone method for the gitlab-multi-runner. It just seems to use HTTP as a default, and my only options regarding cloning is whether it will do a full clone or a fetch.\n\nCan someone explain how I could get that clone/fetch to work on a runner over SSH instead of HTTP?\nGitlab Version: GitLab Community Edition 8.10.7"}, {"role": "assistant", "content": "As a newcomer to gitlab, I've managed to hack a workaround to this issue as I also haven't found a built-in way to change the default cloning process (although here is a recent comment about how it can be done).\nBy disabling the automatic cloning process, you can effectively override its behavior completely by simply writing your own cloning process in a before_script. Only for the purposes of example does the below show how to accomplish this for HTTP cloning but could be adapted for ssh cloning (if you're trying to use HTTP cloning you should use the built-in cloning process and the config.toml):\n\nCreate a new user called \"gitlab-runner\" and generate their user auth token for later use (or in your case, you would generate ssh keys).\n\nDisable cloning process for runner by adding the following variable in either your project or group settings: .../settings/ci_cd\nkey: GIT_STRATEGY\nvalue: none\n\nClone your repo in a before_script such as:\n\n\n\nbefore_script:\n  ## clean the working directory\n  - BUILD_DIR=/home/gitlab-runner/builds/$RUNNER_TOKEN/0\n  - CLONE_DIR=\"$BUILD_DIR/$CI_PROJECT_PATH\"\n  - cd $BUILD_DIR\n  - rm -rf $CLONE_DIR\n  - mkdir -p $CLONE_DIR\n\n  ## clone the project each time (inefficient, consider performing fetch instead if it already exists)\n  - git clone http://gitlab-runner:$GITLABRUNNER_USER_AUTH_TOKEN@server:8888/${CI_PROJECT_PATH}.git $CLONE_DIR\n  - cd $CLONE_DIR\n\nNote: Here are the relevant variables I also configured in step 2 rather than hard coding them in the script:\n\nRUNNER_TOKEN: \"Runner Token\" value listed in the Admin \"Runners\" menu for the particular runner you are trying to run.\nGITLABRUNNER_USER_AUTH_TOKEN: This is the auth token you generated in step 1.\n\nFurther Reading:\nYou can avoid the fake account approach taken above by instead issuing Deploy Keys. Or if security implications of access to any project is a concern, Deploy Tokens are an alternative with more security control. For comparison, see the docs:\n\nDeploy keys are shareable between projects that are not related or don\u2019t even belong to the same group. Deploy tokens belong to either a project or a group.\n\n\nA deploy key is an SSH key you need to generate yourself on your machine. A deploy token is generated by your GitLab instance, and is provided to users only once (at creation time).\n\n\nA deploy key is valid as long as it\u2019s registered and enabled. Deploy tokens can be time-sensitive, as you can control their validity by setting an expiration date to them.\n\n\nYou can\u2019t log in to a registry with deploy keys, or perform read / write operations on it, but this is possible with deploy tokens.\nYou need an SSH key pair to use deploy keys, but not deploy tokens."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "how to reference branch in gitlab markdown?\n\nI would like to use gitlab markdown syntax to refer to a branch in README.md file.\nI tried @develop, but it doesn't work. Any ideas?"}, {"role": "assistant", "content": "Not exactly what you were looking for but at least something - try this markdown construct.\n[myReference](../../tree/myBranch/myPath/myFile.cpp#L310-313)\n\nThis will navigate you away from the main branch towards the branch you want (myBranch in this example)\nHowever if the branchname changes then things will be broken. I really feel this functionality should be added to gitlab in near future"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI Build failed gitlab-runner-prebuilt.tar.xz: no such file or directory\n\nI just installed Gitlab Runner on my dev machine (Ubuntu 17.10) for testing.\nWhen I run the runner I got:\n$: sudo gitlab-runner exec docker test       \n   Running with gitlab-ci-multi-runner dev (1.4.2)\n   Using Docker executor with image php:5.6 ...\n   ERROR: Build failed (system failure): open /var/lib/gitlab-runner/gitlab-runner-prebuilt.tar.xz: no such file or directory\n   FATAL: open /var/lib/gitlab-runner/gitlab-runner-prebuilt.tar.xz: no such file or directory \n\n.gitlab-ci.yml file:\nimage: php:5.6\n\nbefore_script:\n  - php -v\n\nstages:\n  - test\n\ntest:\n  script:\n  - php -v\n\nCurrent installation process:\nsudo apt-get install gitlab-runner\n\nOutput:\n...\nConfiguring gitlab-ci-multi-runner (1.4.2+dfsg-1) ...\nI: generating GitLab Runner Docker image. This may take a while...\nE: No mirror specified and no default available\nW: please run 'sudo /usr/lib/gitlab-runner/mk-prebuilt-images.sh' to generate Docker image.\n...\n\nSo I did:\n$: sudo /usr/lib/gitlab-runner/mk-prebuilt-images.sh\n   I: generating GitLab Runner Docker image. This may take a while...\n   E: No mirror specified and no default available"}, {"role": "assistant", "content": "Got the same problem today. Turns out cdebootstrap command in usr/lib/gitlab-runner/mk-prebuilt-images.sh is causing this error message:\ncdebootstrap \\\n     --flavour=minimal \\\n     --exclude=\"dmsetup,e2fsprogs,init,systemd-sysv,systemd,udev\" \\\n     --include=\"bash,ca-certificates,git,netcat-traditional\" \\\n     stable ./debian-minbase\n\nChange the last line to:\n     stable ./debian-minbase https://deb.debian.org/debian/ \n\nThe script should now proceed without any errors. More info on debootstrap can be found here."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to copy a Gitlab project to another Gitlab repository?\n\nI want to copy a GitLab project to another repository which should be completely independent from the original project.\nFor this reason, I tried forking the original project into another project. But inside the original project, the maintainer still can see a list of forks and knows where the other forks are maintained.\nI want to have a complete copy without any link to the main project so it cannot be managed by the original project maintainer.\nHow can I do this?"}, {"role": "assistant", "content": "Another option is to use Gitlab's export/import feature.\n\nExisting projects running on any GitLab instance or GitLab.com can be exported with all their related data and be moved into a new GitLab instance.\n\nThe difference with the other answer is that it also copies the following:\n\nExported contents\nThe following items will be exported:\n\nProject and wiki repositories\nProject uploads\nProject configuration, excluding integrations\nIssues with comments, merge requests with diffs and comments, labels, milestones, snippets, and other project entities\nDesign Management files and data\nLFS objects\nIssue boards\nPipelines history\nPush Rules\n\n\nSo it depends on your use-case if you want to copy just the codes or if you also want to also migrate the other non-code items as listed above. The result would still be 2 separate projects (i.e. It will not appear as a fork).\nTake note that:\n\nThe GitLab import/export button is displayed if the project import option is enabled.\n\nTo export, go to your project's Settings > General page:\n\nThen wait for the email with the downloadable tar.gz. file.\n(On my version of Gitlab, if you click the button twice, you can download directly from the browser.)\nThen to import, on Gitlab, select the New button > New Project from the top bar.\nThen, select Import Project > Gitlab export.\n\nThe UI screenshots above may change on future Gitlab versions. Again, make sure to refer to your Gitlab instance's docs pages, or check out the public one from Gitlab EE: Project import/export ."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Clone another GitLab repository in GitLab CI script\n\nI've seen this: `git clone project2` in gitlab-ci.yml? as well as a bunch of similar posts with similar answers implying that one should use Git submodules.\nWithout getting into arguments about whether submodules in Git work well, in my case, that just isn't an option at all (what other project to check out depends on the arguments passed to the trigger of the job, or, at least, it should).\nAnother requirement is that I need to be able to track the user who started the chain of triggers.  I.e. hard-coding my personal token, or just any token will not do it: I need GitLab to use the permissions of the user who executed the job in order to clone other repositories.\nShort of giving up GitLab and looking for a mature CI alternative, is there any way to get this done?"}, {"role": "assistant", "content": "As New CI job permissions model states that there are 2 options: use gitlab-ci-token:${CI_JOB_TOKEN} or write it to ~/.netrc (doesn't work for me).\nBut we have multiple dependent repositories defined in package.json so our solution is to overwrite git config\ngit config --global url.\"https://gitlab-ci-token:${CI_JOB_TOKEN}@your-gitlab.com/\".insteadOf \"ssh://[email\u00a0protected]/\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Notify all group members of failed pipelines in GitLab\n\nThe goal is to have everyone get a notification for every failed pipeline (at their discretion). Currently, any of us can run a pipeline on this project branch, and the creator of the pipeline gets an email, no one else does. I have tried setting the notification level to watch and custom (with failed pipelines checked) at project, group and global levels without success. The help page regarding notifications says the failed pipeline checkbox for custom notification levels notifies the author of the pipeline (which is the behavior I am experiencing). Is there any way to allow multiple people to get notified of a failed pipeline?\n\nUsing Gitlab CE v10.0\nHave Group (security::internal)\nGroup has Project (security::internal)\nProject has scheduled pipleine (runs nighly)\nPipeline runs integration tests (purposely failing)\nSchedule created by me (schedules have to have an owner)\nWhen the automated pipeline runs and fails, I get an email (good)\nNo one else gets email (bad)"}, {"role": "assistant", "content": "Have a look at following Integration:\nProject -> Settings -> Integrations -> Pipelines emails"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to download a single file from GitLab?\n\nI know it is possible to fetch then use checkout with the path/to/file to download that specific file.\nMy issue is that I have a 1 MB data cap per day and git fetch will download all the data anyway even if it does not save them to disc until I use git checkout. I still used my data\nIs my understanding of how git fetch/checkout correct? is there a way to download a specific file only to see if there is a new version before proceeding with the download."}, {"role": "assistant", "content": "Gitlab has a rest API for that.\nYou can GET a file from repository with curl:\ncurl https://gitlab.com/api/v4/projects/:id/repository/files/:filename\\?ref\\=:ref\n\nFor example:\ncurl https://gitlab.com/api/v4/projects/12949323/repository/files/.gitignore\\?ref\\=master\n\nIf your repository isn't public you also need to provide an access token by adding --header 'Private-Token: <your_access_token>'.\n\nLinks:\nYou can check how to find repository api id here.\nApi documentation\nMore on tokens\nThere is also a python library that uses this api.\nNote that this is GitLab specific solution and won't work for other hostings."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How can I restart bundle nginx in gitlab separately?\n\nI have installed Gitlab CE version. I can find nginx bundled in Gitlab. However I cannot find a way to restart nginx separately. I have tried sudo service nginx restart but it gives:\n* Restarting nginx nginx                                     [fail] \n\nI have checked all the document but cannot find a solution. I am trying to add vhost to the bundled nginx according to this tutorial. But I stuck at that step. Is there other way to add vhost to bundled nginx with Gitlab? Or How can I check whether my nginx conf work?\nEdit: 502 error I have solved.\nI try to use NON-bundle nginx according to this doc , But after I modify gitlab.rb and run sudo gitlab-ctl reconfigure , I got 502 Whoops, GitLab is taking too much time to respond. error. \nHere is my gitlab.conf for nginx.\nupstream gitlab {\n  server unix://var/opt/gitlab/gitlab-git-http-server/sockets/gitlab.socket fail_timeout=0;\n  #\n}\n\nserver {\n  listen *:80;\n  server_name blcu.tk;\n  server_tokens off;\n  root /opt/gitlab/embedded/service/gitlab-rails/public;\n\n  client_max_body_size 250m;\n\n  access_log  /var/log/gitlab/nginx/gitlab_access.log;\n  error_log   /var/log/gitlab/nginx/gitlab_error.log;\n\n\n# Ensure Passenger uses the bundled Ruby version\npassenger_ruby /opt/gitlab/embedded/bin/ruby;\n\n# Correct the $PATH variable to included packaged executables\npassenger_env_var PATH \"/opt/gitlab/bin:/opt/gitlab/embedded/bin:/usr/local/bin:/usr/bin:/bin\";\n\n# Make sure Passenger runs as the correct user and group to\n# prevent permission issues\npassenger_user git;\npassenger_group git;\n\n# Enable Passenger & keep at least one instance running at all times\npassenger_enabled on;\npassenger_min_instances 1;\n\nlocation / {\n  try_files $uri $uri/index.html $uri.html @gitlab;\n}\n\n location @gitlab {\n    # If you use https make sure you disable gzip compression \n    # to be safe against BREACH attack\n\n    proxy_read_timeout 300; # Some requests take more than 30 seconds.\n    proxy_connect_timeout 300; # Some requests take more than 30 seconds.\n    proxy_redirect     off;\n\n    proxy_set_header   X-Forwarded-Proto $scheme;\n    proxy_set_header   Host              $http_host;\n    proxy_set_header   X-Real-IP         $remote_addr;\n    proxy_set_header   X-Forwarded-For   $proxy_add_x_forwarded_for;\n    proxy_set_header   X-Frame-Options   SAMEORIGIN;\n\n    proxy_pass http://gitlab;\n  }\n  location ~ ^/(assets)/  {\n    root /opt/gitlab/embedded/service/gitlab-rails/public;\n    # gzip_static on; # to serve pre-gzipped version\n    expires max;\n    add_header Cache-Control public;\n  }\n\n\n  error_page 502 /502.html;\n}"}, {"role": "assistant", "content": "To restart only one component of GitLab Omnibus you can execute sudo gitlab-ctl restart <component>. Therefore, to restart Nginx:\nsudo gitlab-ctl restart nginx\nAs a further note, this same concept is possible with nearly all of the gitlab-ctl commands. For example, sudo gitlab-ctl tail allows you to see all GitLab logs. Applying this concept, sudo gitlab-ctl tail nginx will tail only Nginx logs."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to migrate GitLab to a new server?\n\nI am trying to migrate an GitLab setup from 7.8.2 to 7.12.2. I am not really sure how to go about this. I have installed a new box, on Ubuntu 14.04.2.\nNow I would really like to just export the old user/group database and import it on the new server, then copy all the repositories from the old server to the new one. And tell the users to start using the new one.\nI do not know which database my new gitlab installation uses, neither the old one.\nI have been up and down the gitlab documentation, but cannot find sufficient information on how to migrate from one server to another.\nI followed the instructions on https://about.gitlab.com/downloads/ for ubuntu, and all seems to work fine. I am looking for a way to export the users/groups from the old gitlab box and import it on the new gitlab box. and then just copy all the repositories from the old box to the new one.\nAny assistance? I know next to nothing about gitlab :("}, {"role": "assistant", "content": "I would take the following steps\n\nFind out if gitlab is installed by hand or with gitlab-omnibus. This you need to know for the exact backup and update steps.\nDo a backup of the old version just to be safe\nUpdate the current 7.8.2 instance to 7.12.2 instance by following the update guideline\nBack up the newly updated gitlab system \nRestore the backup on the new system\n\nBackup & restore documentation can be found here"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI: Two independent scheduled jobs\n\nConsider the following gilab-ci.yml script:\nstages:\n  - build_for_ui_automation\n  - independent_job\n\nvariables:\n  LC_ALL: \"en_US.UTF-8\"\n  LANG: \"en_US.UTF-8\"\n\nbefore_script:\n  - gem install bundler\n  - bundle install\n\nbuild_for_ui_automation:\n  dependencies: []\n  stage: build_for_ui_automation\n  artifacts:\n    paths:\n      - fastlane/screenshots\n      - fastlane/logs\n      - fastlane/test_output\n      - fastlane/report.xml\n  script:\n    - bundle exec fastlane ui_automation\n  tags:\n    - ios\n  only:\n    - schedules\n  allow_failure: false\n\n# This should be added and trigerred independently from \"build_for_ui_automation\"\nindependent_job:\n  dependencies: []\n  stage: independent_job\n  artifacts:\n    paths:\n      - fastlane/screenshots\n      - fastlane/logs\n      - fastlane/test_output\n      - fastlane/report.xml\n  script:\n    - bundle exec fastlane independent_job\n  tags:\n    - ios\n  only:\n    - schedules\n  allow_failure: false\n\nI'd like to be able to schedule these two jobs independently, but following the rules:\n\nbuild_for_ui_automation runs every day at 5 AM\nindependent_job runs every day at 5 PM\n\nHowever, with the current setup I can only trigger the whole pipeline, which will go through both jobs in sequence.\nHow can I have a schedule triggering only a single job?"}, {"role": "assistant", "content": "Note - This answer used, only-except of GitLab CI to manipulate what job gets added to the schedule. However, as of today, GitLab has stopped active maintenance of the same commands and suggests we use rules instead. Here's the link.\nI have modified the original answer to use rules and tested the working.\nTo build off @Naor Tedgi's answer, you can define a variable in your pipeline schedules. For example, set SCHEDULE_TYPE = \"build_ui\" in the schedule for build_for_ui_automation and SCHEDULE_TYPE = \"independent\" in the schedule for independent_job. Then your .gitlab-ci.yml file could be modified as:\nstages:\n  - build_for_ui_automation\n  - independent_job\n\nvariables:\n  LC_ALL: \"en_US.UTF-8\"\n  LANG: \"en_US.UTF-8\"\n\nbefore_script:\n  - gem install bundler\n  - bundle install\n\nbuild_for_ui_automation:\n  dependencies: []\n  stage: build_for_ui_automation\n  artifacts:\n    paths:\n      - fastlane/screenshots\n      - fastlane/logs\n      - fastlane/test_output\n      - fastlane/report.xml\n  script:\n    - bundle exec fastlane ui_automation\n  tags:\n    - ios\n  rules:\n    - if: '$CI_PIPELINE_SOURCE == \"schedule\" && $SCHEDULE_TYPE == \"build_ui\"'\n      when: always\n      variables:\n        SCHEDULE_TYPE: \"build_ui\"\n        ANOTHER_VARIABLE: \"dummy\"\n      allow_failure: false\n\n# This should be added and trigerred independently from \"build_for_ui_automation\"\nindependent_job:\n  dependencies: []\n  stage: independent_job\n  artifacts:\n    paths:\n      - fastlane/screenshots\n      - fastlane/logs\n      - fastlane/test_output\n      - fastlane/report.xml\n  script:\n    - bundle exec fastlane independent_job\n  tags:\n    - ios\n  rules:\n    - if: '$CI_PIPELINE_SOURCE == \"schedule\" && $SCHEDULE_TYPE == \"independent\"'\n      when: always\n      variables:\n        SCHEDULE_TYPE: \"independent\"\n        ANOTHER_VARIABLE: \"dummy123\"\n      allow_failure: false\n\nwhere note the syntax change in the only sections to execute the jobs only during schedules and when the schedule variable is matching."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Use GitLab API from a GitLabCI build script\n\nI have a GitLab CI build script like this:\ncreate release:\n  stage: deploy\n  tags:\n    - basic\n  only:\n    - tags\n  script:\n    - GITLOG=$(echo \"# Changes Log\"; git log `git tag | tail -2 | head -1`..${CI_BUILD_TAG} --pretty=format:\" - %s\")\n    - curl -X POST -d \"private_token=$CI_BUILD_TOKEN&description=$GITLOG\" \"http://git.example.com/api/v3/projects/${CI_PROJECT_ID}/repository/tags/${CI_BUILD_TAG}/release\"\n\nThe purpose of this step is to automatically add a Changes Log from Git in the GitLab Releases section.\nThat works if I manually run this on the command line and put in the variables... \nThe problem is that the value of CI_BUILD_TOKEN in the build runner isn't a valid GitLab Private Token - it's only a token to connect to the Docker Registry - as per the documentation.\nIs there a way to get a valid GitLab API token that the build runner can use to access the API for the project it's running a build for? Seems like this should be possible.\nGitLab Runner:\ngitlab-runner -v\nVersion:      1.2.0\nGit revision: 3a4fcd4\nGit branch:   HEAD\nGO version:   go1.6.2\nBuilt:        Sun, 22 May 2016 20:05:30 +0000\nOS/Arch:      linux/amd64"}, {"role": "assistant", "content": "You can have read-only access with the API from the runner, but only if you add a header with the CI_JOB_TOKEN.\ne.g.\ncurl -H \"JOB_TOKEN: $CI_JOB_TOKEN\" \"https://gitlab.com/api/v4/projects/2828837/repository/tags\n\nAnd only when the project is public with everyone has access from the same project.\nIf you want access to private projects as well and/or write access, please up-vote GitLab issue #29566 and/or #41084.\nAs an alternative for the time being, you can create an access token on gitlab, and add it to the secret variables, under project settings/ci_cd although not really advised to do as your personal access token will be used by everyone who trigger the job."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to copy a file from the repository, into the Docker container used for a job, in gitlab-ci.yml\n\nHow can I add a file from my project into a Docker using in a gitlab-ci job. Suppose I have below job in my .gitlab-ci.yml .\nbuild:master:\n  image: ubuntu:latest\n  script:\n    - cp sample.txt /sample.txt\n  stage: build\n  only:\n    - master\n\nHow to copy a sample.txt inside Ubuntu image? I was thinking as it is already a running container so we can't perform copy command directly but have to run\ndocker cp sample.txt mycontainerID:/sample.txt\n\nbut again how will I get mycontainerID? because it will be running inside a Gitlab runner and any random id will be assigned for every run. Is my assumption is wrong?"}, {"role": "assistant", "content": "The file is already inside the container. If you read carefully through the CI/CD build log, you will see at the very top after pulling the image and starting it, your repository is cloned into the running container.\nYou can find it under /builds/<organization>/<repository>\n(note that these are examples, and you have to adjust to your actual organization and repository name)\nOr with the variable $CI_PROJECT_DIR\nIn fact, that is the directory you are in when starting the job.\nFor example, this .gitlab-ci.yml:\nimage: alpine\n\ntest:\n  script:\n    - echo \"the project directory is - $CI_PROJECT_DIR\"\n    - cat $CI_PROJECT_DIR/README.md ; echo\n    - echo \"and where am I? - $PWD\"\n\nreturns this pipeline output:\n\nAs you can see, I could print out the content of the README.md, inside the container."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to solve the \"remote: You are not allowed to upload code.\" error on GitLab CI/CD job?\n\nI am currently trying to use GitLab to run a CI/CD job that runs a Python file that makes changes to a particular repository and then commits and pushes those changes to master. I also have a role of Master in the repository. It appears that all git functions run fine except for the git push, which leads to fatal: You are not currently on a branch. and with using git push origin HEAD:master --force, that leads to fatal: unable to access 'https://gitlab-ci-token:xxx@xxx/project.git/': The requested URL returned error: 403. I've been looking over solutions online, one being this one, and another being unprotecting it, and couldn't quite find what I was looking for just yet. This is also a sub-project within the GitLab repository. \nRight now, this is pretty much what my .gitlab-ci.yml looks like.\nbefore_script:\n  - apt-get update -y\n  - apt-get install git -y\n  - apt-get install python -y\n  - apt-get python-pip -y\n\nmain:\n  script:\n    - git config --global user.email \"xxx@xxx\"\n    - git config --global user.name \"xxx xxx\"\n    - git config --global push.default simple\n    - python main.py\n\nMy main.py file essentially has a function that creates a new file within an internal directory provided that it doesn't already exist. It has a looks similar to the following:\nimport os\nimport json\n\ndef createFile(strings):\n    print \">>> Pushing to repo...\";\n    if not os.path.exists('files'):\n        os.system('mkdir files');\n    for s in strings:\n        title = (\"files/\"+str(s['title'])+\".json\").encode('utf-8').strip();\n        with open(title, 'w') as filedata:\n            json.dump(s, filedata, indent=4);\n    os.system('git add files/');\n    os.system('git commit -m \"Added a directory with a JSON file in it...\"');\n    os.system('git push origin HEAD:master --force');\n\ncreateFile([{\"title\":\"A\"}, {\"title\":\"B\"}]);\n\nI'm not entirely sure why this keeps happening, but I have even tried to modify the repository settings to change from protected pull and push access, but when I hit Save, it doesn't actually save. Nonetheless, this is my overall output. I would really appreciate any guidance any can offer.\n Running with gitlab-runner 10.4.0 (00000000)\n      on cicd-shared-gitlab-runner (00000000)\n Using Kubernetes namespace: cicd-shared-gitlab-runner\n Using Kubernetes executor with image ubuntu:16.04 ...\n Waiting for pod cicd-shared-gitlab-runner/runner-00000000-project-00000-concurrent-000000 to be running, status is Pending\n Waiting for pod cicd-shared-gitlab-runner/runner-00000000-project-00000-concurrent-000000 to be running, status is Pending\n Running on runner-00000000-project-00000-concurrent-000000 via cicd-shared-gitlab-runner-0000000000-00000...\n Cloning repository...\n Cloning into 'project'...\n Checking out 00000000 as master...\n Skipping Git submodules setup\n $ apt-get update -y >& /dev/null\n $ apt-get install git -y >& /dev/null\n $ apt-get install python -y >& /dev/null\n $ apt-get install python-pip -y >& /dev/null\n $ git config --global user.email \"xxx@xxx\" >& /dev/null\n $ git config --global user.name \"xxx xxx\" >& /dev/null\n $ git config --global push.default simple >& /dev/null\n $ python main.py\n [detached HEAD 0000000] Added a directory with a JSON file in it...\n  2 files changed, 76 insertions(+)\n  create mode 100644 files/A.json\n  create mode 100644 files/B.json\n remote: You are not allowed to upload code.\n fatal: unable to access 'https://gitlab-ci-token:xxx@xxx/project.git/': The requested URL returned error: 403\n HEAD detached from 000000\n Changes not staged for commit:\n    modified:   otherfiles/otherstuff.txt\n no changes added to commit\n remote: You are not allowed to upload code.\n fatal: unable to access 'https://gitlab-ci-token:xxx@xxx/project.git/': The requested URL returned error: 403\n >>> Pushing to repo...\n Job succeeded"}, {"role": "assistant", "content": "Here is a resource from Gitlab that describes how to make commits to the repository within the CI pipeline: https://gitlab.com/guided-explorations/gitlab-ci-yml-tips-tricks-and-hacks/commit-to-repos-during-ci/commit-to-repos-during-ci\nTry configuring your gitlab-ci.yml file to push the changes rather than trying to do it from the python file."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab: Is it possible to run pipeline on a specific runner?\n\nIs it possible to run a pipeline on a specific runner? (not using tags)\nIs it feasible to use environments, or even gitlab runner exec maybe?\n\nScenario:\nHave an existing project with multiple runners already attached to it (specific project token used to register the runner) and has it's own associated tags (so can't change these either).\nI'm adding a new runner, however need to test it first to ensure it works, but I need to force the pipeline to build on this machine, without changing any tags, or specific project of the runner."}, {"role": "assistant", "content": "You have two mechanisms by which you can attempt to isolate a new runner for testing:\n\nuse tags and private runner attachment (already called out)\nuse the gitlab-runner exec verb directly on the runner\ncanary the runner for a single build only\n\nOption 1\nuse tags and private runner attachment (already called out).\nTo further expand on this... even in a draconian setup where you can't alter tags and whatnot -- you can always FORK the project.  \nIn your new private fork, you can go to Settings >> CI/CD and override the .gitlab-ci.yml file in the Custom CI Configuration Path under the General Pipelines Settings.  This allows you to git cp .gitlab-ci.yml .mycustomgitlab-ci.yml and then simply git add/git commit/git push and you're in business.\nOpinion: If you cannot use the mechanisms in place to adjust the tags on the questionable runner and isolate a new forked project, this isn't a technical problem, it is a political problem.\nOption 2\nGitlab-runner exec....\nAssuming you're using a shell gitlab runner...\n\nSSH to the questionable gitlab runner box you're trying to test\nClone the repo for the project in question to ... say ... /tmp/myrepo\nExecute Gitlab-Runner: /path/to/gitlab-runner exec shell {.gitlab-ci.yml target}\n\nSee https://docs.gitlab.com/runner/commands/#gitlab-runner-exec and a blog about it at https://substrakt.com/how-to-debug-gitlab-ci-builds-locally/\nOption 3\nCanary the gitlab-runner for a single build.\nYou can spin up the gitlab-runner process to do N number of builds and then go back offline.  See: https://docs.gitlab.com/runner/commands/#gitlab-runner-run-single\n... This is not zero-impact, but will definitely limit the blast radius of any problems."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Docker Gitlab change forgotten root password\n\nI'm running my Gitlab with Docker and \nI forgot my Gitlab root password. How to change it ?"}, {"role": "assistant", "content": "I found a way to make it work.\nFirst connect to your Gitlab with command line\nsearch for your Docker CONTAINER_ID\ndocker ps -all\neg\n\ndocker exec -it d0bbe0e1e3db bash <-- with your CONTAINER_ID\n$ gitlab-rails console -e production\n\nuser = User.where(id: 1).first\nuser.password = 'your secret'\nuser.password_confirmation = 'your secret'\nuser.save\nexit"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to setup admin user with gitlab with LDAP authentication?\n\nI've just setup gitlab, but I'm completely lost with regards to admin user. The wiki seems silent about this topic, and google hasn't been of help either.\nSo, how do I setup admin users with gitlab on LDAP authentication?"}, {"role": "assistant", "content": "You can also set admin permissions to a user by doing something like this in the rails console:\nUser.find_by_email(\"[email\u00a0protected]\") do |i|\n    i.admin = true\n    i.save\nend"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Not able to \"git pull\" - Host key verification failed\n\nI've got root access to our production server and I want to deploy the latest version in git to the server but I'm running into the error below when I \"git pull\" on the folder I want to update. \nI've browsed around a bit, but can't find a clear answer on what to do..\nThe staging server runs on the same machine, but just in a different folder and when I pull on that folder it all goes fine.\nI'm not very experienced when it comes to Linux, so please help me out with a clear answer on how to fix :-)\nOtherwise I have access to anything I need\np.s.\nThis has worked in the past, so I'm assuming it's got something to do with the SSH key\nError:\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@       WARNING: POSSIBLE DNS SPOOFING DETECTED!          @\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\nThe ECDSA host key for www.site.org has changed,\nand the key for the corresponding IP address x.x.x.x\nis unknown. This could either mean that\nDNS SPOOFING is happening or the IP address for the host\nand its host key have changed at the same time.\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\nIT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!\nSomeone could be eavesdropping on you right now (man-in-the-middle attack)!\nIt is also possible that a host key has just been changed.\nThe fingerprint for the ECDSA key sent by the remote host is\n*************\nPlease contact your system administrator.\nAdd correct host key in /root/.ssh/known_hosts to get rid of this message.\nOffending ECDSA key in /root/.ssh/known_hosts:1\n  remove with: ssh-keygen -f \"/root/.ssh/known_hosts\" -R gitlab.site.org\nECDSA host key for gitlab.site.org has changed and you have requested strict checking.\nHost key verification failed."}, {"role": "assistant", "content": "In the log you see the following text:\n\n(...)\n\nPlease contact your system administrator.\nAdd correct host key in /root/.ssh/known_hosts to get rid of this message.\nOffending ECDSA key in /root/.ssh/known_hosts:1\nremove with: ssh-keygen -f \"/root/.ssh/known_hosts\" -R gitlab.site.org\nECDSA host key for gitlab.site.org has changed and you have requested strict checking.\nHost key verification failed.\n\nSo it is a matter of performing the command that is suggested there:\nssh-keygen -f \"/root/.ssh/known_hosts\" -R gitlab.site.org"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to solve Access denied in gitlab?\n\nWhen I run : git push, there is exist error like this : \nremote: Access denied\nfatal: unable to access 'https://gitlab.com/myname/mysystem.git/': The requested URL returned error: 403\n\nIs there any people who can help me?"}, {"role": "assistant", "content": "For Windows users, check this unbelievable easy solution, which works for me:\nGo to Windows Credential Manager (press Windows Key and type 'credential') to edit the git entry under Windows Credentials. Replace old password with the new one."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to add GitLab repository in Eclipse?\n\nHow to add Git-Lab on Eclipse? \nSo that I can just push or fetch from GitLab.\nI am a newbie in this, please give more explanation."}, {"role": "assistant", "content": "I Preparation\nMake sure you have eGit in Eclipse:\n\nHelp -> Installation details\nSee that \"Eclipse Git Team provider\" is in the list.\n\nIf it is not installed, follow the indications in the answer from @VonC\nMake sure you have the URL to the repository in GitLab. Something like https://gitlab.com/<someusername>/<somerepository> You get it from gitlab.com when you are at the overview page for the project:\n\nMenu (the hamburger icon \u2261, 3 horizontal lines),-> projects, then click in the one you want to work with from eclipse. Now you are in the overview page. Right beneath the name of the project and its description there are a few buttons to allow you to perform some actions. One of those buttons is a selector for SSH/HTTPS protocols. For now, select HTTPS and copy the URL that follows it: that is the URL to the project.\n\nII Now clone the repository locally, using Eclipse eGit.\nThese steps have been tested in Eclipse Kepler and Eclipse Luna. Rumor has it that they are outdated and might not work as indicated. If you use a newer Eclipse, take care and post back the new steps :-)\n\nWindow -> Open Perspective -> Other\nSearch for \"Git\", select it, and click \"OK\"\nClick the button with an arrow and the tool tip \"Clone a Git repository and add the clone to this view\"\nIn the \"Source Git Repository\" wizard:\n\n\nURI: the URL from the repository in GitLab, like  https://gitlab.com/<someusername>/<somerepository>\neGit has filled in the host and repository path for you.\nLeave the connection as it is (https and no port) and fill in the details for the authentication: user and password you use to log in GitLab.com.\nIf you tick the \"Store in Secure Store,\" Eclipse will handle user/password for you from now on; I do it, but it is not advisable if you share Eclipse installation with someone else, or you do not trust your PC to hold your passwords.\nClick next\n\nBranch selection wizard.\n\n\nIf there are more than one branch in the repository, you may now choose which one you want to clone locally, the one with which you want to interact. You may also choose to clone all branches to have them available.\nOnce you are done, click Next\n\nLocal destination wizard.\n\n\nYou may now choose where you want to place your local Git repository. eGit defaults to a subdirectory under you user, unrelated to eclipse, it works well. If you do not like it, change to your liking.\nAs with other Git installations, it will name the GitLab.com repository as \"origin\". You may also change that if you really want.\nIn the projects box check the \"Import all projects\" and, if you work with \"Working Sets\", you may choose now in which one to place it.\nClick Finish.\n\n\neGit now works for a bit and shows you the newly cloned repository in the view. You have a cloned repository with which you will be able to interact from Eclipse.\nIII Now import the project into Eclipse.\n\nFile -> Import...\nGit -> Projects from Git -> Next\nExisting local repository -> Next\nSelect the newly cloned repository -> Next\nImport using the New Project Wizard -> Finish\nChoose the project type that is hosted in GitLab.com. In my case is \"Java Project;\" in other occasions it has been \"Maven -> Maven Project\". Then click Next\nName the project and change the settings you want. As destination, do not use the default location, but navigate to the location of the cloned repository (as used in step 6 in the previous section cloning the repository) -> Next\nVerify that the import looks like you want it and click Finish.\n\nYou may now work within Eclipse and use the Team menus to sync and commit and push."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI how to ignore directory using rules syntax?\n\nI was able to ignore directory, file changes using the following syntax.\nbuild:\n  script: npm run build\n  except:\n    changes:\n      - \"*.md\"\n      - \"src/**/*.ts\"\n\nWith this configuration build job is going to run except git changes include only *.md extension file or *.ts files in src directory. They're ignored.\nBut then they deprecated this only:changes, except:changes syntax and warned to use rules syntax instead. Unfortunately, I cannot seem to find how to ignore directory, file changes using this new syntax."}, {"role": "assistant", "content": "Based on documents of rules: changes, it seems when: never must be used with rules: changes syntax. Like the following:\nbuild:\n  script: npm run build\n  rules:\n    - changes:\n      - \"*.md\"\n      - \"src/**/*.ts\"\n      when: never\n\n    - when: always\n\nIf changed paths in the repository match above regular expressions then the job will not be added to any pipeline. In other cases the job always will be run by pipelines."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Build .NET solution using GitLab CI Pipeline\n\nI have a solution with several .NET projects in it. I use GitLab, not self-hosted, for version control and would like to start using their CI tools as well. I have added the following .gitlab-ci.yml file to my root:\nstages:\n  - build\n  - test\n\nbuild_job:\n  stage: build\n  script:\n  - 'echo building...'\n  - 'msbuild.exe Bizio.sln'\n  except:\n  - tags\n\ntest_job:\n  stage: test\n  script:\n  - 'echo: testing...'\n  - 'msbuild.exe Bizio.sln'\n  - 'dir /s /b *.Tests.dll | findstr /r Tests\\\\bin\\\\ > tests_list.txt'\n  - 'for /f %%f in (tests_list.txt) do mstest.exe /testcontainer: \"%%f\"'\n  except:\n  - tags\n\nThe build stage always fails because it doesn't know what msbuild is. The exact error is:\n\n/bin/bash: line 61: msbuild.exe: command not found\n\nAfter some investigating, I've figured out that I'm using a shared runner. Here is the entire output from the job run:\nRunning with gitlab-runner 10.6.0-rc1 (0a9d5de9)\n  on docker-auto-scale 72989761\nUsing Docker executor with image ruby:2.5 ...\nPulling docker image ruby:2.5 ...\nUsing docker image sha256:bae0455cb2b9010f134a2da3a1fba9d217506beec2d41950d151e12a3112c418 for ruby:2.5 ...\nRunning on runner-72989761-project-1239128-concurrent-0 via runner-72989761-srm-1520985217-1a689f37...\nCloning repository...\nCloning into '/builds/hyjynx-studios/bizio'...\nChecking out bc8085a4 as master...\nSkipping Git submodules setup\n$ echo building...\nbuilding...\n$ C:\\Windows\\Microsoft.NET\\Framework\\v4.0.30319\\MSBuild.exe Bizio.sln\n/bin/bash: line 61: msbuild.exe: command not found\nERROR: Job failed: exit code 1\n\nIt looks like the shared runner I have is using a Docker image for Ruby, which seems wrong. I don't know how I can change that or select a different one that can be used for .NET. After some further investigating I'm getting worried that I'll have to jump through a lot of hoops to get what I want, like using an Azure VM to host a GitLab Runner that can build .NET apps.\nWhat do I need to do to use GitLab's CI pipelines to build my .NET solution using a non-self-hosted GitLab instance?"}, {"role": "assistant", "content": "You should be able to setup your own shared runner on a machine with the Framework 4 build tools on it (either using a Docker image, like microsoft/dotnet-framework-build, or just your native machine).\nThe simplest case to get going is using your own desktop, where you know your solution already builds. (Since using Docker images for the build is absolutely possible, but involves all of the extra steps of making sure you have docker working on your machine).\n\nDownload gitlab-runner on your computer from https://docs.gitlab.com/runner/install/windows.html \n\nCreate a directory on computer (C:\\gitlab-runner)  \nDownload the latest binary x86 or x64 to that folder\nRename the binary to \"gitlab-runner.exe\"\n\nGet a gitlab-ci token for your runner\n\n\nProbably the easiest way to do this is to go to your project in gitlab.com and go to Settings -> CI/CD and expand General Pipeline Settings.\nIn the Runner Token section, click the Reveal Value button to show the token value. You will need this during the runner registration step.\n\nRegister the gitlab runner according to Registering Runners - Windows\n\nOpen an elevated command prompt (Run as administrator)\ncd to c:\\gitlab-runner\ntype gitlab-runner register\nThe register prompts will take you through the steps to register the runner, but in a nutshell, you will be putting in \ngitlab.com as your coordinator URL, entering the token from your project \ngiving your runner a name\ntagging your runner (so that you can associate it with projects that it is capable of building, testing, etc - for simplicity, you can skip tags now)\nallowing it to run for untagged jobs (again, simplicity, say true)\nlock runner to current project (simplicity, say true)\nand choosing the executor (enter shell, which is basically saying use the Windows Command-line)  \n\nInstall gitlab-runner as a service, so that it is mostly always checking for work to do\n\n\nIn your command prompt, type gitlab-runner install\nThen type gitlab-runner start\n(Now, if you go to Services, you will see gitlab-runner listed, and it should be running - Just when when/if the runner crashes, you should go to Services to restart it)\n\n\nWhew. Now that runner is setup, it should be activated when you push a commit or a merge is requested. \nIf you are having issues still with the .gitlab-ci.yml file building properly, you can debug it locally (without having to keep triggering it through gitlab.com) by going to your solution folder in the command line and then executing c:\\gitlab-runner\\gitlab-runner build (To test the build step, for example).\nIf the build step has problem finding your solution file, you might want to try changing it from 'msbuild.exe Bizio.sln' to 'msbuild.exe .\\Bizio.sln'"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Meaning of \"Allowed to push\" and \"Allowed to merge\" in Gitlab\n\nWhat's the meaning of \"Allowed to push\" and \"Allowed to merge\" in Gitlab protected branches"}, {"role": "assistant", "content": "Quoting Gitlab Documentation here\n\nUsing the \"Allowed to push\" and \"Allowed to merge\" settings, you can control the actions that different roles can perform with the protected branch. For example, you could set \"Allowed to push\" to \"No one\", and \"Allowed to merge\" to \"Developers + Masters\", to require everyone to submit a merge request for changes going into the protected branch\n\nAllowed to push allows the set of people to directly fast-forward commit and non-force push to a particular branch, ideally for protected branches it should be allowed only for Maintainers.\nAllowed to merge allows the set of people to merge/pull request into a branch, which for Protected branches like master, should ideally be only for Maintainers again."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Critical situation in removing a local branch\n\nI'm using the following command to remove a local branch with force delete option:\n$ git branch -D <branch_name>\n\nMy question is, If I delete a local branch that had an upstream set and then do a normal push, it won't delete the remote branch right?\nWhat should I do in this situation?\n\n[NOTE]:\n\n\"-D\" is force delete option.\nI want to delete the local branch and keep the remote branch on origin."}, {"role": "assistant", "content": "git will only delete your local branch, please keep in mind that local and remote branches actually have nothing to do with each other. They are completely separate objects in Git.\nEven if you've established a tracking connection (which you should for most scenarios), this still does not mean that deleting one would delete the other, too!\nIf you want any branch item to be deleted, you need to delete it explicitly.\nDeleting local branches in Git\ngit branch -d <branch_name>\n\nusing a capital -D is like a \"force\" version of -d. If the branch isn't fully merged you'll get an error if you use the lowercase version. This again has no relevance to the remote branches and will only delete your local branch. \nDeleting remote branches in Git\ngit push origin --delete <branch_name>\n\nso to your question\n\nIf I delete a local branch that had an upstream set and then do a\n  normal push, it won't delete the remote branch right?\n\nYou are correct it will not delete the remote branch."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to default to side-by-side view in GitLab\n\nHow can I make Side-by-side be the default diff for my GitLab installation or project or profile?"}, {"role": "assistant", "content": "Update February 2016\nThe issue is now at issue CE 3071 and... was resolved by commit 9fdd605!\nA cookie now retain your diff view choice, with GitLab 8.5.0+.\n\nOriginal answer (February 2015)\nThat doesn't seem to be possible right now, and can be voted up at the  suggestion 7082397\n\nRemember side-by-side diff choice\nRight now when I want to review code, I have to choose side-by-side diff each time I open a Merge Request because that choice is not stored/saved anywhere.\nEither store my last choice/change of viewer globally somewhere and use it on all diff views from that point on.\nOr let me have a config option on my account where I can specify my preferred choice.\n\nThe side-by-side diff view was introduced with GitLab 6.4 (Dec. 2013) with commit b51c2c8."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Is it dangerous to keep code in gitlab and github\n\nIs it dangerous to keep code in gitlab and github?\nI heard it is quite safe to commit our code to gitlab and github.\nThe reason is every code is hashed and it is nearly impossible for everyone to alter the code without using git tool.\nIs this true?"}, {"role": "assistant", "content": "As I mentioned in \"Why does Git use a cryptographic hash function?\", it is \"safe\" in term of data integrity (Linus Torvalds, 2007):\n\nWe check checksums that is considered cryptographically secure. Nobody has been able to break SHA-1, but the point is, SHA-1 as far as git is concerned, isn't even a security feature. It's purely a consistency check.\n  The security parts are elsewhere.\n  A lot of people assume since git uses SHA-1 and SHA-1 is used for cryptographically secure stuff, they think that it's a huge security feature. It has nothing at all to do with security, it's just the best hash you can get.\nHaving a good hash is good for being able to trust your data\n\nThis has nothing to do with:\n\nprivacy (which doesn't depend on Git itself, but on the Git hosting server, like gitHub or BitBucket)\nuser identity (to really be sure about a commit user, as Thilo comments, you can sign commits (see \"A Git Horror Story: Repository Integrity With Signed Commits\")\n\n\nThe OP add:\n\nwhat I mean is the owner of gitlab or github may steal our code\n\nThis is a question of trust: Does the git hosting server have access to your code if it is in a private repo? Technically yes.\nWill they access your private code? As mentioned in \"Can third party hosts be trusted for closed-source/private source code management?\", nothing prevents them to.\nYet, many startups have their private code on, for instance, GitHub.\nIf you have real confidentiality concern, then it is important you keep the ownership of the all codebase, including the server where it is stored (meaning having your own Git repo hosting server)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to access GitLab issues using CURL?\n\nI'd like to get a list of the issues for the project YYYYYY and a username XXXXXX.\ncurl --header \"PRIVATE-TOKEN: myownprivatetoken\" \"https://gitlab.com/api/v3/projects/YYYYYY/issues\"\n\ncurl --header \"PRIVATE-TOKEN: myownprivatetoken\" --header \"SUDO: XXXXXX\" \"https://gitlab.com/api/v3/projects/YYYYYY/issues\"\n\ncurl --header \"PRIVATE-TOKEN: myownprivatetoken\" \"https://gitlab.com/api/v3/XXXXXX/projects/YYYYYY/issues\"\n\nBut they only return:\n{\"message\":\"404 Project Not Found\"}\n\nor\n<html><body>You are being <a href=\"https://gitlab.com/users/sign_in\">redirected</a>.</body></html>\n\nIt seems to me that I have misinterpreted the API docs at http://doc.gitlab.com/ce/api/issues.html and http://doc.gitlab.com/ce/api/README.html .\nSo what am I doing wrong?"}, {"role": "assistant", "content": "The documentation tell you this about how to retrieve issues from a project: \nGET /projects/:id/issues\n\nAnd you tried: \ncurl --header \"PRIVATE-TOKEN: xxx\" \"https://gitlab.com/api/v3/projects/YYYYYY/issues\"\n\nThis is correct, but the parameter you give YYYYYY has to be the project id, so it has to be an integer, not text with the project name or path. You need to use something like : \ncurl --header \"PRIVATE-TOKEN: xxx\" \"https://gitlab.com/api/v3/projects/234/issues\"\n\nWhere 234 is the id of your project. To get this integer id of your project, simply do a : \ncurl --header \"PRIVATE-TOKEN: xxx\" \"https://gitlab.com/api/v3/projects\n\nThis will list all your projects and will give you the unique integer identifier of a project in the id field:\n[\n  {\n    \"id\": 4,            <-------- //This one\n    \"name\": \"my super mega project\",\n    \"description\": null,\n    ....."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "integrating gitlab with sonarqube\n\nI have GitLab CE (v8.5 at least) installed on my server. I would like to integrate it with sonarqube so that merge requests shows any issues in the comment section. Has anyone integrated these 2 systems successfully?\nAt the moment, only sonarqube plugin I found is the following but I'm not able to successfully integrate it with GitLab.\nhttps://gitlab.talanlabs.com/gabriel-allaigre/sonar-gitlab-plugin\nI used a docker container for sonarqube (v5.5) and copied the plugin into extensions directory. Configured gitlab user token and gitlab uri in the plugin's setting page in sonarqube.\nI'm using GitLab CI for continuous integration and I have the following build job for sonarqube (using gradle)\nsh gradlew sonarqube -Psonar.analysis.mode=preview -Psonar.issuesReport.console.enable=true \\\n  -Psonar.gitlab.commit_sha=$CI_BUILD_REF -Psonar.gitlab.ref_name=$CI_BUILD_REF_NAME \\\n  -Psonar.gitlab.project_id=$CI_PROJECT_ID\n\nBut, I'm not sure what to after this. Couple of questions:\n\nWhat happens when a merge request does not exist yet? In my git workflow, users will submit a merge request after they're done working on their branch. So, how will this plugin know which merge request to update?\nRight now I have the sonarqube valiation task set to be running only on master branch. I think this will need to be changed to user branches too, right?\n\nI did try submitting a merge request, but I didn't see any comments being added. I think I'm missing some configuration or a process. Really appreciate if you can help point me to the right direction."}, {"role": "assistant", "content": "I had the same problem than yours. Comments were not showing in the GitLab MR. I made it work with two fixes:\n\nmake sure the preview mode is used. If it is not, the issues are not reported to GitLab\nfor issues to appear as GitLab comments, they have to be \"new\" issues. If you launched an analysis of your project before pushing to GitLab, the issues will not be considered as new by SonarQube, and no comment will be added to the MR.\n\nIf this does not solve your problem, try cloning the plugin repo, adding traces to the code (CommitIssuePostJob.java is the place to look), package the jar with maven and deploy the patched jar to your Sonar installation. That is how I saw that I had no new issues to report."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "External URL must include a FQDN\n\nI set up a fresh CentOS 6.6 install and used the Omniubus installer for the CE of Gitlab.\nWhen running gitlab-ctl reconfigure I get the following errors:\n================================================================================\nRecipe Compile Error in /opt/gitlab/embedded/cookbooks/gitlab/recipes/default.rb\n================================================================================\n\n\nRuntimeError\n------------\nExternal URL must include a FQDN\n\n\nCookbook Trace:\n---------------\n  /opt/gitlab/embedded/cookbooks/gitlab/libraries/gitlab.rb:95:in `parse_external_url'\n  /opt/gitlab/embedded/cookbooks/gitlab/libraries/gitlab.rb:191:in `generate_config'\n  /opt/gitlab/embedded/cookbooks/gitlab/recipes/default.rb:34:in `from_file'\n\n\nRelevant File Content:\n----------------------\n/opt/gitlab/embedded/cookbooks/gitlab/libraries/gitlab.rb:\n\n 88:  \n 89:      def parse_external_url\n 90:        return unless external_url\n 91:  \n 92:        uri = URI(external_url.to_s)\n 93:  \n 94:        unless uri.host\n 95>>         raise \"External URL must include a FQDN\"\n 96:        end\n 97:        Gitlab['user']['git_user_email'] ||= \"gitlab@#{uri.host}\"\n 98:        Gitlab['gitlab_rails']['gitlab_host'] = uri.host\n 99:        Gitlab['gitlab_rails']['gitlab_email_from'] ||= \"gitlab@#{uri.host}\"\n100:  \n101:        case uri.scheme\n102:        when \"http\"\n103:          Gitlab['gitlab_rails']['gitlab_https'] = false\n104:        when \"https\"\n\nThe FQDN of the server is correctly set, I have an external IP. DNS is configured for the FQDN to point at my external IP.\nHere's the contents of my /etc/gitlab/gitlab.rb in case that is useful:\n# Check and change the external_url to the address your users will type in their browser\nexternal_url 'gitlab.thefallenphoenix.net'\ngitlab_rails['gitlab_email_from'] = '[email\u00a0protected]'"}, {"role": "assistant", "content": "EDIT: This is now fixed with adding http:// or https:// to the domain in the .rb file. Tested on Debian 9 with Gitlab EE.\n\nAdd a = sign to the gitlab.rb.\nIt should be:\nexternal_url = 'gitlab.thefallenphoenix.net'\ngitlab_rails['gitlab_email_from'] = '[email\u00a0protected]'\n\nAfter that it should install fine. At least it worked for me on CentOS 6.6."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI - avoid build when adding tag\n\nHow do I prevent a gitlab ci pipeline being triggered when I add a git tag? I'm running this command locally (as opposed to within a gitlab-ci job) \ngit tag -a \"xyz\"\n\nand then pushing the tag; and this triggers various pipelines. I want to exclude some of those pipelines from running. \nI'm trying variations on ideas from questions such as this; that question is using only, I'm wanting to exclude, so I'm trying except. The answers there have two variants, one with refs one without.\nbuild:  \n  # ... my work here ...  \n  except:\n    - tags\n\n\nbuild:  \n  # ... my work here ...  \n  except:\n    refs:\n      - tags\n\nNeither seem to have any effect; I add a tag, the build still happens.\nMy understanding may be completely awry here as there seem to be three possible meanings of the word tags and when reading docs or examples I'm not always sure which meaning is applicable:\n\nGit tags applied using git tag\nGitlab CI tags used to determine which runners pick a job\nThe ref identifier of a commit used to trigger a pipeline via the REST API. This is usually a branch name, but could be a git tag.\n\nI'm interested in controlling what happens if the first case. It does seem clear from comments so far that \"except: -tags\" is not relevant to my case, so is there any approach that does work?"}, {"role": "assistant", "content": "It looks like GitLab recommends using rules instead of except as per the documentation\n\nonly and except are not being actively developed. rules is the\npreferred keyword to control when to add jobs to pipelines.\n\nSo it'd be\nyour_job:\n  stage: your_stage\n  script:\n    - echo \"Hello\"\n  rules:\n    - if: $CI_COMMIT_TAG\n      when: never \n    - when: always"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Deploy every build to a server using Gitlab CI\n\nI've set up my own Gitlab server with one project and a Gitlab runner configured for it. I'm new to continuous integration server and therefore don't know how to accomplish the following.\nEvery time I commit to the master branch of my project I would like to deploy the repository to another server and run two shell-commands there (npm installand forever restartall)\nHow would I do this? Do I need a runner on the machine which the project is deployed to as well?"}, {"role": "assistant", "content": "You could use gitlab-ci and gitlab-runner [runners.ssh] to deploy to single or mutiple servers.\nthe flow: \n(git_project with yml file)  --> (gitlab && gitlab-ci) --> (gitlabrunner) ---runners.ssh---> (deployed_server,[deploye_server2])\n\n\nyou need register gitlab-runner to gitlab-ci and set the tag to delpoyServer on gitlab web .\n/etc/gitlab-runner/config.toml:\n [[runners]]\n  url = \"http://your.gitlab.server/ci\"\n  token = \"1ba879596cf3ff778ee744e6decedd\"\n  name = \"deployServer1\"\n  limit = 1\n  executor = \"ssh\"\n  builds_dir = \"/data/git_build\"\n  [runners.ssh]\n    user = \"you_user_name\"\n    host = \"${the_destionation_of_deployServer_IP1}\"\n    port = \"22\"\n    identity_file = \"/home/you_user_name/.ssh/id_rsa\"\n\n\n[[runners]]\n  url = \"http://your.gitlab.server/ci\"\n  token = \"1ba879596cf3ff778ee744e6decedd\"\n  name = \"deployServer2\"\n  limit = 1\n  executor = \"ssh\"\n  builds_dir = \"/data/git_build\"\n  [runners.ssh]\n    user = \"you_user_name\"\n    host = \"${the_destionation_of_deployServer_IP2}\"\n    port = \"22\"\n    identity_file = \"/home/you_user_name/.ssh/id_rsa\"\n\n\nthe runner.ssh means, the runner will login into ${the_destionation_of_deployServer_IP1} and ${the_destionation_of_deployServer_IP2}, then clone the project to builds_dir.\n\nwrite the yml file\nfor example:\n.gitlab-ci.yml\njob_deploy:\n  stage: deploy\n  tags: delpoyServer1\n  script:\n    -  npm install &&  forever restartall\njob_deploy:\n  stage: deploy\n  tags: delpoyServer2\n  script:\n    -  npm install &&  forever restartall\n\nset the your gitlab-runner to delpoyServer1 and delpoyServer2tags in 'http://your.gitlab.server/ci/admin/runners'\n\nwhen you push you code to gitlab\nthe gitlab-ci server will parser your .gitlab-ci.yml file in your project, choose a runner with the tags: deployServer1 or deployServer2; \nthe gitlab-runnerwith the deployServer1 tag  will login  into ${the_destionation_of_deployServer_IP1} and ${the_destionation_of_deployServer_IP2} with ssh , clone the project to builds_dir, then  execute you script: npm install &&  forever restartall.\n\n\nlink: \n\ngitlab-runner register\nrunners.ssh"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How can I create a table of content in GitLab wiki?\n\nI am a big fan of the __TOC__ that creates a table of content on a Wikimedia page.\nWhenever you write things like this on a Wikimedia page:\nThis is a page for my project\n\n## Credits ##\n\nbla bla\n\n## License ##\n\nbla bla\n\n__TOC_ automagically creates a table of content that allows you to navigate through inner links of the page.\nI noticed that this is somehow possible in GitHub wiki pages: How do I create some kind of table of content in GitHub wiki? by using different tricks.\nHowever, I miss this feature in GitLab wiki pages. Does it provide such functionality?"}, {"role": "assistant", "content": "So this exists! I finally found a Merge Request in in the GitLab Community Edition: Replace Gollum [[_TOC_]] tag with result of TableOfContentsFilter\nAs its name describes, to have a table of contents you need to write the following:\n[[_TOC_]]\n\nAll together, you can write something like:\nThis is a page for my project\n\n[[_TOC_]]\n\n## Credits\n\nbla bla\n\n## License\n\nbla bla\n\nand will show like this:\n\n\n\nThis is available from the GitLab 8.6 release as described in its milestone."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Pagination in Gitlab API only returns 100 per_page max\n\nI am currently using GitLab API to return all projects within a group. The question I have is, how do I return all projects if there are over 100 projects in the group?\nThe curl command I'm using is curl --header \"PRIVATE-TOKEN: **********\" http://gitlab.example.com/api/v4/groups/myGroup/projects?per_page=100&page=1\nI understand that the default page=1 and the max per_page=100 so what do I do if there are over 100 projects? If I set page=2, it just returns all the projects after the first 100."}, {"role": "assistant", "content": "Check the response for the X-Total-Pages header. As long as page is smaller than total pages, you have to call the api again and increment the page variable.\nhttps://docs.gitlab.com/ee/api/rest/index.html#pagination-link-header"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "SSL certificate problem: unable to get local issuer certificate AZURE DEVOPS\n\nI have a problem... My code in Gitlab, Pipeline in Azure DevOps. I use classic editor. When i start pipeline i have error \"fatal: unable to access 'fatal: unable to access 'https://my.repos.example:***.git/': SSL certificate problem: unable to get local issuer certificate\"\nPlease help me!"}, {"role": "assistant", "content": "For me this issue came up when attempting to clone a repository through Visual Studio 2019.  Upon selecting the Azure option in the repository menu I then picked the codebase I wanted to clone.  After this step I was prompted with an error of:\n \"SSL certificate problem: unable to get local issuer certificate\"\n\nI ran the git command setting up the global ssl backend:\n> git config --global http.sslbackend schannel\n\nAnd the next time I tried the steps listed above, all was well."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to leave a GitLab project not owned by me?\n\nIf I had contributed in  a project, for which I am not an owner or administrator, how can I get myself out of that project? I do not find the leave button as documented  in issue 744.\nhttps://gitlab.com/gitlab-org/gitlab-ce/merge_requests/744\nThe project owner has stopped responding to me and I badly want myself out of it. Please help."}, {"role": "assistant", "content": "Updated answer for 2020:\nLeaving a group automatically removes you from all projects added by that group. \nAt the top menu chose Groups\\Your Groups. Select the group you want to leave and press leave."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to auto deploy Docker Image on own server with GitLab?\n\nI am trying to Google it for few hours, but can't find it.\nI have Java/Spring application (+MySQL if it matters) and I am looking to create CI for that.\nI know what to do and how:\n\nI know that I have to move my Git repo to Gitlab.\nPush to repo will trigger CI script.\nGitlab will build my docker image into Gitlab Docker Registry.\n\nQuestion is:\nWhat do I have to do to force docker compose on my VPS to pull the new image from Gitlab and restart the server? \nI know (correct me if I am wrong) that on my VPS I should run docker-compose pull && docker-compose up inside my app folder, but I have literally no idea how to make it automatically with Gitlab?"}, {"role": "assistant", "content": "What do I have to do to force docker compose on my VPS to pull the new image from Gitlab and restart the server? \n\n@m-uu, you don't need restart the server at all, just do docker-compose up to pull new image and restart service\n\nI know (correct me if I am wrong) that on my VPS I should run docker-compose pull && docker-compose up inside my app folder, but I have literally no idea how to make it automatically with Gitlab?\n\nYes, you are on the right way. Look at my Gitlab CI configuration file, I think it doesn't difficult to change it for Java project. Just give you ideas how to build, push to your registry and deploy an image to your server. One thing you need to do is generate SSH keys and push public to server (.ssh/authorized_keys) and private to GITLAB pipeline secret variable (https://docs.gitlab.com/ee/ci/variables/#secret-variables)\ncache:\n  key: \"cache\"\n  paths:\n  - junte-api\n\nstages:\n  - build\n  - build_image\n  - deploy\n\nbuild:\n  image: golang:1.7\n  stage: build\n  script:\n    - 'which ssh-agent || ( apt-get update -y && apt-get install openssh-client -y )'\n    - eval $(ssh-agent -s)\n    - echo \"$SSH_PRIVATE_KEY\" > ~/key && chmod 600 ~/key\n    - ssh-add ~/key\n    - mkdir -p ~/.ssh\n    - '[[ -f /.dockerenv ]] && echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" > ~/.ssh/config'\n\n    - go get -u github.com/kardianos/govendor\n    - mkdir -p $GOPATH/src/github.com/junte/junte-api\n    - mv * $GOPATH/src/github.com/junte/junte-api\n    - cd $GOPATH/src/github.com/junte/junte-api\n    - govendor sync\n    - go build -o junte-api\n    - cd -\n    - cp $GOPATH/src/github.com/junte/junte-api .\n\nbuild_image:\n  image: docker:latest\n  stage: build_image\n  script:\n    - docker login -u gitlab-ci-token -p $CI_BUILD_TOKEN $CI_REGISTRY\n    - docker build -t $CI_REGISTRY_IMAGE .\n    - docker push $CI_REGISTRY_IMAGE\n\ndeploy-dev:\n  stage: deploy\n  image: junte/ssh-agent\n  variables:\n    # should be set up at Gitlab CI env vars\n    SSH_PRIVATE_KEY: $SSH_DEV_PRIVATE_KEY\n  script:\n    # copy docker-compose yml to server\n    - scp docker-compose.dev.yml root@SERVER_IP:/home/junte/junte-api/\n    # login to gitlab registry       \n    - ssh root@SERVER_IP docker login -u gitlab-ci-token -p $CI_BUILD_TOKEN $CI_REGISTRY\n    # then we cd to folder with docker-compose, run docker-compose pull to update images, and run services with `docker-compose up -d`\n    - ssh root@SERVER_IP \"cd /home/junte/junte-api/ && docker-compose -f docker-compose.dev.yml pull api-dev && HOME=/home/dev docker-compose -f docker-compose.dev.yml up -d\"\n  environment:\n      name: dev\n  only:\n    - dev\n\nYou also need Gitlab runner with Docker support. How install it look at in Gitlab doc, please.\nAbout stages:\n\nbuild - just change it to build what you need\nbuild_image - very simple, just login to gitlab registry, build new image and push it to registry. Look at cache part, it need to cache files between stages and can be different for you.\ndeploy-dev - that part more about what you asked. Here first 6 commands just install ssh and create your private key file to have access to your VPS. Just copy it and add your SSH_PRIVATE_KEY to secret vars in Gitlab UI. Last 3 SSH commands more interesting for you."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "git fetch --unshallow gives :\"fatal: --unshallow on a complete repository does not make sense\" error\n\nI am unable to git clone a remote repository using plain\ngit clone path \n\nI get the error \"The remote end hung up unexpectedly\".\nThe complete msg I get is :\nCloning into 'xyzabc'...\nremote: Counting objects: 4328, done.\nremote: Compressing objects: 100% (3861/3861), done.\nselect: Not enough memory2192/4328), 123.71 MiB | 164.00 KiB/s\nffatal: The remote end hung up unexpectedly\natal: early EOF\nfatal: index-pack failed\n\nI search online for a solution and after trying every other solution landed on solution of doing :\ngit clone --depth=1 path\n\nfollowed by\ngit fetch --unshallow\n\nNow the clone is completing fully. But, when I try to run git fetch --unshallow to recieve the complete project, I get the error :\nfatal: --unshallow on a complete repository does not make sense\n\nI dont know what to do please guide"}, {"role": "assistant", "content": "I too found the same message. Looks like it's not allowing to unshallow a shallow clone. You might want to try. \ngit fetch --depth=10000\n\nassuming there are 10000 depths in your clone."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI - unique build number\n\nIs there any unique number in Gitlab CI which can be used as build number as we use in Jenkins. I came to know about the variable \"CI_PIPELINE_IID\" but the problem with this variable is, it updates for all branches and there is no such variable exist for each branch."}, {"role": "assistant", "content": "We solved the same issue using the variable $CI_PIPELINE_IID, which is defined as\n\nThe project-level IID (internal ID) of the current pipeline. This ID is unique only within the current project.\n\nAnd is quite similar to Jenkins' $BUILD_NUMBER\nSee also https://docs.gitlab.com/ee/ci/variables/predefined_variables.html#variables-reference"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Generating a gitlab ssh key from windows\n\nI've tried following this guide on generating an ssh key in order to use gitlab.\nBefore I know if I should generate a key I must check if there is one already like this:\ntype %userprofile%\\.ssh\\id_rsa.pub\n\nIf it says this, then I must generate the key:\nthe system cannot find the path specified\n\nWhat is the next step? Because the guide doesn't say anything in case this is the message I get.\nEdit: I've tried\nssh-keygen -t rsa -C \"[email\u00a0protected]\"\n\nAnd I get \n'ssh-keygen' is not recognized as an internal or external command, \noperable program or batch file.\n\nEdit 2: I am on windows."}, {"role": "assistant", "content": "ON windows if you have git for windows installed, run git-gui. Then click Help then click Show Ssh Key, then click Generate Key.\nWhile you're at it, then copy to the clipboard, and then go to your Gitlab account page and add the SSH key to your Gitlab account's ssh settings."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Getting docker-compose TypeError: kwargs_from_env() got an unexpected keyword argument 'ssl_version' in GitLab\n\nI'm using GitLab CICD, in docker-test stage as defined\ndocker_test: image: docker:stable services: - docker:stable-dind stage: docker-test\n...\nyesterday worked fine, but today - GitLab pipeline 'docker_test' fails with:\nTypeError: kwargs_from_env() got an unexpected keyword argument 'ssl_version'\nI've found on the internet that it could be an upgrade to 7.0.0\nhttps://docker-py.readthedocs.io/en/stable/change-log.html\nSomeone here suggested (for a different setup) downgrading to prev 6.3.1\nAfter searching - have no idea how to do that.\nMaybe there are other solutions to this?"}, {"role": "assistant", "content": "Summarising the discussion at docker-py:\nDocker1 has made a change in v7.0.0 that breaks Docker Compose v1 written in Python (pip install docker-compose available as docker-compose). It has been deprecated and replaced by Docker Compose v2 implemented in Go which comes OOB as docker compose (sub-command).\nPermanent fix: Switch to Docker Compose v2 (no extra installation required, read the migration docs to fix compatibility issues).  Docker Compose v2 switch is totally worth, btw; it is a near implementation.\nTemporary fix: Downgrade Docker1 using pip install docker==6.1.3 to the version that works with Docker Compose (v1).\n\nNote: There is a request to provide backward compatibility \u2014 not sure if it will be accepted.\nCredit: Tim Panohos's answer for the issue link.\n1. Docker's python wrapper docker-py; not the real executable docker which is written in Go."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab: How to disable automatic startup?\n\nI have not found a way to disable the automatic startup and it ends up using too much RAM when I'm not using.\nThe init files are not inside /etc/init or init.d.\nI try update-rc.d gitlab remove and no results.\nI am using GitLab 8.5.4 in Debian 8."}, {"role": "assistant", "content": "Problem is solved!\nI contacted the GitLab by their official page on Facebook and here is the answer.\nI am using GitLab in a Desktop and it was using ~700MB.\nIf you too want turn off GitLab on startup, just execute in a terminal:\nsudo systemctl disable gitlab-runsvdir.service"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Pylint badge in gitlab\n\nGitlab has functionality to generade badges about build status and coverage percentage.\nIs it possible to create custom badge to display Pylint results?\nOr just display this results in README.md?\nI already have CI job for Pylint"}, {"role": "assistant", "content": "I have written a python badge generation package that produces badges very visually similar to the main badge services.  It is highly flexible, you can import and use in your python code, or run from the command line.\nI use this in GitLab CI to display pylint and coverage scores.\nThere are other ways to do this using shields.io (see other answer from kubouch), but this approach can be used in situations where you may not have external internet access, such as in a corporate / enterprise setting where firewalls or proxies are blocking internet access.\nGitLab CI Setup\n1. Generate the badge\nMy CI pipeline has a step that runs pylint, and I used sed to extract the score from the output text.  I then use anybadge (details below) to generate a pylint score badge, and save it as public/pylint.svg.\npylint:\n  stage: test\n  script:\n    - pylint --rcfile=.pylintrc --output-format=text <LIST-OF-FILES-TO-RUN-PYLINT-AGAINST> | tee pylint.txt\n    - score=$(sed -n 's/^Your code has been rated at \\([-0-9.]*\\)\\/.*/\\1/p' pylint.txt)\n    - echo \"Pylint score was $score\"\n    - anybadge --value=$score --file=public/pylint.svg pylint\n\nIf pylint generates a non-zero rc then GitLab will see that as a command error and the job will fail, meaning no badge is generated, and missing image will show where the badge is used.\nNOTE: pylint WILL OFTEN generate non-zero return codes since it uses the exit code to communicate the status of the lint check.  I suggest using something like pylint-exit to handle pylint return codes in CI pipelines.\n2. Register badge as pipeline artifact\nI register the generated badge file as an artifact in the CI job by including this in the .gitlab-ci.yml:\npylint:\n    ...\n    - echo \"Pylint score was $score\"\n    - anybadge --value=$score --file=public/pylint.svg pylint\n  artifacts:\n    paths:\n      - public/pylint.svg\n\n3. Publish badge to GitLab Pages\nI include a pages publish step, which deploys everything in the public directory to GitLab pages:\npages:\n  stage: deploy\n  artifacts:\n    paths:\n    - public\n  only:\n  - master\n\n4. Include badge in README.md\nWhen the master pipeline runs for the project, the pylint.svg file is published to GitLab Pages, and I can then reference the image from my project README.md so that the latest pylint badge is displayed.\nIf you are using https://gitlab.com for your project then the URL for the svg artifact will usually be something like this (replace NAMESPACE with your username, or group name if your project is under a group - more details here):\nhttps://NAMESPACE.gitlab.io/pyling.svg\nIn your README.md you can include an image with:\n![pylint](https://NAMESPACE.gitlab.io/pyling.svg)\n\nIf you want to make the image into a link you can use:\n[![pylint](https://NAMESPACE.gitlab.io/pyling.svg)](LINKTARGET)\n\nLet me know if you need more information on any of the setup.\nAnybadge Python Package\nHere's some more info on the anybadge Python package:\nYou can set the badge label and value, and you can set the color based on thresholds.  There are pre-built settings for pylint, coverage, and pipeline success, but you can create any badge you like.\nHere is a link to the github project with more detailed documentation: https://github.com/jongracecox/anybadge\nInstall with pip install anybadge\nExample python code:\nimport anybadge\n\n# Define thresholds: <2=red, <4=orange <8=yellow <10=green\nthresholds = {2: 'red',\n              4: 'orange',\n              6: 'yellow',\n              10: 'green'}\n\nbadge = anybadge.Badge('pylint', 2.22, thresholds=thresholds)\n\nbadge.write_badge('pylint.svg')\n\nExample command line use:\nanybadge --label pylint --value 2.22 --file pylint.svg 2=red 4=orange 8=yellow 10=green\n\nUpdate 2019\nUsing GitLab Pages is no longer required\nIt is now possible to directly access to the latest articfact, which simplify the workaround.\n\nUse a dedicated pylint artifact instead of public, and remove the unnecessary deploy step (or edit it if already used):\n\npylint:\n  stage: test\n  before_script:\n    - pip install pylint pylint-exit anybadge\n  script:\n    - mkdir ./pylint\n    - pylint --output-format=text . | tee ./pylint/pylint.log || pylint-exit $?\n    - PYLINT_SCORE=$(sed -n 's/^Your code has been rated at \\([-0-9.]*\\)\\/.*/\\1/p' ./pylint/pylint.log)\n    - anybadge --label=Pylint --file=pylint/pylint.svg --value=$PYLINT_SCORE 2=red 4=orange 8=yellow 10=green\n    - echo \"Pylint score is $PYLINT_SCORE\"\n  artifacts:\n    paths:\n      - ./pylint/\n\nNote that here I copy the Pylint log file in the folder artifact, in this way it will be accessible without looking at the pipeline logs.\nThe badge image will then be available at https://gitlab.example.com/john-doe/foo/-/jobs/artifacts/master/raw/pylint/pylint.svg?job=pylint, and the Pylint log at https://gitlab.example.com/john-doe/foo/-/jobs/artifacts/master/raw/pylint/pylint.log?job=pylint.\n2. You can use GitLab's builtin badges instead of images in README\nGitLab can now include badges in a projet or group, that will be displayed in the project header.\nGot to Settings / General / Badges, then create a new badge by setting its link and image link, as described above:"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab API for all projects under group\n\nI want to get a list of all the projects which are under a particular group in Gitlab. Here is the example scenario:\nGroup A (id: 1) has 3 Project\n\nGroup A / Project 1\nGroup A / Project 2\nGroup A / Project 3\n\nGroup B (id: 2) has 5 Projects\n\nGroup B / Project 1\nGroup B / Project 2\nGroup B / Project 3\nGroup B / Project 4\nGroup B / Project 5\n\nNow if I hit the rest api GET /groups it will give me only the list of groups. If i hit the rest api GET /projects/all, it will give me a list of all the projects.\nWhat I am looking for, is an operation something like GET /groups/:groupid/projects/all\nThat is: all the projects for that particular group. Like if I say GET /groups/1/projects/all it will give me Project 1, Project 2 and Project 3.\nThe only way I can think of is to get a list of all the projects and loop over them to see if it matches my group name, but this will be lot of unnecessary  parsing.\nHow can I achieve this in a better way?\nI am working on Gitlab CE 7.2.1. I am referring the Gitlab API documententation"}, {"role": "assistant", "content": "You can also use the recently released Gitlab GraphQL API to query groups by name :\n{\n  group(fullPath: \"your_group_here\") {\n    projects {\n      nodes {\n        name\n        description\n        httpUrlToRepo\n        nameWithNamespace\n        starCount\n      }\n    }\n  }\n}\n\nYou can go to the following URL : https://[your_gitlab_host]/-/graphql-explorer and past the above query\nThe Graphql endpoint is a POST on \"https://$gitlab_url/api/graphql\"\nAn example using curl and jq:\ngitlab_url=<your gitlab host>\naccess_token=<your access token>\ngroup_name=<your group>\n\ncurl -s -H \"Authorization: Bearer $access_token\" \\\n     -H \"Content-Type:application/json\" \\\n     -d '{ \n          \"query\": \"{ group(fullPath: \\\"'$group_name'\\\") { projects {nodes { name description httpUrlToRepo nameWithNamespace starCount}}}}\"\n      }' \"https://$gitlab_url/api/graphql\" | jq '.'"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Why is gitlab asking me to enter my user credentials?\n\ngit is asking me to enter my gitlab user credentials when pushing or pulling code. I am using gitlab.com, I'm not self-hosting gitlab.\nI followed the instructions to set up my ssh key. I created a key, I copied the contents from ~/.ssh/id_rsa.pub, added the key to gitlab using gitlab's user interface, and git still asks me for my user and password.\ngit remote -v\norigin  https://gitlab.com/<my_user>/<my_repo> (fetch)\norigin  https://gitlab.com/<my_user>/<my_repo> (push)"}, {"role": "assistant", "content": "You are using HTTPS authentication.  Switch to an SSH-based URL (in this case, probably ssh://[email\u00a0protected]/path/to/repo.git or [email\u00a0protected]:path/to/repo.git).  For instance:\ngit remote set-url origin ssh://[email\u00a0protected]/<user>/<repo>\n\n(Alternatively, if you're comfortable with using your configured editor, you can run git config --edit and edit the URL directly in the configuration file.  Make sure whatever editor you choose stores files in plain-text format, not any enhanced rich-text or UTF-16 encoding.)\nBackground\nIn order to connect one Git to another, you may need to authenticate yourself.  There are several ways to do that.  (Whether you need to do that depends on the kind of connection you are making, and whether the repository is public.)\nIf you are authenticating over https://, your Git may ask for a user name and password.  It can use various credential helpers, which may also store user names and/or passwords. You can configure which credential helper to use, including the \"cache\" and \"store\" helpers, which use different additional data. Note that the available set of credential helpers varies based on your underlying operating system as well.\nIf you are authenticating over ssh://, you will use an ssh key (SSH authentication).\nIf you use a URL that begins with user@host:, you are using SSH authentication."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Redefine tab as 4 spaces in Gitlab CE\n\nSee this huge identations is painful (for me). Is there a way to set tab size to 4 spaces. \nThis picture is taken from local Gitlab CE server with minimal customization. I think tabsize 8 spaces is default."}, {"role": "assistant", "content": "Go to Settings \u2192 Preferences \u2192 Behavior and set Tab width."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Does removing a GitHub Repo also remove the Git Contribution History from the chart on your profile page?\n\nIf I have a Repository called my_project and make a large number of commits over a few different weeks, my contribution history on my GitHub/GitLab (Should be true for both), the main page profile will look like the following:\n\nAs above you can see varied commits in the contribution panel, dark colours for more and light green for less, with grey as no commits to the repo.\nIf I remove the repo does this all become grey? As in does the commit history for this graph on my landing page turn all those coloured cells from green to grey as there is no repo there any more associated with those commits.\nThe only reason I ask this, is because I have made a repo which I no longer need and was using to test out some python and git, however if I remove the repo I am worried that my profile will show that I have made no contributions for the past month on GitHub/GitLab, but I have, it's only I want to remove the project as it's no longer needed.\nAny help is appreciated!"}, {"role": "assistant", "content": "Yes, it will be removed too.\nHowever, if you don't want it you can make that repo as private so that publically it is not accessible to anyone and your contribution still shows up in history"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What are the differences between gitlab team and gitlab group?\n\nI'm using Gitlab 5.0 to manage my git repositories and I've never used github before Gitlab.\nWhen I create a group, I see a new directory with this group name in /home/git/repositories.\nBut with team, no such thing is done.\nAlso, with group, I can create a project for the group and the assignments (for users of this group) is done automatically.\nI can't see any other differences between group and team and I would like to understand that.\nThank you in advance and sorry for the bad English (I'm french),"}, {"role": "assistant", "content": "GitLab 6.0 (August 2013, 22d)\nSee commit 3bc4845:\nFeature: Replace teams with group membership\n\nWe introduce group membership in 6.0 as a replacement for teams.\n  The old combination of groups and teams was confusing for a lot of people.\n  And when the members of a team where changed, this wasn't reflected in the project permissions.\nIn GitLab 6.0 you will be able to add members to a group with a permission level for each member.\n  These group members will have access to the projects in that group.\n  Any changes to group members will immediately be reflected in the project permissions.\n  You can even have multiple owners for a group, greatly simplifying administration.\n\n\n\nWhy do references to Teams still exist in GitLab 7 then? e.g. \"Filter by Team\"\n\n\n\"Team\" seems now (GitLab 6.x->7.x 2015) seems limited to a project (see for example features/project/team_management.feature, and app/models/project_team.rb or spec/models/project_team_spec.rb).\nA project can be part of a group: see \"Gitlab API for all projects under group\".\n\"Group\" references users, and can group multiple projects, (See features/groups.feature, app/models/group.rb, app/models/members/group_member.rb)\n\nAs a user, you are a first a member of a group, and have roles ('Reporter', 'Developer', ...) associated to a project (which makes you a member of that project, part of the \"team\" for that project).\nNo role, means \"not a member of the team for a project\".\nSee db/migrate/20140914145549_migrate_to_new_members_model.rb.\n\nAnswer for GitLab 5.x (before August 2013, 22d)\n\nGroup is for grouping projects, similar to a folder (git repositories)\nTeam is for grouping resources (people)\n\nThose notions have been refined in GitLab 4.2.\nThat allows you to manage authorization in a more convenient way, given permissions to a group of projects in one operation, and/or given permission to a group of people, referenced by their team.\nGitLab 5.x no longer used Gitolite, but before 5.0, teams and groups are coming from Gitolite, and its gitolite.conf configuration file.\nThis is where team and groups were declared and associated in order to grant permission access.\nEven without gitolite, the idea persists: managing the authorization through association between teams (of people) and groups (of projects)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab-CI: Cannot link to a non running container\n\nI've tried to get my setup work with gitlab-ci. I have a simple gitlab-ci.yml file\nbuild_ubuntu:\n  image: ubuntu:14.04\n  services:\n    - rikorose/gcc-cmake:gcc-5\n  stage: build\n  script:\n    - apt-get update\n    - apt-get install -y python3 build-essential curl\n    - cmake --version\n  tags:\n    - linux\n\nI want to get a ubuntu 14.04 LTS with gcc and cmake (apt-get version is to old) installed. If i use it locally (via docker --link command) everything works, but when the gitlab-ci-runner will process it i get the following waring (which is in my case an error)\nRunning with gitlab-ci-multi-runner 9.2.0 (adfc387)\non xubuntuci1 (19c6d3ce)\nUsing Docker executor with image ubuntu:14.04 ...\nStarting service rikorose/gcc-cmake:gcc-5 ...\nPulling docker image rikorose/gcc-cmake:gcc-5 ...\nUsing docker image rikorose/gcc-cmake:gcc-5 \nID=sha256:ef2ac00b36e638897a2046c954e89ea953cfd5c257bf60103e32880e88299608 \nfor rikorose/gcc-cmake service...\nWaiting for services to be up and running...\n\n*** WARNING: Service runner-19c6d3ce-project-54-concurrent-0-rikorose__gcc-\ncmake probably didn't start properly.\n\nError response from daemon: Cannot link to a non running container: /runner-\n19c6d3ce-project-54-concurrent-0-rikorose__gcc-cmake AS /runner-19c6d3ce-\nproject-54-concurrent-0-rikorose__gcc-cmake-wait-for-service/runner-\n19c6d3ce-project-54-concurrent-0-rikorose__gcc-cmake\n\nDoes anybody know how i can fix this?\nThanks in advance\nTonka"}, {"role": "assistant", "content": "You must start the gitlab-runner container with\n--privileged true\n\nbut that is not enough. Any runner containers that are spun up by gitlab after registering need to be privileged too. So you need to mount the gitlab-runner\ndocker exec -it runner /bin/bash\nnano /etc/gitlab-runner/config.toml\n\nand change privileged flag from false into true:\nprivileged = true\n\nThat will solve the problem!\nnote: you can also mount the config.toml as a volume on the container then you won't have to log into the container to change privileged to true because you can preconfigure the container before running it."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "PostgreSQL: background worker \"logical replication launcher\" exited with exit code 1\n\nUsing our own instance of Gitlab we get the error background worker \"logical replication launcher\" exited with exit code 1 when trying to use the postgres service in our runners. Haven't found anything useful over the internet. Any idea what's going on? \nVersions:\n\nGitlab 12.4.3\ngitlab-runner 12.5.0 (limit of 4 concurrent jobs)\npostgres 12.1 (tried with 11 and same result)\nDigitalOcean droplet: CPU-Optimized / 8 GB / 4 vCPUs \n\nRelevant part in gitlab-ci.yml:\nimage: golang:1.12\n\nservices:\n  - postgres\n\nvariables:\n  POSTGRES_USER: postgres\n  POSTGRES_DB: xproject_test\n  POSTGRES_PASSWORD: postgres\n\nFailure log:\nRunning with gitlab-runner 12.5.0 (577f813d)\n  on xproject sEZeszwx\nUsing Docker executor with image xproject-ci ...\nStarting service postgres:latest ...\nPulling docker image postgres:latest ...\nUsing docker image sha256:9eb7b0ce936d2eac8150df3de7496067d56bf4c1957404525fd60c3640dfd450 for postgres:latest ...\nWaiting for services to be up and running...\n\n*** WARNING: Service runner-sEZeszwx-project-18-concurrent-0-postgres-0 probably didn't start properly.\n\nHealth check error:\nservice \"runner-sEZeszwx-project-18-concurrent-0-postgres-0-wait-for-service\" timeout\n\nHealth check container logs:\n\n\nService container logs:\n2019-11-20T10:16:23.805738908Z The files belonging to this database system will be owned by user \"postgres\".\n2019-11-20T10:16:23.805807212Z This user must also own the server process.\n2019-11-20T10:16:23.805818432Z \n2019-11-20T10:16:23.806094094Z The database cluster will be initialized with locale \"en_US.utf8\".\n2019-11-20T10:16:23.806120707Z The default database encoding has accordingly been set to \"UTF8\".\n2019-11-20T10:16:23.806208494Z The default text search configuration will be set to \"english\".\n2019-11-20T10:16:23.806264704Z \n2019-11-20T10:16:23.806282587Z Data page checksums are disabled.\n2019-11-20T10:16:23.806586302Z \n2019-11-20T10:16:23.806931287Z fixing permissions on existing directory /var/lib/postgresql/data ... ok\n2019-11-20T10:16:23.807763042Z creating subdirectories ... ok\n2019-11-20T10:16:23.808045789Z selecting dynamic shared memory implementation ... posix\n2019-11-20T10:16:23.835644353Z selecting default max_connections ... 100\n2019-11-20T10:16:23.866604734Z selecting default shared_buffers ... 128MB\n2019-11-20T10:16:23.928432088Z selecting default time zone ... Etc/UTC\n2019-11-20T10:16:23.929447992Z creating configuration files ... ok\n2019-11-20T10:16:24.122662589Z running bootstrap script ... ok\n2019-11-20T10:16:24.706975030Z performing post-bootstrap initialization ... ok\n2019-11-20T10:16:24.819117668Z initdb: warning: enabling \"trust\" authentication for local connections\n2019-11-20T10:16:24.819150100Z You can change this by editing pg_hba.conf or using the option -A, or\n2019-11-20T10:16:24.819157763Z --auth-local and --auth-host, the next time you run initdb.\n2019-11-20T10:16:24.819272849Z syncing data to disk ... ok\n2019-11-20T10:16:24.819313390Z \n2019-11-20T10:16:24.819328954Z \n2019-11-20T10:16:24.819340787Z Success. You can now start the database server using:\n2019-11-20T10:16:24.819349374Z \n2019-11-20T10:16:24.819357407Z     pg_ctl -D /var/lib/postgresql/data -l logfile start\n2019-11-20T10:16:24.819365840Z \n2019-11-20T10:16:24.857656160Z waiting for server to start....2019-11-20 10:16:24.857 UTC [46] LOG:  starting PostgreSQL 12.1 (Debian 12.1-1.pgdg100+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 8.3.0-6) 8.3.0, 64-bit\n2019-11-20T10:16:24.860371378Z 2019-11-20 10:16:24.860 UTC [46] LOG:  listening on Unix socket \"/var/run/postgresql/.s.PGSQL.5432\"\n2019-11-20T10:16:24.886271885Z 2019-11-20 10:16:24.886 UTC [47] LOG:  database system was shut down at 2019-11-20 10:16:24 UTC\n2019-11-20T10:16:24.892844968Z 2019-11-20 10:16:24.892 UTC [46] LOG:  database system is ready to accept connections\n2019-11-20T10:16:24.943542403Z  done\n2019-11-20T10:16:24.943591286Z server started\n2019-11-20T10:16:25.084670051Z CREATE DATABASE\n2019-11-20T10:16:25.086153670Z \n2019-11-20T10:16:25.086604000Z \n2019-11-20T10:16:25.086694058Z /usr/local/bin/docker-entrypoint.sh: ignoring /docker-entrypoint-initdb.d/*\n2019-11-20T10:16:25.086711933Z \n2019-11-20T10:16:25.088473308Z 2019-11-20 10:16:25.088 UTC [46] LOG:  received fast shutdown request\n2019-11-20T10:16:25.090893184Z waiting for server to shut down....2019-11-20 10:16:25.090 UTC [46] LOG:  aborting any active transactions\n2019-11-20T10:16:25.092499368Z 2019-11-20 10:16:25.092 UTC [46] LOG:  background worker \"logical replication launcher\" (PID 53) exited with exit code 1\n2019-11-20T10:16:25.093942785Z 2019-11-20 10:16:25.093 UTC [48] LOG:  shutting down\n2019-11-20T10:16:25.112341160Z 2019-11-20 10:16:25.112 UTC [46] LOG:  database system is shut down\n2019-11-20T10:16:25.189351710Z  done\n2019-11-20T10:16:25.189393803Z server stopped\n2019-11-20T10:16:25.189929555Z \n2019-11-20T10:16:25.189967760Z PostgreSQL init process complete; ready for start up.\n2019-11-20T10:16:25.189982340Z \n2019-11-20T10:16:25.214046388Z 2019-11-20 10:16:25.213 UTC [1] LOG:  starting PostgreSQL 12.1 (Debian 12.1-1.pgdg100+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 8.3.0-6) 8.3.0, 64-bit\n2019-11-20T10:16:25.214092434Z 2019-11-20 10:16:25.213 UTC [1] LOG:  listening on IPv4 address \"0.0.0.0\", port 5432\n2019-11-20T10:16:25.214172706Z 2019-11-20 10:16:25.214 UTC [1] LOG:  listening on IPv6 address \"::\", port 5432\n2019-11-20T10:16:25.219769380Z 2019-11-20 10:16:25.219 UTC [1] LOG:  listening on Unix socket \"/var/run/postgresql/.s.PGSQL.5432\"\n2019-11-20T10:16:25.241614800Z 2019-11-20 10:16:25.241 UTC [64] LOG:  database system was shut down at 2019-11-20 10:16:25 UTC\n2019-11-20T10:16:25.248887712Z 2019-11-20 10:16:25.248 UTC [1] LOG:  database system is ready to accept connections\n\n*********"}, {"role": "assistant", "content": "First thing, your Database container is ready to accept the connection, as you can see from the logs\n2019-11-20T10:16:25.248887712Z 2019-11-20 10:16:25.248 UTC [1] LOG:  database system is ready to accept connections\n\nThis is the expected behaviour of the offical Postgres image If you look into the entrypoint of Postgres it performs two tasks.\n\nit will run any *.sql files, run any executable *.sh scripts, and source any non-executable *.sh scripts found in that directory to do further initialization before starting the service from this directory /docker-entrypoint-initdb.d\nafter initialization completion, it stops the process and runs it again as the main process of the container.\n\n\ndo you know why I get that shutdown request?\n\n# stop postgresql server after done setting up user and running scripts\ndocker_temp_server_stop() {\n    PGUSER=\"${PGUSER:-postgres}\" \\\n    pg_ctl -D \"$PGDATA\" -m fast -w stop\n}\n\nthen after completion\n.\n.\n\n            echo 'PostgreSQL init process complete; ready for start up.'\n\n.\n.\nexec \"$@\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Is it possible to \"lock\" group of jobs across multiple gitlab pipelines\n\nI have multiple jobs working with a single external resource (Server). The first job deploys the app to the environment, the second execute tests at this environment, third execute integration tests at this environment.\nI know there is Resource group option. But it locks only jobs. If two pipelines run concurrently I need to execute job1, job2, job3 from the first pipeline, and only when the first pipeline release resource - the second pipeline can launch jobs1-3. Is there a way to achieve this? There are other jobs in the pipeline - they should work concurrently."}, {"role": "assistant", "content": "This should be possible in 13.9 by using resource_group with process mode = oldest_first. Details available at: https://docs.gitlab.com/ee/ci/resource_groups/index.html#pipeline-level-concurrency-control-with-cross-projectparent-child-pipelines"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to create tag automatically upon accepted merge request in GitLab?\n\nThis is for a repository containing a library. The library version number is incremented (manually) each time a Merge Request to master is accepted.\nHowever, if I want to access a file from version X.Y.Z, I have to look for the commit that incremented the version number to X.Y.Z, get its date, and then look in the history of the file for the version at that date.\nI would like to create a tag per version, automatically when the Merge Request to master is created. Is this possible?\nI hoped it would be possible with the new GitLab slash commands, but there currently is not support for tags.\nIs there any other possibility than using web hooks?"}, {"role": "assistant", "content": "While facing the same challenge, I stumbled upon this suggestion on GitLab's former issue tracker on GitHub1:\n\u201cYou can write up a script to use GitLab API to accept a merge request, get the commit of the merge and then tag that commit.\u201d --MadhavGitlab\n(just to mention that \u2014 for me that's not sufficient)\n\n1 EDIT:\nLooks like all issues have been purged from the GitHub mirror, so this link does no longer work, but luckily the relevant quote persists right here."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "In GitLab CI, is there a variable for a Merge Request's target branch?\n\nIn my pipeline, I'd like to have a job run only if the Merge Requests target branch is a certain branch, say master or release. \nIs this possible?\nI've read through https://docs.gitlab.com/ee/ci/variables/ and unless I missed something, I'm not seeing anything that can help."}, {"role": "assistant", "content": "Update: 2019-03-21\nGitLab has variables for merge request info since version 11.6 (https://docs.gitlab.com/ce/ci/variables/ see the variables start with CI_MERGE_REQUEST_). But, these variables are only available in merge request pipelines.(https://docs.gitlab.com/ce/ci/merge_request_pipelines/index.html)\nTo configure a CI job for merge requests, we have to set:\nonly: \n  - merge_requests\n\nAnd then we can use CI_MERGE_REQUEST_* variables in those jobs.\nThe biggest pitfall here is only: merge_request has complete different behavior from normal only/except parameters.\nusual only/except parameters:\n(https://docs.gitlab.com/ce/ci/yaml/README.html#onlyexcept-basic)\n\n\nonly defines the names of branches and tags for which the job will run.\nexcept defines the names of branches and tags for which the job will not run.\n\n\nonly: merge_request: (https://docs.gitlab.com/ce/ci/merge_request_pipelines/index.html#excluding-certain-jobs)\n\nThe behavior of the only: merge_requests parameter is such that only jobs with that parameter are run in the context of a merge request; no other jobs will be run.\n\nI felt hard to reorganize jobs to make them work like before with only: merge_request exists on any job. Thus I'm still using the one-liner in my original answer to get MR info in a CI job.\n\nOriginal answer:\nNo.\nBut GitLab have a plan for this feature in 2019 Q2: https://gitlab.com/gitlab-org/gitlab-ce/issues/23902#final-assumptions\nCurrently, we can use a workaround to achieve this. The method is as Rekovni's answer described, and it actually works.\nThere's a simple one-liner, get the target branch of an MR from the current branch:\nscript: # in any script section of gitlab-ci.yml\n  - 'CI_TARGET_BRANCH_NAME=$(curl -LsS -H \"PRIVATE-TOKEN: $AWESOME_GITLAB_API_TOKEN\" \"https://my.gitlab-instance.com/api/v4/projects/$CI_PROJECT_ID/merge_requests?source_branch=$CI_COMMIT_REF_NAME\" | jq --raw-output \".[0].target_branch\")'\n\nExplanation:\nCI_TARGET_BRANCH_NAME is a newly defined variable which stores resolved target branch name. Defining a variable is not necessary for various usage.\nAWESOME_GITLAB_API_TOKEN is the variable configured in repository's CI/CD variable config. It is a GitLab personal access token(created in User Settings) with api scope.\nAbout curl options: -L makes curl aware of HTTP redirections. -sS makes curl silent(-s) but show(-S) errors. -H specifies authority info accessing GitLab API.\nThe used API could be founded in https://docs.gitlab.com/ce/api/merge_requests.html#list-project-merge-requests. We use the source_branch attribute to figure out which MR current pipeline is running on. Thus, if a source branch has multiple MR to different target branch, you may want to change the part after | and do your own logic.\nAbout jq(https://stedolan.github.io/jq/), it's a simple CLI util to deal with JSON stuff(what GitLab API returns). You could use node -p or any method you want."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to disable auto pipelines in gitlab\n\nSince gitlab limited free tier minutes on gitlab CI/CD. I would like to disable auto start for my pipeline after commit.\nI would like to run pipeline only manually by click in gitlab interface.\nHow can I do it?"}, {"role": "assistant", "content": "You can disable the Gitlab CI/CD Pipelines in project by following steps:\n\nGo to Project's Settings >> General >> Visibility, project features, permissions\nExpand the Repository section\nEnable or Disable the CI/CD toggle\nThen, click on Save Changes\n\nYou can verify the same, the CI/CD option has been disappeared from left-hand side panel.\n\n\n\nI have now updated the answer with reference to question:\nAdding [ci skip] or [skip ci] inside the commit message will not trigger a pipeline on push.\nMore reference: https://docs.gitlab.com/ee/ci/yaml/#skip-pipeline"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Error: before_script config should be an array of strings\n\nGitLab : \n\n.gitlab-ci.yml syntax error\n\ndocker exec -i XXX pip3 install -r ./requirements_os_specific.txt --target=./packages --platform=manylinux1_x86_64 --only-binary=:all:\n\nthis command giving a syntax error . \n\n\"Error: before_script config should be an array of strings\"\n\nThis work fine if I remove \"--only-binary=:all:\"\nvariables :    IMAGE_NAME: xxx   \n\nbefore_script:\n  - whoami\n  - echo $GitLabPassword\n  - docker login -u Prasenjit.Chowdhury -p $GitLabPassword xxxxxxx\n  - docker -v\n  - docker exec -i abc python -V\n  - docker exec -i abc aws --version\n  - docker exec -i abc pip3 install -r ./requirements_os_specific.txt --target=./packages --platform=manylinux1_x86_64 --only-binary=:all:\n\n:\nThis script works fine if I remove the last line"}, {"role": "assistant", "content": "You have to escape a colon : in yaml. This can be done by surrounding the whole entry with quotes \".\nReplace:\n- docker exec -i abc pip3 install -r ./requirements_os_specific.txt --target=./packages --platform=manylinux1_x86_64 --only-binary=:all:\n\nwith:\n- \"docker exec -i abc pip3 install -r ./requirements_os_specific.txt --target=./packages --platform=manylinux1_x86_64 --only-binary=:all:\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to color text in Markdown/GitLab\n\nI'm trying color text in markdown. In editor preview all looks good, but when I push it to a GitLab repository the text is not colored. How can I color text?\nIn his beard lived three <span style=\"color:red\">cardinals</span>."}, {"role": "assistant", "content": "You could try this it seems that Gitlab renders it pretty nice, hope it helps:\n$`\\textcolor{red}{\\text{your text}}`$ \n$`\\textcolor{blue}{\\text{your text}}`$ \n$`\\textcolor{green}{\\text{your text}}`$ \n\nAlso there's diff fence:\n```diff\n- RED text\n+ GREEN text\n! ORANGE text\n# GRAY text\n```"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How can I delete group in gitlab?\n\nIn our organisation we recently moving to git, I have created a group accidentally I would be appreciate if there is a way to delete this group."}, {"role": "assistant", "content": "In the most recent version (Mar. 2019):\n\nAt top bar, click on Groups.\nType part of the name of the desired group or click on Explore Groups. Click on the desired group.\nGo to Settings > General\nExpand Path, transfer, remove\nAt the bottom of page you find Remove group. Click on the button and type the name of the group to activate Confirm button. Then click on Confirm to delete the group."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI and MsBuild (with tests)\n\nI am in the process of migrating my svn repsitories to git with GitLab.\nNow I have seen that there is a continuous integration implementation with GitLab CI and just want to try it out.\nI already installed and configured a Runner but Gitlab complains that I don't have a .gitlab-ci.yml file.\nI already use TeamCity for continuous integration so I don't want to put too much effort into writing a build script.\nCan anybody tell me where I can find a basic example of a gitlab-ci.yml file that basically just builds my Solution and runs all tests (MSTests)?"}, {"role": "assistant", "content": "Apparently there is no simple msbuild example but this should get you started:\nvariables:\n  Solution: MySolution.sln\n\nbefore_script:\n  - \"echo off\"\n  - 'call \"%VS120COMNTOOLS%\\vsvars32.bat\"'\n  # output environment variables (usefull for debugging, propably not what you want to do if your ci server is public)\n  - echo.\n  - set\n  - echo.\n\nstages:\n  - build\n  - test\n  - deploy\n\nbuild:\n  stage: build\n  script:\n  - echo building...\n  - 'msbuild.exe \"%Solution%\"'\n  except:\n  - tags\n\ntest:\n  stage: test\n  script:\n  - echo testing...\n  - 'msbuild.exe \"%Solution%\"'\n  - dir /s /b *.Tests.dll | findstr /r Tests\\\\*\\\\bin\\\\ > testcontainers.txt\n  - 'for /f %%f in (testcontainers.txt) do mstest.exe /testcontainer:\"%%f\"'\n  except:\n  - tags\n\ndeploy:\n  stage: deploy\n  script:\n  - echo deploying...\n  - 'msbuild.exe \"%Solution%\" /t:publish'\n  only:\n  - production\n\nFiguring out which tests to run is a bit tricky. My convention is that every project has a folder tests in which the test projects are named after the schema MyProject.Core.Tests (for a project called MyProject.Core) \nJust as a first feedback towards gitlab-ci\nI like the simplicity and the source control integration. But I would like to be able to modify the script before execution (especially while changing the script) but I could imaging to rerun a specific commit and inject variables or change the script (I can do that with teamcity). Or even ignore a failed test and rerun the script again (I do that a lot with teamcity). I know gitlab-ci does not know anything about my tests I just have a command line that returns an error code."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI preserve environment between build stages\n\nI am working on a python project and using miniconda to manage my environment. I am using GitLab for CI with the following runner configuration\nstages:\n  - build\n  - test \n\nbuild:\n  stage: build\n  script:\n    - if hash $HOME/miniconda/bin/conda 2>/dev/null; \n      then\n         export PATH=\"$HOME/miniconda/bin:$PATH\";\n      else\n        wget http://repo.continuum.io/miniconda/Miniconda-latest-Linux-x86_64.sh -O miniconda.sh;\n        bash miniconda.sh -b -p $HOME/miniconda;\n        export PATH=\"$HOME/miniconda/bin:$PATH\";\n      fi\n    - conda update --yes conda\n\ntest:\n  stage: test\n  script:\n    - conda env create --quiet --force --file environment.yml\n    - source activate myenv\n    - nosetests --with-coverage --cover-erase --cover-package=mypackage --cover-html\n    - pylint --reports=n tests/test_final.py\n    - pep8 tests/test_final.py\n    - grep pc_cov cover/index.html | egrep -o \"[0-9]+\\%\" | awk '{ print \"covered \" $1;}'\n\nI assumed (incorrectly) that my build stage would setup the correct environment in which I could run my test stage. Looking at this question and this GitLab issue I see that \n\neach job defined in .gitlab-ci.yml is run as separate build (where we\n  assume that there's no history)\n\nBut the alternative of lumping everything together in one stage isn't appealing\nstages:\n  - test \n\ntest:\n  stage: test\n  script:\n    - if hash $HOME/miniconda/bin/conda 2>/dev/null; \n      then\n         export PATH=\"$HOME/miniconda/bin:$PATH\";\n      else\n        wget http://repo.continuum.io/miniconda/Miniconda-latest-Linux-x86_64.sh -O miniconda.sh;\n        bash miniconda.sh -b -p $HOME/miniconda;\n        export PATH=\"$HOME/miniconda/bin:$PATH\";\n      fi\n    - conda update --yes conda\n    - conda env create --quiet --force --file environment.yml\n    - source activate myenv\n    - nosetests --with-coverage --cover-erase --cover-package=mypackage --cover-html\n    - pylint --reports=n tests/test_final.py\n    - pep8 tests/test_final.py\n    - grep pc_cov cover/index.html | egrep -o \"[0-9]+\\%\" | awk '{ print \"covered \" $1;}'\n\nThe only other option I can think of is to put the environment creation steps in a before_script stage, but it seems redundant to continuously recreate the same environment before each stage."}, {"role": "assistant", "content": "The independence of the jobs is a design feature. You might have noticed that GitLab's interface allows you to re-run a single job which wouldn't be possible if the jobs depended on each other.\nI don't know what Miniconda exactly performs but if it builds a virtual environment in specific folders, you can use cache to preserve the content of those folders between the jobs. However, you cannot fully rely on it because the documentation states that...\n\nThe cache is provided on a best-effort basis, so don't expect that the\n  cache will be always present. For implementation details, please check\n  GitLab Runner.\n\nConsidering that your job absolutely depends on the environment being built, you would need a mechanism to detect whether the (cached) environment exists and re-create it only if needed.\nI think you are taking good path trying to separate the environment setup and the jobs because it might save lots of time in case you decide one day to run different tests simultaneously (jobs at the same stage run in parallel)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to prevent git commit --no-verify command?\n\nI would like to setup a pre-commit hook for all git repos to validate syntax errors using jshint and phplint. But the issue is that the git has a feature which can skip pre-commit hook from happening by using --no-verify flag. But i don't need to use that option. Can i prevent that --no-verify flag for git Please suggest a way."}, {"role": "assistant", "content": "First off: you can't definitively prevent someone from passing the --no-verify option.  That said, it's a good practice to use pre-commit hooks for linting, and it's a good practice to avoid passing the --no-verify option without reason.\nIf, however, you want to make it more cumbersome to pass the --no-verify option, you could:\n\ngenerate a verification token and append it to the commit message in pre-commit;\nexit pre-receive with a non-zero exitcode if this token is missing or invalid.  (Examples of things you can do in pre-receive hooks: https://github.com/github/platform-samples/tree/master/pre-receive-hooks)\n\nSomeone determined to avoid passing --no-verify could manually do step 1, which is why this isn't 100% effective.  I wouldn't recommend setting this up in a professional context, but I'm all for people using the tools at their disposal to instill good habits for themselves, while learning more about git hooks."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How can I understand the role of \"/bin/true\" command in \"docker run ...\" command?\n\nI am following this document to install gitlab docker image, and get confused with the command:  \ndocker run --name gitlab_data genezys/gitlab:7.5.2 /bin/true\n\nI know \"/bin/true\" command just returns a success status code, but how can I understand the role of /bin/true in this docker run ... command?"}, {"role": "assistant", "content": "Running and thus creating a new container even if it terminates still keeps the resulting container image and metadata lying around which can still be linked to.\nSo when you run docker run ... /bin/true you are essentially creating a new container for storage purposes and running the simplest thing you can.\nIn Docker 1.5 was introduced the docker create command so I believe you can now \"create\" containers without confusingly running something like /bin/true\nSee: docker create\nThis is new method of managing data volume containers is also clearly documented in the section Creating and mounting a Data Volume Container"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do you push to a gitlab repo using a gitlab-ci job?\n\nI am new to GitLab CI/CD jobs, but I'm trying to set up a Python script that when pushed to GitLab, triggers the CI/CD job to run it, and call an internal function that pushes to GitLab again provided that certain criteria are met. So, for example, suppose I have the following:\ndef hasFileInDirectory():\n    # checks if the current directory has at least 1 other file in it\n    if (1 or more files exist):\n        print 'Great! You have enough files!';\n    else:\n        print 'Oh no! You need more files! Let me create one!';\n        createFile('missingFile'+str(random.randint(0,1000000)+'.txt');\n        os.system('git add -A');\n        os.system('git commit -m \"Automatically added new file...\"');\n        os.system('git push origin HEAD:master --force');\n\nThis function seems to run perfectly fine if I run it myself from the command line, however, it seems to not be able to run in the GitLab CI/CD job. The output I am getting is:\nremote: You are not allowed to upload code.\nfatal: unable to access 'https://gitlab-ci-token:[email\u00a0protected]/path_to/my_repository.git/': The requested URL returned error: 403\n\nThis error occurs when I call git push so I was wondering what I could do to fix this. I would really appreciate any help!"}, {"role": "assistant", "content": "A GitLab CI runner cannot yet push to a repo: there is a proposal in progress here.\nIn the meantime, you can use an SSH URL, with:\n\nAn SSH private key is defined as a secret variable through the Settings > CI/CD Pipelines web interface in GitLab, and\nthe public part of the SSH key is stored as a deployment key Settings > Repository > Deploy Keys section of the same web UI.\n\nOr, as mentioned here, you can use a \u201cpersonal access token\u201d in Settings of your profile.\n\nI created a token with scope api and configure in my pipeline.\nOpen the project in gitlab console, go to Settings > CI/CD > Secret variables, create a variable with value the key (generated in profile).\nI replace \u201c${CI_JOB_TOKEN}\u201d to my variable \u201c${VAR01}\u201d.\n\nWith a gitlab-ci.yml\n\nscript:\n\n\n   - url_host=`git remote get-url origin | sed -e \"s/https:\\/\\/gitlab-ci-token:.*@//g\"`\n   - git remote set-url origin \"https://gitlab-ci-token:${CI_TAG_UPLOAD_TOKEN}@${url_host}\"\n\nCI_TAG_UPLOAD_TOKEN is the Secret variable"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Storing secrets and credentials securely in GitLab\n\nI am wondering if it's possible to store credentials like passwords, tokens and keys safely in my GitLab project.\nCurrently there are a bunch of Java files with some passwords stored in it for testing purposes. However, I don't want to push this information on my repo due to security reasons. I tried using environment variables in the project, but they only seem to work for the .gitlab-ci.yml file.\nMy question is does anyone use a vault like Hashicorps or Blackbox to encrypt sensitive information?\nThanks"}, {"role": "assistant", "content": "If you are not using environment variables in GitLab, then you are asking if it is possible to store secrets in GitLab. I have not done this myself, but I found this post about it:\nhttps://embeddedartistry.com/blog/2018/03/15/safely-storing-secrets-in-git/\nThe author suggests three ways of storing secrets in git:\n\nBlackbox\ngit-secret\ngit-crypt\n\nThe author was using BlackBox, but was going to migrate to git-crypt. From a quick look at it, git-crypt looks like something that I could use myself."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "SourceTree always Permission denied (publickey)\n\ni use soureTree for clone ssh project.\n\ni've already created ssh key\ni've already set up gitlab ssh key setting\ni've ssh-add \"mysshkey\"\ni've ssh-add -K 'mysshkey'\n\nwhen i print ssh -T ,i can make it success in the command line.\nwhen i git clone, pull ,push in ssh ways...It still works in the command line.(terminal)\nbut in sourcetree still get error now:\nPermission denied (publickey)\n\nhow can i solve it?"}, {"role": "assistant", "content": "I downloaded SourceTree 2.7.6 and encountered same problem.\nI think @Frankie_0927 are right, private key must be named id_rsa and must be registered in ssh agent.\nfor other people encountered this problem: \ntry generate a pair of key following the instructions in below link:\nhttps://help.github.com/articles/connecting-to-github-with-ssh/\nstore the private key id_rsa in ~/user/YOURUSERNAME/.ssh (path for mac) and post public key in github account.\nthen run \nssh-add -l\n\nyou will see \nThe agent has no identities.\n\nso you run \nssh-add -K ~/.ssh/id_rsa\n\nto add the key into ssh agent.\nafter this, run\nssh-add -l\n\nagain, you will see the key is added and the problem should be solved."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Unable to access GitLab: SSL certificate has expired\n\nIn Visual Studio, I'm trying to pull some changes from the repository on GitLab, but it gives me an error:\n\nGit failed with a fatal error.\nunable to access https://gitlab...git/: SSL certificate problem: certificate has expired*\n\nHow can I generate a new certificate and add it to VS? I don't have any experience with GitLab."}, {"role": "assistant", "content": "There's a quick fix you can run in the command line:\ngit config --global http.sslVerify \"false\"\n\nThe solution was found in the following article.\nUpdated:\nWhile the original solution provided a quick workaround, it's essential to emphasize the security implications and responsible usage due to the concerns raised in the comments.\nWarning: The below quick fix can expose you to security risks by disabling SSL verification:\ngit config --global http.sslVerify \"false\" \n\nUse this solution with utmost caution and strictly for troubleshooting purposes.\nA Safer Alternative:\n\nUpdate Git: Ensure you are using the latest version of Git which might have improved handling of SSL and certificate issues.\n\nFor Windows\ndownload and install from the official website \n\nFor macOS (using Homebrew):\nbrew upgrade git\n\nFor Debian-based Linux distributions:\nsudo apt-get update && sudo apt-get upgrade git \n\n2. Verify Certificate:\nIdentify why the certificate has expired and engage the repository\nadministrator or IT department for a resolution, as managing and\nrenewing certificates is typically their responsibility.\nUsing the Quick Fix Responsibly:\nIf you find yourself obliged to use the quick fix:\n\nLocal Environment Only:\n\nEnsure it is applied only in a secure and controlled environment. Never in a production setting.\n\nLimited Time:\n\nRe-enable SSL verification as soon as possible by running\ngit config --global http.sslVerify \"true\"\n\nAdditional Notes:\n\nQuality vs. Security:\n\nAs commented by Eric K, having a valid SSL certificate doesn\u2019t equate to the safety of the code you pull. Always ensure code quality and integrity.\n\nEngage Experts:\n\nIf unsure, consult your IT department or cybersecurity experts regarding expired certificates and any temporary workarounds.\nConclusion:\nSecurity should always be paramount. Adopt solutions that not only solve the immediate problem but also uphold the integrity and security of your development environment and code."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Code block in spoiler with markdown\n\nIs there any way in markdown to combine the code (inside ```) with the spoiler (after !>) syntax in order to obtain some code inside a spoiler ?\nI'm using the markdown implemented in GitLab."}, {"role": "assistant", "content": "https://docs.gitlab.com/ee/user/markdown.html#details-and-summary\nYou can use raw HTML\n<p>\n<details>\n<summary>Click this to collapse/fold.</summary>\n\nThese details <em>remain</em> <strong>hidden</strong> until expanded.\n\n<pre><code>PASTE LOGS HERE</code></pre>\n\n</details>\n</p>\n\nor now GitLab supports Markdown within <details> blocks\n<details>\n<summary>Click this to collapse/fold.</summary>\n\nThese details _remain_ **hidden** until expanded.\n\n```\nPASTE LOGS HERE\n```\n\n</details>"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Is it possible to use pip to install a package over ssh in a self-hosted gitlab?\n\nI have a self-hosted gitlab and I would like to install a package hosted there using ssh.\nI tried:\npip install git+ssh://git@<my_domain>:se7entyse7en/<project_name>.git\n\nHere's the output:\nDownloading/unpacking git+ssh://git@<my_domain>:se7entyse7en/<project_name>.git\nCloning ssh://git@<my_domain>:se7entyse7en/<project_name>.git to /var/folders/3r/v7swlvdn2p7_wyh9wj90td2m0000gn/T/pip-4_JdRU-build\nssh: Could not resolve hostname <my_domain>:se7entyse7en: nodename nor servname provided, or not known\nfatal: Could not read from remote repository.\n\nPlease make sure you have the correct access rights and the repository exists.\n\nUpdate:\nI tried to upload it on gitlab.com and after having uploaded the repo I tried to install it by running:\npip install git+ssh://[email\u00a0protected]:loumarvincaraig/<project_name>.git\n\nbut the nothing changed. In particular here's the content of pip.log:\n\n/Users/se7entyse7en/Envs/test/bin/pip run on Mon Nov 17 22:14:51 2014\nDownloading/unpacking git+ssh://[email\u00a0protected]:loumarvincaraig/<project_name>.git\n\nCloning ssh://[email\u00a0protected]:loumarvincaraig/<project_name>.git to /var/folders/3r/v7swlvdn2p7_wyh9wj90td2m0000gn/T/pip-91JVFi-build\n\nFound command 'git' at '/usr/local/bin/git'\nRunning command /usr/local/bin/git clone -q ssh://[email\u00a0protected]:loumarvincaraig/<project_name>.git /var/folders/3r/v7swlvdn2p7_wyh9wj90td2m0000gn/T/pip-91JVFi-build\nComplete output from command /usr/local/bin/git clone -q ssh://[email\u00a0protected]:loumarvincaraig/<project_name>.git /var/folders/3r/v7swlvdn2p7_wyh9wj90td2m0000gn/T/pip-91JVFi-build:\n\n\nCleaning up...\n\nCommand /usr/local/bin/git clone -q ssh://[email\u00a0protected]:loumarvincaraig/<project_name>.git /var/folders/3r/v7swlvdn2p7_wyh9wj90td2m0000gn/T/pip-91JVFi-build failed with error code 128 in None\n\nException information:\nTraceback (most recent call last):\nFile \"/Users/se7entyse7en/Envs/test/lib/python2.7/site-packages/pip/basecommand.py\", line 134, in main\nstatus = self.run(options, args)\nFile \"/Users/se7entyse7en/Envs/test/lib/python2.7/site-packages/pip/commands/install.py\", line 236, in run\nrequirement_set.prepare_files(finder, force_root_egg_info=self.bundle, bundle=self.bundle)\nFile \"/Users/se7entyse7en/Envs/test/lib/python2.7/site-packages/pip/req.py\", line 1092, in prepare_files\nself.unpack_url(url, location, self.is_download)\nFile \"/Users/se7entyse7en/Envs/test/lib/python2.7/site-packages/pip/req.py\", line 1231, in unpack_url\nreturn unpack_vcs_link(link, loc, only_download)\nFile \"/Users/se7entyse7en/Envs/test/lib/python2.7/site-packages/pip/download.py\", line 410, in unpack_vcs_link\nvcs_backend.unpack(location)\nFile \"/Users/se7entyse7en/Envs/test/lib/python2.7/site-packages/pip/vcs/__init__.py\", line 240, in unpack\nself.obtain(location)\nFile \"/Users/se7entyse7en/Envs/test/lib/python2.7/site-packages/pip/vcs/git.py\", line 111, in obtain\ncall_subprocess([self.cmd, 'clone', '-q', url, dest])\nFile \"/Users/se7entyse7en/Envs/test/lib/python2.7/site-packages/pip/util.py\", line 670, in call_subprocess\n% (command_desc, proc.returncode, cwd))\nInstallationError: Command /usr/local/bin/git clone -q ssh://[email\u00a0protected]:loumarvincaraig/<project_name>.git /var/folders/3r/v7swlvdn2p7_wyh9wj90td2m0000gn/T/pip-91JVFi-build failed with error code 128 in None"}, {"role": "assistant", "content": "I don't know why, but by running the following command it worked (slash instead of : after <my_domain>):\npip install git+ssh://git@<my_domain>/se7entyse7en/<project_name>.git\n#                                    ^\n#                             slash instead of :"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Using a private Docker Image from Gitlab Registry as the base image for CI\n\nHow should I authenticate if I want to use an image from the Gitlab Registry as a base image of another CI build?\nAccording to https://gitlab.com/gitlab-org/gitlab-ci-multi-runner/blob/master/docs/configuration/advanced-configuration.md#using-a-private-docker-registry I first have to manually login on the runner machine. Somehow it feels strange to login with an existing Gitlab user. \nIs there a way to use the CI variable \"CI_BUILD_TOKEN\" (which is described as \"Token used for authenticating with the GitLab Container Registry\") for authentication to pull the base image from Gitlab Registry?\nEDIT: I found out that I can use images from public projects. But I don't really want to make my docker projects public.\nUPDATE: Starting with Gitlab 8.14 you can just use the docker images from the build in docker registry. See https://gitlab.com/gitlab-org/gitlab-ci-multi-runner/blob/master/docs/configuration/advanced-configuration.md#support-for-gitlab-integrated-registry"}, {"role": "assistant", "content": "All of the above answers including the acepted one are deprecated, This is possible in 2021:\nhttps://docs.gitlab.com/ee/ci/docker/using_docker_images.html#access-an-image-from-a-private-container-registry\n\nTL;DR\nSet the CI/CD variable DOCKER_AUTH_CONFIG value with appropriate authentication information in following format:\nStep 1:\n# The use of \"-n\" - prevents encoding a newline in the password.\necho -n \"my_username:my_password\" | base64\n\n# Example output to copy\nbXlfdXNlcm5hbWU6bXlfcGFzc3dvcmQ=\n\nStep 2 (This JSON is the value to be set for DOCKER_AUTH_CONFIG variable):\n{\n    \"auths\": {\n        \"registry.example.com:5000\": {\n            \"auth\": \"(Base64 content from above)\"\n        }\n    }\n}"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Trigger Gitlab-CI Pipeline only when there is a new tag\n\nI have following gitlab-ci conf. file:\nbefore_script:\n  - echo %CI_BUILD_REF%\n  - echo %CI_PROJECT_DIR%\n\nstages:\n  - createPBLs\n  - build\n  - package\n\n\ncreate PBLs:\n  stage: createPBLs\n  script: \n    - xcopy /y /s \"%CI_PROJECT_DIR%\" \"C:\\Bauen\\\"\n    - cd \"C:\\Bauen\\\"\n    - ./run_orcascript.cmd\n\n\nbuild:\n  stage: build\n  script:\n  - cd \"C:\\Bauen\\\"\n  - ./run_pbc.cmd\n  except:\n  - master\n\nbuild_master:\n  stage: build\n  script:\n  - cd \"C:\\Bauen\\\"\n  - ./run_pbcm.cmd\n  only:\n  - master\n\npackage:\n  stage: package\n  script:\n  - cd \"C:\\Bauen\\\"\n  - ./cpfiles.cmd\n  artifacts:\n    expire_in: 1 week\n    name: \"%CI_COMMIT_REF_NAME%\"\n    paths:\n      - GitLab-Build\n\nHow can I add the rule that the pipeline will ONLY trigger if a new tag has been added to a branch? The tag should start with \"Ticket/ticket_\"\nCurrently he is building for every push."}, {"role": "assistant", "content": "You need to use only syntax:\nonly:\n  - tags\n\nThis would trigger for any Tag being pushed. If you want to be a bit more specific you can do:\nonly:\n  - /Ticket\\/ticket\\_.*/\n\nwhich would build for any push with the Ticket/ticket_ tag."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is the correct usage of cache/artifacts in Gitlab CI?\n\nI am facing an issue when cached files are not used in project builds. In my case, I want to download composer dependencies in build stage and then add them into final project folder after all other stages succeeds. I thought that if you set cache attribute into .gitlab-ci.yml file, it will be shared and used in other stages as well. But this sometime works and sometimes not.\nGitlab version is 9.5.4\nHere is my .gitlab-ci.yml file:\nimage: ponk/debian:jessie-ssh\n\nvariables:\n    WEBSERVER: \"[email\u00a0protected]\"\n    WEBSERVER_DEPLOY_DIR: \"/domains/example.com/web-presentation/deploy/\"\n    WEBSERVER_CDN_DIR: \"/domains/example.com/web-presentation/cdn/\"\n    TEST_VENDOR: '[ \"$(ls -A ${WEBSERVER_DEPLOY_DIR}${CI_COMMIT_REF_NAME}/${CI_COMMIT_SHA}/vendor)\" ]'\n\ncache:\n  key: $CI_PIPELINE_ID\n  untracked: true\n  paths:\n    - vendor/\n\nbefore_script:\n\n\nstages:\n    - build\n    - tests\n    - deploy\n    - post-deploy\n\nBuild sources:\n    image: ponk/php5.6\n    stage: build\n    script:\n        # Install composer dependencies\n        - composer -n install --no-progress\n    only:\n        - tags\n        - staging\n\n\nDeploy to Webserver:\n    stage: deploy\n    script:\n        - echo \"DEPLOYING TO ... ${WEBSERVER_DEPLOY_DIR}${CI_COMMIT_REF_NAME}/${CI_COMMIT_SHA}\"\n        - ssh $WEBSERVER mkdir -p ${WEBSERVER_DEPLOY_DIR}${CI_COMMIT_REF_NAME}/${CI_COMMIT_SHA}\n        - rsync -rzha app bin vendor www .htaccess ${WEBSERVER}:${WEBSERVER_DEPLOY_DIR}${CI_COMMIT_REF_NAME}/${CI_COMMIT_SHA}\n        - ssh $WEBSERVER '${TEST_VENDOR} && echo \"vendor is not empty, build seems ok\" || exit 1'\n        - ssh $WEBSERVER [ -f ${WEBSERVER_DEPLOY_DIR}${CI_COMMIT_REF_NAME}/${CI_COMMIT_SHA}/vendor/autoload.php ] && echo \"vendor/autoload.php exists, build seems ok\" || exit 1\n        - echo \"DEPLOYED\"\n    only:\n        - tags\n        - staging\n\nPost Deploy Link PRODUCTION to Webserver:\n    stage: post-deploy\n    script:\n        - echo \"BINDING PRODUCTION\"\n        - ssh $WEBSERVER unlink ${WEBSERVER_DEPLOY_DIR}production-latest || true\n        - ssh $WEBSERVER ln -s ${WEBSERVER_DEPLOY_DIR}${CI_COMMIT_REF_NAME}/${CI_COMMIT_SHA} ${WEBSERVER_DEPLOY_DIR}production-latest\n        - echo \"BOUNDED  $CI_COMMIT_SHA -> production-latest\"\n        - ssh $WEBSERVER sudo service php5.6-fpm reload\n    environment:\n        name: production\n        url: http://www.example.com\n    only:\n        - tags\n\nPost Deploy Link STAGING to Webserver:\n    stage: post-deploy\n    script:\n        - echo \"BINDING STAGING\"\n        - ssh $WEBSERVER unlink ${WEBSERVER_DEPLOY_DIR}staging-latest || true\n        - ssh $WEBSERVER ln -s ${WEBSERVER_DEPLOY_DIR}${CI_COMMIT_REF_NAME}/${CI_COMMIT_SHA} ${WEBSERVER_DEPLOY_DIR}staging-latest\n        - echo \"BOUNDED  ${CI_COMMIT_SHA} -> staging-latest\"\n        - ssh $WEBSERVER sudo service php5.6-fpm reload\n    environment:\n        name: staging\n        url: http://staging.example.com\n    only:\n        - staging\n\nIn Gitlab documentation it says: cache is used to specify a list of files and directories which should be cached between jobs.\nFrom what I understand I've set up cache correctly - I have untracked set to true, path includes vendor folder and key is set to Pipeline ID, which should be the same in other stages as well.\nI've seen some set ups which contained Artifacts, but unless you use it with Dependencies, it shouldn't have any effect.\nI don't know what I'm doing wrong. I need to download composer dependencies first, so I can copy them via rsync in next stage. Do you have any ideas/solutions? Thanks"}, {"role": "assistant", "content": "Artifacts should be used to permanently make available any files you may need at the end of a pipeline, for example generated binaries, required files for the next stage of the pipeline, coverage reports or maybe even a disk image. But cache should be used to speed up the build process, for example if you compiling a C/C++ binary it usually takes a long time for the first build but subsequent builds are usually faster because it doesn't start from scratch, so if you were to store the temporary files made by the compiler by using cache, it would speed up the compilation across different pipelines. \nSo to answer you, you should use artifacts because you seem to need to run composer every pipeline but want to pass on the files to the next job. You do not need to explicitly define dependencies in your gitlab-ci.yml because if not defined each job pulls all the artifacts from all previous jobs. Cache should work but it is unreliable and is better for a config where it makes it better but is not a necessity."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to configure git hooks for all developers\n\nI want to apply consistent commit message rule globally for all developers to have jira issue in commit message.\nUsing enterprise github.\nAs found, it can be achieve using, .git/hooks/commit-msg file to updated accordingly.\nIssue: How to apply this updated git hooks to available for all the developers.\nI don't see any changes appear on git status.\nNot sure if it has to configure different way so, commit-msg constrain will apply for all developers instead of locally one.\nCan you please guide on this."}, {"role": "assistant", "content": "Any files in .git/hooks are not part of the repository and will not be transmitted by any push or fetch operation (including the fetch run by git pull).  The reason is simple enough; see below.  By the same token, a developer who has a Git repository has full control over his/her/their .git/hooks directory and whether any pre-commit and commit-msg hook is run (git commit --no-verify will skip both of these hooks).\nWhat all this means is that you cannot force a developer to use any particular pre-commit or commit-msg hook.  Instead of making this happen (which you can't do), you should do what you can to make it easy for your developers to use some hook(s) that you supply.  There are many ways to achieve this.  In the examples below I'll mention pre-commit hooks rather than commit-msg hooks.\nOne very simple one is to have a script that you write as a setup command that:\n\nclones the repository or repositories developers should use; then\nadds to those clones the hooks that you'd like them to use.\n\nIf the clones already exist, this command can simply update the hooks in place, so that your developers can just run the setup script again if the hooks have changed.\nAnother is to have a script in the repository that installs symbolic links, so that .git/hooks/pre-commit becomes a symbolic link to ../../scripts/pre-commit.  This path climbs back out of hooks and then .git and then reaches into scripts/pre-commit, which means that the script in scripts/pre-commit is the one that will be run.  You can of course use different names, e.g., make .git/hooks/pre-commit a symlink to ../../.git-precommit, if you like.  This method does of course require that your developers' systems support symbolic links.\nYour scripts, whether they're all in the repository itself or in some separate repository or whatever, can be as simple or as fancy as you like, and you can write them in any language that you like.  This applies both to \"install some hooks\" scripts, and to the hooks themselves.  The only constraint is that the hooks must be able to run on the developers' machines.  Note that there are entire frameworks for Git hooks, such as Husky and the various options on pre-commit.com.\nOne small warning: it's easy to go overboard here.  I'll recommend that anyone contemplating setting up fancy hooks have a look at this blog post for instance.  Your check on commit messages is an example of not going overboard: it's simple and fast and does not get in anyone's way.\nWhy hooks are not copied\nImagine if git clone did copy and install hooks.  Then imagine that the hook in some repository includes this bit of pseudo shell script in, say, the post-checkout hook:\nif [ ! -x /tmp/trojan-horse ]; then\n    install-trojan-horse &\nfi\n\nAs soon as you clone this repository, boom, you've been pwned."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to disable 'detached' pipelines in Gitlab?\n\nWe have a normal repository, with some code and tests.\nOne job has 'rules' statement:\n  rules:\n    - changes:\n      - foo/**/*\n      - foo_scenarios/**/*\n      - .gitlab-ci.yml\n\nThe problem is that presence of rules causes Gitlab to run 'detached pipeline', which wasn't my intention, and it's annoying. Is there any way to disable those 'detached' pipelines, but keep the rules section in place?"}, {"role": "assistant", "content": "rules:\n    - if: '$CI_PIPELINE_SOURCE == \"merge_request_event\"'\n      when: never\n    - changes:\n      - foo/**/*\n      - foo_scenarios/**/*\n      - .gitlab-ci.yml\n      when: always\n\nI have not tested this, but I believe this is what you are looking for. This page and this one too are both easily navigable and are very helpful for finding the answer to basic gitlab-ci.yml questions.\nEdit- Gitlab will evaluate the rules in order, and it stops evaluating subsequent rules as soon as one of the conditions are met. In this case, it will evaluate if: '$CI_PIPELINE_SOURCE == \"merge_request_event\"' first, and if it evaluates to true, no more rules will be checked. If the first rule evaluates to false, it will move on to the next rule."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab where is config.toml\n\nIm working on adding code quality to gitlab.\none of the step requires making changes to config.toml.\nI have .gitlab-ci.yml at root level of project repository.and pipeline picks up this file.\nwhere do i define config.toml ? at root level or i need to create a new folder like\n/etc/gitlab-runner/config.toml"}, {"role": "assistant", "content": "The config.toml file is what configures a runner. You wouldn't have one unless you're running your own gitlab-runners, in which case it would be in /etc/gitlab-runner/config.toml on the host running the runner. More information on Gitlab Runner and running it yourself is available here."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to create a default branch in GitLab?\n\nI am not able to push code to GitLab for the first time. \nI have created a Gitlab project on the web interface.\nI have created an ASP MVC project.\nI did \"git init\" in that directory.\nI added remote origin.\nI added and committed the changes and then, when I want to push the changes to remote I get the following error:\nremote: A default branch (e.g. master) does not yet exist for\n...\nremote: Ask a project Owner or Maintainer to create a default branch:\n...\nerror: failed to push some refs to\n\nSo I want to know if I can create a branch with the role Developer?\nIf yes how to create a default branch?\nIf no, what should my next steps be?"}, {"role": "assistant", "content": "This is followed by issue 54155\n\nIt seems as though 'developer' should not be able to create projects if it does not have permission to then populate that project without asking an admin to intervene.\nI don't understand, why I have enough permissions to create a project, but not to make it ready enough so I can push into it, and need to use another persons time in my organization to get ready to work.\nIMHO it would be logical to either allow users with status developer to create a project in a way that it's ready to push code to - or just don't let developers create a project and tell them they have to ask a maintainer or owner.\n\nIssue 51688 mentions:\n\nThen I have to login with gitlab admin admin...Aggregate access to user test to test6.git as a dev or maintainer... and finally I can make push... But if user test creates another repo, I have to repeat all these steps again....\nMaintainer can create new branch. Please use maintainer account to push the new project.\nBut it doesn't make sense that a user has permissions to create empty repositories but not initialize a default branch or push to their newly created repository."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab issuing temporary IP bans - 403 forbidden\n\nMy GitLab instance setup will occasionally put in place an IP ban on our own IP address, resulting in all our users in the office getting 403 / Forbidden on any web page or git request.\nThe ban is being put in place as a result of repeated errors authenticating, which is a separate problem altogether, but I would like to prevent our own IP address from being IP banned. It lasts for about one hour.\nIn the nginx logs, nothing unusual pops up in the gitlab_access.log or gitlab_error.log files. The server is still running, and external IP addresses are unaffected while the ban is in place.\nI would like to be able to whitelist our own IP address, or to be able to disable the ban once it occurs (restarting gitlab doesn't remove the ban). If neither of these are possible, then just finding the setting to tweak the ban duration down from one hour would be OK too."}, {"role": "assistant", "content": "We are running Gitlab EE and for us this issue was caused by a combination of using git lfs inside a build on a Gitlab CI runner, and having installed the rack-attack gem on the Gitlab server.\nBackground\nIn order to work around an issue with git-lfs 1.2.1 (where it insisted on requiring username and password despite cloning a public repository), the build contained this line:\ngit clone https://fakeuser:[email\u00a0protected]/group/repo.git\n\nOn build, this resulted in every LFS request from the runner triggering a login attempt with fakeuser, which obviously failed every time. However, since no login was actually required by the server, the client could continue downloading the files using LFS, and the build passed.\nIssue\nThe IP banning started when the package rack-attack was installed. By default, after 10 failed login attempts, rack-attack bans the origin IP for one hour. This resulted in all runners being completely blocked from Gitlab (even visiting the web page from the runner would return 403 Forbidden).\nWorkaround (insecure)\nA short-term workaround, if the servers (Gitlab runners in our case) are trusted, is to add the servers' IPs to a whitelist in the rack-attack configuration. Adjusting the ban time, or allowing more failed attempts, is also possible.\nExample configuration in /etc/gitlab/gitlab.rb:\ngitlab_rails['rack_attack_git_basic_auth'] = {\n  'enabled' => true,\n  'ip_whitelist' => [\"192.168.123.123\", \"192.168.123.124\"],\n  'maxretry' => 10,\n  'findtime' => 60,\n  'bantime' => 600\n}\n\nIn this example, we are whitelisting the servers 192.168.123.123 and 192.168.123.124, and adjusting down the ban time from one hour to 10 minutes (600 seconds). maxretry = 10 allows a user to get the password wrong 10 times before ban, and findtime = 60 means that the failed attempts counter resets after 60 seconds.\nThen, you should reconfigure gitlab before changes take effect: sudo gitlab-ctl reconfigure\nMore details, and for the YAML version of the config example, see gitlab.yml.example.\nNOTE: whitelisting servers is insecure, as it fully disables blocking/throttling on the whitelisted IPs.\nSolution\nThe solution to this problem should be to stop the failing login attempts, or possibly just reduce the ban time, as whitelisting leaves Gitlab vulnerable to password brute-force attacks from all whitelisted servers."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to reattach a detached HEAD in GIT\n\n(I can see there are many questions about this but I haven't found one that solves my exact problem).\nI'm running gitlab-ci and when the runner checks out my code it does so as a detached head. Here is what I get when running a git status command in the runners directory.\ngit status\n# HEAD detached at 847fe59\nnothing to commit, working directory clean\n\nWhat I need to do for what I am working on is to re-attach this head back to my develop branch and then git pull in the full repo for use in a docker container. I guess gitlab ci only checks out the last commit to save cloning down the full repo which is understandable.\nIn my .gitlab-ci.yml file I've tried the following...\n- git checkout origin/$CI_BUILD_REF_NAME\n- git pull\n\nWhich gives the following output in the console...\n    $ git checkout $CI_BUILD_REF_NAME\n    Switched to a new branch 'develop'\n    Branch develop set up to track remote branch develop from origin.\n$ git pull\nYou are not currently on a branch. Please specify which\nbranch you want to merge with. See git-pull(1) for details.\n\nIs there an easy way to reattach the head? Most of the solutions I've seen deal with the fact a change has been committed onto the detached head however this isn't the case for me. I just want to get my full develop branch in my docker container with all of my git history.\nOr if there is a way to stop gitlab ci from checking out the detached head that would also be great."}, {"role": "assistant", "content": "A detached HEAD is simply a HEAD containing the raw hash ID of a commit.  As noted in the comments, it's generally pretty reasonable to use this for a build system, whether that's some sort of continuous integration or not: you might check out a specific commit by hash ID, or check out a tag name, but either way HEAD winds up containing the commit hash ID and is now guaranteed to be steady.\nIf you do want to have an \"attached\" (not-detached) HEAD, though, all you have to do in Git terms is to run git checkout <branch-name>.  This writes the name of the branch into HEAD, and now HEAD is attached to that branch.  This means that it's not HEAD at all, but rather the branch name, that determines which commit is current.  Anything that updates the branch name, changes the current commit.\nNote that this property only applies to branch names, i.e., with names that live in the refs/heads/ name-space.  The name origin/branch is typically shorthand for refs/remotes/origin/branch, which is not a branch name; it's a remote-tracking name (sometimes called a remote-tracking branch, which is a poor set of words because that sure sounds like \"branch\", doesn't it?).  Supplying any name to git checkout that can be resolved to a commit, but is not a branch name, results in a detached HEAD (if the checkout works at all, anyway).\nIf you want to have an attached HEAD, it must be attached to a branch name, i.e., a reference whose name starts with refs/heads/."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab Runner - How to allow only one Pipeline run at a time\n\nI am new to GitLab and facing a problem where if I trigger two pipelines at the same time on same gitlab-runner, they both run in parallel and results in failure. What I want is to limit the run to one pipeline at a time and others in queue. \nI have set the concurrent = 1 in config.toml and restarted the runner but it didn't help. My ultimate goal is to prevent multi-pipeline run on the runner.\nThanks."}, {"role": "assistant", "content": "Set resource_group in the Job, and give a unique name for all other tasks that should be blocked.\nExample from the documentation:\ndeploy-to-production:\n  script: deploy\n  resource_group: production"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "dynamically setting artifact path/folder structure on gitlab-ci.yml\n\nI have the following gitlab-ci.yml file that reads the package.json using the jq processor to dynamically set the variable name of the artifact folder, something along the lines of \nimage: node:latest\n\nstages:\n - build\n\nbefore_script:\n    ## steps ignored for purpose of question\n    - export NAME_OF_ARTIFACT_FOLDER=$(cat package.json | jq -r .name)\"_\"$(cat package.json | jq -r .version)\".zip\"\n    - echo $NAME_OF_ARTIFACT_FOLDER ##prints the expected name here eg. myApp_1.0.0.zip\n\nprod_build:\n  stage: build\n  script:\n   - echo $NAME_OF_ARTIFACT_FOLDER ##prints the expected name here eg. myApp_1.0.0.zip\n   - yarn run build\n  artifacts:\n    paths:\n    - dist/$NAME_OF_ARTIFACT_FOLDER ## this does not work\n    expire_in: 2 hrs\n\nThe issue here is - dist/$NAME_OF_ARTIFACT_FOLDER does not work, not sure if am missing something here.\nEDIT\nUpon hard coding the expected path such as the following, it works fine, which would mean that the folder name is valid and that the artifact is indeed identified appropriately, but does NOT work when coming from $NAME_OF_ARTIFACT_FOLDER\n artifacts:\n    paths:\n    - dist/myApp_1.0.0.zip ##hardcoding the expected works just fine\n    expire_in: 2 hrs"}, {"role": "assistant", "content": "While @Jakub Kania was not that wrong with it's summary\n\nhttps://stackoverflow.com/a/49659852/529977\nThat is no variables set in your script part of the job can be used.\n\nand I have to redict my own comment beneath @Matt Bracewell's post\n\nhttps://stackoverflow.com/a/66707954/529977\nI don't see this will help anything because it addresses artifacts:name but not artifacts:paths . paths is still not dynamically usable as you can see in https://docs.gitlab.com/ee/ci/variables/where_variables_can_be_used.html\n\n~~the undocumented part says:__~~\nyou can use any variable in artifacts:path that is available at job level\ni.e.\n  prod_build:\n+   variables:\n+      NAME_OF_ARTIFACT: \"myApp_*.zip\"\n    stage: build\n    script:\n     - echo $NAME_OF_ARTIFACT\n     - yarn run build\n    artifacts:\n      paths:\n      - dist/$NAME_OF_ARTIFACT\n      expire_in: 2 hrs\n\nThat's indeed consequent to what is asked in Artifacts Filename Cannot Be Set with Dynamic Variables even they don't ask for paths but names\ngenerate for myself:\n  script:\n    - mkdir build\n    - |\n      cat > build/artifact1$$.txt <<EOF\n      Hello World! ${CI_PROJECT_ID} ${CI_PIPELINE_IID}\n      EOF\n    - export MY_VAR_FILE_NAME=artifact1$$\n    - echo \"MY_VAR_FILE_NAME=${MY_VAR_FILE_NAME}\" >> generate.env\n    - |\n      cat > build/artifact2$$.txt <<EOF\n      The end is near! ${CI_PROJECT_ID} ${CI_PIPELINE_IID}\n      EOF\n    - export MY_VAR_FILE2_NAME=artifact2$$\n    - echo \"MY_VAR_FILE2_NAME=${MY_VAR_FILE2_NAME}\" >> generate.env\n    - |\n      cat > build/ci${CI_PIPELINE_IID}.txt <<EOF\n      Happy to hear you! ${CI_PROJECT_ID} ${CI_PIPELINE_IID}\n      EOF\n  artifacts:\n    reports:\n      # using the https://docs.gitlab.com/ee/ci/yaml/artifacts_reports.html#artifactsreportsdotenv \n      # does NOT do the trick to fill a job variable before artifact:paths is evaluated!\n      dotenv: generate.env\n    paths: \n      - build/ci${CI_PIPELINE_IID}.txt # WORKS!\n      - build/$MY_VAR_FILE_NAME.txt    # doen't work\n      - build/$MY_VAR_FILE2_NAME.txt   # doen't work\n\n\u26a0\ufe0f unknown variables are expanded to empty and build/$MY_VAR_FILE_NAME.txt becomes build/ i.e. all files in build folder are artifacts - mentioned in pipeline out WARNING: build/.txt: no matching files. Ensure that the artifact path is relative to the working directory  resp. unexpected build/: found 4 matching files and directories\nAs a workaround - but yes, it's ugly -, you can do the trick either by using wildcards (but I assume you have good reasons to do not)\nprod_build\n  artifacts:\n    paths:\n      - dist/*.zip\n\nOR splitting into two jobs\ngenerate before save:\n  script:\n    - mkdir build\n    - |\n      cat > build/artifact1$$.txt <<EOF\n      Hello World! ${CI_PROJECT_ID} ${CI_PIPELINE_IID}\n      EOF\n    - export MY_VAR_FILE_NAME=artifact1$$\n    - echo \"MY_VAR_FILE_NAME=${MY_VAR_FILE_NAME}\" >> generate.env\n    - |\n      cat > build/artifact2$$.txt <<EOF\n      The end is near! ${CI_PROJECT_ID} ${CI_PIPELINE_IID}\n      EOF\n    - export MY_VAR_FILE2_NAME=artifact2$$\n    - echo \"MY_VAR_FILE2_NAME=${MY_VAR_FILE2_NAME}\" >> generate.env\n  artifacts:\n    reports:\n      # using the https://docs.gitlab.com/ee/ci/yaml/artifacts_reports.html#artifactsreportsdotenv trick to fill a job variable for downstream of successor job\n      dotenv: generate.env\n    paths: \n      - build/*.txt\n\nsave artifacts:\n  ## this is your expected input:\n  # variables:\n  #   MY_VAR_FILE_NAME: #filled by dotenv\n  #   MY_VAR_FILE2_NAME: #filled by dotenv\n  needs:\n    - generate before save\n  script:\n    - find build/\n    - echo \"expecting \u2026 \"\n    - echo \"- $MY_VAR_FILE_NAME\"\n    - echo \"- $MY_VAR_FILE2_NAME\"\n  artifacts:\n    paths: \n      - build/$MY_VAR_FILE_NAME.txt    # WORKS\n      - build/$MY_VAR_FILE2_NAME.txt   # WORKS\n\ni.e. in your case:\nimage: node:latest\n\nstages:\n - build\n\npre_prod_build:\n  stage: build\n  script:\n    ## steps ignored for purpose of question\n    - export NAME_OF_ARTIFACT_FOLDER=$(cat package.json | jq -r .name)\"_\"$(cat package.json | jq -r .version)\".zip\"\n    - echo $NAME_OF_ARTIFACT_FOLDER ##prints the expected name here eg. myApp_1.0.0.zip\n    - echo \"NAME_OF_ARTIFACT_FOLDER=${NAME_OF_ARTIFACT_FOLDER}\" >> artifact_name.dotenv\n  artifacts:\n    reports:\n      dotenv: artifact_name.dotenv\n\nprod_build:\n  stage: build\n  ## this is your expected input:\n  # variables:\n  #   NAME_OF_ARTIFACT_FOLDER: # set by pre_prod_build dotenv\n  needs:\n    - job: pre_prod_build\n  script:\n   - echo $NAME_OF_ARTIFACT_FOLDER ##prints the expected name here eg. myApp_1.0.0.zip\n   - yarn run build\n  artifacts:\n    paths:\n    - dist/$NAME_OF_ARTIFACT_FOLDER ## NOW IT WORKS\n    expire_in: 2 hrs"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "The Runner of type Shell don't work: Job failed (system failure): preparing environment:\n\n1- Environment:\n\nGitlab-CE\nGitLab 13.2.1 (b55baf593e6)\nGitLab Shell 13.3.0\nGitLab Workhorse v8.37.0\nGitLab API v4\nRuby 2.6.6p146\nRails 6.0.3.1\nPostgreSQL 11.7\nDebian GNU / Linux 10 server (buster)\n\n2- .gitlab-ci.yml file:\nbefore_script:\n  - echo \"--------- STARTING WORK ------------\"\n\njob_homologacao:\n   only:\n     - homologation\n   script:\n     - cd /home/ati/\n     - mkdir test\n     - echo \"got here\"\n\njob_producao:\n   only:\n     - master\n   script:\n     - cd /home/ati/test/\n     - echo \"got here\"\n\n3- Error presented when the runner is executed:\nRunning with gitlab-runner 13.2.1 (efa30e33) on runner with Akx_BvYF shell\nPreparing the \"shell\" performer\nUsing Shell executor ...\nPreparing environment\nRunning on hermes ...\nERROR: Job failed (system failure): prepare environment: exit status 1. Check https://docs.gitlab.com/runner/shells/index.html#shell-profile-loading for more information\n4- correction attempts:\nI read and executed all the procedures contained in the codumentation:\n\nhttps://docs.gitlab.com/runner/faq/README.html#job-failed-system-failure-preparing-environment\nhttps://docs.gitlab.com/runner/shells/index.html#shell-profile-loading"}, {"role": "assistant", "content": "I was erroneously editing the file .bash_logout located inside my Home /home/ati/\nGitlab when installing gitlab-runner create a Home for it in /home/gitlab-runner/\nI just had to comment on the contents of the /home/gitlab-runner/.bash_logout file for the job to work."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab integration with SonarQube\n\nI am pretty new to Development community and specifically to DevOps practices , as a part of project we are trying to integrate SonarQube with Gitlab , did some R& D on SonarQube and Git CI ( Continuous Integration ) and look like plugin is released for Github and SonarQube whereas not for Gitlab. \nHow realistic is it to configure GitLab with SonarQube for inspecting code quality for every pull request and what will be the best practice to integrate these two piece.\nThanks"}, {"role": "assistant", "content": "you don't really need a plugin.\nmake something like this in your .gitlab-ci.yml\nstages: \n- build \nbuild_master:\n  image: maven\n  stage: build\n  artifacts:\n    paths:\n    - target/*.jar\n  script:\n  - mvn package sonar:sonar -Dsonar.host.url=https://sonar.yourdomain.tld/ \n  only:\n  - master\n\nand every master push will be tested!\n(this is for a Java project...)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI CD variable are not getting injected while running gitlab pipeline\n\nI am running the below code section in gitlab-ci.yml file:\n  script:\n- pip install --upgrade pip\n- cd ./TestAutomation\n- pip install -r ./requirements.txt\n\nBelow are the keys and values. So I have to pass any values to the pipeline with key as a variable\nENV : dev\nI have added all the above three variables in the GitLab CI CD variables sections by expanding them. just added a single value along with key\nI also found like we can add variables in the .yml file itself as below. I am not sure how we can add multiple values for one key\nvariables:\n TEST:\n   value: \"some value\" # this would be the default value\n   description: \"This variable makes cakes delicious\"\n\nWhen I run the pipeline I am getting errors as looks like these variables and values are not injected properly.\nMore details:\nAnd the same error I am getting while running the pipeline. Hence my suspect is like Category variable is not injected properly when I am running through the pipeline\nIf needed I will show it on the share screen\nWhat I have observed is --the values associated with keys which I am passing as parameter or variables , those are not injected or replaced instead of key. So ideally ${Category} should be replaced with value smoke etc"}, {"role": "assistant", "content": "When Gitlab CI CD variables are not getting injected into your pipelines as environment variables, please follow the following steps to verify.\n\nCheck whether the variable is defined. You need to have at least the Maintainer role setup for your user. Go to Settings --> CI/CD --> Variables. You can see all project variables, and group variables (inherited).\n\nNext, check whether these variables are defined as Protected variables. If they are marked as Protected, then they are only exposed to protected branches or protected tags. I would suggest to uncheck this, if your current branch is not a protected branch. If not you can always make your current branch a protected one.\n\n\nNext, check whether your code is accessing the environment variables correctly. Based on your scripting language, just access as if you are accessing a regular environment variable.\n\nYou don't really need to define these variables in the .gitlab-ci.yaml file. (Even though their documentation says so)\n\n\nHope this helps."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab-CI Multi Runner php composer cache\n\nI'm using gitlab-ci-multi-runner with docker containers. Everything is going fine, but docker containers don't keep the composer cache so in every run composer downloads dependencies again and again, which takes a lot of time. Is there any way to configure gitlab-ci-runner docker container to keep the composer cache or mount a volume on each run where the composer cache is kept?"}, {"role": "assistant", "content": "You can change the composer cache path by exporting the COMPOSER_CACHE_DIR environment variable in your runner configuration file, and then add a volume in the [runners.docker] section to match it.\nIf you run gitlab-runner as root or with sudo, then your configuration file is located at /etc/gitlab-runner/config.toml. Otherwise it's located at $HOME/.gitlab-runner/config.toml.\n# config.toml\n\n[[runners]]\n  name = \"Generic Docker Runner\"\n  ...\n  environment = [\"COMPOSER_CACHE_DIR=/cache\"]\n  executor = \"docker\"\n  [runners.docker]\n    ...\n    volumes = [\"/var/cache:/cache:rw\"]\n    cache_dir = \"/cache\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI script: exclude branches\n\nI'm trying to improve the project building script, described in YML-file, the improvement itself seems quite trivial, but the idea of accidentally ruining the auto-builds scares me a bit.\nRight now there are several branches, version tags and other stuff in the project.\nA development branch, not built by the runners would be of use, because copying a huge project somehow between virtual machines to test the build on different platforms is not convenient at all. So, I want to exclude from builds some \"prj-dev\" branch.\nAnd there we have:\nstages:\n - build\n - linuxbuild\njob:\n tags:\n - win2008build\n stage: build\n script:\n  # something complex\n\njob1:\n tags:\n - linux\n stage: linuxbuild\n script:\n  # something else complex\n\nI googled and found a solution like:\nstages:\n - build\n - linuxbuild\njob:\n tags:\n - win2008build \n branches:\n  except:\n    - *dev-only\n\nBut it seems that our pipelines are quite different, the tags are not git tags, they are pipeline tags. So, I'm considering rather to use a config like:\nstages:\n - build\n - linuxbuild\njob:\n tags:\n - win2008build \n except:\n   branches:\n    - *dev-only\n\n...which would mean \"build as usual, but not my branch\". There are complications in trying it both ways, I'm pretty sure someone should know the recipe for sure.\nSo, if you please, -- how do I exclude my dev branch without changing the pipelines, config only? Is it possible at all?"}, {"role": "assistant", "content": "All you need to do is use except in the gitlab-ci.yml file and add your branches directly below like this:\nmybuild:\n    stage: test\n    image: somedockerimage\n    script:\n        - some script running\n    except:\n        - branch-name\n\nThis is working on my project without problems."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "kubernetes pods/nodes is forbidden\n\nI'm using kubernetes on-prem\nWhile I build gitlab using kubernetes has some problem.\nI think it's related with serviceaccount or role-binding.\nbut couldn't find correct way\nI found these posts\nKubernetes log, User \"system:serviceaccount:default:default\" cannot get services in the namespace\nhttps://github.com/kubernetes/kops/issues/3551\nmy error logs\n==> /var/log/gitlab/prometheus/current <==\n2018-12-24_03:06:08.88786 level=error ts=2018-12-24T03:06:08.887812767Z caller=main.go:240 component=k8s_client_runtime err=\"github.com/prometheus/prometheus/discovery/kubernetes/kubernetes.go:372: Failed to list *v1.Node: nodes is forbidden: User \\\"system:serviceaccount:default:default\\\" cannot list resource \\\"nodes\\\" in API group \\\"\\\" at the cluster scope\"\n2018-12-24_03:06:08.89075 level=error ts=2018-12-24T03:06:08.890719525Z caller=main.go:240 component=k8s_client_runtime err=\"github.com/prometheus/prometheus/discovery/kubernetes/kubernetes.go:320: Failed to list *v1.Pod: pods is forbidden: User \\\"system:serviceaccount:default:default\\\" cannot list resource \\\"pods\\\" in API group \\\"\\\" at the cluster scope\""}, {"role": "assistant", "content": "The issue is due to your default service account doesn't have the permission to get the nodes or pods at the cluster scope. The minimum cluster role and cluster role binding to resolve that is:\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRole\nmetadata:\n  name: prom-admin\nrules:\n# Just an example, feel free to change it\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"nodes\"]\n  verbs: [\"get\", \"watch\", \"list\"]\n\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n  name: prom-rbac\nsubjects:\n- kind: ServiceAccount\n  name: default\nroleRef:\n  kind: ClusterRole\n  name: prom-admin\n  apiGroup: rbac.authorization.k8s.io\n\nThe above cluster role provide permission to default service account to access any pods or nodes in any namespace.\nYou can change the cluster role to provide more permission to service account, if you want to grant access all permission to default service account then, replace resources: [\"*\"] in prom-admin\nHope this helps."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Close Gitlab issue via commit\n\nI spend my day doing this:\n\nRead an issue on a Gitlab-powered issue tracker,\nFix the issue,\nCommit and push to the same Gitlab-powered Git server,\nMark the issue as closed.\n\nTo remove the 4th step, how can I close the issue automatically when committing?"}, {"role": "assistant", "content": "Commit and push using this syntax:\ngit commit -m \"Sort more efficiently\" -m \"Closes #843\"\ngit push\n\nThis will commit and close the issue.\nNote that unlike Github a single -m will not work.\nThe following will appear on the issue page:\n\nReferences:\n\nhttps://docs.gitlab.com/ee/user/project/issues/managing_issues.html#closing-issues-automatically\nHow to commit a change with both \"message\" and \"description\" from the command line?"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "No \"accept merge request\" button with developer level access\n\nI'm not seeing an \"Accept Merge Request\" button in gitlab despite having \"Developer\" level access. Instead there is this message:\nReady to be merged automatically\n\nAsk someone with write access to this repository to merge this request.\n\nAccording to the documentation, users with \"Developer\" access have the ability to \"manage merge requests\", but this doesn't seem possible in this case. I have two \"Developer\" level users that are seeing this problem, one of which pushed the project to the gitlab instance to begin with. I assume he must have write access?\nVersion information below\nGitLab 7.14.3\nGitLab Shell 2.6.5\nGitLab API v3\nRuby 2.1.6p336\nRails 4.1.11 \n\nPlease let me know if any more info is required."}, {"role": "assistant", "content": "Developers can accept merge requests. However, it depends on how the project is configured, too.\nDevelopers can accept merge requests when:\n\nThe merge target is not a protected branch.\nThe merge target is a protected branch, if an owner/maintainer has checked the 'Developers can push' checkbox on the protected branch setting.\n\nIf a developer is seeing the message you describe it is probably because of a protected branch and the 'Developers can push' box is unchecked."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Add users to group in GitLab\n\nI am filled with chagrin having to ask this, but I can't figure out how to add users in GitLab.  I get to the screen where it allows me to add new members as follows:\n\nFrom my Group page -> click the 'members' icon on the toolbar along\n  the left edge -> click 'Add Members' expando button -> enter username\n  in 'Find existing member by name' or 'People' fields and get no\n  results.\n\nThe 'People' field auto-populates with a bunch of names I don't recognize.  But won't let me find a user who has registered by username or actual name.  Am I missing something?"}, {"role": "assistant", "content": "What version?  These instructions are for gitlab community edition on ubuntu; the deb was named gitlab_7.4.3-omnibus.5.1.0.ci-1_amd64: \n\nLogin\nClick the gears icon (top right) to enter the Admin area\nClick the Groups link (top center) to enter the Groups page\nClick the name of the group you wish to extend (\"Mygroup\")\nLook at the right side of the screen; if you have the right privs you should see \"Add user(s) to the group:\"\nType the first few letters of the user name into the box, a drop-down should appear so you can select the user.\n\nHTH"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Is it possible to install a package from a repository on Gitlab using Composer?\n\nI am trying to get composer to download a library from my repository on Gitlab, however, it does not have a composer.json file in it so I'm not sure if this is possible.\n    \"require\": {\n        \"username/repository-name\"\n    },\n    \"repositories\": [{\n        \"type\": \"package\",\n        \"package\": {\n            \"version\": \"dev-master\",\n            \"name\": \"username/repository-name\",\n            \"source\": {\n                \"url\": \"https://gitlab.com/username/repository.git\",\n                \"type\": \"git\",\n                \"reference\": \"master\"\n            }\n        }\n    }],"}, {"role": "assistant", "content": "I found the answer and it works for me here (the last answer, not the accepted answer):\nUsing Composer and Private Repository on GIthub using VCS on Build Server\nThis is what I make it works:\n    \"repositories\": [\n      {\n        \"type\": \"package\",\n        \"package\": {\n          \"name\": \"username/repository\",\n          \"version\": \"0.1.0\",\n          \"type\": \"package\",\n          \"source\": {\n              \"url\": \"[email\u00a0protected]:username/repository.git\",\n              \"type\": \"git\",\n              \"reference\": \"master\"\n          }\n        }\n      }\n    ],\n    \"require\": {           \n        \"username/repository\": \"*\"\n    },"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Migrate or export Github wiki to Gitlab\n\nCurrently we are working with github and we are actually quiet happy with it. But the costs will grow more and more in near future. Now we've started evaluating other git solutions and stumbled over gitlab, and i've to say, it looks very interesting for us. I've seen that there is as well a wiki feature similar to github. But one important thing is nowhere described... \nThe only thing i've found is this two year old entry https://groups.google.com/forum/#!msg/gitlabhq/YSM_Il9yk04/_-ybpN4BekYJ\nDoes anybody know if there are any news in that matter? it looks like it is possible, but how? is there any manual or howto that could help me?\nThanks a lot!"}, {"role": "assistant", "content": "Github wikis and GitLab wikis are both just Git repositories containing text files, so you can just pull from one and push to the other.\nGo to any page on your Github wiki and click the Clone URL button. You'll get a URL like https://github.com/Homebrew/homebrew.wiki.git. Clone it to your computer:\ngit clone https://github.com/Homebrew/homebrew.wiki.git\ncd homebrew.wiki\n\nThen, on your GitLab wiki, click the Git Access tab, find the URL in the instructions (in the first line under the Clone Your Wiki heading), and push to that URL:\ngit push https://gitlab.com/adambrenecki/test-project.wiki.git\n\nIf you can't find the URLs, they should be roughly the same as on this page, with the usernames/repo names changed as appropriate."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "docker login in custom gitlab-runner: No such host (http://docker:2375/v1.39/auth: dial tcp: lookup docker on 172.31.0.2:53: no such host)\n\nI have a private repo on gitlab.com. I have already setup a CI/CD pipeline using gitlab shared runners. On code push, a docker image is built, login to gitlab private docker registry and push the image. It works fine with the shared runners. Now I'm trying to create custom runners for the pipeline.\nI've created a droplet on DigitalOcean (Docker 18.09.2~3 on Ubuntu 18.04 - 8 GB / 4 CPUs / 160 GB SSD)\nssh into the droplet\ncreate a runner (from https://docs.gitlab.com/runner/install/docker.html#docker-image-installation-and-configuration)\ndocker run -d --name gitlab-runner --restart always \\\n  -v /srv/gitlab-runner/config:/etc/gitlab-runner \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  gitlab/gitlab-runner:latest\n\nand register it (from https://docs.gitlab.com/runner/register/index.html#one-line-registration-command)\ndocker run --rm -t -i -v /srv/gitlab-runner/config:/etc/gitlab-runner gitlab/gitlab-runner register \\\n  --non-interactive \\\n  --executor \"docker\" \\\n  --docker-image alpine:3 \\\n  --url \"https://gitlab.com/\" \\\n  --registration-token \"MY_TOKEN\" \\\n  --description \"docker-runner\" \\\n  --tag-list \"docker,digitalocean\" \\\n  --run-untagged=\"true\" \\\n  --locked=\"false\"\n\non running the pipeline, it fails at this command\ndocker login -u gitlab-ci-token -p $CI_BUILD_TOKEN $CI_REGISTRY\n\nalso if I use\ndocker login -u gitlab-ci-token -p $CI_BUILD_TOKEN registry.gitlab.com \n\nwith this error message\nerror during connect: Post http://docker:2375/v1.39/auth: dial tcp: lookup docker on 67.207.67.2:53: no such host\n\nI also get the same error if I use my local PC.\nI have tried editing /etc/hosts with no success.\nIt still works with the shared runners, but fails with my custom runners. What am I missing?\ndocker info\nContainers: 4\nRunning: 1\nPaused: 0\n Stopped: 3\nImages: 4\nServer Version: 18.09.2\nStorage Driver: overlay2\n Backing Filesystem: extfs\n Supports d_type: true\n Native Overlay Diff: true\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins:\n Volume: local\n Network: bridge host macvlan null overlay\n Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\nSwarm: inactive\nRuntimes: runc\nDefault Runtime: runc\nInit Binary: docker-init\ncontainerd version: 9754871865f7fe2f4e74d43e2fc7ccd237edcbce\nrunc version: 09c8266bf2fcf9519a651b04ae54c967b9ab86ec\ninit version: fec3683\nSecurity Options:\n apparmor\n seccomp\n  Profile: default\nKernel Version: 4.15.0-45-generic\nOperating System: Ubuntu 18.04.2 LTS\nOSType: linux\nArchitecture: x86_64\nCPUs: 4\nTotal Memory: 7.79GiB\nName: docker-s-4vcpu-8gb-sgp1-01\nID: XF6Y:25TY:YXNO:RDHT:PEGU:KGR7:GPEM:DDBE:MAQ5:5VIJ:4GHB:Q7TF\nDocker Root Dir: /var/lib/docker\nDebug Mode (client): false\nDebug Mode (server): false\nRegistry: https://index.docker.io/v1/\nLabels:\nExperimental: false\nInsecure Registries:\n 127.0.0.0/8\nLive Restore Enabled: false\nProduct License: Community Engine\n\nthis is the /etc/hosts file on the shared runner that processes the pipeline successfully\n127.0.0.1   localhost\n::1 localhost ip6-localhost ip6-loopback\nfe00::0 ip6-localnet\nff00::0 ip6-mcastprefix\nff02::1 ip6-allnodes\nff02::2 ip6-allrouters\n127.0.0.1   0hshit.hopto.org\n127.0.0.1   daymndaymn.myftp.org\n127.0.0.1   loba.webhop.me\n172.17.0.3  docker 50d9e6c88489 runner-72989761-project-11958054-concurrent-0-docker-0\n172.17.0.4  runner-72989761-project-11958054-concurrent-0"}, {"role": "assistant", "content": "In GitLab 13.3 you can do the following in config.toml file of the runner:\nAdd in [[runners]] section:\n  pre_build_script = \"export DOCKER_HOST=tcp://docker:2375\"\n  environment = [\"DOCKER_DRIVER=overlay2\", \"DOCKER_TLS_CERTDIR=\"]\n\nand in [runners.docker] section\nadd:\ntls_cert_path = \"\"\n\nand change privileged to true.\nIn the end you will have something like this:\nconcurrent = 1\ncheck_interval = 0\n\n[session_server]\n  session_timeout = 1800\n\n[[runners]]\n  name = \"some_name\"\n  url = \"https://my.url.com\"\n  token = \"a_token\"\n  executor = \"docker\"\n  pre_build_script = \"export DOCKER_HOST=tcp://docker:2375\"\n  environment = [\"DOCKER_DRIVER=overlay2\", \"DOCKER_TLS_CERTDIR=\"]\n  [runners.custom_build_dir]\n  [runners.cache]\n    [runners.cache.s3]\n    [runners.cache.gcs]\n    [runners.cache.azure]\n  [runners.docker]\n    tls_cert_path = \"\"\n    tls_verify = false\n    image = \"ruby:2.6\"\n    privileged = true\n    disable_entrypoint_overwrite = false\n    oom_kill_disable = false\n    disable_cache = false\n    volumes = [\"/cache\"]\n    shm_size = 0\n\nIn .gitlab-ci.yml\nYou only have to do this to user docker:\nservices:\n  - docker:dind"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI/CD - Change Working Directory\n\nI am trying to implement a CI/CD pipeline for Terraform, however I need to change the pwd before running any further commands. \nIt appears the Terraform container only accepts Terraform commands, so cd/ls/echo $PATH are unrecognised. Do I need build an image which supports this and use that, or can I use the maintained Terraform images?\nI tried changing the ENTRYPOINT but appears only a minimal install is available due to the Alpine image."}, {"role": "assistant", "content": "You can change the entrypoint to /usr/bin/env in order to run a cd command. Example with gitlab-ci:\nvalidate_terraform:\n  image:\n    name: hashicorp/terraform:light\n    entrypoint: [\"/usr/bin/env\"]\n  stage: test\n\n  script:\n    - cd infrastructure/\n    - terraform init\n    - terraform validate"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to use multiple ssh keys for multiple gitlab accounts with the same host [duplicate]\n\nThis question already has answers here:\n                                \n                            \n\n\n\n\nGitHub: Multiple account setup\n\n                                (4 answers)\n                            \n\nClosed 8 years ago.\n\n\n\nI want to use 2 accounts in Gitlab website, every account with a different ssh key\nI generated the keys successfully and add them in ~/.ssh  folder\nI created ~/.ssh/config file and use one of them , it's works good\nI can also make swapping between the two keys by editing the ~/.ssh/config file\nThe problem is : I want to use them in the same time , but all the  tutorials i found taking about different hosts :/ \nactually my two accounts are in the same host\nhow can i edit the ~/.ssh/config file to accept two accounts for the same host\nNote:  I read this question but i can't get help from it\nMy two accounts are username1 and username2\nrepo URL looks like : [email\u00a0protected]:username1/test-project.git\nMy current ~/.ssh/config file:\nHost gitlab.com-username1\n  HostName gitlab.com\n  User git\n  IdentityFile ~/.ssh/id_rsa\n\nHost gitlab.com-username2\n  HostName gitlab.com\n  User git\n  IdentityFile ~/.ssh/id_rsa_username2\n\nUpdate 1: \n1) When I use one key in the ~/.ssh/config file , everything works perfect (but it's very boring to update it every time i want to change the user i use)\n2) When i use this lines\nssh -T [email\u00a0protected]\nssh -T [email\u00a0protected]\nits works good and return a welcoming message\nFrom 1) and 2) , i think the problem is definitely from the ~/.ssh/config file , specifically in Host variable \nUpdate 2: (the solving) \nthe solving was to edit the .git/config file from \n[remote \"origin\"]\n  url = [email\u00a0protected]:username1/test-project.git \nto \n[remote \"origin\"]\n  url = [email\u00a0protected]:username1/test-project.git\nand do the same for the username2"}, {"role": "assistant", "content": "You have got complete ssh configuration. First of all, check if it works:\nssh -T [email\u00a0protected]\nssh -T [email\u00a0protected]\n\nshould succeed in both cases. If not, the keys are not set up correctly. Verify that the keys are on gitlab for respective users.\nIf it works, move on to your git repository and open .git/config. It will have some part like:\n[remote \"origin\"]\n  url = [email\u00a0protected]:username1/test-project.git\n\nReplace it with \n[remote \"origin\"]\n  url = [email\u00a0protected]:username1/test-project.git\n\n(or username1 if you want to connect using this username). Then it should allow you to push."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab-ci.yml - override a specific job and script execution\n\nI have a .gitlab-ci.yml file that says:\ninclude:\n  - project: 'my-proj/my-gitlab-ci'\n    ref: master\n    file: '/pipeline/gitlab-ci.yml'\n\nBecause of some \"Inconvenience\" I would like to override some specific stage that is defined on the above mentioned gitlab-ci.yml file injected on my top level .gitlab-ci.yml file. The plan stage I am interested in has the following thing:\nplan-dummy:\n  stage: plan\n  script:\n    - terraform plan -lock=false -var-file=vars/vars.tfvars\n\nWhat I want to do is override the above on the main .gitlab-ci.yml file such that only the script is executed as an override:\nplan-dummy:\n  stage: plan\n  script:\n    - terraform refresh   # This is the line I want to add as an additional step before next \n    - terraform plan -lock=false -var-file=vars/dev.tfvars\n\nHow do I achieve that without fiddling with the injected file? Yes, I know that alternative is to do dirty copy-paste from child file, but I don't want to do that.\nRegards,"}, {"role": "assistant", "content": "simply reuse the same job name and add the configuration you need:\nplan-dummy:\n  before_script:\n    - terraform refresh"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Property to prevent gitlab from protecting default branches\n\nWith version 7.4 gitlab changed the behaviour of protected branches in new projects.\nIn every new project the default branch e.g. master is a protected branch, meaning developers are not able to push to it. In my company a lot of developers work on the default/master branch and are now struggeling when starting a new project.\nMy Question: Is there a property in the ui or in the gitlab.rb to restore the pre 7.4 behaviour and to not protect the default branch?"}, {"role": "assistant", "content": "I'm not Sure if the is a default param, but per project you can change master as unprotected , in your project, go to settings -> protected branches and unprotect master\n\nUpdate\nThe gilt team published a post related to your question!!\nhttps://about.gitlab.com/2014/11/26/keeping-your-code-protected/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Can I render HTML on GitLab?\n\nGitLab doesn't render HTML for me, but just display the source code:\n\nBackground: I used sphinx to generate the HTML and tried to show the doc at GitLab.\nI looked at other projects' repositories, such as pandas, sphinx. They only have .rts files in the repository, and not HTML files. I guess they generate HTML for their websites but don't upload to Git.\nI don't have a website and want to show doc at GitLab. Is there a way to do that? Or do I have to generate other formats (other than HTML, e.g. PDF) instead?"}, {"role": "assistant", "content": "First of all, Git and products like GitLab and GitHub are different things. Git doesn't ever render anything; it's a version control system. It doesn't have a web interface.\nSecondly, GitLab's core product isn't supposed to render anything. It's not a web host, it's a tool for hosting, sharing, and managing Git repositories. However you might want to try GitLab Pages:\n\nGitLab Pages is a feature that allows you to publish static websites directly from a repository in GitLab.\nYou can use it either for personal or business websites, such as portfolios, documentation, manifestos, and business presentations. You can also attribute any license to your content.\nPages is available for free for all GitLab.com users as well as for self-managed instances (GitLab Core, Starter, Premium, and Ultimate).\n\nGitLab Pages will publish content from the public/ directory of your repository, so you should move your files there. You will also need a .gitlab-ci.yml file in the root of your repository containing something like\nimage: alpine:latest\n\npages:\n  stage: deploy\n  script:\n  - echo 'Nothing to do...'\n  artifacts:\n    paths:\n    - public\n  only:\n  - master\n\n(taken from the sample repository). Add that file, then commit and push. After deployment is complete, your site should be available at https://youruser.gitlab.io/yourproject.\nNote that GitHub has a similar product (that works differently).\nFinally,\n\nI looked at other projects' repositories, such as pandas, sphinx. They only have .rts files in the repository, and not HTML files. I guess they generate HTML for their websites but don't upload to Git.\n\nit's very likely that the reStructured Text files are the only source that exists, and that HTML is generated from them automatically. Sphinx this format by default. If you're interested in working from another format like Markdown or reStructured Text you may want to explore GitLab Pages' support for static site generators."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How can I add hooks to gitlab?\n\nI setup a new Gitlab on CentOs on /opt/gitlab-6.9.2-0/apps/gitlab/ and created a new repository under continuous-delivery group. The full path is /opt/gitlab-6.9.2-0/apps/gitlab/gitlab-satellites/continuous-delivery/cd-test\n. There is only one file under this path which is README.txt. \nWhat I try to achieve is to create a new file when somebody pushes changes to the server. Below are what I have done on the server:\n\nCreate post-update and update files under .git/hooks/' each file creates a new file usingecho \"text\" >> file_name`\nchmod them to 775.\n\nWhen I push changes from my local to the server, there is no file being created. So, I would like to know what I have to do to fix this problem.\nUpdate 1\nI added post-receive and post-update to repositories path as VonC suggested\n[root@git-cd hooks]# pwd\n/opt/gitlab-6.9.2-0/apps/gitlab/repositories/continuous-delivery/cd-test.git/hooks\n[root@git-cd hooks]# ll\ntotal 48\n-rwxrwxr-x. 1 git git  452 Jun 10 06:01 applypatch-msg.sample\n-rwxrwxr-x. 1 git git  896 Jun 10 06:01 commit-msg.sample\n-rwxrwxr-x. 1 git git   44 Jun 11 00:37 post-receive\n-rwxrwxr-x. 1 git git   41 Jun 11 00:38 post-update\n-rwxrwxr-x. 1 git git  189 Jun 10 06:01 post-update.sample\n-rwxrwxr-x. 1 git git  398 Jun 10 06:01 pre-applypatch.sample\n-rwxrwxr-x. 1 git git 1642 Jun 10 06:01 pre-commit.sample\n-rwxrwxr-x. 1 git git 1281 Jun 10 06:01 prepare-commit-msg.sample\n-rwxrwxr-x. 1 git git 1352 Jun 10 06:01 pre-push.sample\n-rwxrwxr-x. 1 git git 4972 Jun 10 06:01 pre-rebase.sample\nlrwxrwxrwx. 1 git git   57 Jun 10 06:01 update -> /opt/gitlab-6.9.2-0/apps/gitlab/gitlab-shell/hooks/update\n-rwxrwxr-x. 1 git git 3611 Jun 10 06:01 update.sample\n\nBoth file contains a script that adds a new line to an existing file, \"post-receive-2\" >> /var/log/hooks_test.log. then pushed changes from my local machine to the server. But it still doesn't append the text.\nUpdate 2\nScript in post-receive was wrong, it didn't have echo. After I added echo (echo \"post-receive-2\" >> /var/log/hooks_test.log then it works as expected!"}, {"role": "assistant", "content": "That would be because those satellite repos aren't the one you would push to, so their hook aren't trigger when you would think (ie, not when someone is pushing to the GitLab server).\nPR 6185 introduced the archicture overview documentation\n\n/home/git/gitlab-satellites - checked out repositories for merge requests and file editing from web UI.  This can be treated as a temporary files directory.\nThe satellite repository is used by the web interface for editing repositories and the wiki which is also a git repository.\n\nYou should add your hook in the bare repos ~git/repositories.\nOr (update Q4 2014, from GitLab 7.5+ Nov 2014), you can use custom hooks (instead of webhooks), as mentioned below by Doka.\n\nCustom git hooks must be configured on the filesystem of the GitLab server.\n  Only GitLab server administrators will be able to complete these tasks. Please explore webhooks as an option if you do not have filesystem access.\n\nOn the GitLab server, navigate to the project's repository directory.\n  For a manual install the path is usually /home/git/repositories/<group>/<project>.git.\n  For Omnibus installs the path is usually /var/opt/gitlab/git-data/repositories/<group>/<project>.git.\nCreate a new directory in this location called custom_hooks.\nInside the new custom_hooks directory, create a file with a name matching the hook type.\n  For a pre-receive hook the file name should be pre-receive with no extension.\nMake the hook file executable and make sure it's owned by git."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Runner is not healthy and will be disabled\n\nI hosts my repository with gitlab.com and I install runner in the DigitalOcean. It ran fine until today 16March2019 14:24 Thailand time.\n# gitlab-runner status\nRuntime platform                                    arch=amd64 os=linux pid=16937 revision=4745a6f3 version=11.8.0\ngitlab-runner: Service is running!\n# gitlab-runner unregister --all-runners\nRuntime platform                                    arch=amd64 os=linux pid=16299 revision=4745a6f3 version=11.8.0\nRunning in system-mode.\n\nWARNING: Unregistering all runners\nERROR: Unregistering runner from GitLab forbidden   runner=2bcd7af4\nERROR: Failed to unregister runner HerrRunner\n# gitlab-runner list\nRuntime platform                                    arch=amd64 os=linux pid=16346 revision=4745a6f3 version=11.8.0\nListing configured runners                          ConfigFile=/etc/gitlab-runner/config.toml\nHerrRunner                                          Executor=shell Token=2bcd7af455f866ede7991992a68780 URL=https://gitlab.com/\n# gitlab-runner --debug run\nRuntime platform                                    arch=amd64 os=linux pid=16395 revision=4745a6f3 version=11.8.0\nStarting multi-runner from /etc/gitlab-runner/config.toml ...  builds=0\nChecking runtime mode                               GOOS=linux uid=0\nRunning in system-mode.\n\nConfiguration loaded                                builds=0\nlistenaddress: \"\"\nsessionserver:\n  listenaddress: \"\"\n  advertiseaddress: \"\"\n  sessiontimeout: 1800\nmetricsserveraddress: \"\"\nconcurrent: 1\ncheckinterval: 0\nloglevel: null\nlogformat: null\nuser: \"\"\nrunners:\n- name: HerrRunner\n  limit: 0\n  outputlimit: 0\n  requestconcurrency: 0\n  runnercredentials:\n    url: https://gitlab.com/\n    token: 2bcd7af455f866ede7991992a68780\n    tlscafile: \"\"\n    tlscertfile: \"\"\n    tlskeyfile: \"\"\n  runnersettings:\n    executor: shell\n    buildsdir: \"\"\n    cachedir: \"\"\n    cloneurl: \"\"\n    environment: []\n    preclonescript: \"\"\n    prebuildscript: \"\"\n    postbuildscript: \"\"\n    shell: \"\"\n    ssh: null\n    docker: null\n    parallels: null\n    virtualbox: null\n    cache:\n      type: \"\"\n      path: \"\"\n      shared: false\n      s3: null\n      gcs: null\n      s3cachepath: \"\"\n      cacheshared: false\n      serveraddress: \"\"\n      accesskey: \"\"\n      secretkey: \"\"\n      bucketname: \"\"\n      bucketlocation: \"\"\n      insecure: false\n    machine: null\n    kubernetes: null\nsentrydsn: null\nmodtime: 2018-08-12T18:07:07.963445119Z\nloaded: true\n  builds=0\nWaiting for stop signal                             builds=0\nListen address not defined, metrics server disabled  builds=0\nListen address not defined, session server disabled  builds=0\nStarting worker                                     builds=0 worker=0\nFeeding runners to channel                          builds=0\nDialing: tcp gitlab.com:443 ...\nERROR: Checking for jobs... forbidden               runner=2bcd7af4\nFeeding runners to channel                          builds=0\nERROR: Checking for jobs... forbidden               runner=2bcd7af4\nFeeding runners to channel                          builds=0\nERROR: Checking for jobs... forbidden               runner=2bcd7af4\nERROR: Runner https://gitlab.com/2bcd7af455f866ede7991992a68780 is not healthy and will be disabled!\nFeeding runners to channel                          builds=0\nFeeding runners to channel                          builds=0\nFeeding runners to channel                          builds=0\n^CWARNING: Requested service stop: interrupt          builds=0\nAll workers stopped. Can exit now                   builds=0\n\nUltimate Goal\nGet my runner up and run again\nQuestion:\n\nWhat does not healthy means?\nI can't unregister my runner. How to fix this?"}, {"role": "assistant", "content": "I was integrating my runner for the first time, and anyone familiar with gitlab will know this was never going to be a walk in the park. I spent many hours chasing down this error message only to find I was completely looking in the wrong direction.\nERROR: Checking for jobs... forbidden               runner=s3xBVnW8\nERROR: Checking for jobs... forbidden               runner=s3xBVnW8\nERROR: Checking for jobs... forbidden               runner=s3xBVnW8\nERROR: Runner https://gitlab.com/s3xBVnW8JZPTaocALN3i is not healthy and will be disabled!\n\nI now believe my runner was telling me that the \"runner\" at gitlab.com is not healthy and has been rejected (by my runner).  When I left it running and put a pipeline job in, it processed fine, there was no issue at my end, I had spent hours looking for nothing!"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Multiple Routers and Services on the same container with traefik 2\n\nI'm currently trying to get traefik to use multiple routers and services on a single container, which isn't working and i don't know if this is intended at all.\nWhy?\nSpecificly i'm using an gitlab omnibus container and wanted to use / access multiple services inside the omnibus container since gitlab is providing not only \"the gitlab website\" with it. \nWhat did i try?\nI simply tried adding another router to my docker compose file via labels\nThis is what i have:\nlabels:\n  - \"traefik.http.routers.gitlab.rule=Host(`gitlab.example.com`)\"\n  - \"traefik.http.services.gitlab.loadbalancer.server.port=80\"\n\nThis is what i want:\nlabels:\n  - \"traefik.http.routers.gitlab.rule=Host(`gitlab.example.com`)\"\n  - \"traefik.http.services.gitlab.loadbalancer.server.port=80\"\n  - \"traefik.http.routers.registry.rule=Host(`registry.gitlab.example.com`)\"\n  - \"traefik.http.services.registry.loadbalancer.server.port=5000\"\n\nThis doesn't work since traefik probably getting confused with what to route to which service and i couldn't find a mechanism that tells traefik exactly which router goes to which service in a case like this.\nIs this even possible or am i just missing a little bit of traefik magic?"}, {"role": "assistant", "content": "I found the solution to my Question.\nThere's indeed a little bit i missed:\n\ntraefik.http.routers.myRouter.service=myService\n\nWith this Label i can point a Router to a specific Service and should be able to add multiple services to one container:\nlabels:\n  - \"traefik.http.routers.gitlab.rule=Host(`gitlab.example.com`)\"\n  - \"traefik.http.routers.gitlab.service=gitlab\"\n  - \"traefik.http.services.gitlab.loadbalancer.server.port=80\"\n  - \"traefik.http.routers.registry.rule=Host(`registry.gitlab.example.com`)\"\n  - \"traefik.http.routers.registry.service=registry\"\n  - \"traefik.http.services.registry.loadbalancer.server.port=5000\"\n\nHere each router is pointed to a specific service explicitly which normally happens implicitly."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to Integrate GitLab-Ci w/ Azure Kubernetes + Kubectl + ACR for Deployments?\n\nOur previous GitLab based CI/CD utilized an Authenticated curl request to a specific REST API endpoint to trigger the redeployment of an updated container to our service, if you use something similar for your Kubernetes based deployment this Question is for you.\n\nMore Background\nWe run a production site / app (Ghost blog based) on an Azure AKS Cluster.  Right now we manually push our updated containers to a private ACR (Azure Container Registry) and then update from the command line with Kubectl.\nThat being said we previously used Docker Cloud for our orchestration and fully integrated re-deploying our production / staging services using GitLab-Ci.\nThat GitLab-Ci integration is the goal, and the 'Why' behind this question.\nMy Question\nSince we previously used Docker Cloud (doh, should have gone K8s from the start) how should we handle the fact that GitLab-Ci was able to make use of Secrets created the Docker Cloud CLI and then authenticate with the Docker Cloud API to trigger actions on our Nodes (ie. re-deploy with new containers etc).\nWhile I believe we can build a container (to be used by our GitLab-Ci runner) that contains Kubectl, and the Azure CLI, I know that Kubernetes also has a similar (to docker cloud) Rest API that can be found here (https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster) \u2014\u00a0specifically the section that talks about connecting WITHOUT Kubectl appears to be relevant (as does the piece about the HTTP REST API).\nMy Question to anyone who is connecting to an Azure (or potentially other managed Kubernetes service):\n\nHow does your Ci/CD server authenticate with your Kubernetes service provider's Management Server, and then how do you currently trigger an update / redeployment of an updated container / service?\n\nIf you have used the Kubernetes HTTP Rest API to re-deploy a service your thoughts are particularly value-able!\nKubernetes Resources I am Reviewing\n\nHow should I manage deployments with kubernetes\nKubernetes Deployments\n\nWill update as I work through the process."}, {"role": "assistant", "content": "Creating the integration\nI had the same problem of how to integrate the GitLab CI/CD with my Azure AKS Kubernetes cluster. I created this question because I was having some error when I tried to add my Kubernetes cluester info into GitLab.\nHow to integrate them:\n\nInside GitLab, go to \"Operations\" > \"Kubernetes\" menu.\nClick on the \"Add Kubernetes cluster\" button on the top of the page\nYou will have to fill some form fields, to get the content that you have to put into these fields, connect to your Azure account from the CLI (you need Azure CLI installed on your PC) using az login command, and then execute this other command to get the Kubernetes cluster credentials: az aks get-credentials --resource-group <resource-group-name> --name <kubernetes-cluster-name>\nThe previous command will create a ~/.kube/config file, open this file, the content of the fields that you have to fill in the GitLab \"Add Kubernetes cluster\" form are all inside this .kube/config file\n\nThese are the fields:\n\nKubernetes cluster name: It's the name of your cluster on Azure, it's in the .kube/config file too. \nAPI URL: It's the URL in the field server of the .kube/config file.\nCA Certificate: It's the field certificate-authority-data of the .kube/config file, but you will have to base64 decode it.\n\nAfter you decode it, it must be something like this:\n-----BEGIN CERTIFICATE-----\n...\nsome base64 strings here\n...\n-----END CERTIFICATE-----\n\n\nToken: It's the string of hexadecimal chars in the field token of the .kube/config file (it might also need to be base 64 decoded?). You need to use a token belonging to an account with cluster-admin privileges, so GitLab can use it for authenticating and installing stuff on the cluster. The easiest way to achieve this is by creating a new account for GitLab: create a YAML file with the service account definition (an example can be seen here under Create a gitlab service account in the default namespace) and apply it to your cluster by means of kubectl apply -f serviceaccount.yml.\nProject namespace (optional, unique): I leave it empty, don't know yet for what or where this namespace can be used.\n\nClick in \"Save\" and it's done. Your GitLab project must be connected to your Kubernetes cluster now.\nDeploy\nIn your deploy job (in the pipeline), you'll need some environment variables to access your cluster using the kubectl command, here is a list of all the variables available:\nhttps://docs.gitlab.com/ee/user/project/clusters/index.html#deployment-variables\nTo have these variables injected in your deploy job, there are some conditions:\n\nYou must have added correctly the Kubernetes cluster into your GitLab project, menu \"Operations\" > \"Kubernetes\" and these steps that I described above\nYour job must be a \"deployment job\", in GitLab CI, to be considered a deployment job, your job definition (in your .gitlab-ci.yml) must have an environment key (take a look at the line 31 in this example), and the environment name must match the name you used in menu \"Operations\" > \"Environments\".\n\nHere are an example of a .gitlab-ci.yml with three stages:\n\nBuild: it builds a docker image and push it to gitlab private registry\nTest: it doesn't do anything yet, just put an exit 0 to change it later\nDeploy: download a stable version of kubectl, copy the .kube/config file to be able to run kubectl commands in the cluster and executes a kubectl cluster-info to make sure it is working. In my project I didn't finish to write my deploy script to really execute a deploy. But this kubectl cluster-info command is executing fine.\n\nTip: to take a look at all the environment variables and their values (Jenkins has a page with this view, GitLab CI doesn't) you can execute the command env in the script of your deploy stage. It helps a lot to debug a job."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to write .gitlab-ci.yml job to run only in merge-request\n\nHow to right write job in .gitlab-ci.yml when it run only in  merge requests?\ntest_c:\n  stage: test\n  script:\n    - echo \"This job tests something. It will only run when all jobs in the\"\n    - echo \"build stage are complete.\"\n  only:\n    - merge_requests\n\nThis job not run in merge request, but not run and in commint in master or develop."}, {"role": "assistant", "content": "Gitlab documentation recommends using 'rules' instead of 'only'. You can accomplish only merge_requests by doing the following:\ntest_c:\n  stage: test\n  script:\n    - echo \"This job tests something. It will only run when all jobs in the\"\n    - echo \"build stage are complete.\"\n  rules:\n    - if: '$CI_PIPELINE_SOURCE == \"merge_request_event\"'\n\nhttps://docs.gitlab.com/ee/ci/yaml/#workflowrules"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to remove a forked project in Gitlab\n\nI forked a project to a group. But there is no option to delete that forked project. I saw danger zone in Github. Is there any option available to delete forked project from Gitlab?"}, {"role": "assistant", "content": "login with master role in the repository.\ngo to forked project. then from left panel, go to Settings => General.\nlike this:\n\nclick the Expand from Advance settings panel.\n\ngo to bottom page and click Remove project.\n\nthen type your projectName and click Confirm.\n\nI hope is useful."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Run gitlab-ci.yml only when merge request to master made\n\nI am currently having my project in GitLab and Heroku. What I wanna do is as soon as I ask for merge request with my feature branch (let's call it crud-on-spaghetti), I want to automatically run the tests on this branch (npm test basically, using Mocha/Chai), and after they succeed, merge this crud-on-spaghetti with master, commit it and push it to origin/master (which is remote on GitLab) and after git push heroku master (basically, push it to the master branch in Heroku, where my app is stored). I have read several articles on GitLab CI and I think this is more suitable for me (rather than Heroku CI, because I do not have DEV and PROD instances). \nSo, as of now, I do this manually. And this is my .gitlab-ci.yml file now (which is not committed/pushed yet):\nstages:\n  - test\n  - deploy\n\ntest_for_illegal_bugs:\n  stage: test\n  script:\n    - npm test\n\ndeploy_to_dev:\n  stage: deploy\n  only:\n    - origin master\n  script:\n    - git commit\n    - git push origin master\n    - git pull heroku master --rebase\n    - git push heroku master\n\nHence, my questions is: What do I exactly need to write in .gitlab-ci.yml in order to automate all these \"manipulations\" (above)?\nPS. And another (theoretical) follow-up question: how is GitLab-CI Runner triggered? For instance, if I want it to trigger upon merge request with master, do I do that using only: ... in .gitlab-ci.yml?"}, {"role": "assistant", "content": "As of 2023 the keywords only and except have been deprecated in favor of rules (see docs).\nIn newer versions\nUsing rules: to restrict the execution of a job to a merge request to the target branch:\n  rules:\n    - if: '$CI_PIPELINE_SOURCE == \"merge_request_event\" && $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == \"master\"'\n\nFor older versions\nRestrict stages to Merge Requests:\nTo have your test stage only being executed when a Merge Request (MR) is opened, use:\n   only:\n     - merge_requests\n\nAccording to the Gitlab docs, you can further restrict this to only being executed for MRs with a certain target branch, e.g. only MRs for master\n   only:\n     - merge_requests\n   except:\n     variables:\n       - $CI_MERGE_REQUEST_TARGET_BRANCH_NAME != \"master\"\n\nThis adds an exception for all target branches that are not master.\nRestrict stages to Branches:\nAs already mentioned by @marcolz, this is achieved by\n   only:\n     - master\n\nto only execute the stage for pushes to the master branch."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Open a file directly from a GitLab private repository\n\nI have a private repository on a GitLab server and using the SSH I can pull a project using git clone.\nBut I want to run a script on linux command line directly from the server (more specific, a Drupal / Drush .make file)\nI tried to run it using the raw file:\ndrush make http://server.com/user/project/raw/master/file.make\n\n(for the convenience of non Drupal users let\u2019s say)\ncurl http://server.com/user/project/raw/master/file.make\n\nWithout success. Of course, it returns me the login page.\nIs it possible?"}, {"role": "assistant", "content": "With Chris's valuable help, here is how you can run a script (drupal .make file in my case) from a GitLab server. (Probably it works for GitHub but I didn't test it. Maybe the syntax will be a bit different). (Of course this works for any type of script)\nIt can be done using the authentication tokens. Here is the documentation of the GitLab's API and here is the GitHub's API\nFor convenient I will use the https://gitlab.com as the example server.\n\nGo to https://gitlab.com/profile/account and find your \"Private token\"\nThen print the list of the projects and find the id of your project you are looking for\ncurl https://gitlab.com/api/v3/projects?private_token=<your_private_token>\nor go there with your browser (a json viewer will help a lot)\nThen print the list of the files that are on this project and find the id of your file you are looking for\ncurl https://gitlab.com/api/v3/projects/<project_id>/repository/tree?private_token=<your_private_token>\nFinally get / run the file!\ncurl https://gitlab.com/api/v3/projects/<project_id>/repository/raw_blobs/<file_id>?private_token=<your_private_token>\n\nIn case you want to run the script (drupal .make)\ndrush make https://gitlab.com/api/v3/projects/<project_id>/repository/raw_blobs/<file_id>?private_token=<your_private_token> <drupal_folder>\n(If you are here looking for a workflow to integrate GitLab with Aegir .make platforms without using tokens (maybe SSH?) please make a thread and paste here the link.)\nEDIT\nYou can get the file without the project_id by using the encoded project name. For example the my-user-name/my-project will become: my-user-name%2Fmy-project"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Can we use the Github mac app with GitLab?\n\nI like the GitHub Mac app, which I use with my GitHub account. I have joined a GitLab project and I was wondering whether I can use the GitHub app with a GitLab repository. I found a post that discuss that the Windows GitHub app works with GitLab and one that show how to add a repo. Both these posts gave me hope that the GitHub Mac App would work with GitLab. I also see that you can use BitBucket with the GitHub Mac app, but I don't understand whether and how to link a GitLab repository to my GitHub Mac app.\nMany thanks!"}, {"role": "assistant", "content": "With the mac app, you have to do the clone on the command line. Open a terminal, navigate to directory that you want to be the parent of your local repo, and git clone the repo. As soon as this is done, go into the github mac app and Go to File->Add Local Repo\nYou can then add the repo directory file picker, and from there you should be set. The first time you push back to origin through the app, it will ask for your gitlab username and password, and optionally store them in the keychain."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to access variables in gitlab-ci.yml using gitlab-ci-multi-runner on windows\n\nI can't find out how to access variables in a build-script provided by the gitlab-ci.yml-file.\nI have tried to declare variables in two ways:\n\nPrivate Variables in the Web-Interface of GitLab CI\nVariable overrides/apennding in config.toml\n\nI try to access them in my gitlab-ci.yml-files commands like that:\nmsbuild ci.msbuild [...] /p:Configuration=Release;NuGetOutputDir=\"$PACKAGE_SOURCE\"\n\nwhere $PACKAGE_SOURCE is the desired variable (PACKAGE_SOURCE) but it does not work (it does not seem to be replaced). Executing the same command manually works just as expected (replacing the variable name with its content) \nIs there some other syntax required i am not aware of?\nI have tried:\n$PACKAGE_SOURCE\n$(PACKAGE_SOURCE)\n${PACKAGE_SOURCE}\n\nPS: Verifying the runner raises no issues, if this matters."}, {"role": "assistant", "content": "I presume you are using Windows for your runner?   I was having the same issue myself and couldn't even get the following to work:\nscript:\n  - echo $MySecret\n\nHowever, reading the Gitlab documentation it has an entry for the syntax of environment variables in job scripts:\n\nTo access environment variables, use the syntax for your Runner\u2019s shell\n\nWhich makes sense as most of the examples given are for bash runners.  For my windows runner, it uses %variable%.\nI changed my script to the following, which worked for me.   (Confirmed by watching the build output.)\nscript:\n  - echo %MySecret%\n\nIf you're using the powershell for your runner, the syntax would be $env:MySecret"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to pull a remote branch locally?\n\nI created a project on Gitlab and cloned it on my computer. So I only have one branch (master) locally (git branch only shows master). A colleague created a new branch. So now there are 2 branches on Gitlab but not on my computer.\nHow do I do to have the branch created by my co-worker on my computer too so as git branch shows both master and  new-branch ?\nThank you."}, {"role": "assistant", "content": "First, update your remote-tracking branches (local replicas of the remote branches, with which you can't interact in the same way you do with your own local branches). It's typically done with\ngit fetch\n\n(without any parameters, --all is implied)\nYour local repo will then know every new branch your coworker could have created since you last fetched (or pulled, since a pull does a fetch as a first step).\nThen you'll be able to create a local counterpart for any of these remote branches with\ngit checkout <branchName>\n\nHere, note that <branchName> is meant to be given without the <remote>/ prefix, or else git will attempt to check out the so-named remote-tracking branch, which it can't, by design. At this point it will then resolve the branch ref to the commit which this remote-tracking branch points to, check this commit out directly, resulting in a detached HEAD state. (which is no big deal but can unsettle people starting to use git)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab: There has been a runner system failure\n\nI use Gitlab for doing Continuous Integration and Development and all of a sudden I get this error message \"There has been a runner system failure, please try again\"\n\nThere's no real error message or error code.\nI've tried restarting the gitlab runner, using gitlab-runner restart, I've done a reboot of the server its running on but I keep getting this error message on Gitlab whenever I push a code change."}, {"role": "assistant", "content": "After a couple of hours, I realized the issue is that the server that Gitlab Runner is running on has no space left.\nI logged into the server in question.  Looked at the Gitlab log file using the following command:\njournalctl -u gitlab-runner\nAnd it showed me the following logs:\nMay 21 08:20:41 gitlab-runner[18936]: Checking for jobs... received                       job=178911 repo_url=https://.......git runner=f540b942\nMay 21 08:20:41 gitlab-runner-01 gitlab-runner[18936]: WARNING: Failed to process runner                   builds=0 error=open /tmp/trace543210445: no space left on device executor=docker runner=f540b942\n\nTo fix this issue I ran the docker container prune command which clears out stopped containers.\nAlternatively you could use the docker system prune command which would remove all unused objects.\nSee https://linuxize.com/post/how-to-remove-docker-images-containers-volumes-and-networks/ for more information about those docker commands.\nAfterwards, I no longer got the error on Gitlab when pushing changes."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab Request to merge branch-A into develop (3 commits behind) should I worry?\n\nWhen creating a merge request in gitlab I often get a message:\nRequest to merge branch-A into develop ([x] commits behind) \nwhat does gitlab want to tell me?\nshould I worry or do I need to fix something (what)?"}, {"role": "assistant", "content": "After some time a merge request is open in a project it is normal that the version of the branch you are trying to merge into becomes outdated due to other people merging their own changes to it. \nGitlab helps you by showing how much the version of the branch you updated is behind the remote branch. \nBeing behind will not set any hindrance to the act of merging, but it is a common practice to rebase your commits on top of the branch your merging into. This will make your merge request updated by putting your commits chronologically after the ones that already are in that branch. That approach makes the work of the person responsible for the merge easier because the commiter himself has already resolved any conflicts that would have happened.\nTo do a rebase following the scenario you proposed would be like this:\n# Add a remote named `upstream` pointing to the original repository\ngit remote add upstream https://gitlab.example.com/example/your_project.git\n\n# Fetch the latest commmits from `upstream`\ngit fetch upstream\n\n# Checkout our branch-A\ngit checkout branch-A\n\n# Rebase our branch on top of the `upstream/develop` branch\ngit rebase upstream/develop\n\n# If needed fix any conflicts that may have appeared and then `git rebase --continue`  \n\n# Push the changes to the branch of your merge request\ngit push --force origin branch-A\n\nNote: The --force flag is necessary when you push because you are rewriting the commit history of origin/branch-A. From git's doc:\n\n[--force] can cause the remote repository to lose commits; use it with care."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to change the source branch for existing merge request in gitlab?\n\nI have a merge request and a source branch is already bound to it. Now I pushed another branch and want to change the merge request to be point to the new branch. Is that possible with gitlab-ce? If yes, how?\nIn essence, I want to use \"Fast-forward merge\" as merge method without being forced to force-push to the source branch."}, {"role": "assistant", "content": "No, regarding https://gitlab.com/gitlab-org/gitlab-foss/-/issues/47020 this is unfortunately not possible. The statement is from last year, but it seems that there were no changes in supporting this for now.\nTo not lose the discussion completely, you can link the old MR in the new MR. With that you at least have some indirect relation to the discussion."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to get total time spend in Gitlab?\n\nIs there a way to get the total time spend on all issues that a user have spend with the time tracking /spend slash command?\nTime tracking stats with the API gets just a small amount of data: https://docs.gitlab.com/ce/api/issues.html#get-time-tracking-stats\nGitlab CE 9.1.4"}, {"role": "assistant", "content": "As I see it is possible to parse comments from API v3 and calculate total. \nFor example,\nhttps://gitlab.com/api/v3/projects/:id/issues/:issue_id/notes?private_token=your_token\n{\n  id: 73113225,\n  body: \"added 1h of time spent at 2018-05-15\",\n  attachment: null,\n  author: {\n    ...\n    username: \"mnvxxx\",\n  },\n  ...\n}\n\nMore info:\nhttps://docs.gitlab.com/ee/api/notes.html\nUPDATE\nCurrently I has created instrument for calculating spent time by every contributor. I hope it will be helpful:\nhttps://github.com/zubroide/gitpab"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Using Gitlab Variables in Gitlab README.md for SonarQube Badges\n\nI'm using Gitlab and Sonarqube and the Sonarqube Plugin SVG Badges.\nTo represent the Sonarqube state on gitlab I have something like this in my README.md file:\n[![coverage](https://sonar.domain.com/api/badges/measure?key=com.domain:projectname&metric=coverage)](https://sonar.domain.com/component_measures/metric/coverage/list?id=de.domain:projectname)\n\nThis works perfect. My badge is shown, the link is working, everything is fine.\nIs there some way to build something like:\n[![coverage](https://sonar.domain.com/api/badges/measure?key={MYDOMAIN}:{THIS}&metric=coverage)](https://sonar.domain.com/component_measures/metric/coverage/list?id={MYDOMAIN}:{THIS})\n\nI want to provide a skeleton that every Developer just can copy and paste into their README.md file and the variables are filled into the README automatically, with something like .gitlab-ci.yml\nI also tried the permanent Gitlab Variables mentioned here but that wasn't working too!\n [![coverage](https://sonar.domain.com/api/badges/measure?key=com.mydomain:$CI_PROJECT_NAME&metric=coverage)](https://sonar.domain.com/component_measures/metric/coverage/list?id={MYDOMAIN}:$CI_PROJECT_NAME)\n\nAnyone has some idea?"}, {"role": "assistant", "content": "The variables in https://gitlab.com/help/ci/variables/README.md are present only in a CI environment (i.e. a job), so you can't use them in the Markdown viewer when displaying the file. - That's a great idea for a feature proposal, though. I opened one - https://gitlab.com/gitlab-org/gitlab-ce/issues/32255. Feel free to chime in.\nWhat you could do is add a placeholder where you want those variables to go and then create a job which sed's them.\nupdate_readme:\n  script:\n    - echo $CI_PROJECT_NAME # Sanity check\n    - sed -ie \"s/{THIS}/$CI_PROJECT_NAME/g\" README.md\n\nNote the use of double-quotes (\") and not single quotes ('). Using double-quotes will interpolate $CI_PROJECT_NAME while single-quotes would just retain it's literal value."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Only 'npm install' in GitLab CI when package.json has been updated\n\nI'm using GitLab CI for a project and the first step of the process is npm install. I cache node_modules for quicker runs of the same job later on, and also define them as build artifacts in order to use them in later stages. However, even though I cache node_modules and it's up-to-date, calling npm install each time the install_packages job is run takes a long time, since the command goes through all of package.json and checks for updates of packages and such (I assume).\nIs there any way to only run npm install in the install_packages job depending on some condition? More specifically (what I think would be the best solution), whether or not package.json has been changed since last build?\nBelow is the relevant part of my .gitlab-ci.yml file:\nimage: node:6.9.1\n\nstages:\n  - install\n  - prepare\n  - deploy\n\ninstall_packages:\n  stage: install\n  script:\n    - npm prune\n    - npm install\n  cache:\n    key: ${CI_BUILD_REF_NAME}\n    paths:\n      - node_modules/\n  artifacts:\n    paths:\n      - node_modules/\n  only:\n    - master\n    - develop\n\nbuild_and_test:\n  stage: prepare\n  script:\n    #do_stuff...\n\ndeploy_production:\n  stage: deploy\n  #do_stuff...\n\ndeploy_staging:\n  stage: deploy\n  #do_stuff..."}, {"role": "assistant", "content": "Just use the only:changes flag doc\nThe job will be:\ninstall_packages:\n  stage: install\n  script:\n    - npm prune\n    - npm install\n  cache:\n    key: ${CI_COMMIT_REF_NAME}\n    paths:\n      - node_modules/\n  artifacts:\n    paths:\n      - node_modules/\n  only:\n    refs:\n      - master\n      - develop\n    changes:\n      - package.json\n\nAnother point is: You set the cache the right way?\nRead this:\nhttps://docs.gitlab.com/runner/configuration/autoscale.html#distributed-runners-caching\nhttps://docs.gitlab.com/ee/ci/caching/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "XAMPP: Another web server is already running\n\nI get the following error after installing gitlab..\nroot@Blase:~# sudo /opt/lampp/lampp start\nStarting XAMPP for Linux 7.0.9-1...\nXAMPP: Starting Apache...fail.\n[XAMPP:  Another web server is already running.][1]\nXAMPP: Starting MySQL...already running.\n\nI cannot access my localhost/phpmyadmin or any projects folder as am redirected to Gitlab.\nI tried to view which program is using port 80 by running:\n\"netstat -tulpn | grep --color :80\" and i got the output shown in attached image.\nAny help guys?"}, {"role": "assistant", "content": "I had to stop all the services, \n$sudo /etc/init.d/apache2 stop\n\n$sudo /etc/init.d/mysql stop\n\n$sudo /etc/init.d/proftpd stop\n\nThen I restarted the server\nsudo /opt/lampp/lampp restart"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to uninstall gitlab from local ubuntu 14.04 server\n\nHow do I uninstall gitlab?\nI deleted the /home/gitlab directory but it still opens up when I browse to my hostname."}, {"role": "assistant", "content": "This worked on ubuntu 16.04\nsudo apt-get remove gitlab-ce\n\nsudo rm -rf /var/opt/gitlab\n\n--kill all process live\nsudo pkill -f gitlab\n\n-- Remove paths\nsudo rm -rf /opt/gitlab\n\nsudo rm -rf /etc/gitlab\n\nrm -rf /var/opt/gitlab"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to delete a Gitlab repository\n\nI have googled a while now and could not find a solution that fits the current UI of Gitlab. I am trying to remove a repository I previously created on Gitlab. I navigate to edit project by clicking the settings cog on the right. After scrolling down to the bottom I can not find a section called remove project. Instead, I only see rename project. I should have the proper rights because I am the master of the project.\nAny ideas?"}, {"role": "assistant", "content": "Go to Settings > Expand Advanced Settings > Remove Project"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "how to create a gitlab bot to automate issues handling\n\nWe're working on a few project hosted on Gitlab and it would be really convenient for us to have a bot to automate some issues handling.\nE.g.: automatically close issues that have been tagged as 'waiting answer from client' more than 20 days ago\nI can't find any guide nor tutorial on how doing this, I don't even know if it could be done entirely in GitHub or do I need to create my bot from an external service."}, {"role": "assistant", "content": "Depending on exactly what you want to do, there are a number of options. I've used all of these approaches for different tasks:\n\nIf you want to write something from scratch, and have full control over every aspect of the bot's workflow, the python-gitlab library is very nice.\nIf you want something that mainly responds to events gidgetlab is great for this.\nIf you want something that automates a merge-request workflow, you might just want to run an instance of marge-bot.\nIf you want something more sophisticated, and you don't want to start from scratch, it might be worth forking some of GitLab's internal bot repos.\n\nThe triage-ops repo automates triage on labels and MRs, using the gitlab-triage gem.\nThe async-retrospectives repo automates the generation of end-of-sprint information, which is then posted as an issue. There's a blog post you can read about it.\n\n\n\nIn your case, if it's mostly a matter of closing stale issues, etc. I would be inclined to fork triage-ops, which already has policies for this already. The policies themselves are written as YAML files, and run as scheduled GitLab pipelines, so it's pretty easy to get started, you just have to specialise the policies to suit your workflow."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Closing gitlab merge request\n\nWe are using Gitlab (the gitlab.com free version).  My colleague is creating merge requests and we are merging from one branch (development) into another (master).  When my colleague merges into master the MR is shown as Merged.  I am then running some tests on the merged branch (not done automatically through GL currently) and when happy with the merge I am wanting to close the merge request.  However I do  not have any option to close it - I do not have a close button and if I type /close in the comments it does not do anything.\nNeither my colleague or myself are able to close the MRs.  We both have Master status and have tried changing various MR project settings but to no avail.\nPLease can anyone help?"}, {"role": "assistant", "content": "In Gitlab, the merged status means the relevant commits have been merged and no action is needed.\nA closed merge request is one that has been put aside or considered irrelevant. It is therefore not merged into the code base.\nTherefore, you only merge MRs when you're happy with the changes and close them if you think the changes are not worthy of being integrated into the code base ever.\nA typical workflow would be the following:\n\nUser A works on a new feature in a feature branch and pushes their work to that branch.\nThey can open a merge request to merge their feature branch into master.\nUser B pulls the feature branch, eventually rebasing it onto master, and runs the tests they want.\nIf User B is happy with the changes/new feature, they can merge the MR  into master (or whatever branch you merge into)\nThe merge request will be shown as merged\n\nOf course it's better if the tests run automatically in a CI."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Am I allowed to use GitLab Community Edition for commercial projects? [closed]\n\nClosed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.\n                                \n                            \n\n\n\n\n\n\n\n\n\n\n\n This question does not appear to be about programming within the scope defined in the help center.\n\n\nClosed 9 years ago.\n\n\n\n\n\n\n\n                        Improve this question\n                    \n\n\n\nI've been just handed the access to a VPS at work, and I thought of installing GitLab CE on it for better teamwork organisation.\nDoes the GitLab CE license allow me to do so?"}, {"role": "assistant", "content": "Yup, it is under the MIT license. There is nothing preventing you from using it for commercial projects. The other editions simply add more features and support."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to reuse job in .gitlab-ci.yml\n\nI currently have two jobs in my CI file which are nearly identical. \nThe first is for manually compiling a release build from any git branch. \ndeploy_internal:\n  stage: deploy\n  script: ....<deploy code>\n  when: manual\n\nThe second is to be used by the scheduler to release a daily build from develop branch. \nscheduled_deploy_internal:\n  stage: deploy\n  script: ....<deploy code from deploy_internal copy/pasted>\n  only: \n      variables:\n          - $MY_DEPLOY_INTERNAL != null\n\nThis feels wrong to have all that deploy code repeated in two places. It gets worse. There are also deploy_external, deploy_release, and scheduled variants.\nMy question:\nIs there a way that I can combine deploy_internal and scheduled_deploy_internal such that the manual/scheduled behaviour is retained (DRY basically)? \nAlternatively: Is there is a better way that I should structure my jobs?\nEdit:\nOriginal title: Deploy job. Execute manually except when scheduled"}, {"role": "assistant", "content": "You can use YAML anchors and aliases to reuse the script.  \ndeploy_internal:\n  stage: deploy\n  script:\n    - &deployment_scripts |\n      echo \"Deployment Started\"\n      bash command 1\n      bash command 2\n  when: manual\n\nscheduled_deploy_internal:\n  stage: deploy\n  script:\n    - *deployment_scripts\n  only:\n    variables:\n      - $MY_DEPLOY_INTERNAL != null\n\nOr you can use extends keyword.\n.deployment_script:\n  script:\n    - echo \"Deployment started\"\n    - bash command 1\n    - bash command 2\n\ndeploy_internal:\n  extends: .deployment_script\n  stage: deploy\n  when: manual\n\nscheduled_deploy_internal:\n  extends: .deployment_script\n  stage: deploy\n  only:\n    variables:\n      - $MY_DEPLOY_INTERNAL != null"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Is there a way to disable \"remove source branch\" default option?\n\nWe are working on Gitlab and each time I start merging a branch, Gitlab makes the option \"Remove source branch\" checked by default (which is -I think- dangerous).\n\nAs I don't guarantee that me or a colleague can forget to uncheck this option and make the mistake of removing the branch, I'm wondering if there is a solution to make it unchecked by default (which is -I think- will be more secure)?"}, {"role": "assistant", "content": "Go to Settings > General > Merge requests\nUncheck the box: Enable 'Delete source branch' option by default\n\nThis option is only available for the maintaniner role."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab runner pulls image for every job\n\nI have a GitLab runner using docker as the executor. My problem is, it pulls the image I have defined for every job, which takes more time to finish the pipeline\n\nHow can I cache the image and add a pull policy for the job or the runner ? Anyone please?"}, {"role": "assistant", "content": "The pull policy by default for a docker executor is \"Always\". You can use \"if-not-present\" pull policy to make sure it is only pulled when it is not available locally.\nRead the documentation for option here and how the policies work here"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to resolve \"GitLab: API is not accessible\" when pushing to a new repository?\n\nwe have a locally-hosted Enterprise Edition of GitLab at my place of employment (currently at v7.12.00-ee ceb5083). I can create a repository through the GUI without issue.  But when I try to add anything to the repository, I get this error:\nD:\\ws\\testing [master]> git push -u origin master\nCounting objects: 3, done.\nWriting objects: 100% (3/3), 219 bytes | 0 bytes/s, done.\nTotal 3 (delta 0), reused 0 (delta 0)\nremote: GitLab: API is not accessible\nTo http://gitlab.ops.cld/duffrw/testing.git\n ! [remote rejected] master -> master (pre-receive hook declined)\nerror: failed to push some refs to 'http://gitlab.ops.cld/duffrw/testing.git'\n\nI see in the /var/log/gitlab/gitlab-shell/gitlab-shell.log file that the API isn't responding, and is giving an \"Internal Server Error\":\nE, [2015-07-22T16:05:51.812454 #15110] ERROR -- : API call <POST http://127.0.0.1:8080/api/v3/internal/allowed> failed: 500 => <{\"message\":\"500 Internal Server Error\"}>.\n\nA few questions... Where can I go from here? There must some sort of service provider that isn't running. Why not? What's it called? How do I start it?\nI checked in /var/log/gitlab/nginx/gitlab_access.log and found these lines, but I didn't see anything interesting:\n172.31.201.164 - - [22/Jul/2015:16:05:50 +0000] \"GET /duffrw/testing.git/info/refs?service=git-receive-pack HTTP/1.1\" 401 0 \"-\" \"git/1.9.5.msysgit.1\"\n172.31.201.164 - - [22/Jul/2015:16:05:50 +0000] \"GET /duffrw/testing.git/info/refs?service=git-receive-pack HTTP/1.1\" 401 0 \"-\" \"git/1.9.5.msysgit.1\"\n172.31.201.164 - duffrw [22/Jul/2015:16:05:51 +0000] \"GET /duffrw/testing.git/info/refs?service=git-receive-pack HTTP/1.1\" 200 179 \"-\" \"git/1.9.5.msysgit.1\"\n172.31.201.164 - duffrw [22/Jul/2015:16:05:51 +0000] \"POST /duffrw/testing.git/git-receive-pack HTTP/1.1\" 200 124 \"-\" \"git/1.9.5.msysgit.1\"\n\nThere aren't any errors for the push of this repository in /var/log/gitlab/nginx/gitlab_error.log and /var/log/gitlab/nginx/error.log is completely empty.\nWhat am I missing?\nUpdate:\nUsing the gitlab-ctl tail command is very handy!  It revealed a stack trace, which I sent to GitLab and they told me that this was a bug in 7.12.00. It is fixed in 7.13.00."}, {"role": "assistant", "content": "If using gitlab.com, the server is either being updated or having issues.\nYou can check https://status.gitlab.com for updates from the GitLab team.\nThere's also a Twitter account you can follow: https://twitter.com/gitlabstatus"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Set default reviewers for merge request in GitLab\n\nHow I can set default reviewers in GitLab Premium?\nIn Settings \u2192 General I have only Merge request (MR) approvals, not reviewers."}, {"role": "assistant", "content": "You can use \"Default description template for merge requests\" either via Settings->Merge Requests or via file in .gitlab/merge_request_templates to do it via a workaround. (Doc)\nIn the template you can use the chat code\n/assign_reviewer @user1 @user2 @user3\n\nto automatically assign user1, user2 and user3 as reviewers when creating a new MR."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "AWS ECS: Force redeployment on new latest image in ECR\n\nI know that there are already countless questions in this direction, but unfortunately I was not able to find the right answer yet. If a post already exists, please just share the link here.\nI have several gitlab CI / CD pipelines. The first pipeline uses Terraform to build the complete infrastructure for an ECS cluster based on Fargate. The second / third pipeline creates nightly builds of the frontend and the backend and pushes the Docker Image with the tag \"latest\" into the ECR of the (staging) AWS account.\nWhat I now want to achieve is that the corresponding ECS tasks are redeloyed so that the latest Docker images are used. I actually thought that there is a way to do this via CloudWatch Events or whatsoever, but I don't find a really good starting point here. A workaround would be to install the AWS CLI in the CI / CD pipeline and then do a service update with \"force new deployment\". But that doesn't seem very elegant to me. Is there any better way here?\nConditions:\n\nThe solution must be fully automated (either in AWS or in gitlab CI / CD)\nSwitching to AWS CodePipeline is out of discussion\nIdeally as close as possible to AWS standards. I would like to avoid extensive lambda functions that perform numerous actions due to their maintainability.\n\nThanks a lot!"}, {"role": "assistant", "content": "Ok, for everybody who is interested in an answer. I solved it that way:\nI execute the following AWS CLI command in the CICD pipeline\naws ecs update-service --cluster <<cluster-name>> --service <<service-name>> --force-new-deployment --region <<region>>\n\nNot the solution I was looking for but it works."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "SSH Key asks for password\n\nI stuck here now for like 2 Days a week.\nI've got a CentOs machine with Gitlab4 and gitolite. Everything worked fine for weeks, but suddenly last weekend something strange happend quite all binaries disappeared from the mashine ( like yum, python, ruby, mysql ect. ) i've really no clue how that can happn... After hours of reinstalling and compiling gitlab was working again.\nBut i cant get the ssh keys between the gitlab and git user working.\nI already deleted and recreated the git user, set again all permissions, recreated the ssh keys, reinstalld gitolite ect. But nothing worked i keep getting the same error.\ngit user .ssh folder\n-rwx------ 1 git git  557 Mar 27 16:46 authorized_keys\n\ngitlab user .ssh folder\n-rw------- 1 gitlab gitlab 1671 Mar 27 16:45 id_rsa\n-rw-r--r-- 1 gitlab gitlab  406 Mar 27 16:45 id_rsa.pub\n-rw-r--r-- 1 gitlab gitlab  391 Mar 27 16:50 known_hosts\n\nSSH error:\nssh -vvvT git@localhost\nOpenSSH_4.3p2, OpenSSL 0.9.8e-fips-rhel5 01 Jul 2008\ndebug1: Reading configuration data /etc/ssh/ssh_config\ndebug1: Applying options for *\ndebug2: ssh_connect: needpriv 0\ndebug1: Connecting to localhost [127.0.0.1] port 22.\ndebug1: Connection established.\ndebug1: identity file /home/gitlab/.ssh/identity type -1\ndebug3: Not a RSA1 key file /home/gitlab/.ssh/id_rsa.\ndebug2: key_type_from_name: unknown key type '-----BEGIN'\ndebug3: key_read: missing keytype\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug3: key_read: missing whitespace\ndebug2: key_type_from_name: unknown key type '-----END'\ndebug3: key_read: missing keytype\ndebug1: identity file /home/gitlab/.ssh/id_rsa type 1\ndebug1: identity file /home/gitlab/.ssh/id_dsa type -1\ndebug1: Remote protocol version 2.0, remote software version OpenSSH_4.3p2\ndebug1: match: OpenSSH_4.3p2 pat OpenSSH*\ndebug1: Enabling compatibility mode for protocol 2.0\ndebug1: Local version string SSH-2.0-OpenSSH_4.3p2\ndebug1: SSH2_MSG_KEXINIT sent\ndebug1: SSH2_MSG_KEXINIT received\ndebug2: kex_parse_kexinit: diffie-hellman-group-exchange-sha1,diffie-hellman-group1-sha1\ndebug2: kex_parse_kexinit: ssh-rsa,ssh-dss\ndebug2: kex_parse_kexinit: aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,arcfour,aes192-cbc,aes256-cbc,[email\u00a0protected],aes128-ctr,aes192-ctr,aes256-ctr\ndebug2: kex_parse_kexinit: aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,arcfour,aes192-cbc,aes256-cbc,[email\u00a0protected],aes128-ctr,aes192-ctr,aes256-ctr\ndebug2: kex_parse_kexinit: hmac-md5,hmac-sha1,hmac-ripemd160,[email\u00a0protected],hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: hmac-md5,hmac-sha1,hmac-ripemd160,[email\u00a0protected],hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: none,zlib\ndebug2: kex_parse_kexinit: none,zlib\ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: first_kex_follows 0 \ndebug2: kex_parse_kexinit: reserved 0 \ndebug2: kex_parse_kexinit: diffie-hellman-group-exchange-sha1,diffie-hellman-group1-sha1\ndebug2: kex_parse_kexinit: ssh-rsa,ssh-dss\ndebug2: kex_parse_kexinit: aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,arcfour,aes192-cbc,aes256-cbc,[email\u00a0protected],aes128-ctr,aes192-ctr,aes256-ctr\ndebug2: kex_parse_kexinit: aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,arcfour,aes192-cbc,aes256-cbc,[email\u00a0protected],aes128-ctr,aes192-ctr,aes256-ctr\ndebug2: kex_parse_kexinit: hmac-md5,hmac-sha1,hmac-ripemd160,[email\u00a0protected],hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: hmac-md5,hmac-sha1,hmac-ripemd160,[email\u00a0protected],hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: none,zlib\ndebug2: kex_parse_kexinit: none,zlib\ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: first_kex_follows 0 \ndebug2: kex_parse_kexinit: reserved 0 \ndebug2: mac_init: found hmac-md5\ndebug1: kex: server->client aes128-cbc hmac-md5 none\ndebug2: mac_init: found hmac-md5\ndebug1: kex: client->server aes128-cbc hmac-md5 none\ndebug1: SSH2_MSG_KEX_DH_GEX_REQUEST(1024<1024<8192) sent\ndebug1: expecting SSH2_MSG_KEX_DH_GEX_GROUP\ndebug2: dh_gen_key: priv key bits set: 132/256\ndebug2: bits set: 502/1024\ndebug1: SSH2_MSG_KEX_DH_GEX_INIT sent\ndebug1: expecting SSH2_MSG_KEX_DH_GEX_REPLY\ndebug3: check_host_in_hostfile: filename /home/gitlab/.ssh/known_hosts\ndebug3: check_host_in_hostfile: match line 1\ndebug1: Host 'localhost' is known and matches the RSA host key.\ndebug1: Found key in /home/gitlab/.ssh/known_hosts:1\ndebug2: bits set: 505/1024\ndebug1: ssh_rsa_verify: signature correct\ndebug2: kex_derive_keys\ndebug2: set_newkeys: mode 1\ndebug1: SSH2_MSG_NEWKEYS sent\ndebug1: expecting SSH2_MSG_NEWKEYS\ndebug2: set_newkeys: mode 0\ndebug1: SSH2_MSG_NEWKEYS received\ndebug1: SSH2_MSG_SERVICE_REQUEST sent\ndebug2: service_accept: ssh-userauth\ndebug1: SSH2_MSG_SERVICE_ACCEPT received\ndebug2: key: /home/gitlab/.ssh/identity ((nil))\ndebug2: key: /home/gitlab/.ssh/id_rsa (0x848ba50)\ndebug2: key: /home/gitlab/.ssh/id_dsa ((nil))\ndebug1: Authentications that can continue: publickey,password\ndebug3: start over, passed a different list publickey,password\ndebug3: preferred publickey,keyboard-interactive,password\ndebug3: authmethod_lookup publickey\ndebug3: remaining preferred: keyboard-interactive,password\ndebug3: authmethod_is_enabled publickey\ndebug1: Next authentication method: publickey\ndebug1: Trying private key: /home/gitlab/.ssh/identity\ndebug3: no such identity: /home/gitlab/.ssh/identity\ndebug1: Offering public key: /home/gitlab/.ssh/id_rsa\ndebug3: send_pubkey_test\ndebug2: we sent a publickey packet, wait for reply\ndebug1: Authentications that can continue: publickey,password\ndebug1: Trying private key: /home/gitlab/.ssh/id_dsa\ndebug3: no such identity: /home/gitlab/.ssh/id_dsa\ndebug2: we did not send a packet, disable method\ndebug3: authmethod_lookup password\ndebug3: remaining preferred: ,password\ndebug3: authmethod_is_enabled password\ndebug1: Next authentication method: password\n\nThe auth log gives me:\nApr  2 10:19:13 venus sshd[15693]: User git not allowed because account is locked\nApr  2 10:19:13 venus sshd[15693]: Failed none for illegal user git from ::ffff:127.0.0.1 port 56906 ssh2\n\nThanks for any Help."}, {"role": "assistant", "content": "You mention:\nApr 2 10:19:13 venus shd[15693]: User git not allowed because account is locked \nApr 2 10:19:13 venus sshd[15693]: Failed none for illegal user git from ::ffff:127.0.0.1 port 56906 ssh2\n\nThis article mentions:\n\nOpenSSH now checks for locked accounts by default.\nOn Linux systems, locked accounts are defined as those that have !! in the password field of /etc/shadow.\nThis is the default entry for accounts created with the useradd command.\n  Even if you are using GSI authentication and do not need local passwords, sshd won't let the user login with this message:\n\nToo many authentication failures for username\n\n\nIn the sshd debugging info it will indicate that the account is locked:\n\nUser username not allowed because account is locked\n\n\nHere is some additional information from the sshd Manual:\n\nRegardless of the authentication type, the account is checked to ensure that it is accessible.\n    An account is not accessible if it is locked, listed in DenyUsers or its group is listed in DenyGroups.\n    The definition of a locked account is system dependant.\n    Some platforms have their own account database (eg AIX) and some modify the passwd field ( \"*LK*\" on Solaris and UnixWare, \"*\" on HP-UX, containing \"Nologin\" on Tru64, a leading \"*LOCKED*\" on FreeBSD and a leading \"!!\" on Linux).\n    If there is a requirement to disable password authentication for the account while allowing still public-key, then the passwd field should be set to something other than these values (eg \"NP\" or \"*NP*\" ).\n\nFix: Replace !! with (for example) NP in /etc/shadow.\n\n\nAs mentioned by jszakmeister (comments) and Yongcan-Frank-Lv (comments):\nsudo passwd -u git\n\nwould be enough to unlock the account."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Activating conda environment during gitlab CI\n\nMy .gitlab-ci.yml file looks like this:\nanomalydetector:\n  image: continuumio/miniconda:4.7.10\n  stage: build\n  tags:\n    - docker\n  script:\n    - conda env create -f environment.yml\n    - conda activate my-env\n    - pytest tests/.\n\nOn Gitlab, this job starts fine, and the logs read\n$ conda env create -f environment.yml\nCollecting package metadata (repodata.json): ...working... done\nSolving environment: ...working... done\n\n\n==> WARNING: A newer version of conda exists. <==\n  current version: 4.7.10\n  latest version: 4.7.11\n\nOk, so I'm using a conda version later than 4.4, so conda activate should work. However, the job fails with the following:\n# To activate this environment, use\n#\n#     $ conda activate my-env\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n\n$ conda activate my-env\n\nCommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\nTo initialize your shell, run\n\n    $ conda init <SHELL_NAME>\n\nI have then tried editing my .gitlab-ci.yml file so that there is a command\nconda init bash\n\nbut then get the message\n==> For changes to take effect, close and re-open your current shell. <==\n\nHow can I activate my conda environment in the gitlab CI process?"}, {"role": "assistant", "content": "conda init touches the .bashrc file. To reinitialize the shell you can source it:\n  - conda create --name myenv\n  - conda init bash\n  - source ~/.bashrc    # <- !!!\n  - conda activate myenv \n\nWhether this is better or worse than source activate myenv is a separate discussion, I guess."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "AWS Cloudfront error? invalidation max times while deploying?\n\nI got the error while I'm deploying something from gitlab.\n$ aws cloudfront create-invalidation --distribution-id=EVB1B2B3B4B56 --paths \"/*\"\n**An error occurred (ServiceUnavailable) when calling the CreateInvalidation operation (reached max retries: 2): CloudFront encountered an internal error. Please try again.**\n\nI sort it out by creating invalidation manually from AWS console and it works . This is the case happens sometimes causes this error, at that time I'm doing manually . What was the permanent solution ? Please help me to sort it out this."}, {"role": "assistant", "content": "I experienced a similar issue when creating multiple invalidations while deploying the same application to many distributions. The error still happens randomly, sometimes just retrying the deployment later works fine, and others fail on a different distribution.\nI found a related issue showing the same error in the github aws-cdk repo, there seems to be an error with the AWS Cloudfront API during peak hours.\n\nFrom the CloudFront team:\nCreateInvalidation API suffers from high fault rate during the daily\ntraffic peaks. It will return faults upto 50% of the requests. It is\nprimarily due to the limited capacity of the API.\nWe have evidence that some requests failed even after six retries ,\nduring the peak. We are working on improving this , but there is no\nquick fix for this and we are expecting it will get better by the end\nof Q1 2022.\n\nI still didn\u00b4t find a \"clean\" solution to this, what I have done is handle the error within my CLI script and automatically retry until it eventually succeeds."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI ignores script exit code other than 1\n\nI'm trying to set up a GitLab pipeline, so that certain exit_codes are okay for a script I'm executing.\nI have tried both shell and a ruby script, but both seem to have the same behaviour.\ntest_job:\n  stage: build\n  image: ruby:3.0\n  script:\n    - chmod +x ci/wrap.sh\n    - ./ci/wrap.sh\n  allow_failure:\n    exit_codes:\n      - 64\n\nAs you can see, I am just executing the script and nothing more, my expectation would be, that the last script executed is used a the exit status for the job.\nIn the script I'm only calling exit 64, which should be a \"allowed failure\" in that case, the pipeline log however says that the job failed because of exit code 1:\n\nHow do I get GitLab to accept the exit code of this (or a ruby) script as the job exit code?"}, {"role": "assistant", "content": "I found a way to fix this problem. Apparently Gitlab Runner uses the -e flag, which means that any non-zero exit code will cancel the job. This can be updated by using set +e, but then you still need to capture the actual exit code for the job.\nUsing $? in two different lines of the configuration does not work, because Gitlab does echo calls in-between them.\nSo the exit code needs to be captured directly, example:\nscript:\n  - set +e\n  - ruby \"ci/example.rb\" || EXIT_CODE=$?\n  - exit $EXIT_CODE"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab-runner x509: certificate signed by unknown authority\n\nI'm trying to register a new runner on gitlab following these steps :\nhttps://docs.gitlab.com/runner/register/index.html\nBut when I enter the url, token and tags, an error message pops-up saying:\n\nERROR: Registering runner... failed           runner=CS-XXX status=couldn't execute POST against https://example.com/api/v4/runners: Post https://example.com/api/v4/runners: x509: certificate signed by unknown authority\n\nI'm working on a new server and already installed the gitlab-runner."}, {"role": "assistant", "content": "you need to use tls-ca-file option during registration or in the configuration of your runner.\nHere is an example of non-interactive registration with tls-ca-file option :\ngitlab-runner register \\\n      --non-interactive \\\n      --registration-token YOUTOKEN \\\n      --url https://example.com/ \\\n      --tls-ca-file /path/to/your/ca.crt\n\nOther way, you can refer the tls-ca-file option in your config.toml under the [[runners]] section\nmore info : https://docs.gitlab.com/runner/configuration/tls-self-signed.html"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Connecting to docker-in-docker from a GitLab CI runner\n\nI have a GitLab pipeline that I want to:\n\nBuild a Java app\nTest using docker-compose\nPush to my Docker repository\n\nThe primary issue I'm having is that this works:\nservices:\n  - docker:dind\n\ndocker_test:\n  stage: docker_test\n  image: docker:latest\n  script:\n  - docker version\n\nThe output is printed as expected:\n> gitlab-ci-multi-runner exec docker --docker-privileged docker_test\n...\n$ docker version\nClient:\n Version:      17.06.0-ce\n...\nServer:\n Version:      17.06.0-ce\n...\nBuild succeeded\n\nWhile this does not (installation steps for docker-ce omitted):\nservices:\n  - docker:dind\n\ndocker_test:\n  stage: docker_test\n  image: ubuntu:latest       << note change\n  script:\n  - docker version\n\nIt fails with:\n$ docker version\nClient:\n Version:      17.06.0-ce\n API version:  1.30\n Go version:   go1.8.3\n Git commit:   02c1d87\n Built:        Fri Jun 23 21:23:31 2017\n OS/Arch:      linux/amd64\nCannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\nERROR: Build failed: exit code 1\nFATAL: exit code 1\n\nHow do I make my ubuntu image (or whatever image is going to build my project) connect to the linked Docker-in-Docker service? What is docker:latest doing that I'm not?\nI've read up on the GitLab services documentation, but it only makes sense to me from a hostname perspective. (If you have a mysql service, you can connect over mysql:3306.)\nEdit: Updating the command to echo $DOCKER_HOST, I see in the docker:latest image:\n$ echo $DOCKER_HOST\ntcp://docker:2375\n\nAnd in the ubuntu:latest image I see:\n$ echo $DOCKER_HOST\n(nothing - but SO doesn't let me add a blank code line)"}, {"role": "assistant", "content": "As the information you've added, I hope that this does work:\nservices:\n  - docker:dind\n\ndocker_test:\n  stage: docker_test\n  image: ubuntu:latest\n  variables:\n      DOCKER_HOST: \"tcp://docker:2375\"\n  script:\n  - docker version\n\nAlternatively:\nservices:\n  - docker:dind\n\ndocker_test:\n  stage: docker_test\n  image: ubuntu:latest \n  script:\n  - export DOCKER_HOST=tcp://docker:2375\n  - docker version\n\nIt seems that Gitlab does not set the DOCKER_HOST variable for custom images."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "is there any way to auto merge branches in gitlab?\n\nIn my gitlab project there are 3 main branches: develop, stage and master.\nEach time when updated code is pushed to develop branch, I have to merge it to stage branch and then merge it again to master branch manually.\nThis doesn't seem efficient.\nIs there any way to merge branches automatically when there is no conflict?\nFurthermore, it is possible to use a file named \"gitlab-ci.yml \" for auto merge something like\n# merge develop branch to stage branch\nmerge-to-stage:\n    only:\n    - develop\n    script:\n    - merge (develop) to (stage) << something like this\n\n# merge stage branch to master branch when the job above is completed\nstage-to-master:\n    only:\n    - stage\n    script:\n    - merge (stage) to (master) << something like this\n\n\nPlease give me your kind advice."}, {"role": "assistant", "content": "There is no way to automate this within GitLab. But you can automate this using GitLab CI.\nBe aware that the GitLab CI Runners are independent from GitLab and just get a local copy of a Git repository. So your CI script wont be able to run git merge & git push out of the box.\nWhat you need to do is set up a SSH connection from the GitLab CI Runner to your GitLab instance. Use a before script for this. There are several answers on StackOverflow and a good blog post on GitLab how to achive this.\nmerge-job:\n  before_script:\n    - 'which ssh-agent || ( apt-get update -y && apt-get install openssh-client -y )'\n    - eval $(ssh-agent -s)\n    - ssh-add <(echo \"$GIT_SSH_PRIV_KEY\")\n    - mkdir -p ~/.ssh\n    - cat gitlab-known-hosts >> ~/.ssh/known_hosts\n\nThen run your Git commands like git merge. Then push.\nmerge-to-stage:\n  only:\n    - develop\n  script:\n    # If this is the last job you can stay here, otherwise better clone the repo into a working directory\n    # git clone <URL> <working-directory> && cd <working directory>\n    - git checkout stage\n    - git merge develop\n    - git push origin stage\n\nThe schema of your next pipeline jobs depend on what you mean with when there is no conflict. In your example code you merge all stage branches into the higher branch (feature to develop, develop to stage, stage to main). If so, then you should make sure that there is a merge job for each stage and these merge jobs are placed at the end of the pipeline. Then the merge won't happen if there was a CI error or a merge conflict before.\nAlternatively you could also have just one job, which uses GitLabs push options. With these options you may create merge requests for your feature branch which are automatically merged and closed when a CI Pipeline is successful. This strategy would only merge your feature branch changes and not the whole stage branches.\nmerge-to-stage-branches:\n  only:\n    - <feature branch names that are no WIP anymore>\n  script:\n    # <scripts to merge feature into develop>\n    git push -o merge_request.create -o merge_request.target=develop -o merge_request.merge_when_pipeline_succeeds\n    # <repeat merge for each stage branch>\n    # <repeat push for each stage branch>"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab: Sorry, we cannot cherry-pick this merge request automatically\n\nI got following error in the Gitlab:\nSorry, we cannot cherry-pick this merge request automatically. This merge request may already have been cherry picked, or a more recent commit may have updated some of its content.\n\nI have branch X from which I have to cherry pick commits to the branch Y. Maybe I have already done cherry pick, which is after this failed cherry pick. I have about 10 cherry picks to do.\nWhat I should to do?\nI was thinking if I create new branch Z (before Y) and try add cherry picks in the right order. Maybe that would be solution? What you think?"}, {"role": "assistant", "content": "I did the cherry picks so that I picked up the merge request commits with commands like this:\ngit cherry-pick -m 1 <merge request commit hash 1>\ngit cherry-pick -m 1 <merge request commit hash 2>\n...\ngit cherry-pick -m 1 <merge request commit hash N>\n\nThe -m 1 parameter is a little bit cryptical in the documentation, but I have done a lot of cherry picks and this is working."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Configure Gitlab account in Pycharm\n\nCan anyone explain how to configure a Gitlab account on PyCharm 3.4?\nIn the options I can see Github, but nothing about how to configure a Gitlab account."}, {"role": "assistant", "content": "Install gitlab Integration plugin from settings menu"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to restrict merging specific branch into other branches in Gitlab?\n\nIs there a way to restrict merging from a specific branch into other branches? Allow me to explain:\nI have a 'testing' branch and a 'master' branch in Gitlab. The team creates feature branches, merges them into 'testing' for approval and then merge the feature branch into 'master' once approved.\nSometimes, it can take months to get approval of some features, and therefore code is sat in the 'testing' branch for a while. Meanwhile, another feature branch may try to merge into 'testing' and conflicts will arise. This is expected, however, we are only human, and occasionally someone may accidentally merge 'testing' into their feature branch when handling the conflict, which is obviously wrong. Instead, we should switch to 'testing' and merge our feature branch into 'testing' thus managing the conflict within the testing branch.\nAny advise is appreciated."}, {"role": "assistant", "content": "To begin, be sure your needs is very normal and traditional.\nThe answer is ... Yes.\nHow to prevent merging from a branch to another, setting up a server Git Hook\nThese are some useful links:\n\nGit Hook explanations in Official Git Book\nGitLab server-side Hook explanations\nAn example with a Git Hook written in Ruby to prevent merging 'staging' branch to 'master' one\n\nTo help you (and for fun ^^), I wrote a dedicated hook in Python to reach your specific needs (you just need to adapt FORBIDDEN_SOURCE_BRANCH and FORBIDDEN_IF_NOT_DEST_BRANCH if you want to work with some other branches).\n#!/bin/python\n##\n## Author: Bertrand Benoit <mailto:[email\u00a0protected]>\n## Description: Git Hook (server-side) allowing to prevent merge from some branches to anothers\n## Version: 0.9\n\nimport sys, subprocess, re\n\nFORBIDDEN_SOURCE_BRANCH='testing'\nFORBIDDEN_IF_NOT_DEST_BRANCH='master'\n\n# Considers only merge commit.\nif not (len(sys.argv) >=2 and sys.argv[2] == 'merge'):\n    sys.exit(0)\n\n# Defines which is the source branch.\nwith open(sys.argv[1], 'r') as f:\n    mergeMessage=f.readline()\nmergeBranchExtract=re.compile(\"Merge branch '([^']*)'.*$\").search(mergeMessage)\nif not mergeBranchExtract:\n    print('Unable to extract branch to merge from message: ', mergeMessage)\n    sys.exit(0) # Ensures normal merge as failback\n\n# Checks if the merge (source) branch is one of those to check.\nmergeBranch=mergeBranchExtract.group(1)\nif mergeBranch != FORBIDDEN_SOURCE_BRANCH:\n  sys.exit(0) # It is NOT the forbidden source branch, so keeps on normal merge\n\n# Defines which is the current branch.\ncurrentBranchFullName=subprocess.check_output(['git', 'symbolic-ref', 'HEAD'])\ncurrentBranchExtract=re.compile(\"^.*/([^/]*)\\n$\").search(currentBranchFullName)\nif not currentBranchExtract:\n  print('Unable to extract current branch from: ', currentBranchFullName)\n  sys.exit(1) # Ensures normal merge as failback\n\n# Checks if the current (destination) branch is one of those to check.\ncurrentBranch=currentBranchExtract.group(1)\nif currentBranch != FORBIDDEN_IF_NOT_DEST_BRANCH:\n  print(\"FORBIDDEN: Merging from '\" + mergeBranch + \"' to '\" + currentBranch + \"' is NOT allowed. Contact your administrator. Now, you should use git merge --abort and keep on your work.\")\n  sys.exit(1) # This is exactly the situation which is forbidden\n\n# All is OK, so keeps on normal merge\nsys.exit(0)\n\nTo share all this work, I created a new Gitlab repository, in which I'll add further hooks when needed :)\nFor information, you can also setup protected branches to keep them safe from some users\nThis is the complete documentation about that.\nLet me know if you need further help."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Where can I manage files uploaded to wiki of a Gitlab.com project?\n\nI have uploaded some files to my Gitlab repository on \"gitlab.com\" while creating wiki for my private project.\nNow my questions are:\n\nCan I see list of the uploaded files?\nIs there any way to remove some of them?\nWhy permission of uploaded file is public? Can I change it to private?\n\nCurrent version of gitlab is Enterprise Edition\u00a08.9.4-ee."}, {"role": "assistant", "content": "Attached files trough the wiki editor are uploaded to /uploads/. As of GitLab version 8.9.0 you are unable to manage these files (i.e. deleting them).\nIf you want to manage attached files yourself you can clone the wiki as repository. You can find the clone URL in Wiki -> Git Access. It should look something like this: git@<link to gitlab>:<group/user name>/<project name>.wiki.git. In the cloned repository you'll not find the /uploads/ directory, because it is located outside of the repository. Bun there you can put your images or other attachments, and link them within your wiki. The link to the image is relative to the repo root so if your image image.png is in the root folder you can link it with markdown like this![Image title](image.png).\nPermission wise these files will only be visible to Users which have at least Guest access to your project, even if they have a direct link."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI not caching\n\nI have the following gitlab ci yaml file:\nimage: steveedson/ci\n\nstages:\n  - build\n\ncache:\n  untracked: true\n  key: \"$CI_PROJECT_ID\"\n  paths:\n    - node_modules/\n    - _site/vendor/\n    - .bundled/\n    - .yarn\n\nbuild:\n  stage: build\n  script:\n    - ls -l\n    - yarn config set cache-folder .yarn\n    - yarn install\n    - ...\n\nWhen my successful builds finish, they show:\nCreating cache 1970478...\nCreated cache\n\nAnd when the next commit triggers a build, I get:\nChecking cache for 1970478...\nSuccessfully extracted cache\n\nBut the ls -l in my first step doesn't show the cached directories. I've tried caching the cache key but this doesn't help.\nThis is running on gitlab.com, not a private server."}, {"role": "assistant", "content": "So, my configuration is correct, and Gitlab does support caches between jobs, however they have not added this to shared runners on gitlab.com, yet.\nThe issue is here https://gitlab.com/gitlab-com/infrastructure/issues/919 and should be added soon."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to import gitlab repository to bitbucket Repository\n\nI have a gitlab Repository and I want it to update it on the bitbucket account.\n\nPlease provide me steps to follow, so that it can be helpful to me to\n  migrate it in bitbucket from Gitlab."}, {"role": "assistant", "content": "1) Create the repository in Bitbucket using the UI\n2) Clone the Gitlab repository using the \"--bare\" option\ngit clone --bare GITLAB-URL\n\n3) Add the Bitbucket remote\ncd REPO-NAME\ngit remote add bitbucket BITBUCKET-URL\n\n4) Push all commits, branches and tags to Bitbucket\ngit push --all bitbucket\ngit push --tags bitbucket\n\n5) Remove the temp repository\ncd ..\nrm -rf REPO-NAME"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "./deploy.sh not working on gitlab ci\n\nMy problem is the bash script I created got this error \"/bin/sh: eval: line 88: ./deploy.sh: not found\" on gitlab. Below is my sample script .gitlab-ci.yml.\nI suspect that gitlab ci is not supporting bash script.\nimage: docker:latest\n\nvariables:\n  IMAGE_NAME: registry.gitlab.com/$PROJECT_OWNER/$PROJECT_NAME\n  DOCKER_DRIVER: overlay\n\nservices:\n  - docker:dind\n\nstages:\n  - deploy\n\nbefore_script:\n - docker login -u gitlab-ci-token -p $CI_BUILD_TOKEN registry.gitlab.com\n - docker pull $IMAGE_NAME:$CI_BUILD_REF_NAME || true\n\nproduction-deploy:\n  stage: deploy\n  only:\n    - master@$PROJECT_OWNER/$PROJECT_NAME\n  script:\n    - echo \"$PRODUCTION_DOCKER_FILE\" > Dockerfile\n    - docker build --cache-from $IMAGE_NAME:$CI_BUILD_REF_NAME -t $IMAGE_NAME:$CI_BUILD_REF_NAME .\n    - docker push $IMAGE_NAME:$CI_BUILD_REF_NAME\n    - echo \"$PEM_FILE\" > deploy.pem\n    - echo \"$PRODUCTION_DEPLOY\" > deploy.sh\n    - chmod 600 deploy.pem\n    - chmod 700 deploy.sh\n    - ./deploy.sh\n  environment:\n    name: production\n    url: https://www.example.com\n\nAnd this also my deploy.sh.\n#!/bin/bash\n\nssh -o StrictHostKeyChecking=no -i deploy.pem ec2-user@targetIPAddress << 'ENDSSH'\n // command goes here\nENDSSH\n\nAll I want is to execute deploy.sh after docker push but unfortunately got this error about /bin/bash thingy.\nI really need your help guys. I will be thankful if you can solve my problem about gitlab ci bash script got error \"/bin/sh: eval: line 88: ./deploy.sh: not found\"."}, {"role": "assistant", "content": "This is probably related to the fact you are using Docker-in-Docker (docker:dind). Your deploy.sh is requesting /bin/bash as the script executor which is NOT present in that image.\nYou can test this locally on your computer with Docker:\ndocker run --rm -it docker:dind bash\n\nIt will report an error. So rewrite the first line of deploy.sh to \n#!/bin/sh\n\nAfter fixing that you will run into the problem that the previous answer is addressing: ssh is not installed either. You will need to fix that too!"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab-CI get pom version in pipeline\n\nI'd like to build docker image via gitlab CI with project's version as a tag:\ndocker build -t dockerimage:VERSION-IN-POM .\n\nIn jenkins' pipeline i'm getting the version like that: \n${pom.version}\n\nIs it possible to read the version in a similar, convenient way from gitlab CI? Or do I have to write scripts for that?"}, {"role": "assistant", "content": "Assuming you have maven in build environment, you could use maven help plugin and grep to extract version.\nVERSION=$(mvn --non-recursive help:evaluate -Dexpression=project.version | grep -v '\\[.*')\necho $VERSION"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to deploy Python packages to Gitlab Package Registry with Poetry?\n\nI'm trying to set up Poetry to deploy packages to our internal Gitlab Package Registry. According to other sources online the repository ID should be https://gitlab.com/api/v4/projects/<project id>/packages/pypi, but no matter what I try, Poetry returns\n\n[UploadError]\nHTTP Error 404: Not Found\n\nAnyone got this working ?"}, {"role": "assistant", "content": "If you are attempting to deploy from GitLab CI, GitLab automatically creates a user and token combination that can be used to authenticate in the CI context under the user gitlab-ci-token and the password in the $CI_JOB_TOKEN variable.\nAll you need to do that is poetry specific is set the config values for poetry to know the package registry exists, then pass this for authentication. All of which can be done just in the CI config/script.\n  script:\n    - poetry build\n    - poetry config repositories.gitlab \"${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/pypi\"\n    - poetry config http-basic.gitlab gitlab-ci-token \"$CI_JOB_TOKEN\"\n    - poetry publish --repository gitlab\n\nIf you are deploying from outside of GitLab CI, then you would need that access token and to provide values as used in the script above."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Using docker-compose in a GitLab CI pipeline\n\nI'm trying to implement a GitLab continuous integration (CI) pipeline with the following .gitlab-ci.yml file:\nimage: docker:latest\n\n# When using dind, it's wise to use the overlayfs driver for\n# improved performance.\nvariables:\n  DOCKER_DRIVER: overlay\n\nservices:\n  - docker:dind\n\nbefore_script:\n  - docker info\n  - curl -L \"https://github.com/docker/compose/releases/download/1.10.0/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n  - chmod +x /usr/local/bin/docker-compose\n  - export PATH=/usr/local/bin:$PATH\n  - echo $PATH\n\nstages:\n  - build\n  - test\n\nbuild:\n  stage: build\n  script:\n    - docker-compose build\n    - docker-compose up -d\n\ntest:\n  stage: test\n  script:\n    - cd tests/tester\n    - pytest test_run_tester.py\n  except:\n    - /^.*skip_tests$/\n\nHowever, in GitLab I'm getting the following error message:\nRunning with gitlab-ci-multi-runner 1.10.4 (b32125f)\nUsing Docker executor with image docker:latest ...\nStarting service docker:dind ...\nPulling docker image docker:dind ...\nWaiting for services to be up and running...\nPulling docker image docker:latest ...\nRunning on runner-2e54fd37-project-13-concurrent-0 via scw-de9c9c...\nFetching changes...\nHEAD is now at 2504a08 Update CI config\nFrom https://lab.iperlane.com/gio/ipercron-compose\n   2504a08..5c2f23f  CI         -> origin/CI\nChecking out 5c2f23f1 as CI...\nSkipping Git submodules setup\n$ docker info\nContainers: 0\n Running: 0\n Paused: 0\n Stopped: 0\nImages: 0\nServer Version: 1.13.1\nStorage Driver: overlay\n Backing Filesystem: extfs\n Supports d_type: true\nLogging Driver: json-file\nCgroup Driver: cgroupfs\nPlugins: \n Volume: local\n Network: bridge host macvlan null overlay\nSwarm: inactive\nRuntimes: runc\nDefault Runtime: runc\nInit Binary: docker-init\ncontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1\nrunc version: 9df8b306d01f59d3a8029be411de015b7304dd8f\ninit version: 949e6fa\nSecurity Options:\n seccomp\n  Profile: default\nKernel Version: 4.8.14-docker-2\nOperating System: Alpine Linux v3.5 (containerized)\nOSType: linux\nArchitecture: x86_64\nCPUs: 4\nTotal Memory: 7.751 GiB\nName: 90395a030c02\nID: 7TKR:5PQN:XLFM:EJST:NF2V:NLQC:I2IZ:6OZG:TR4U:ZEAK:EVXE:HIF7\nDocker Root Dir: /var/lib/docker\nDebug Mode (client): false\nDebug Mode (server): false\nRegistry: https://index.docker.io/v1/\nExperimental: false\nInsecure Registries:\n 127.0.0.0/8\nLive Restore Enabled: false\nWARNING: bridge-nf-call-iptables is disabled\nWARNING: bridge-nf-call-ip6tables is disabled\n$ curl -L \"https://github.com/docker/compose/releases/download/1.10.0/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100   600    0   600    0     0   1175      0 --:--:-- --:--:-- --:--:--  1176\n\n  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n  3 7929k    3  254k    0     0   116k      0  0:01:08  0:00:02  0:01:06  258k\n 17 7929k   17 1358k    0     0   433k      0  0:00:18  0:00:03  0:00:15  704k\n 61 7929k   61 4861k    0     0  1164k      0  0:00:06  0:00:04  0:00:02 1636k\n100 7929k  100 7929k    0     0  1703k      0  0:00:04  0:00:04 --:--:-- 2300k\n$ chmod +x /usr/local/bin/docker-compose\n$ export PATH=/usr/local/bin:$PATH\n$ docker-compose build\n/bin/sh: eval: line 51: docker-compose: not found\nERROR: Build failed: exit code 127\n\nThe system seems not to be able to find docker-compose, even after installing it and adding it to the path. Is there perhaps another image such that docker-compose commands can be made, or a different way to install it in the .gitlab-ci.yml?"}, {"role": "assistant", "content": "The problem\nThis is complex problem.\nThe docker:latest image is based on alpine (Alpine Linux), which is built using musl-libc. This system is very barebones, and as such doesn't have everything a full-fledged desktop Linux might have. In fact, dynamic executables need to be compiled specifically for this system.\ndocker-compose is a Python application, bundled into a Linux executable using PyInstaller. These executables are really only expected to be able to run on the system which they were built. If you run an alpine container, and apk add file, you can see that the (dynamically-linked) executable you downloaded is expecting a specific interpreter.\n# file /usr/local/bin/docker-compose\n/usr/local/bin/docker-compose.pyinstaller: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.32, BuildID[sha1]=00747fe5bcde089bb4c2f1ba7ab5348bc02ac5bf, stripped\n\nThe problem is /lib64/ld-linux-x86-64.so.2 doesn't exist in alpine. In fact, /lib64 doesn't even exist.\nThe solution\nBecause docker-compose is a Python application, it can also be installed using pip:\nTesting this inside an alpine container:\n$ docker run --rm -it alpine /bin/bash\n\nHere are the commands you can run manually, or add to your .gitlab-ci.yml before_script:\n# apk add --no-cache python py2-pip\n...\n# pip install --no-cache-dir docker-compose\n...\n# docker-compose -v\ndocker-compose version 1.11.1, build 7c5d5e4\n\n\nIt turns out there is actually an open issue for this:\n\nhttps://github.com/docker/compose/issues/3465"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Triggering a pipeline and waiting for it to finish from another pipeline\n\nI have two different project repositories: my application repository, and an API repository. My application communicates with the API.\nI want to set up some integration and E2E tests of my application. The application will need to use the latest version of the API project when running these tests.\nThe API project is already setup to deploy when triggered\ndeploy_integration_tests:\n  stage: deploy\n  script:\n  - echo \"deploying...\"\n  environment:\n    name: integration_testing\n  only:\n    - triggers\n\nMy application has an integration testing job set up like this:\nintegration_test\n  stage: integration_test\n  script:\n    - echo \"Building and deploying API...\"\n    - curl.exe -X POST -F token=<token> -F ref=develop <url_for_api_trigger>\n    - echo \"Now running the integration test that depends on the API deployment...\"\n\nThe problem I am having is that the trigger only queues the API pipeline (both projects are using the same runner) and continues before the API pipeline has actually run.\nIs there a way to wait for the API pipeline to run before trying to run the integration test?\nI can do something like this:\nintegration_test_dependency\n  stage: integration_test_dependency\n  script:\n    - echo \"Building and deploying API...\"\n    - curl.exe -X POST -F token=<token> -F ref=develop <url_for_api_trigger>\n\nintegration_test\n  stage: integration_test\n  script:\n    - echo \"Now running the integration test that depends on the API deployment...\"\n\nBut that still doesn't grantee that the API pipeline runs and finishes before moving on to the integration_test stage.\nIs there a way to do this?"}, {"role": "assistant", "content": "I've come across this limitation recently and have set up an image that can be re-used to make this a simple build step:\nhttps://gitlab.com/finestructure/pipeline-trigger\nSo in your case this would look like this using my image:\nintegration_test\n  stage: integration_test\n  image: registry.gitlab.com/finestructure/pipeline-trigger\n  script:\n    - echo \"Now running the integration test that depends on the API deployment...\"\n    - trigger -a <api token> -p <token> <project id>\n\nJust use the project id (instead of having to find the whole url) and create a personal access token, which you supply here (best do this via a secret).\nThe reason the latter is needed is for polling the pipeline status. You can trigger without it but getting the result needs API authorisation.\nSee the project description for more details and additional things pipeline-trigger can do."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Use Gitlab's CI/CD with submodules - cannot run ssh\n\nI have a two private repositories: MyProject, MyProjetUtils.\nMy project uses the MyProjectUtils as a submodule.\nMy .gitsubmodules looks like this:\n[submodule \"MyProjetUtils\"]\n    path = MyProjetUtils\n    url = [email\u00a0protected]:MyCompany/MyProjetUtils.git\n\nMy .gitlab-ci.yml file looks like this:\ndefault:\n  image: python:latest\nvariables:\n  GIT_SUBMODULE_STRATEGY: recursive\nall_test:\n  stage: test\n  script:\n    - apt-get update\n    - pip install -r requirements.txt\n    - python tests/run_tests.py\n\nThe error I'm getting during the job run:\nUpdating/initializing submodules recursively with git depth set to 50...\nSubmodule 'MyProjetUtils' ([email\u00a0protected]:MyCompany/MyProjetUtils.git) registered for path 'MyProjetUtils'\nCloning into '/builds/MyCompany/MyProject/MyProjetUtils'...\nerror: cannot run ssh: No such file or directory\nfatal: unable to fork\nfatal: clone of '[email\u00a0protected]:MyCompany/MyProjetUtils.git' into submodule path '/builds/MyCompany/MyProject/MyProjetUtils' failed\nFailed to clone 'MyProjetUtils'. Retry scheduled\n\nThis error occur before the test stage. I've looked for answer here, and here but could not find an answer."}, {"role": "assistant", "content": "The first link you posted has the solution you are looking for:\n\nWhen your submodule is on the same GitLab server, you should use relative URLs in your .gitmodules file. Then you can clone with HTTPS in all your CI/CD jobs. You can also use SSH for all your local checkouts.\n\nAssuming that your submodules are in the same group, update your .gitmodules to use a relative URL.\nie:\n[submodule \"MyProjetUtils\"]\n    path = MyProjetUtils\n    url = ../../MyCompany/MyProjetUtils.git\n\nMay need to update ../../ to work for your groups."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Get latest tag in .gitlab-ci.yml for Docker build\n\nI want to add a tag when building a Docker image, I'm doing this so far but I do not know how to get the latest tag on the repository being deployed.\ndocker build -t company/app .\n\nMy goal\ndocker build -t company/app:$LATEST_TAG_IN_REPO? ."}, {"role": "assistant", "content": "Since you're looking for the \"latest\" git tag which is an ancestor of the currently building commit you probably want to use\ngit describe --tags --abbrev=0\n\nto get it and use it like:\ndocker build -t company/app:$(git describe --tags --abbrev=0) .\n\nRead here for the finer points on git describe"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab Pages: Failed to verify domain ownership\n\nThis morning I got emails for each of my Gitlab Pages that are hosted on custom domains, saying that the domain verification failed.\nThat's fine, because I don't think I ever verified them in the first place - good on Gitlab for getting this going.\nWhen I head on over the the Settings>Pages>Domain_Details on each repo, I see the instructions to create the following record:\n_gitlab-pages-verification-code.blog.ollyfg.com TXT gitlab-pages-verification-code={32_digit_long_code}\n\nOn creating this record, and clicking the \"Verify Ownership\" button, I get the message \"Failed to verify domain ownership\".\nI have ensured that the record is set, and calling\ndig -t txt +short _gitlab-pages-verification-code.blog.ollyfg.com\n\nReturns:\n\"gitlab-pages-verification-code={same_32_digit_long_code}\"\n\nIs this a bug in Gitlab? Am I doing something wrong?\nThanks!"}, {"role": "assistant", "content": "The docs (and the verification page) were a little confusing for me.  Here's what worked for me, on GoDaddy:\n\nA Record:\nName: @\nValue: 35.185.44.232\nCNAME:\nName: example.com\nValue: username.gitlab.io\nTXT Record:\nName: @\nValue: gitlab-pages-verification-code=00112233445566778899aabbccddeeff\n\nVerified with Gitlab, and also:\ndig -t txt +short example.com"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Git submodule fails with Could not access submodule\n\nOperating system: Linux\ngit version: 2.26.2\nGit repo provider of my repo: gitlab\nRepo provider of the failing submodules: Github\n.gitmodules\n[submodule \"libraries/stb\"]\n    path = libraries/stb\n    url = https://github.com/nothings/stb.git\n    branch = master\n[submodule \"libraries/harfbuzz\"]\n    path = libraries/harfbuzz\n    url = https://github.com/harfbuzz/harfbuzz.git\n    branch = master\n[submodule \"libraries/shaderc\"]\n    path = libraries/shaderc\n    url = https://github.com/google/shaderc.git\n    branch = master\n[submodule \"libraries/freetype2\"]\n    path = libraries/freetype2\n    url = https://github.com/aseprite/freetype2.git\n    branch = master\n[submodule \"libraries/VulkanMemoryAllocator\"]\n    path = libraries/VulkanMemoryAllocator\n    url = https://github.com/GPUOpen-LibrariesAndSDKs/VulkanMemoryAllocator.git\n    branch = master\n[submodule \"libraries/googletest\"]\n    path = libraries/googletest\n    url = https://github.com/google/googletest.git\n    branch = master\n[submodule \"libraries/Eigen\"]\n    path = libraries/Eigen\n    url = https://gitlab.com/libeigen/eigen.git\n    branch = master\n[submodule \"libraries/benchmark\"]\n    path = libraries/benchmark\n    url = https://github.com/google/benchmark.git\n[submodule \"libraries/rapidcheck\"]\n    path = libraries/rapidcheck\n    url = https://github.com/emil-e/rapidcheck.git\n    branch = master\n[submodule \"libraries/magic_get\"]\n    path = libraries/magic_get\n    url = https://github.com/apolukhin/magic_get.git\n    branch = master\n\ncommand and output:\ngit pull --recurse-submodules=true\n\nFetching submodule libraries/Eigen\nFetching submodule libraries/VulkanMemoryAllocator\nFetching submodule libraries/benchmark\nFetching submodule libraries/freetype2\nFetching submodule libraries/googletest\nFetching submodule libraries/harfbuzz\nCould not access submodule 'libraries/magic_get'\nCould not access submodule 'libraries/rapidcheck'\nCould not access submodule 'libraries/shaderc'\nCould not access submodule 'libraries/stb'\n\ngit submodule status:\ngit submodule status \n a145e4adf5e71391d64c0ab150a8c26851cf332d libraries/Eigen (before-git-migration-159-ga145e4adf)\n 755fd47121ce0c77ef11818e4987790ae99c2eba libraries/VulkanMemoryAllocator (v2.1.0-334-g755fd47)\n d3ad0b9d11c190cb58de5fb17c3555def61fdc96 libraries/benchmark (v1.5.0-56-gd3ad0b9)\n fbbcf50367403a6316a013b51690071198962920 libraries/freetype2 (VER-2-10-0)\n dcc92d0ab6c4ce022162a23566d44f673251eee4 libraries/googletest (release-1.8.0-2331-gdcc92d0a)\n 89ad3c6cc520517af15174391a9725e634929107 libraries/harfbuzz (2.6.5-71-g89ad3c6c)\n\ngit tree\ngit ls-tree -r HEAD\n160000 commit a145e4adf5e71391d64c0ab150a8c26851cf332d  Eigen\n160000 commit 755fd47121ce0c77ef11818e4987790ae99c2eba  VulkanMemoryAllocator\n160000 commit d3ad0b9d11c190cb58de5fb17c3555def61fdc96  benchmark\n160000 commit fbbcf50367403a6316a013b51690071198962920  freetype2\n160000 commit dcc92d0ab6c4ce022162a23566d44f673251eee4  googletest\n160000 commit 89ad3c6cc520517af15174391a9725e634929107  harfbuzz\n160000 commit 762a4ec1f4458a84bc19cd6efc1e993add90ec95  libigl\n160000 commit 03afd0b83ce67062a105cfcbe80bbca152743f0a  magic_get\n160000 commit 7bc7d302191a4f3d0bf005692677126136e02f60  rapidcheck\n160000 commit 011139094ec790ff7f32ea2d80286255fc9ed18b  shaderc\n160000 commit b42009b3b9d4ca35bc703f5310eedc74f584be58  stb\n\n\nThis used to work about 6 months ago"}, {"role": "assistant", "content": "Just in case, make sure all submodules are initialized:\ngit submodule update --init --recursive\n\nThen, try the pull --recurse-submodules=true again.\nSomehow, activating the traces improve the situation:\ngit -c trace2.eventTarget=1 pull --recurse-submodules=true"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab, Permission denied (publickey), version 6-4 stable\n\nPermission denied (publickey). fatal: Could not read from remote\nrepository.\nPlease make sure you have the correct access rights and the repository\nexists.\nGitlab version 6-4 stable \nroot@gitlab:/home/git/gitlab# sudo -u git -H bundle exec rake gitlab:env:info RAILS_ENV=production\n\nSystem information\nSystem:     Ubuntu 12.04\nCurrent User:   git\nUsing RVM:  no\nRuby Version:   2.0.0p353\nGem Version:    2.0.14\nBundler Version:1.5.2\nRake Version:   10.1.0\n\nGitLab information\nVersion:    6.4.3\nRevision:   38397db\nDirectory:  /home/git/gitlab\nDB Adapter: mysql2\nURL:        http://gitlab.xxx.xxx\nHTTP Clone URL: http://gitlab.xxx.xxx/some-project.git\nSSH Clone URL:  [email\u00a0protected]/some-project.git\nUsing LDAP: no\nUsing Omniauth: no\n\nGitLab Shell\nVersion:    1.8.0\nRepositories:   /home/git/repositories/\nHooks:      /home/git/gitlab-shell/hooks/\nGit:        /usr/bin/git\n\n\n\nroot@gitlab:/home/git/gitlab# sudo -u git -H bundle exec rake gitlab:check RAILS_ENV=production\n\nChecking Environment ...\n\nGit configured for git user? ... yes\nHas python2? ... yes\npython2 is supported version? ... yes\n\nChecking Environment ... Finished\n\nChecking GitLab Shell ...\n\nGitLab Shell version >= 1.7.9 ? ... OK (1.8.0)\nRepo base directory exists? ... yes\nRepo base directory is a symlink? ... no\nRepo base owned by git:git? ... yes\nRepo base access is drwxrws---? ... yes\nupdate hook up-to-date? ... yes\nupdate hooks in repos are links: ... \nAlexander  / Test ... repository is empty\nRunning /home/git/gitlab-shell/bin/check\nCheck GitLab API access: OK\nCheck directories and files: \n    /home/git/repositories: OK\n    /home/git/.ssh/authorized_keys: OK\nTest redis-cli executable: redis-cli 2.2.12\nSend ping to redis server: PONG\ngitlab-shell self-check successful\n\nChecking GitLab Shell ... Finished\n\nChecking Sidekiq ...\n\nRunning? ... yes\nNumber of Sidekiq processes ... 1\n\nChecking Sidekiq ... Finished\n\nChecking LDAP ...\n\nLDAP is disabled in config/gitlab.yml\n\nChecking LDAP ... Finished\n\nChecking GitLab ...\n\nDatabase config exists? ... yes\nDatabase is SQLite ... no\nAll migrations up? ... yes\nGitLab config exists? ... yes\nGitLab config outdated? ... no\nLog directory writable? ... yes\nTmp directory writable? ... yes\nInit script exists? ... yes\nInit script up-to-date? ... yes\nprojects have namespace: ... \nAlexander  / Test ... yes\nProjects have satellites? ... \nAlexander  / Test ... can't create, repository is empty\nRedis version >= 2.0.0? ... yes\nYour git bin path is \"/usr/bin/git\"\nGit version >= 1.7.10 ? ... yes (1.8.5)\n\nChecking GitLab ... Finished\n\nAnd trying to push \nroot@gitlab:/home/git/repositories/test# git push origin master\n\nPermission denied (publickey). fatal: Could not read from remote repository. Please make sure you have the correct access rights and\n  the repository exists.\n\nshh -vv [email\u00a0protected]\n alex@xxxxxxx:~$ ssh -vv [email\u00a0protected]\nOpenSSH_6.2p2 Ubuntu-6ubuntu0.1, OpenSSL 1.0.1e 11 Feb 2013\ndebug1: Reading configuration data /etc/ssh/ssh_config\ndebug1: /etc/ssh/ssh_config line 19: Applying options for *\ndebug2: ssh_connect: needpriv 0\ndebug1: Connecting to gitlab.xxx.xxx [192.168.0.40] port 22.\ndebug1: Connection established.\ndebug1: identity file /home/alex/.ssh/id_rsa type 1\ndebug1: Checking blacklist file /usr/share/ssh/blacklist.RSA-2047\ndebug1: Checking blacklist file /etc/ssh/blacklist.RSA-2047\ndebug1: identity file /home/alex/.ssh/id_rsa-cert type -1\ndebug1: identity file /home/alex/.ssh/id_dsa type -1\ndebug1: identity file /home/alex/.ssh/id_dsa-cert type -1\ndebug1: identity file /home/alex/.ssh/id_ecdsa type -1\ndebug1: identity file /home/alex/.ssh/id_ecdsa-cert type -1\ndebug1: Enabling compatibility mode for protocol 2.0\ndebug1: Local version string SSH-2.0-OpenSSH_6.2p2 Ubuntu-6ubuntu0.1\ndebug1: Remote protocol version 2.0, remote software version OpenSSH_5.9p1 Debian-5ubuntu1.1\ndebug1: match: OpenSSH_5.9p1 Debian-5ubuntu1.1 pat OpenSSH_5*\ndebug2: fd 3 setting O_NONBLOCK\ndebug1: SSH2_MSG_KEXINIT sent\ndebug1: SSH2_MSG_KEXINIT received\ndebug2: kex_parse_kexinit: ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group-exchange-sha1,diffie-hellman-group14-sha1,diffie-hellman-group1-sha1\ndebug2: kex_parse_kexinit: [email\u00a0protected],[email\u00a0protected],[email\u00a0protected],ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],ssh-rsa,ssh-dss\ndebug2: kex_parse_kexinit: aes128-ctr,aes192-ctr,aes256-ctr,arcfour256,arcfour128,[email\u00a0protected],[email\u00a0protected],aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,[email\u00a0protected]\ndebug2: kex_parse_kexinit: aes128-ctr,aes192-ctr,aes256-ctr,arcfour256,arcfour128,[email\u00a0protected],[email\u00a0protected],aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,[email\u00a0protected]\ndebug2: kex_parse_kexinit: [email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],hmac-md5,hmac-sha1,[email\u00a0protected],[email\u00a0protected],hmac-sha2-256,hmac-sha2-512,hmac-ripemd160,[email\u00a0protected],hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: [email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],hmac-md5,hmac-sha1,[email\u00a0protected],[email\u00a0protected],hmac-sha2-256,hmac-sha2-512,hmac-ripemd160,[email\u00a0protected],hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: none,[email\u00a0protected],zlib\ndebug2: kex_parse_kexinit: none,[email\u00a0protected],zlib\ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: first_kex_follows 0 \ndebug2: kex_parse_kexinit: reserved 0 \ndebug2: kex_parse_kexinit: ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group-exchange-sha1,diffie-hellman-group14-sha1,diffie-hellman-group1-sha1\ndebug2: kex_parse_kexinit: ssh-rsa,ssh-dss,ecdsa-sha2-nistp256\ndebug2: kex_parse_kexinit: aes128-ctr,aes192-ctr,aes256-ctr,arcfour256,arcfour128,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,[email\u00a0protected]\ndebug2: kex_parse_kexinit: aes128-ctr,aes192-ctr,aes256-ctr,arcfour256,arcfour128,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,[email\u00a0protected]\ndebug2: kex_parse_kexinit: hmac-md5,hmac-sha1,[email\u00a0protected],hmac-sha2-256,hmac-sha2-256-96,hmac-sha2-512,hmac-sha2-512-96,hmac-ripemd160,[email\u00a0protected],hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: hmac-md5,hmac-sha1,[email\u00a0protected],hmac-sha2-256,hmac-sha2-256-96,hmac-sha2-512,hmac-sha2-512-96,hmac-ripemd160,[email\u00a0protected],hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: none,[email\u00a0protected]\ndebug2: kex_parse_kexinit: none,[email\u00a0protected]\ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: first_kex_follows 0 \ndebug2: kex_parse_kexinit: reserved 0 \ndebug2: mac_setup: found hmac-md5\ndebug1: kex: server->client aes128-ctr hmac-md5 none\ndebug2: mac_setup: found hmac-md5\ndebug1: kex: client->server aes128-ctr hmac-md5 none\ndebug1: sending SSH2_MSG_KEX_ECDH_INIT\ndebug1: expecting SSH2_MSG_KEX_ECDH_REPLY\ndebug1: Server host key: ECDSA xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\ndebug1: Host 'gitlab.xxx.xxx' is known and matches the ECDSA host key.\ndebug1: Found key in /home/alex/.ssh/known_hosts:30\ndebug1: ssh_ecdsa_verify: signature correct\ndebug2: kex_derive_keys\ndebug2: set_newkeys: mode 1\ndebug1: SSH2_MSG_NEWKEYS sent\ndebug1: expecting SSH2_MSG_NEWKEYS\ndebug2: set_newkeys: mode 0\ndebug1: SSH2_MSG_NEWKEYS received\ndebug1: Roaming not allowed by server\ndebug1: SSH2_MSG_SERVICE_REQUEST sent\ndebug2: service_accept: ssh-userauth\ndebug1: SSH2_MSG_SERVICE_ACCEPT received\ndebug2: key: /home/alex/.ssh/id_rsa (0x7f8d86afa4f0),\ndebug2: key: /home/alex/.ssh/id_dsa ((nil)),\ndebug2: key: /home/alex/.ssh/id_ecdsa ((nil)),\ndebug1: Authentications that can continue: publickey\ndebug1: Next authentication method: publickey\ndebug1: Offering RSA public key: /home/alex/.ssh/id_rsa\ndebug2: we sent a publickey packet, wait for reply\ndebug1: Server accepts key: pkalg ssh-rsa blen 276\ndebug2: input_userauth_pk_ok: fp xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\ndebug1: Authentication succeeded (publickey).\nAuthenticated to gitlab.xxx.xxx ([192.168.0.40]:22).\ndebug1: channel 0: new [client-session]\ndebug2: channel 0: send open\ndebug1: Requesting [email\u00a0protected]\ndebug1: Entering interactive session.\ndebug1: Remote: Forced command.\ndebug1: Remote: Port forwarding disabled.\ndebug1: Remote: X11 forwarding disabled.\ndebug1: Remote: Agent forwarding disabled.\ndebug1: Remote: Pty allocation disabled.\ndebug1: Remote: Forced command.\ndebug1: Remote: Port forwarding disabled.\ndebug1: Remote: X11 forwarding disabled.\ndebug1: Remote: Agent forwarding disabled.\ndebug1: Remote: Pty allocation disabled.\ndebug2: callback start\ndebug2: fd 3 setting TCP_NODELAY\ndebug2: client_session2_setup: id 0\ndebug2: channel 0: request pty-req confirm 1\ndebug1: Sending environment.\ndebug1: Sending env LC_PAPER = de_DE.UTF-8\ndebug2: channel 0: request env confirm 0\ndebug1: Sending env LC_ADDRESS = de_DE.UTF-8\ndebug2: channel 0: request env confirm 0\ndebug1: Sending env LC_MONETARY = de_DE.UTF-8\ndebug2: channel 0: request env confirm 0\ndebug1: Sending env LC_NUMERIC = de_DE.UTF-8\ndebug2: channel 0: request env confirm 0\ndebug1: Sending env LC_TELEPHONE = de_DE.UTF-8\ndebug2: channel 0: request env confirm 0\ndebug1: Sending env LC_IDENTIFICATION = de_DE.UTF-8\ndebug2: channel 0: request env confirm 0\ndebug1: Sending env LANG = en_US.UTF-8\ndebug2: channel 0: request env confirm 0\ndebug1: Sending env LC_MEASUREMENT = de_DE.UTF-8\ndebug2: channel 0: request env confirm 0\ndebug1: Sending env LC_TIME = de_DE.UTF-8\ndebug2: channel 0: request env confirm 0\ndebug1: Sending env LC_NAME = de_DE.UTF-8\ndebug2: channel 0: request env confirm 0\ndebug2: channel 0: request shell confirm 1\ndebug2: callback done\ndebug2: channel 0: open confirm rwindow 0 rmax 32768\ndebug2: channel_input_status_confirm: type 100 id 0\nPTY allocation request failed on channel 0\ndebug2: channel 0: rcvd adjust 2097152\ndebug2: channel_input_status_confirm: type 99 id 0\ndebug2: shell request accepted on channel 0\nWelcome to GitLab, Anonymous!\ndebug1: client_input_channel_req: channel 0 rtype exit-status reply 0\ndebug1: client_input_channel_req: channel 0 rtype [email\u00a0protected] reply 0\ndebug2: channel 0: rcvd eow\ndebug2: channel 0: close_read\ndebug2: channel 0: input open -> closed\ndebug2: channel 0: rcvd eof\ndebug2: channel 0: output open -> drain\ndebug2: channel 0: obuf empty\ndebug2: channel 0: close_write\ndebug2: channel 0: output drain -> closed\ndebug2: channel 0: rcvd close\ndebug2: channel 0: almost dead\ndebug2: channel 0: gc: notify user\ndebug2: channel 0: gc: user detached\ndebug2: channel 0: send close\ndebug2: channel 0: is dead\ndebug2: channel 0: garbage collecting\ndebug1: channel 0: free: client-session, nchannels 1\nConnection to gitlab.xxx.xxx closed.\nTransferred: sent 4088, received 2432 bytes, in 0.3 seconds\nBytes per second: sent 14872.5, received 8847.8\ndebug1: Exit status 0\n\nalex@xxxxx:~$ ssh [email\u00a0protected]\nPTY allocation request failed on channel 0\nWelcome to GitLab, Anonymous!\nConnection to gitlab.xxx.xx closed.\nI tried with 5.4 stable and the same problem on production server. \nBut when for the sake of interest I installed 5.4 on local test server with virtual box and It works fine. Now I am even had compared everything, but It does not push on production server. Looks like this problem is related to SSH. \nI searched already a lot, but all solutions I tried did not work in my case. I have already no idea, feels like it is kind of software bug...\nI will appreciate any help. Thanks in advance! \nKind regards,\nAlex"}, {"role": "assistant", "content": "Try also pushing to the https url instead of the ssh this can save you lot of trouble - for example use this:\ngit remote add origin https://gitlab.com/someuser/algorithm-excercises.git\n\ninstead of:\ngit remote add origin [email\u00a0protected]:someuser/algorithm-excercises.git"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "can we use dynamic jobs names in gitlab-ci.yml?\n\nI have to migrate from jenkins to gitlab and I would like to be able to use dynamic job names in order to have some information directly in the pipeline summary without having to click on each job etc.... in jenkins we can immediately see the parameters passed to our job and this is not the case in gitlab-ci.\nMy test runner being on a windows I tried to define the yml as follows:\njob_%myParam%:\n  stage: build\n  script:\n    - set>varList.txt\n  artifacts:\n    paths:\n    - varList.txt\n\nWhen I start my job with %myParam%=true, the variable is not interpreted in the job name and so it takes the name of job_%myParam% instead of expected \"job_true\".\nIs that even possible?\nthks :)"}, {"role": "assistant", "content": "As of gitlab 12.9, this can be done using trigger and child pipelines \u2014 although a little involved:\nQuoting the example from the gitlab doc:\ngenerate-config:\n  stage: build\n  script: generate-ci-config > generated-config.yml\n  artifacts:\n    paths:\n      - generated-config.yml\n\nchild-pipeline:\n  stage: test\n  trigger:\n    include:\n      - artifact: generated-config.yml\n        job: generate-config\n\nIn your case, you would put the definition of job_%myParam% in job.yml.in, then have the script generate-ci-config be e.g. sed \"s/%myParam%/$PARAM/g\" job.yml.in.\nThis is probably a bit much for just changing the names of course, and there will be a cost associated to the additional stage; but it does answer the question, and may be useful to do more, like start with different versions of the parameter in the same pipeline."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab - Xcode Can't connect with remote repository\n\nI am having troubles when I connect with my repository through Xcode.\nI have a Gitlab version (full pre-)installed on TurnkeyLinux Virtual Appliance on a remote server. \nIn the Gitlab Web interface, I've created a new test user: \"testuser\" with a password \"password\" and a new project \"testproject\". This user was assigned to this project.\nThe git url project are:\nHTTP: http://example.com/testuser/testproject.git\nSSH: [email\u00a0protected]:testuser/testproject.git\n\nI can see the repositories folder rightly created with a \"Terminal\" through SSH connection.\nNow, I want add this git repository to my Xcode repositories.\nSo, In\nXCode > Preferences > Account     \n\nI'm trying add it, using both urls and my user credentials, but always receive the following message:\n\"Authentication failed because the name or password was incorrect.\"\n\nCould anyone help me?"}, {"role": "assistant", "content": "The user/password would only be needed for an http url, not an ssh one.\nWhen using the http url to add a repo in your XCode Accounts, make sure there is no proxy which would prevent the resolution of the example.com server.\nIf it is still not working, then, as in \"Authentification issue when pushing Xcode project to GitHub\", try to use an url like: \nhttps://testuser:[email\u00a0protected]/testuser/testproject.git"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to run a specific job in gitlab CI\n\nWe are facing a problem where we need to run one specific job in gitlab CI. We currently not know how to solve this problem. We have multitple jobs defined in our .gitlab-ci.yml but we only need to run a single job within our pipelines. How could we just run one job e.g. job1 or job2? We can't use tags or branches as a software switch in our environment.\n.gitlab-ci.yml:\nbefore_script:\n  - docker info\n\njob1:\n  script:\n    - do something\n\njob2:\n  script:\n    - do something"}, {"role": "assistant", "content": "You can use a gitlab variable expression with only/except like below and then pass the variable into the pipeline execution as needed.\nThis example defaults to running both jobs, but if passed 'true' for \"firstJobOnly\" it only runs the first job.\nOld Approach -- (still valid as of gitlab 13.8) - only/except\nvariables:\n  firstJobOnly: 'false'\n\nbefore_script:\n  - docker info\n\njob1:\n  script:\n    - do something\n\njob2:\n  script:\n    - do something\n  except:\n    variables:\n      - $firstJobOnly =~ /true/i\n\nUpdated Approach - rules\nWhile the above still works, the best way to accomplish this now would be using the rules syntax. A simple example similar to my original reply is below.\nIf you explore the options in the rules syntax, depending on the specific project constraints there are many ways this could be achieved.\nvariables:\n  firstJobOnly: 'false'\n\njob1:\n  script: \n    - do something\n\njob2:\n  script: \n    - do something\n  rules:\n    - if: '$firstJobOnly == \"true\"'\n      when: never\n    - when: always"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to make GitLab Runner in Docker see a custom CA Root certificate\n\nI have installed and configured: \n\nan on-premises GitLab Omnibus on ServerA running on HTTPS\nan on-premises GitLab-Runner installed as Docker Service in ServerB\n\nServerA certificate is generated by a custom CA Root\nThe Configuration\nI've have put the CA Root Certificate on ServerB:\n/srv/gitlab-runner/config/certs/ca.crt\n\nInstalled the Runner on ServerB as described in Run GitLab Runner in a container - Docker image installation and configuration:\ndocker run -d --name gitlab-runner --restart always \\\n           -v /srv/gitlab-runner/config:/etc/gitlab-runner \\\n           -v /var/run/docker.sock:/var/run/docker.sock \\\n           gitlab/gitlab-runner:latest\n\nRegistered the Runner as described in Registering Runners - One-line registration command:\ndocker run --rm -t -i \n            -v /srv/gitlab-runner/config:/etc/gitlab-runner \n           --name gitlab-docker-runner gitlab/gitlab-runner register \\\n           --non-interactive \\\n           --executor \"docker\" \\\n           --docker-image alpine:latest \\\n           --url \"https://MY_PRIVATE_REPO_URL_HERE/\" \\\n           --registration-token \"MY_PRIVATE_TOKEN_HERE\" \\\n           --description \"MyDockerServer-Runner\" \\\n           --tag-list \"TAG_1,TAG_2,TAG_3\" \\\n           --run-untagged \\\n           --locked=\"false\"\n\nThis command gave the following output:\n\nUpdating CA certificates...\nRuntime platform                                    arch=amd64 os=linux pid=5 revision=cf91d5e1 version=11.4.2\n  Running in system-mode.\nRegistering runner... succeeded                     runner=8UtcUXCY\n  Runner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded!\n\nI checked with\n$ docker exec -it gitlab-runner bash \n\nand once in the container with\n$ awk -v cmd='openssl x509 -noout -subject' '\n/BEGIN/{close(cmd)};{print | cmd}' < /etc/ssl/certs/ca-certificates.crt\n\nand the custom CA root is correctly there.\nThe Problem\nWhen running Gitlab-Runner from GitLab-CI, the pipeline fails miserably telling me that:\n\n$ git clone https://gitlab-ci-token:${CI_BUILD_TOKEN}@ServerA/foo/bar/My-Project.wiki.git\n    Cloning into 'My-Project.wiki'...\n    fatal: unable to access 'https://gitlab-ci-token:xxxxxxxxxxxxxxxxxxxx@ServerA/foo/bar/My-Project.wiki.git/': server certificate verification failed. CAfile: /etc/ssl/certs/ca-certificates.crt CRLfile: none\n   ERROR: Job failed: exit code 1\n\nIt does not recognize the Issuer (my custom CA Root), but according to The self-signed certificates or custom Certification Authorities, point n.1, it should out-of-the-box:\n\nDefault: GitLab Runner reads system certificate store and verifies the GitLab server against the CA\u2019s stored in system.\n\nI've then tried the solution from point n.3, editing \n/srv/gitlab-runner/config/config.toml:\n\nand adding: \n[[runners]]\ntls-ca-file = \"/srv/gitlab-runner/config/certs/ca.crt\"\n\nBut it still doesn't work.\nHow can I make Gitlab Runner read the CA Root certificate?"}, {"role": "assistant", "content": "You have two options:\nIgnore SSL verification\nPut this at the top of your .gitlab-ci.yml:\nvariables:\n  GIT_SSL_NO_VERIFY: \"1\"\n\nPoint GitLab-Runner to the proper certificate\nAs outlined in the official documentation, you can use the tls-*-file options to setup your certificate, e.g.:\n[[runners]]\n  ...\n  tls-ca-file = \"/etc/gitlab-runner/ssl/ca-bundle.crt\"\n  [runners.docker]\n  ...\n\nAs the documentation states, \"this file will be read every time when runner tries to access the GitLab server.\"\nOther options include tls-cert-file to define the certificate to be used if needed."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "ssh command -T option\n\nI'm wondering what the -T option in the following command does, cannot see this option in the manual somehow:\n$ ssh -T [email\u00a0protected]\nWelcome to GitLab, Simeon !\n\nCould somebody explain?"}, {"role": "assistant", "content": "I explained before what TTY was: a text terminal is needed when you open an interactive session to a remote server.\nBut: in the context of a remote Git repository hosting server (GitHub, Gitlab, BitBucket, ...), no remote server will ever allow you to open an interactive session (for security reason)\nThen only reason why you would still do an ssh -T [email\u00a0protected] would be to test if you are correctly authenticated, and the session would immediately end with:\nHi username!  You've successfully authenticated, \nbut GitHub does not provide shell access. \n\nSince no tty is needed for that test, you should use the -T option when making this test."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Creating webhooks via GitLab API\n\nIs there any way of creating webhooks in GitLab via API similiar to what we have in GitHub using GitHub API by Koshuke?"}, {"role": "assistant", "content": "You can add, list, edit and delete webhooks.\nPOST /projects/:id/hooks\nYou can add a webhook with your project ID or with namespace/project_name\nTake a look at this http://doc.gitlab.com/ce/api/projects.html#add-project-hook"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Raspberry Pi and GitLab\n\nIs there a way I can run GitLab (http://gitlab.org/gitlab-ce) and GitLab CI (http://gitlab.org/gitlab-ci) on a Raspberry Pi device running Raspbian?\nI want to have my own internal Git box where I can store code and possibly allow other friends access to upload their code too. Is it possible?\nThanks."}, {"role": "assistant", "content": "Official way for the Pi 2\nThere is a very easy way to install it on the Raspberry Pi 2.\nwget https://s3-eu-west-1.amazonaws.com/downloads-packages/raspberry-pi/gitlab_7.9.0-omnibus.pi-1_armhf.deb\nsudo dpkg -i gitlab_7.9.0-omnibus.pi-1_armhf.deb\n\nYou might prefer to go to the official page in order to get latest version. It's fast and easy, they recommend at least 1Gb swap.\nOn the Pi B and B+ you will hit the memory limit very soon and get degraded performance as you grow, but on the Pi 2 it works nicely, specially if you mount your repos on an external USB hard disk."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlabs artifact of one project used in further projects\n\nQuestion\n\nWhat is the best way to carry artifacts (jar, class, war) among projects when using docker containers in CI phase.\n\nLet me explain my issue in details, please don't stop the reading... =)\nGitlabs project1\n\nunit tests\netc...\npackage\n\nGitlabs project2\n\nunit test\netc...\nbuild (failing)\n\n\nhere I need one artifact (jar) generated in project1\n\n\nCurrent scenario / comments\n\nI'm using dockers so in each .gitlab-ci.yml I'll have independent containers\nAll is working fine in project1\nIf I use \"shell\" instead of dockers in my .gitlab-ci.yml I can keep the jar file from the project1 in the disk and use when project2 kicks the build\nToday my trigger on call project2 when project1 finish is working nicely\nMy artifact is not an RPM so I'll not add into my repo\n\nPossible solutions\n\nI can commit the artifact of project1 and checkout when need to build project2\nI need to study if cache feature from gitlabs is designed for this purpose (gitlab 8.2.1, How to use cache in .gitlab-ci.yml)"}, {"role": "assistant", "content": "In GitLab silver and premium, there is the\n$CI_JOB_TOKEN available, which allows the following .gitlab-ci.yaml snippet:\nbuild_submodule:\n  image: debian\n  stage: test\n  script:\n  - apt update && apt install -y unzip\n  - curl --location --output artifacts.zip \"https://gitlab.example.com/api/v4/projects/1/jobs/artifacts/master/download?job=test&job_token=$CI_JOB_TOKEN\"\n  - unzip artifacts.zip\n  only:\n  - tags\n\nHowever, if you do not have silver or higher gitlab subscriptions, but rely on free tiers, it is also possible to use the API and pipeline triggers.\nLet's assume we have project A building app.jar which is needed by project B.\nFirst, you will need an API Token.\nGo to Profile settings/Access Tokens page to create one, then store it as a variable in project B. In my example it's GITLAB_API_TOKEN.\nIn the CI / CD settings of project B add a new trigger, for example \"Project A built\". This will give you a token which you can copy.\nOpen project A's .gitlab-ci.yaml and copy the trigger_build: section from project B's CI / CD settings trigger section.\nProject A:\ntrigger_build:\n  stage: deploy\n  script:\n    - \"curl -X POST -F token=TOKEN -F ref=REF_NAME https://gitlab.example.com/api/v4/projects/${PROJECT_B_ID}/trigger/pipeline\"\n\nReplace TOKEN with that token (better, store it as a variable in project A -- then you will need to make it token=${TRIGGER_TOKEN_PROJECT_B} or something), and replace REF_NAME with your branch (e.g. master).\nThen, in project B, we can write a section which only builds on triggers and retrieves the artifacts.\nProject B:\ndownload:\n  stage: deploy\n  only:\n    - triggers\n  script:\n    - \"curl -O --header 'PRIVATE-TOKEN: ${GITLAB_API_TOKEN}' https://gitlab.example.com/api/v4/projects/${PROJECT_A_ID}/jobs/${REMOTE_JOB_ID}/artifacts/${REMOTE_FILENAME}\"\n\nIf you know the artifact path, then you can replace ${REMOTE_FILENAME} with it, for example build/app.jar. The project ID can be found in the CI / CD settings.\nI extended the script in project A to pass the remaining information as documented in the trigger settings section:\n\nAdd variables[VARIABLE]=VALUE to an API request. Variable values can be used to distinguish between triggered pipelines and normal pipelines.\n\nSo the trigger passes the REMOTE_JOB_ID and the REMOTE_FILENAME, but of course you can modify this as you need it:\ncurl -X POST \\\n     -F token=TOKEN \\\n     -F ref=REF_NAME \\\n     -F \"variables[REMOTE_FILENAME]=build/app.jar\" \\\n     -F \"variables[REMOTE_JOB_ID]=${CI_JOB_ID}\" \\\n     https://gitlab.example.com/api/v4/projects/${PROJECT_B_ID}/trigger/pipeline"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to fetch entire repository with GitLab CI/CD?\n\nI'm currently setting up GitLab CI/CD. We use GitVersion in our project, which throws the following error:\n/root/.nuget/packages/gitversiontask/5.3.7/build/GitVersionTask.targets(46,9): error : InvalidOperationException: Could not find a 'develop' or 'master' branch, neither locally nor remotely.\nAccording to this blog this happens, when the CI-server does not fetch the full repository (we have both a develop and a master branch, but I'm working on a different one). For Jenkins we solved this problem by expanding the checkout stage:\nstage(\"Checkout\") { gitlabCommitStatus(name: \"Checkout\") {\n    \n    // These are the normal checkout instructions\n    cleanWs()\n    checkout scm\n    \n    // This is the additional checkout to get all branches\n    checkout([\n      $class: 'GitSCM',\n      branches: [[name: 'refs/heads/'+env.BRANCH_NAME]],\n      extensions: [[$class: 'CloneOption', noTags: false, shallow: false, depth: 0, reference: '']],\n      userRemoteConfigs: scm.userRemoteConfigs,\n    ])\n\n    sh \"git checkout ${env.BRANCH_NAME}\"\n    sh \"git reset --hard origin/${env.BRANCH_NAME}\"\n}}\n\nI'm essentially looking for something equivalent to this for the .gitlab-ci.yml file."}, {"role": "assistant", "content": "By default, runners download your code with a 'fetch' rather than a 'clone' for speed's sake, but it can be configured a number of ways. If you want all jobs in your project's pipeline to be cloned rather than fetched, you can change the default in your CI Settings:\n\n\nIf you don't want all your jobs to clone since it's slower, you can change it in your .gitlab-ci.yml for your job:\nmy_job:\n  stage: deploy\n  variables:\n    GIT_STRATEGY: clone\n  script:\n    - ./deploy\n\nYou can read more about the GIT_STRATEGY variable here: https://docs.gitlab.com/ee/ci/runners/configure_runners.html#git-strategy\nNote: You can also set this variable to none, which is useful if you don't need the code but maybe an artifact created by a previous job. Using this, it won't checkout any code, but skip straight to your script."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab: why \"squash\" merge creates two commits?\n\nTo reproduce it:\n\nCreate issue\nOpen Merge Request (MR) from the issue\nMake changes with multiple commits\nCheck \"squash commits\" and Merge the MR\n\nWhy on earth this creates TWO commits in history with exactly the same changes?\nThe commits titles:\n\nMerge branch '123-branch-name' into 'dev'\nFull Issue name\n\nWhat is the point of that?"}, {"role": "assistant", "content": "Sounds like you create one commit containing your changes (commit Full Issue name) and a merge commit, merging changes from that commit into dev branch.\nThe merge commit is usually created for every merge request. This can be changed in Settings->Merge Request Settings by choosing e.g. Fast Forward Merge instad of Merge Commit. This will lead to only one commit on top of your current dev HEAD, which will only work if dev can be fast forwarded.\nChecking squash commits will squash all commits in the feature branch you want to merge before merging it. Thus, if you had more than one commit in your feature branch, they would be squashed into one commit, which would be merged, creating a merge commit as you described (as long as your merge request settings are set to merge commit, see above).\nThe point of that is that you might want to see that changes were performed on a different branch. This is done by not fast forwarding the branch you merge into, but create a merge request instead. This displays that two lines of development were merged, while a fast forward merge (not creating a merge commit) would not."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to use issues of Gitlab from terminal?\n\nI know you can use Github issues on the command line by installing ghi.\n\nghi\n\nHowever, is there any way to use similar tools for listing/adding/removing/editing issues of repositories on Gitlab ?"}, {"role": "assistant", "content": "GLab seems to be a great option.\n\nGLab is an open source Gitlab Cli tool written in Go (golang) to help work seamlessly with Gitlab from the command line. Work with issues, merge requests, watch running pipelines directly from your CLI among other features.\n\nhttps://github.com/profclems/glab"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab: how can I tell what acess level I have on a project?\n\nI just tried to push to master on a GitLab repo and my push was denied with\n\nremote: GitLab: You are not allowed to push code to protected branches on this project.\n\nLooking at the access level documentation, it seems I'm probably a \"Developer\".\nIs there someplace in the GitLab UI that will tell me my access level and/or full list of permissions on a project?"}, {"role": "assistant", "content": "You can open your user (in current version click on the avatar on the top-right corner) and go to \"Contributed projects\" tab, you'd be able to see your roles for the projects you're contributing to, something like:"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to reject merge request in GitLab?\n\nIs there any way in GitLab UI to reject a merge request because code has issue?\nIf not what is the right way to track this?"}, {"role": "assistant", "content": "I agree with Phil Lucks. In my opinion gitlab is missing functionality. A merge request is a request and as such should be able to be rejected/denied.\nThe following thread gives insight into the thought process that was going on with Closing a request versus denying one. https://gitlab.com/gitlab-org/gitlab-foss/-/issues/23355"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Git \"does not appear to be a git repository\" ip and port instead of domain?\n\nI'm trying to commit my first Git repository to a gitlab instance, which I've set up on a debian-VM. Everything is going to happen via local network. The following commands are shown in gitlab after creating a new repo.\nmkdir test\ncd test\ngit init\ntouch README\ngit add README\ngit commit -m 'first commit'\ngit remote add origin [email\u00a0protected]:1337:Matt/test.git\ngit push -u origin master\n\nAfter entering git push -u origin master this happens:\n[email\u00a0protected]'s password:\nfatal: '1337:Matt/test.git' does not appear to be a Git repository\nfatal: Could not read from remote repository.\n\nPlease make sure you have the correct access rights\nand the repository exists.\n\nCould the problem be the port on which Git is running at? Gitlab is accessible through port 617 so I'am able to reach the GUI via http://xxx.xxx.xxx.xxx:617/Matt/test\nThe password I've entered seems to be correct, because a wrong password will end up in a \"permission denied\" message. OT: I don't know why I've to enter a passwd, because I've generated and added ssh-keys, as described in gitlab, but that's an other problem."}, {"role": "assistant", "content": "I've solved my problem. The given port 1337 wasn't the problem, although it was wrong too, because ssh does not seem to be able to handle a port in url:\nUsing a remote repository with non-standard port\nThe Git-url which worked for me was:\n[email\u00a0protected]:repositories/Matt/test.git\n\nMy Git user home dir is located in /home/git/ and the repositories are stored in /home/git/repositories so i had to add repositories to my Git-path.\nThe reason why GitLab told me to use the url [email\u00a0protected]:1337:Matt/test.git seems to be a wrong configured Git path in GitLab. I'll try to fix this now.\nEdit:\nThe wrong host was configured in /home/git/gitlab/config/gitlab.yml. The \"host\" there must be without port... There is an extra option for the port if needed.\nEdit3:\nStill unable to push or fetch my test-repository without repositories in path..\nhttps://github.com/gitlabhq/gitlab-public-wiki/wiki/Trouble-Shooting-Guide#could-not-read-from-remote-repository\nMaybe something to do with rsa-keys but I don't understand how this belongs together.\nEdit4: (Problem(s) seem to be solved)\nMy rsa-keys were ok. The problem was that I've configured my sshd_config to allow only a certain user for ssh-login. I've simply added Git to the list of allowed users AllowUsers mylogin git\nNow I don't have to login via password anymore (You never have to login via password if ssh rsa keys are set up correctly) and the path works without \"repositories\" as it should. Now I understand, that this is just a normal ssh-connection - I hadn't realized this before..\nThe way I figured it out:\nlogin via terminal as root:\nservice ssh stop #Current SSH-Connection won't be closed..\n/usr/sbin/sshd -d\n\n====debugging mode===\n\nThen in Git Bash:\nssh -Tv [email\u00a0protected]\n\nAfterwards the terminal with sshd running in debug mode has thrown an error that Git is not allowed to login because of AllowUsers...\nDon't forget to start your ssh service afterwards:\nservice ssh start"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "error: cannot overwrite multiple values with a single value\n\nI want to change my git mergetool kdiff3 to p4merge. because I'm getting an error on my windows system using kdiff3 mergetool. \n\n/mingw32/libexec/git-core/git-mergetool--lib: line 128: C:\\Program\n  Files\\KDiff3\\kdiff3: cannot execute binary file: Exec format error\n  application/config/constants.php seems unchanged.\n\nSo that I want to change to kdiff3 to p4merge, Here also I'm getting an error like\n\nwarning: merge.tool has multiple values error: cannot overwrite\n  multiple values with a single value\n         Use a regexp, --add or --replace-all to change merge.tool.\n\n\nHow can I solve this problem? Either kdiff3 or p4merge"}, {"role": "assistant", "content": "It is possible your kdiff3 installation is broken since it is not working. Or maybe you tried to edit config file manually and messed its content. why? Because windows executables have .exe extension in general. you may try editing config again. \nAnyways, that is not important anymore. This is what you need to use if you want to try any other tool.\ngit mergetool --tool=p4merge\n\nThere are possibly others already installed with your git. You can see all of them in addition to compatible others.\ngit mergetool --tool-help\n\nEdit:\nThis command works only if you set your path to the tool correctly. Otherwise, you always get No files need merging result. You already know how to set the path, but I will include here for anyone else that might need.\nGet the list of configuration items:\ngit config -l\n\nSee if you already have values set correctly, if any. then set to correct value or remove.\ngit config --unset mergetool.p4merge.path\ngit config --add mergetool.p4merge.path \"c:/somewhere/p4merge.exe\"\n\n\nEDIT:\nI will offer a cleaning process so, these additional commands will help.\nfirst steps are to make a backup of current settings. The simplest way is using these listings, then copy paste results.\ngit config --list\ngit config --global --list\n\nthen with these edit commands, just get config files' path and backup them (vim shows path) or save to a different location inside the editor.\ngit config --edit\ngit config --global --edit\n\nnow backups are ready, just exit editor. do not try to edit manually if it is not really needed.\ngit config --unset name\ngit config --global --unset name\ngit config --remove-section name\ngit config --global --remove-section name\n\nmerge.tool, mergetool.name, diff.tool and difftool.name are the ones to clean here. when you list the configs again, you should not see these names. local and global should be cleaned separately.\nThen set back those we just cleaned one by one. but this time first try them on local configuration first then if successful set on global too.\ngit config merge.tool name\ngit config mergetool.name.property value\ngit config diff.tool name\ngit config difftool.name.property value\n\nHere property is those like cmd and path, and value is their values which you can copy from your backups. Now the important thing here is to set only 1 tool at a time at first.\nOne last thing about paths. You (the OP) seem to use Linux-like environment, so using / instead of \\\\ would make path and cmd better to understand."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to debug Gitlab LDAP authentication?\n\nI am trying to configure LDAP authentication with gitlab. My configuration is someting like:\nldap:\n    enabled: true\n    host: 'ldap.example.com'\n    base: 'ou=People,o=example.com'\n    port: 636\n    uid: 'uid'\n    method: 'ssl' # \"ssl\" or \"plain\"\n    bind_dn: 'cn=gitlab,ou=Apps,o=example.com'\n    password: 'password'\n    allow_username_or_email_login: true\n\nI tested it with the following :\nldapsearch  -b \"ou=People,o=example.com\" -s sub -D \"cn=gitlab,ou=Apps,o=example.com\" -H ldaps://ldap.example.com:636 -w \"password\" -x \"([email\u00a0protected])\"\n\nThe line above works, but when I try to log in using LDAP, I always got \"invalid credentials\".\nHow can I troubleshoot this and narrow down the root cause f this problem?\nEdit 26/09:\nHere are some things I found on production.log:\nStarted GET \"/users/sign_in\" for 127.0.0.1 at 2013-09-23 17:42:58 -0300\nProcessing by Devise::SessionsController#new as HTML\n  Rendered devise/sessions/_new_ldap.html.haml (1.7ms)\n  Rendered devise/sessions/_new_base.html.haml (1.8ms)\n  Rendered devise/sessions/_oauth_providers.html.haml (0.0ms)\n  Rendered devise/sessions/new.html.haml within layouts/devise (4.2ms)\n  Rendered layouts/_head.html.haml (1.6ms)\n  Rendered layouts/_flash.html.haml (0.1ms)\nCompleted 200 OK in 9ms (Views: 6.9ms | ActiveRecord: 0.0ms)\nStarted POST \"/users/auth/ldap/callback\" for 127.0.0.1 at 2013-09-23 17:43:00 -0300\nProcessing by OmniauthCallbacksController#failure as HTML\n  Parameters: {\"utf8\"=>\"\u00e2\", \"authenticity_token\"=>\"AwqZsVHRqOeZr+GLWWeGM7MyOAdk7cFl8/rZgbVRU+8=\", \"username\"=>\"[email\u00a0protected]\", \"password\"=>\"[FILTERED]\"}\nRedirected to http://example.com/users/sign_in\nCompleted 302 Found in 3ms (ActiveRecord: 0.0ms)\nStarted GET \"/users/sign_in\" for 127.0.0.1 at 2013-09-23 17:43:00 -0300\nProcessing by Devise::SessionsController#new as HTML\n  Rendered devise/sessions/_new_base.html.haml (2.8ms)\n  Rendered devise/sessions/_oauth_providers.html.haml (0.1ms)\n  Rendered devise/sessions/new.html.haml within layouts/devise (3.7ms)\n  Rendered layouts/_head.html.haml (1.7ms)\n  Rendered layouts/_flash.html.haml (0.1ms)\nCompleted 200 OK in 9ms (Views: 6.6ms | ActiveRecord: 0.0ms)\nStarted GET \"/\" for 127.0.0.1 at 2013-09-23 18:50:08 -0300\nProcessing by DashboardController#show as HTML\nCompleted 401 Unauthorized in 1ms\n\nEdit: I finally got the answer: a configuration on devise was stripping everyting after the \"@\". I can't recall the exact name, but I can post as soon as I got access to the machine. I discovered this by adding logs to the ldap oauth login."}, {"role": "assistant", "content": "The OP kidbomb mentions:\n\nA configuration on devise was stripping everything after the \"@\".\n  I discovered this by adding logs to the ldap oauth login.\n\n\nCheck if the LDAP server is also accessible through ldap (not ldaps://)\nldapsearch  -b \"ou=People,o=example.com\" -s sub -D \"cn=gitlab,ou=Apps,o=example.com\" -H ldap://ldap.example.com:389 -w \"password\" -x \"([email\u00a0protected])\"\n\nIf yes, try and modify the gitlab.yml setting file ldap.method from 'ssl' to \"plain\".\nThe goal is to validate if the certificate used for contacting the ldap server is the issue here or not.\nIf you can contact the server through ldap:// (no certificate), that gives you at least a workaround.\nIf not (you have to go through ldaps://), you need to study more in detail the certificate associated to the LDAP server.\nopenssl s_client -connect ldap.example.com:636  2>/dev/null < /dev/null\n\n(I am not using -CAFile or -CAPath here, assuming the CA are at their default place mentioned in /etc/ssl/openssl.cnf)\nIf you get at the end of the output of that command the message:\nerror:num=21:unable to verify the first certificate \n\nThat means you need to get the certificate from the issuer.\nSee \"How To Verify SSL Certificate From A Shell Prompt\"."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Default assignee for issues\n\nIs there a way to set a default assignee for newly cerated issues? All new issues are set to Unassigned. This way no notifications about this issue are sent out unless people set their notification levels to watching. And notification settings can only be set for entire groups or projects you are explicitly set as member."}, {"role": "assistant", "content": "I have finally found a solution for this myself. It's possible to implement default assignees using templates and quick actions:\nSimply put /assign @username into the templates. This way you can even define multiple default assignees for different kinds of issues."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How can I create a table on gitlab wiki?\n\nHow can one create a table on gitlab wiki?\nIt uses github flavored markdown, and this flavor of markdown support tables but I can't make the following example work:\nColons can be used to align columns.\n| Tables        | Are           | Cool  |\n| ------------- |:-------------:| -----:|\n| col 3 is      | right-aligned | $1600 |\n| col 2 is      | centered      |   $12 |\n| zebra stripes | are neat      |    $1 |\n\nThe outer pipes (|) are optional, and you don't need to make the raw Markdown line up prettily. You can also use inline Markdown.\n\nMarkdown | Less | Pretty\n--- | --- | ---\n*Still* | `renders` | **nicely**\n1 | 2 | 3\n\nIs there a trick to activate tables?"}, {"role": "assistant", "content": "Update: See GitLab 14.1 (July 2021)\n\nCreate tables and upload images in the Wiki Content Editor\nCreate tables and upload images in the Wiki Content Editor\nWe began improving your wiki editing experience in GitLab 14.0, when we introduced the MVC of a new WYSIWYG Markdown editor.\nIt supported the most common Markdown formatting options, but with some notable gaps.\nGitLab 14.1 continues to improve your editing experience for images and tables.\nYou can now upload images directly into the editor. You can also insert and edit tables, including copying and pasting content from popular spreadsheet applications to bring tables from other sources into your wiki. \u200b\n\nSee Documentation and Issue.\n\nAnd:\nSee GitLab 14.3 (September 2021)\n\nEdit a table\u2019s structure visually in the new wiki editor\nEdit a table\u2019s structure visually in the new wiki editor\nEditing a Markdown table that has 9 columns and 25 rows is one thing.\nBut adding a tenth column to that table in Markdown?\nThat involves very repetitive and error-prone edits to every row. One mistake or misplaced | and the table fails to render.\nThe new WYSIWYG Markdown editor in the wiki lets you quickly and easily insert a table using the button in the toolbar.\nAfter selecting the initial number of rows and columns, however, dealing with the structure of the table can be more difficult.\nIn GitLab 14.3, you can now click on the caret icon in the top right corner of any selected cell to add or remove columns and rows, either before or after the selected cell.\nNow, as your content scales, the complexity doesn\u2019t follow suit.\n\nSee Documentation and Issue.\n\n\nSee GitLab 14.5 (November 2021)\n\nTables in wikis support block-level elements\nGitLab 14.1 introduced WYSIWYG editing for tables in the new wiki editor, but the types of content supported in table cells were limited by the underlying Markdown implementation: you couldn\u2019t add block-level elements like lists, code blocks, or pull quotes inside a table.\nNow, in GitLab 14.5, these block-level elements are fully supported inside table cells.\nYou can insert lists, code blocks, paragraphs, headings, and even nested tables inside a table cell, giving you more flexibility and freedom to format your content to meet your needs.\n\nSee Documentation and Issue.\n\n\nOriginal answer: 2013:\nIt seems to be still the case, as described in Issue 3651 and issue 1238, even though Flavored Markdown is supported:\nThis wouldn't work:\n| parameters  | desc                 |\n| :---------  | :------------------- |\n| -w | --word | Parameter for Word   |\n\nSo contributions are welcome on this specific bug.\nHowever, AJNeufeld suggest (in 2016) in the comments:\n\nYou need to use the &#124; entity code to get the vertical pipe between \"-w\" and \"--word\", so it appears as \"-w | --word\" in the rendered table.\nIe, the full line should be:\n\n| -w &#124; --word | Parameter for Word |"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to version or tag incrementally in Gitlab CI/CD when merging from Production to Master branch\n\nI\u2019m working on a project and I wanted to tag or give a version number. I wanted gitlab to tag V 1.0, 1.1, etc. in my gitci.yml file when the merging happens and my CI/CD runs successfully."}, {"role": "assistant", "content": "You could use for such purposes \u2014 semantic release tool. It automatically detects which version (major, minor, patch) to increment by commits prefixes. It can update not only gitlab tags, but ie send slack notifications, update version files or have any custom logic\nexample setup will look something like this (full example link will be at the end of answer)\n\n.gitlab-ci.yml file\n\nBuild Release:\n  image: node:dubnium\n  stage: build release\n  script:\n    - npm i semantic-release @semantic-release/changelog @semantic-release/commit-analyzer @semantic-release/gitlab @semantic-release/git @semantic-release/npm @semantic-release/release-notes-generator semantic-release-slack-bot\n    - npx semantic-release\n  only:\n    - master\n  except:\n    refs:\n      - tags\n    variables:\n      - $CI_COMMIT_TITLE =~ /^RELEASE:.+$/\n\n\n.releaserc.yaml file (at the same level as .gitlab-ci.yml)\n\nbranches: ['master']\nci: true\ndebug: true\ndryRun: false\ntagFormat: '${version}'\n\n# Global plugin options (will be passed to all plugins)\npreset: 'conventionalcommits'\ngitlabUrl: 'http://gitlab.mycomany.com/' # your gitlab url\nslackWebhook: 'https://slack.xxx.com/hooks/q3dtkec6yjyg9x6616o3atgkkr' # if you need slack notifies\n\n# Responsible for verifying conditions necessary to proceed with the release:\n# configuration is correct, authentication token are valid, etc...\nverifyConditions:\n  - '@semantic-release/changelog'\n  - '@semantic-release/git'\n  - '@semantic-release/gitlab'\n  - 'semantic-release-slack-bot'\n\n# Responsible for determining the type of the next release (major, minor or patch).\n# If multiple plugins with a analyzeCommits step are defined, the release type will be\n# the highest one among plugins output.\n# Look details at: https://github.com/semantic-release/commit-analyzer#configuration\nanalyzeCommits:\n  - path: '@semantic-release/commit-analyzer'\n\n# Responsible for generating the content of the release note.\n# If multiple plugins with a generateNotes step are defined,\n# the release notes will be the result of the concatenation of each plugin output.\ngenerateNotes:\n  - path: '@semantic-release/release-notes-generator'\n    writerOpts:\n      groupBy: 'type'\n      commitGroupsSort: 'title'\n      commitsSort: 'header'\n    linkCompare: true\n    linkReferences: true\n\n# Responsible for preparing the release, for example creating or updating files\n# such as package.json, CHANGELOG.md, documentation or compiled assets\n# and pushing a commit.\nprepare:\n  - path: '@semantic-release/changelog'\n  - path: '@semantic-release/git'\n    message: 'RELEASE: ${nextRelease.version}'\n    assets: ['CHANGELOG.md']\n\n# Responsible for publishing the release.\npublish:\n  - path: '@semantic-release/gitlab'\n\nsuccess:\n  - path: 'semantic-release-slack-bot'\n    notifyOnSuccess: true\n    markdownReleaseNotes: false\n\nfail:\n  - path: 'semantic-release-slack-bot'\n    notifyOnFail: true\n\n\nto test it try make debug commit:  $ git commit --allow-empty -m \"fix: fake release\" (will bump up path version)\n\n\nFull working example is available here on gitlab"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "[Gitlab]Where can I find Gitlab Pages hosted on my private Gitlab instance?\n\nI tried to set up Gitlab Pages, until now I finished uploading my static website files\ud83d\udc47\nUploading artifacts...\ncoverage/lcov-report: found 77 matching files      \nUploading artifacts to coordinator... ok            id=1038 responseStatus=201 Created token=QXJjgkf2\n\nBut I got no idea where my page hosted.\nI took a glance at this documentation but it was still vague to me.\n\nI have a private Gitlab instance.\nMy Gitlab entry is under http://abc.def.com (I configured a type A DNS to my host IP 111.111.111.111, a reverse proxy pointing at localhost:9000).\nMy project project1 is under my team team1.\nI have also configured DNS http://team1.abc.def.com to 111.111.111.111 , and there is a nginx reverse proxy on my server which http://team1.abc.def.com -> localhost:9000.\n\nI assume I should see my static page available on http://team1.abc.def.com/project1 , but nothing was there. Where exactly are my pages hosted?"}, {"role": "assistant", "content": "You have to activate the pages feature. In your gitlab.rb:\npages_external_url \"IP_OF_YOUR_GITLAB\"\ngitlab_pages['enable'] = true\n\nThere is a tutorial: https://www.youtube.com/watch?v=dD8c7WNcc6s&feature=youtu.be\nAnd the complete documentation: https://docs.gitlab.com/ce/administration/pages/index.html"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Mirror from github to gitlab\n\nIn Gitlab it is now possible to automatically mirror remote GIT repo:\nhttp://docs.gitlab.com/ee/workflow/repository_mirroring.html\nSynchronization is either done manually or via gitlab cron script (running every hour).\nI would like to sync in this way my github repo and run Gitlab CI jobs using my own runners.\nIs is possible to automatize sync task, i.e. via Github webhooks ? Do you know if there is any other way to do it with Gitlab infrastructure ?\nI would like to avoid hacking like:\n - cloning github repo in gitlab runner\n - running my own cron jobs which do sync more often"}, {"role": "assistant", "content": "Mirror does work, but it's slow. If your goal is to run gitlab-ci for a github repository, good news, gitlab has released a new version which lets you use github.com repository with gitlab-ci:\nhttps://about.gitlab.com/2018/03/22/gitlab-10-6-released/\n\nGitLab CI/CD for GitHub feature a part of our GitLab.com Free tier\n\nInstructions:\n\nhttps://about.gitlab.com/2018/03/22/gitlab-10-6-released/#gitlab-cicd-for-external-repos\nhttps://docs.gitlab.com/ee/ci/ci_cd_for_external_repos/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Easy way to setup GitLab with existing Gitolite configuration\n\nI have an existing Gitolite configuration with many users and repositories. It is setup in the default way as the Gitolite installation guide suggests.\nNow I would like to add GitLab to be able to do code reviews and bug tracking.\nWhat's the most convenient way to achieve this?"}, {"role": "assistant", "content": "Original answer (January 2013)\nYou can follow the standard installation, and indicate in your gitlab.yml config file the location of your gitolite repo, as well as the gitolite admin user.\nHowever, GitLab requires from the user to register themselves in GitLab and copy their public ssh key.\nThat means you might need to adapt the way gitolite has stored existing gitolite users, since the name you have used is likely to be different than the name used by GitLab (it uses a name based on the login_email_auuid).\n\nUpdate (August 2018, 5 years later):\nAs commented below by Thomas, a few months after this answer, GitLab released GitLab 5.0, without gitolite.\n\nNow I would like to add GitLab to be able to do code reviews and bug tracking.\n  What's the most convenient way to achieve this?\n\nThese days (2018, GitLab 11.2.x), code review is supported through merge request (it has been so since a few years already).\nSee:\n\n\"Demo: Mastering code review with GitLab\" from Emily von Hoffmann,\n\"Code Review Via GitLab Merge Requests\" from Maxim Letushov."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Docker/GitLab authentication for docker registry returns 401 error\n\nI'm trying to configure my docker registry using auth of gitlab (docker).\nDoing docker login registry.website.com gives me a 401 Unauthorized error:\nError response from daemon: login attempt to https://registry.website.com/v2/ failed with status: 401 Unauthorized\n\nIn the docker logs I find\n{ \"level\":\"info\",\"msg\":\"token signed by untrusted key with ID: \\\"IWNY:KT2H:YUN5:STQP:22LM:YNIU:RT4T:AZO7:TBVL:ZQ3I:Z4JZ:LA3T\\\"\",\"time\":\"2018-12-17T23:36:03.538232467Z\" }\n{ [...] \"level\":\"warning\",\"msg\":\"error authorizing context: invalid token\",\"service\":\"registry\",\"source\":\"registry\",\"time\":\"2018-12-17T23:36:03.53860308Z\",\"version\":\"v2.6.2\" }\n\nMy keys are generated by doing\n$ sudo openssl req -new -newkey rsa:4096 -subj \"/CN=gitlab-issuer\" -nodes -x509 -keyout registry-auth.key -out registry-auth.crt\n$ sudo chmod 400 registry-auth.key\n\nIn my debugging attempt I do get different sha256 digest:\n459b854f47c51bd94e0fd696cc35148cf93065df986abcc368cf13958373d298\n459b854f47c51bd94e0fd696cc35148cf93065df986abcc368cf13958373\n\nAs @VDR has shown this is ok, as the first 30 characters are used. So with that there should not be a problem with the keys. But why do I get the 401 error?\nThis is how I configured gitlab and the registry:\nThe configuration of docker gitlab (gitlab.rb) uses the key by\ngitlab_rails['registry_key_path'] = \"/certs/registry-auth.key\"\n\nConfig of registry has\nauth.token.rootcertbundle: /root/certs/registry-auth.crt\n\nnginx-proxy/vhost.d/docker-registry.conf\nproxy_pass                          http://registry.website.com;\nproxy_set_header  Host              $http_host;   # required for docker client's sake\nproxy_set_header  X-Real-IP         $remote_addr; # pass on real client's IP\nproxy_set_header  X-Forwarded-For   $proxy_add_x_forwarded_for;\nproxy_set_header  X-Forwarded-Proto $scheme;\nproxy_read_timeout                  900;\n\nI don't see what I'm missing here..."}, {"role": "assistant", "content": "If your Gitlab is behind a proxy, you will need to configure the proxy in docker.\nTo configure docker to use the proxy, put the following in your ~/.docker/config.json file where your docker is running.\n{\n  \"auths\" : {\n\n  },\n  \"proxies\":\n  {\n    \"default\":\n    {\n      \"httpProxy\": \"http://myproxy/\",\n      \"httpsProxy\": \"http://myproxy/\"\n    }\n  }\n}\n\nIf there is anything already in the \"auths\": {} section, you should leave it as is.\nSave this file then restart your docker daemon. Once docker is back up, you should be able to run docker login ... without issues."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Git hook to indicate repository is deprecated\n\nWe have a repository (hosted on a GitLab instance) which a handful of projects still reference, but has been deprecated in favor of another solution.\nIs there any way to mark a repository as \"deprecated\"?\nIdeally, every fetch from this repository (as part of a git submodule update) would cause a giant message to be printed during the fetch. I was expecting to add a simple Git hook that would print this deprecated message. However, there doesn't seem to be a \"run this on every fetch\" hook.\nAlso, I see nothing in GitLab that would enable this."}, {"role": "assistant", "content": "Gitlab has feature called \"Broadcast messages\" since 6.3.  On the screenshot they shows message with the same color as header and many users could simply not notice it.\nHowever, it is possible to choose color for these messages since 6.5.  For example, administrators at my work once made blue message and it was very hard not to notice the message.\nSo you may\n\nMake bright and visible broadcast message telling that this instance of Gitlab is deprecated and that everyone should use something else because at day X write access will be closed.\nAt day X make everyone read-only.\nLeave this instance of Gitlab so old links won't be broke and so on."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Another git process seems to be running and thus cant commit\n\nI was committing my git process and thought that it would be okay if I ignore comments so I used this code\ngit commit filename\n\nBash was strange and thus i closed the console\nnow when I use proper command \ngit commit -m\"THIRD COMMIT\" filename\n\nIt give the following response:\nAnother git process seems to be running in this repository, e.g.\nan editor opened by 'git commit'. Please make sure all processes\nare terminated then try again. If it still fails, a git process\nmay have crashed in this repository earlier:\nwhat should I do?"}, {"role": "assistant", "content": "I met this problem recently too.\nrm -f ./.git/index.lock\n\ntry this commend in your git bash, then you can solve your problem."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Docker volume cleanup of gitlab-runner\n\nI am new to docker and jenkins. However ultimately I am creating a job in jenkins so that I can delete the volume cache of gitlab-runner which is stored in our linux machines (CentOS7)\nTo achieve this, I am creating a periodic job every 6 hours with the following command in jenkins:\ndocker volume prune -f \n\nHowever it doesn't clean up the space at all. This is the output of jenkins job :\nStarted by timer\nRunning as SYSTEM\nBuilding remotely on buildbng17 (gitlab) in workspace /mnt/data0/jenkins/workspace/gitlab-cleanup\n[WS-CLEANUP] Deleting project workspace...\n[WS-CLEANUP] Deferred wipeout is used...\n[WS-CLEANUP] Done\n[gitlab-cleanup] $ /bin/sh -xe /tmp/jenkins3799570002967825583.sh\n+ find /mnt/data0/gitlab/data/backups/ -name '*.tgz' -mtime +30\n/mnt/data0/gitlab/data/backups/etc-gitlab-1611415968.tgz\nStarted calculate disk usage of build\nFinished Calculation of disk usage of build in 0 seconds\nStarted calculate disk usage of workspace\nFinished Calculation of disk usage of workspace in 0 seconds\nFinished: SUCCESS\n\nWhen I went to my buildbng17 machine and checked if there is any volume their, so there was volume which I had to clean up by performing\ndocker volume prune\n\nThe only drawback is that I need to do it manually and give that \"y\" when it asks for confirmation. And the data gets clean.\nWhat command should I give in jenkins so that it will automatically clean up the volume without asking for confirmation? (because docker volume prune -f is not working)\nI even tried to run the docker volume prune -f command manually in my linux machine, it still doesn't clean up the volume and shows 0kb freed up (However there is the volume which I checked from docker volume ls)\nIs there any better approach we can do to automate it inside gitlab-runner itself ?\nOr some better feature of jenkins or docker of which I am not aware of?\nThe gitlab-runner keeps on running and covers the diskspace.\nOne more thing : We are using Gitlab and Gitlab-runner on docker.\nThanks in advance,\nSameer"}, {"role": "assistant", "content": "Run these commands to do cleanup:\n# Remove exited containers\ndocker ps -a -q -f status=exited | xargs --no-run-if-empty docker rm -v\n\n# Remove dangling images\ndocker images -f \"dangling=true\" -q | xargs --no-run-if-empty docker rmi\n\n# Remove unused images\ndocker images | awk '/ago/  { print $3}' | xargs --no-run-if-empty docker rmi\n\n# Remove dangling volumes\ndocker volume ls -qf dangling=true | xargs --no-run-if-empty docker volume rm"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Unable to locate credentials - Gitlab Pipeline for S3\n\nI'm deploying the front-end of my website to amazon s3 via Gitlab pipelines. My previous deployments have worked successfully but the most recent deployments do not. Here's the error:\nCompleted 12.3 MiB/20.2 MiB (0 Bytes/s) with 1 file(s) remaining\nupload failed: dist/vendor.bundle.js.map to s3://<my-s3-bucket-name>/vendor.bundle.js.map Unable to locate credentials\n\nUnder my secret variables I have defined four. They are S3 credential variables (AWS_ACCESS_KEY_ID & AWS_SECRET_ACCESS_KEY) for two different buckets. One pair is for the testing branch and the other is for the production branch. \nNot - the production environment variables are protected and the other variables are not.\nHere's the deploy script that I run:\n#/bin/bash\n#upload files\naws s3 cp ./dist s3://my-url-$1 --recursive --acl public-read\n\nSo why am I getting this credential location error? Surely it should just pick up the environment variables automatically (the unprotected ones) and deploy them. Do I need to define the variables in the job and refer to them?"}, {"role": "assistant", "content": "(I encountered this issue many times - Adding another answer for people that have the same error - from other reasons).\nA quick checklist.\nGo to Setting -> CI/CD -> Variables and check:\n\nIf both AWS_ACCESS_KEY_ID & AWS_SECRET_ACCESS_KEY environment variables exist.\nIf both names are spelled right.\nIf their state is defined as protected - they can only be ran against protected branches (like master).\n\nIf error still occurs:\n\nMake sure the access keys still exist and active on your account.\nDelete current environment variables and replace them with new generated access keys and make sure AWS_SECRET_ACCESS_KEY doesn't contain any special characters (can lead to strange errors)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Host Key Verification Failed - GitLab with Visual Studio Code on macOS\n\nI keep getting a \"Host Key Verification Failed\" error when trying to push changes to a git controlled folder/project to Gitlab. For whatever reason, it works fine using Visual Studio for Mac, and I can login to my Gitlab account just fine via web browser."}, {"role": "assistant", "content": "Resolved by deleting any/all Known_hosts files in ~/.ssh/ and then executing ssh [email\u00a0protected] in Terminal and answering \"yes\" (which re-adds [email\u00a0protected] to known_hosts after re-creating a new known_hosts file).\nI did some messing around in known_hosts which probably caused the problem."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "AWS-CDK and Gitlab returns Error: spawnSync docker ENOENT\n\nI am trying to run a Gitlab pipeline that builds an AWS-CDK project via the cdk-synth command. I have followed advice online in terms of what images I should be using in the Gitlab runner but I am running into the following error:\n\nError: spawnSync docker ENOENT\n\nI'm not sure what this error means exactly, I guess it is trying to launch docker (which is used by thecdk synth command) but failing to do so. Again what I have found online all suggests to use the setup I currently have which is:\nimage: node:16.3.0-alpine\n\nstages:\n  - build\n  - test\n  - .post\n\ncache:\n  key: ${CI_COMMIT_REF_SLUG}\n  paths:\n    - .npm\n    - node_modules\n\nbuild:\n  tags:\n    - mytag\n  environment: ${CI_COMMIT_BRANCH}\n  stage: build\n  script:\n    - npm i\n    - cdk synth --no-staging > template.yaml\n  artifacts:\n    paths:\n      - cdk.out\n    expire_in: 30 mins\n\nI'm really lost with this one, it may be staring me right in the face but could someone please point me in the right direction as to why i'd be getting this error when the image i'm using is itself a docker container?"}, {"role": "assistant", "content": "I was stuck on this as well, but was able to get around it by adding esbuild as to my devDependencies in package.json."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to trigger a specific job in gitlab\n\nI want to run a specific job in a pipeline. I thought assigning a tag for the job and then specifying this tag again in the post method will fulfill my needs. The problem is when I trigger using the api(post), all the jobs in the pipeline are triggered even though only one of this tagged.\ngitlab-ci.yml:\njob1:\n  script:\n    - echo \"helloworld!\"\n  tags : [myTag]\n\njob2:\n  script:\n    - echo \"hello gitlab!\"\n\n\nthe api call :\ncurl -X POST -F token=\"xxx\" -F ref=\"myTag\" https://gitlab.com/api/v4/projects/12345678/trigger/pipeline"}, {"role": "assistant", "content": "add a variable to your trigger api call as shown here:\nhttps://docs.gitlab.com/ee/ci/triggers/#making-use-of-trigger-variables\nthen use the only prperty \ninside your gitlab.yml file\nas shown here :\nhttps://docs.gitlab.com/ee/ci/variables/#environment-variables-expressions\nthen only if the variable exists the job will be execute\nfor example\njob1:\n  script: echo \"HELLO\"\n  only:\n    variables:\n      - $variables[API_CALL]=true"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Can\u2019t find my artifacts with GitLab CI\n\nI'm using a shared runner, on gitlab.com. The guide here shows a section for job artifacts. But when I run my job and look at my job page, I just see this:\n\nThere's no section for job artifacts.\nWhat should I try?\nHere's my .gitlab-ci.yml:\nimage: node:7.9\n\nstages:\n  - lint\n  - test\n\ncache:\n  paths:\n    - node_modules/\n\nbefore_script:\n  - npm install\n  - npm install -g grunt-cli\n\nlint:\n  stage: lint\n  script:\n    - grunt lint\n\ntest:\n  stage: test\n  script:\n    - grunt\n    - grunt test\n    - grunt coveralls\n  artifacts:\n    paths:\n      - dist/project*.min.js*"}, {"role": "assistant", "content": "Are your artifacts created in failing test runs (e.g. screenshots when a test fails)?\nIf so, you have to take into account, that artifacts in Gitlab are as a default only collected for successful tests.\nYou have to explicitly configure Gitlab CI to always collect them, e.g.\ntest:\n  ...\n  artifacts:\n    when: always\n    paths:\n      - ..."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Array variable inside .gitlab-ci.yml yaml\n\nI want to use arrays in variables of my gitlab ci/cd yml file, something like that:\nvariables:\n    myarrray: ['abc', 'dcef' ]\n....\nscript: |\n    echo myarray[0]  myarray[1]\n\nBut Lint tells me that file is incorrect:\nvariables config should be a hash of key value pairs, value can be a hash\n\nI've tried the next:\nvariables:\n    arr[0]: 'abc'\n    arr[1]: 'cde'\n....\nscript: |\n    echo $arr[0] $arr[1]\n\nBut build failed and prints out bash error:\nbash: line 128: export: `arr[0]': not a valid identifier\n\nIs there any way to use array variable in .gitlab-ci.yml file?"}, {"role": "assistant", "content": "According to the docs, this is what you should be doing:\n\nIt is not possible to create a CI/CD variable that is an array of values, but you can use shell scripting techniques for similar behavior.\nFor example, you can store multiple variables separated by a space in a variable, then loop through the values with a script:\n\njob1:\n  variables:\n    FOLDERS: src test docs\n  script:\n    - |\n      for FOLDER in $FOLDERS\n        do\n          echo \"The path is root/${FOLDER}\"\n        done"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to retry pipeline (not individual jobs) in GitLab via the UI?\n\nBasically I am looking for the retry button for the pipeline triggered, but all I see is a retry button for the individuals jobs of that pipeline. I don't want to have to push a commit just to retry a pipeline.\nReference screenshot"}, {"role": "assistant", "content": "You can retry the latest push on the pipeline by going to:\n\nCI/CD -> Pipelines -> Run Pipeline -> Select the branch to run.\n\nOtherwise, as you've mentioned, you'd have to manually press the retry button for each individual job for the pipeline (for a pipeline that isn't the latest)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to disable Create Project permission for users by default in GitLab?\n\nI am using the Omnibus GitLab CE system with LDAP authentication.\nBecause of LDAP authentication, anyone in my company can sign in to GitLab and a new GitLab user account associated with this user is created (according to my understanding).\nI want to modify it so that by default this new user (who can automatically sign in based on his LDAP credentials) cannot create new projects.\nThen, I as the admin, will probably handle most new project creation.\nI might give the Create Project permission to a few special users."}, {"role": "assistant", "content": "In newer versions of GitLab >= v7.8 \u2026\nThis is not a setting in config/gitlab.yml but rather in the GUI for admins.\nSimply navigate to https://___[your GitLab URL]___/admin/application_settings/general#js-account-settings, and set Default projects limit to 0.\nYou can then access individual users's project limit at https://___[your GitLab URL]___/admin/users.\n\nSee GitLab's update docs for more settings changed between v7.7 and v7.8.\ngit diff origin/7-7-stable:config/gitlab.yml.example origin/7-8-stable:config/gitlab.yml.example"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab container registry: Any way to automate deletion of old containers?\n\nWe have a GitLab CI pipeline which builds a new Docker image based on an external ETCD snapshot of a Hashicorp Vault secrets back-end. The image is for disaster recovery so we don't have any interest in keeping old versions in the registry. \nIs there any way of purging GitLab registry container images which are older than a certain date. Or to keep a maximum number of recent images and delete the rest?\nThanks\nS"}, {"role": "assistant", "content": "run this command:\nsudo gitlab-ctl registry-garbage-collect -m"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What do the values for gitlab's predefiner variable CI_PIPELINE_SOURCE mean?\n\nIn the gitlab documentation you find a list of predefined variables HERE, where the variable CI_PIPELINE_SOURCE is explained to have the possible values \"push, web, schedule, api, external, chat, webide, merge_request_event, external_pull_request_event, parent_pipeline, trigger, or pipeline.\"\nHowever, it is not explained, what they mean.\n\npush: When you push something to a branch?\nweb: When you trigger a pipeline from the web GUI?\nschedule: When a pipeline is triggered by a schedule\napi: When the pipeline is triggered by an API request\nexternal: ???\nchat: ???\nwebide: ???\nmerge_request_event: Seems to be triggered when a merge request is created. Does not trigger when a change is actually merged\nexternal_pull_request_event: ???\nparent_pipeline: ???\ntrigger: ???\npipeline: another pipeline?\n\nIf someone knows where the documentation for that is hiding, I appreciate if you can let me know where to find it.\nIn addition, how can I figure out when some changes are actually merged into a branch? How can I trigger a pipeline in that event?"}, {"role": "assistant", "content": "Regarding your first set of questions, i have to point you forward to the gitlab CI Documentation and the rules:if section. They have their a good explanation of the states and also some addtion https://docs.gitlab.com/ee/ci/jobs/job_control.html#common-if-clauses-for-rules - i am just screenshoting this, so people can relate to it in the future if the link gets outdated:\n\nRegarding your additional question:\nA merge is a push. We do not check on some branches for CI_PIPELINE_SOURCE but for the branch name and do checks simply against that like:\n    rules:\n        - if: '$CI_COMMIT_BRANCH == \"master\"'\n        - if: '$CI_COMMIT_BRANCH == \"develop\"'\n        - if: '$CI_COMMIT_BRANCH =~ /^release.*$/i'\n        - if: '$CI_PIPELINE_SOURCE == \"merge_request_event\"'\n\nThis works eg perfectly in our case for gitflow. But you can vary your rules and easily define them to your own needs - the rules documentation gives a lot of good examples see: https://docs.gitlab.com/ee/ci/jobs/job_control.html#common-if-clauses-for-rules"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to clone a private git repository into a kubernetes pod using ssh keys in secrets?\n\nI am trying to clone a private git repository(gitLab) into a kubernetes pod, using SSH keys for authentication. I have stored my keys in a secret. Here is the yaml file for the job that does the desired task.\nHeres the same question, but doesnt give the exact solution : \nClone a secure git repo in Kubernetes pod\nLogs of the init container after execution:\nfetch http://dl-cdn.alpinelinux.org/alpine/v3.7/main/x86_64/APKINDEX.tar.gz\nfetch http://dl-cdn.alpinelinux.org/alpine/v3.7/community/x86_64/APKINDEX.tar.gz\nv3.7.1-66-gfc22ab4fd3 [http://dl-cdn.alpinelinux.org/alpine/v3.7/main]\nv3.7.1-55-g7d5f104fa7 [http://dl-cdn.alpinelinux.org/alpine/v3.7/community]\nOK: 9064 distinct packages available\nOK: 23 MiB in 23 packages\nCloning into '/tmp'...\nHost key verification failed.\nfatal: Could not read from remote repository.\n\nPlease make sure you have the correct access rights\nand the repository exists.\n\nThe yaml file which works perfectly for public repo:\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: nest-build-kaniko\n  labels:\n    app: nest-kaniko-example\nspec:\n  template:\n    spec:\n      containers:\n        -\n          image: 'gcr.io/kaniko-project/executor:latest'\n          name: kaniko\n          args: [\"--dockerfile=/workspace/Dockerfile\",\n                \"--context=/workspace/\",\n                \"--destination=aws.dest.cred\"]\n          volumeMounts:\n            -\n              mountPath: /workspace\n              name: source\n            -\n              name: aws-secret\n              mountPath: /root/.aws/\n            -\n              name: docker-config\n              mountPath: /kaniko/.docker/\n      initContainers:\n        -\n          name: download\n          image: alpine:3.7\n          command: [\"/bin/sh\",\"-c\"]\n          args: ['apk add --no-cache git && git clone https://github.com/username/repo.git /tmp/']\n          volumeMounts:\n            -\n              mountPath: /tmp\n              name: source\n      restartPolicy: Never\n      volumes:\n        -\n          emptyDir: {}\n          name: source\n        -\n          name: aws-secret\n          secret:\n            secretName: aws-secret\n        -\n          name: docker-config\n          configMap:\n            name: docker-config\n\nThe yaml file after using git-sync for cloning private repository:\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: nest-build-kaniko\n  labels:\n    app: nest-kaniko-example\nspec:\n  template:\n    spec:\n      containers:\n        -\n          image: 'gcr.io/kaniko-project/executor:latest'\n          name: kaniko\n          args: [\"--dockerfile=/workspace/Dockerfile\",\n                \"--context=/workspace/\",\n                \"--destination=aws.dest.cred\"]\n          volumeMounts:\n            -\n              mountPath: /workspace\n              name: source\n            -\n              name: aws-secret\n              mountPath: /root/.aws/\n            -\n              name: docker-config\n              mountPath: /kaniko/.docker/\n      initContainers:\n        -\n          name: git-sync\n          image: gcr.io/google_containers/git-sync-amd64:v2.0.4\n          volumeMounts:\n            -\n              mountPath: /git/tmp\n              name: source\n            -\n              name: git-secret\n              mountPath: \"/etc/git-secret\"\n          env:\n            - name: GIT_SYNC_REPO\n              value: \"[email\u00a0protected]:username/repo.git\"\n            - name: GIT_SYNC_SSH\n              value: \"true\"\n            - name: GIT_SYNC_DEST\n              value: \"/tmp\"\n            - name: GIT_SYNC_ONE_TIME\n              value: \"true\"\n          securityContext:\n            runAsUser: 0\n      restartPolicy: Never\n      volumes:\n        -\n          emptyDir: {}\n          name: source\n        -\n          name: aws-secret\n          secret:\n            secretName: aws-secret\n        -\n          name: git-secret\n          secret:\n            secretName: git-creds\n            defaultMode: 256\n        -\n          name: docker-config\n          configMap:\n            name: docker-config"}, {"role": "assistant", "content": "You can use git-sync\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: git-sync-test\nspec:\n  selector:\n    matchLabels:\n      app: git-sync-test\n  serviceName: \"git-sync-test\"\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: git-sync-test\n    spec:\n      containers:\n      - name: git-sync-test\n        image: <your-main-image>\n        volumeMounts:\n        - name: service\n          mountPath: /var/magic\n      initContainers:\n      - name: git-sync\n        image: k8s.gcr.io/git-sync-amd64:v2.0.6\n        imagePullPolicy: Always\n        volumeMounts:\n        - name: service\n          mountPath: /magic\n        - name: git-secret\n          mountPath: /etc/git-secret\n        env:\n        - name: GIT_SYNC_REPO\n          value: <repo-path-you-want-to-clone>\n        - name: GIT_SYNC_BRANCH\n          value: <repo-branch>\n        - name: GIT_SYNC_ROOT\n          value: /magic\n        - name: GIT_SYNC_DEST\n          value: <path-where-you-want-to-clone>\n        - name: GIT_SYNC_PERMISSIONS\n          value: \"0777\"\n        - name: GIT_SYNC_ONE_TIME\n          value: \"true\"\n        - name: GIT_SYNC_SSH\n          value: \"true\"\n        securityContext:\n          runAsUser: 0\n      volumes:\n      - name: service\n        emptyDir: {}\n      - name: git-secret\n        secret:\n          defaultMode: 256\n          secretName: git-creds # your-ssh-key\n\nFor more details check this link."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab and Jenkins integration\n\nI've read the differences between Gitlab Community and Enterprise in this page: https://about.gitlab.com/features/\nBased on that page I understand the integration with Jenkins is only available in the enterprise version. However, I've seen that using web hooks I can trigger builds in Jenkins when a push happens in Gitlab. \nSo my question is which is the difference between community and enterprise regarding the integration with jenkins?"}, {"role": "assistant", "content": "On the merge request page, there is a state widget that shows the status of tests for that particular merge request, and on your project home page, there is test status badging. These two UI elements only show up if you enable a 'ci service' on the project. In community you can turn it on with Gitlab CI. In enterprise you can set it up to work with jenkins."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "integrate puppeteer in gitlab with gitlab-ci.yml\n\nIm currently working on e2e test in Chrome Puppeteer. I am at the stage where it would be ideal to integrate my tests in the development process. \nWhat I want to accomplish is the following: my tests run automated before every deploy to production. If they succeed deployment goes through, if they fail deployment is canceled. \nI use a pipeline on gitlab to automate my deployment process. \nSo my main question is how can I integrate my puppeteer tests into the gitlab-ci.yml file?"}, {"role": "assistant", "content": "This might be a bit of a hack but mine are running like this:\ntest:\nimage: node:latest\nstage: run\nscript:\n- apt-get update\n- apt-get install -yq gconf-service libasound2 libatk1.0-0 libc6 libcairo2 libcups2 libdbus-1-3 libexpat1 libfontconfig1 libgcc1 libgconf-2-4 libgdk-pixbuf2.0-0 libglib2.0-0 libgtk-3-0 libnspr4 libpango-1.0-0 libpangocairo-1.0-0 libstdc++6 libx11-6 libx11-xcb1 libxcb1 libxcomposite1 libxcursor1 libxdamage1 libxext6 libxfixes3 libxi6 libxrandr2 libxrender1 libxss1 libxtst6 ca-certificates fonts-liberation libappindicator1 libnss3 lsb-release xdg-utils wget\n- yarn\n- yarn test\n\nThat super long list of libraries are the ones that the puppeteer needs to launch chrome. Ideally you would have a ready docker image but all the premade ones I found did not work for me. \nWhen getting ready for prod you should build your own image that takes from node and installs the dependencies itself."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "\"GitLab is not responding.\" 502 on Ubuntu 14.04 after starting server\n\nI have just installed GitLab on a fresh Ubuntu 14.04 64 bit server. I did so using the Omnibus package as indicated in the download page. There were no error messages during the install and all the remarks from the script were displayed in green.\nWhen I access the server through port 80 I get the following:\n\nFollowing the Trouble Shooting Guide I tried to query the status, but the result is also an error:\nsudo -u git -H bundle exec rake gitlab:check RAILS_ENV=production\nsudo: bundle: command not found\n\nI tried to access the logs but the unicorn.stderr.log file is nowhere to be found in the system.\nThere is a similar question with the same error on Ubuntu 12.04, to which the solution is to increase the unicorn timeout. I have tried to do so but the error message remains."}, {"role": "assistant", "content": "There is a lag of some 5 minutes from the moment gitlab is started/restarted to the point when it is actually able to process requests. Here is an example from the log:\n2015-01-08_09:00:57.37719 [13326] 08 Jan 10:00:57.377 * The server is now ready to accept connections on port 0\n2015-01-08_09:00:57.37722 [13326] 08 Jan 10:00:57.377 * The server is now ready to accept connections at /var/opt/gitlab/redis/redis.socket\n\n[...]\n\n==> /var/log/gitlab/unicorn/unicorn_stderr.log <==\nI, [2015-01-08T10:04:48.676879 #13351]  INFO -- : listening on addr=127.0.0.1:8080 fd=11\nI, [2015-01-08T10:04:48.677663 #13351]  INFO -- : unlinking existing socket=/var/opt/gitlab/gitlab-rails/sockets/gitlab.socket\nI, [2015-01-08T10:04:48.690283 #13351]  INFO -- : listening on addr=/var/opt/gitlab/gitlab-rails/sockets/gitlab.socket fd=12\nI, [2015-01-08T10:04:48.716769 #13413]  INFO -- : worker=0 spawned pid=13413\nI, [2015-01-08T10:04:48.735878 #13351]  INFO -- : master process ready\nI, [2015-01-08T10:04:48.846635 #13416]  INFO -- : worker=1 spawned pid=13416\nI, [2015-01-08T10:04:48.837438 #13413]  INFO -- : worker=0 ready\nI, [2015-01-08T10:04:48.863110 #13416]  INFO -- : worker=1 ready\n\nBefore Unicorn reports that it is up and running on port 8080, the \"GitLab is not responding\" message will be displayed. So all one has to do is wait."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Difference between `go get` and `git clone`?\n\nI had a problem with go-modbus in an issue in Github.\nAuthor suggested me to use:   \n$ go get github.com/goburrow/modbus  \n\ninstead of \n$ git clone https://github.com/goburrow/modbus.git\n\nWhat is the difference between that two commands?"}, {"role": "assistant", "content": "The git clone command will clone a repo into a newly created directory, while go get downloads and installs the packages named by the import paths, along with their dependencies."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "I'm getting a \"No podspec found\" message when doing \"pod install\" against a private gitlab pod/project container\n\nI'm in the middle of some CocoaPods project trying to build my own private Pod, reachable via \"pod install\" from my main project.\nIt's a Swift project, and everything seemed to be working, reading the appropriate tutorials, etc...\nI have to say I've been using cocoapods for some time, but I'm kind of new building my own pods and storing them in my private gitlab space.\nAnd that seems to be my problem: Apparently I don't know how to properly store my recently created pod on my gitlab space. Additionaly, running \"pod install\" can't fetch my podspec file.\nWhat I have now is a main project, with a Podfile. In this project I have the next simple definition for my pods (2 public (SpkinKit and MBProgressHUD) and 1 private, 'commons'):\nMy Podfile is this one: \n# Uncomment this line to define a global platform for your project\nplatform :ios, '8.0'\n\ntarget 'MyBaseApp' do\n  # Comment this line if you're not using Swift and don't want to use dynamic frameworks\n  use_frameworks!\n\n  # Pods for MyBaseApp\n\n  pod 'SpinKit'\n  pod 'MBProgressHUD'\n  pod 'commons', :path => 'ssh://git@internal_ip_numeric_address_of_my_gitlab_machine:2222/myusername/ios_commons_pod.git'\n\nend\n\nIf I type \"pod install --verbose\" I get the following output:\nFetching external sources\n-> Fetching podspec for `commons` from `ssh://git@internal_ip_numeric_address_of_my_gitlab_machine:2222/myusername/ios_commons_pod.git`\n[!] No podspec found for `commons` in `ssh://git@internal_ip_numeric_address_of_my_gitlab_machine:2222/myusername/ios_commons_pod.git`\n\nThis crash doesn't allow the pod to get downloaded, and the process stops here.\nWhat seems to be wrong? As far as I understand I DO have a podspec file in that gitlab path route.\nLook at this screenshot:\n\nThe URL scheme I'm using is the SSH flavoured one, that is the one appearing on the root of my gitlab project homepage (not the HTTP/HTTPS one). \nThis is a limitation of the project, so I can't use the HTTP one.\nOTOH I think my SSH credentials (and key setup) are stored ok on my machine. Why? because I try using a ssh shell against that URL, from the command line, and I can see \"Welcome myusername\" on screen without specifying any username and password (Then the gitlab machine logouts that shell for security reasons, but that's another theme. That's expected behaviour).\nWhatever, I'm still not sure what exact URL format/path should I use in my base app Podfile.\nInside gitlab I have my files and podspec file stored with the structure shown in the last screenshot, but I'm still not 100% sure if I've setup everything ok.\nThe contents of my commons.podspec file are these:\nPod::Spec.new do |s|\n\n  # 1\n  s.platform = :ios\n  s.ios.deployment_target = '8.0'\n  s.name = \"commons\"\n  s.summary = \"commons test fw via pod.\"\n  s.requires_arc = true\n\n  # 2\n  s.version = \"0.1.0\"\n\n  # 3\n  s.license = { :type => \"MIT\", :file => \"LICENSE\" }\n\n  # 4 - Replace with your name and e-mail address\n  s.author = { \"Me\" => \"[email\u00a0protected]\" }\n\n\n  # 5 - Replace this URL with your own Github page's URL (from the address bar)\n  s.homepage = \"http://internal_ip_numeric_address_of_my_gitlab_machine:8888/myusername\"\n\n  # 6 - Replace this URL with your own Git URL from \"Quick Setup\"\n  s.source = { :git => \"http://internal_ip_numeric_address_of_my_gitlab_machine:8888/myusername/ios_commons_pod.git\", :tag => \"#{s.version}\"}\n\n  # 7\n  s.framework = \"UIKit\"\n  s.dependency 'RNCryptor'\n\n  # 8\n  s.source_files = \"commons/**/*.{swift}\"\n\n  # 9\n  s.resources = \"commons/**/*.{png,jpeg,jpg,xib,storyboard}\"\nend\n\nAny hint?\nThanks."}, {"role": "assistant", "content": "The only thing you need to do is change :path => to :git => and it should download the pod from your repo."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab Push Failed error\n\nI keep getting this error when I try to push anything to my own gitlab server:\nPush failed\nFailed with error:\nfatal: The remote end hung up unexpectedly\nfatal: The remote end hung up unexpectedly\nerror: RPC failed;\ncurl 56 Recv failure: Connection was reset\n\nI have no idea why I keep getting this error. I kept trying to push and then out of nowhere it pushed it successfully. But everything I tried to push after that just gave me the same error.\nHere is a more detailed log:\n16:21:39.932: [gallery] git -c core.quotepath=false push --progress --porcelain origin refs/heads/master:master\nCounting objects: 12, done.\nDelta compression using up to 8 threads.\nCompressing objects: 100% (12/12), done.\nWriting objects: 100% (12/12), 1.88 MiB | 25.00 KiB/s, done.\nTotal 12 (delta 3), reused 0 (delta 0)\nfatal: The remote end hung up unexpectedly\nfatal: The remote end hung up unexpectedly\nDone\nerror: RPC failed; curl 56 Recv failure: Connection was reset"}, {"role": "assistant", "content": "Please try one of these methods below:\nMethod 1:\ngit config --global http.postBuffer 157286400\n\nMethod 2:\nIncrease \"client_max_body_size\" of your Nginx configuration in your Gitlab server.\nCheckout this link to get more information:\nhttps://confluence.atlassian.com/stashkb/git-push-fails-client-intended-to-send-too-large-chunked-body-590251250.html\nHope they will be useful! Good luck!!!"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI: Get source branch after merge-request has been accepted\n\nI have a master branch which is supposed to only get commits by merging either a \"release/xxxxx\" branch into it or by merging a \"hotfix/xxxxx\" branch into it.\nThe pipeline for a release branch builds a docker image and publishes it using the tag \"beta\".\nThe pipeline for a release branch builds a docker image and publishes it using the tag \"hotfix\".\nThe pipeline for the master simply re-tags either \"beta\" to \"stable\" (when a release branch has been merged into the master)  or \"hotfix\" to \"stable\" (when a hotfix branch has been merged into the master). Then it also creates a new git tag for that version and a release in gitlab. Finally the docker image gets deployed.\nCurrently the following happens:\n\nA merge request is created to merge \"release/xxxxx\" into \"master\".\nThe pipeline starts automatically (before the merge request has been accepted and merged).\nThe docker job parses the CI_MERGE_REQUEST_SOURCE_BRANCH_NAME variable to determine the source branch of the merge request was a release branch.\nThe docker job then re-tags \"beta\" to \"latest\".\nThe git tag job adds a version tag and gitlab release to the project.\nThe deploy job deploys the docker image.\n\nWhen the merge request is finally accepted the following happens:\n\nThe pipeline starts again.\nThe docker job parses CI_MERGE_REQUEST_SOURCE_BRANCH_NAME which is now empty and thus fails to determine the source branch for this merge.\nThe docker job fails.\n\nI think it's pretty obvious that I don't want to run all these jobs (especially the deploy job) before the merge request has been accepted. \nBut I can't think of a good way to only run the pipeline on the master after a merge-request has been accepted and then still be able to determine the source branch."}, {"role": "assistant", "content": "Using only information stored in git :\nwhen running after a merge request has been accepted, the HEAD commit should be the result of the merge, so HEAD^2 should be the head commit of the branch that was merged.\nYou can have information on :\n\nthe tags that point directly at this commit :\n git tag --points-at HEAD^2\n\n\nthe branches that point directly at this commit :\n git branch --points-at HEAD^2    # for local branches\n git branch -r --points-at HEAD^2 # for remote branches\n\n\nthe branches that contain this commit :\n git branch --contains HEAD^2    # for local branches\n git branch -r --contains HEAD^2 # for remote branches\n\n\n\nUsing environment variables set by gitlab :\nafter reading the predefined variables doc page, I was surprised not to find variables that would indicate that the job was triggered after a merge request was accepted.\nYou may look into gitlab's webhooks : Merge requests events ; these should provide enough information to identify what branches were involved in the merge request after it has been accepted.\n[update] you can also use gitlab's API, see @BastienSander's answer"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to use GitLab CI with a custom Docker image?\n\nI made a simple Dockerfile:\nFROM openjdk\nEXPOSE 8080\n\nand built an image using:\ndocker build -t test .\n\nI installed and configured a docker GitLab CI runner and now I would like to use this runner with my test image. So I wrote the following .gitlab-ci.yml file:\nimage: test\n\nrun:\n  script:\n    - echo \"Hello world!\"\n\nBut to my disappointment, the local test image that I can use on my machine was not found.\nRunning with gitlab-ci-multi-runner 9.4.2 (6d06f2e)\n  on martin-docker-rawip (70747a61)\nUsing Docker executor with image test ...\nUsing docker image sha256:fa91c6ea64ce4b9b44672c6e56eed8312d0ec2afc80730cbee7754bc448ea22b for predefined container...\nPulling docker image test ...\nERROR: Job failed: Error response from daemon: repository test not found: does not exist or no pull access\n\nI do not even know what is going on anymore. How can I make the runner aware of this image that I made?"}, {"role": "assistant", "content": "I had the same question. And I found the answer here: https://forum.gitlab.com/t/runner-cant-use-local-docker-images/5507/6\nAdd the following in the /etc/gitlab-runner/config.toml\n[runners.docker]\n# more config for the runner here...\npull_policy = \"if-not-present\"\n\nMore info here: https://docs.gitlab.com/runner/executors/docker.html#how-pull-policies-work\nMy Dockerfile\nFROM node:latest\nRUN apt-get update -y && apt-get install openssh-client rsync -y\n\nOn the runner I build the image:\ndocker build -t node_rsync .\n\nThe .gitlab-ci.yml in the project using this runner.\nimage: node_rsync\n\njob:\n  stage: deploy\n  before_script:\n    # now in the custom docker image\n    #- 'which ssh-agent || ( apt-get update -y && apt-get install openssh-client -y )'\n    - mkdir -p ~/.ssh\n    - eval $(ssh-agent -s)\n    - '[[ -f /.dockerenv ]] && echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" > ~/.ssh/config'\n    - ssh-add <(tr '@' '\\n' <<< \"$STAGING_PRIVATE_KEY\" | base64 --decode)\n    # now in the custom docker image\n    #- apt-get install -y rsync\n  script:\n    - rsync -rav -e ssh --exclude='.git/' --exclude='.gitlab-ci.yml' --delete-excluded ./ $STAGING_USER@$STAGING_SERVER:./deploy/\n  only:\n    - master\n  tags:\n    - ssh"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How does gitlab decide which runner to use for a job\n\nIf there are more than one available runner for a project, how does gitlab ci decide which runner to use?\nI have an omnibus gitlab 8.6.6-ee installation, with 2 runners configured. The runners are identical (docker images, config, etc) except that they are running on different computers.\nIf they are both idle and a job comes in that either of them could run, which one will run?"}, {"role": "assistant", "content": "To add to Rubinum's answer the 'first' runner would be whichever runner that checks in first that meets all criteria. For example, labels could limit which runners certain jobs run on.\nRunners query the gitlab server every X seconds to check if there are builds. if there's a build queued and multiple meet criteria, the first to ask will win\nUpdate to answer comments:\nRunners communicate through the CI API http://docs.gitlab.com/ce/ci/api/builds.html to get build status. This will eventually imply that it will become a more or less random choosing of the runner based on when it finished the last job and the xamount of msit is waiting to check. \nTo completely answer the question:\nCredit goes to BM5k after digging through the code and finding that x = 3 seconds based on this and this. Also found that:\n\nwhich machine a docker+machine runner will use once that runner has been selected) reveals that the machine selection is more or less (effectively) random as well"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab-CI: gitlab ci trigger build only for merge request\n\nIm using gitlab 8.1.4. And using gitlab-ci thats comes built-in. By default, gitlab-ci is triggering build for every push. How can make it trigger only during creation of merge request?\nThanks in advance"}, {"role": "assistant", "content": "Try the following into your .gitlab-ci.yml file.\nstage: build\nscript:\n    - xxxxx\nartifacts:\n    paths:\n        - xxxxx\ntags:\n    - xxxx\nonly:\n    - merge_requests\n\nSource: https://docs.gitlab.com/ee/ci/yaml/#only-and-except-simplified"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab can't clone repository even though ssh works\n\nAs the title states, I can't clone a repository from a Gitlab 6 server even though the ssh seems to work.\nWhen trying to clone, it looks like this:\ngit clone ssh://[email\u00a0protected]:1337/project/repository.git\nCloning into 'repository'...\nAccess denied.\nfatal: Could not read from remote repository.\n\nPlease make sure you have the correct access rights\nand the repository exists.\n\nIn the project, I have the role of \"developer\" which should have the rights to clone a repository?\nI also checked if my SSH public key is working\nssh [email\u00a0protected] -p 1337 -T\nWelcome to GitLab, Anonymous!\n\nMore irritating to me is that for a friend of mine seems everything to work fine.\nEdit:\nThe main indicator for the problem stated here is the greeting from the SSH Test. In an working enviroment it should be greeting you with your name instead Anonymous!"}, {"role": "assistant", "content": "Try the scp-like syntax:\ngit clone ssh://[email\u00a0protected]:1337:project/repository.git\n\nThat forces the use of ~/.ssh/config actually, which means the url can be simplified to gitlab:project/repositoriy.git. \nBut it turned out to be an ssh key issue in the gitlab server ~gitlab/.ssh/authorized_keys (a bit like in issue 4730).\nThe OP Gelix confirms in the comments:\n\nI removed my key from Gitlab, manually from authorized_keys, readded it on Gitlab. Everything fine now.\n  Message with SSH Test is now also Welcome to GitLab, Felix *****!\n\n(instead of Welcome to GitLab, Anonymous!)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab webhook does not trigger a build on jenkins\n\nI've a group of multibranch pipeline jobs generated with the following piece groovy script:\n[\n      'repo1',\n      'repo2',\n].each { service ->\n\n  multibranchPipelineJob(service) {\n\n    displayName(service)\n\n    branchSources {\n      git {\n        remote(\"[email\u00a0protected]:whatever/${service}.git\")\n        credentialsId('gitlab-ssh-key')\n      }\n    }\n\n    orphanedItemStrategy {\n      discardOldItems {\n        daysToKeep(0)\n        numToKeep(30)\n      }\n    }\n\n    triggers {\n      periodic(5)\n    }\n\n  }\n}\n\nand in each repo a Jenkinsfile that looks as follows:\n#!/usr/bin/env groovy\n\nproperties([\n      gitLabConnection('[email\u00a0protected]'),\n      pipelineTriggers([\n            [\n                  $class               : 'GitLabPushTrigger',\n                  triggerOnPush        : true,\n                  triggerOnMergeRequest: true,\n            ]\n      ]),\n      disableConcurrentBuilds(),\n      overrideIndexTriggers(false)\n])\n\nnode {\n\n  def sbtHome = tool name: 'sbt-0.13.15', type: 'org.jvnet.hudson.plugins.SbtPluginBuilder\\$SbtInstallation'\n\n  stage('Checkout') {\n    checkout scm\n  }\n\n  stage('Build') {\n    sh \"'${sbtHome}/bin/sbt' clean compile\"\n  }\n\n  stage('Test') {\n    sh \"'${sbtHome}/bin/sbt' test\"\n  }\n\n  if (env.BRANCH_NAME == 'develop' || env.BRANCH_NAME == 'master') {\n    stage('Publish') {\n      sh \"'${sbtHome}/bin/sbt' publish\"\n    }\n  }\n}\n\nIt all works correctly. The seeder project generates all the folders from the first script and all the branches for given repo are built correctly.\nUnfortunately I've problems with triggering a build for any branch after commit + push has been made to gitlab. \nI've jenkins configured correctly - I mean the gitlab plugin, there is a connection and it all works well.  \nI've also added a webhook on the gitlab side and it also runs correctly. After a test push is sent I receive 200 OK from jenkins and I do see in logs that scanning the branches has started and detected the changes correctly. Unfortunately the build for the changed branch does not start. Here's an extract from branch scan log: \n  Checking branch ci\n      \u2018Jenkinsfile\u2019 found\n    Met criteria\nChanges detected: ci (a7b9ae2f930b0b10d52bb42f1ecf96a68bba4a30 \u2192 39a4c1a65051d5e90079feec14ad22455a77c58e)\nDid not schedule build for branch: ci\n\nI'm 100% sure that this not a problem with communication between my jenkins instance and gitlab account. I see the webhook being triggered after push to gitlab, I see the request being send and branch scan being run. Changes are also detected but why on earth the job isn't started? I've also read the docs thoroughly and have it all configured correctly. \nJenkins version: 2.150.3\nGitlab version: 11.8.1-ee\n\nEDIT\nIt seems that after upgrading jenkins to v.2.164.1 it all started working correctly."}, {"role": "assistant", "content": "I found this very useful Setup Example (Continuous Integration with Jenkins and GitLab) . Especially the part Source Code management: \n\nWe need to specify the name as \u201corigin\u201d, which will be used by the other sections. For the Refspec we need to input:    +refs/heads/*:refs/remotes/origin/* +refs/merge-requests/*/head:refs/remotes/origin/merge-requests/*\n\nAnd also:\n\nBranch Specifier we need origin/${gitlabSourceBranch} which will be filled in based on the web hook we\u2019ll be setting up next.\n\n\nEdit1\nYou could try the following for one multibranch pipeline:\n\nSelect a branch, for example ci\nSelect \"View Configuration\" \nUnder \"Build Triggers\" select the checkbox \"Build when a change is pushed to GitLab\"\nMake some changes to the code and push to ci\n\n\nEdit2\nI could not find a suitable git-project to run and try to reproduce this behaviour. So if someone know a similar project and could share, please comment and I could do some more testing.\nFor Gitlab (requested a trial key, otherwise it will be a GitLab Community Edition): \nsudo docker run --detach --hostname gitlab.example.com --publish 443:443 --publish 80:80 --publish 22:22 --name gitlab --restart always --volume /srv/gitlab/config:/etc/gitlab --volume /srv/gitlab/logs:/var/log/gitlab --volume /srv/gitlab/data:/var/opt/gitlab gitlab/gitlab-ee:11.8.1-ee.0\n\nFor Jenkins:\nsudo docker run  -u root  --rm  -d  -p 8080:8080  -p 50000:50000  -v jenkins-data:/var/jenkins_home  -v /var/run/docker.sock:/var/run/docker.sock  jenkins/jenkins:2.150.3\n\nThen \"Integration\" \u2014> \"Jenkins CI\" in Gitlab as in this image:\nHope this can help you!"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI script needs entry in /etc/hosts\n\nI have a GitLab CI docker runner to execute my automated tests when I push. One of my tests requires a custom entry in /etc/hosts. I can't figure out how to get the entry into that file.\nHere's basically what my .gitlab-ci.yml file looks like:\nbefore_script:\n  - cat /etc/hosts   # for debugging\n  - ...              # install app dependencies\nspecs:\n  script:\n    - rspec          # <- a test in here fails without the /etc/hosts entry \n\nAll my tests pass, except for the one that requires that /etc/hosts entry.\nLet's say I'm trying to have the hostname myhost.local resolve to the IPv4 address XX.XX.XX.XX...\nI tried using extra_hosts on the runner config, but it didn't seem to have any effect (got idea from here):\n/etc/gitlab-runner/config.toml:\nconcurrent = 1\ncheck_interval = 0\n\n[[runners]]\n  name = \"shell\"\n  url = \"https://mygitlabinstance.com/\"\n  token = \"THETOKEN\"\n  executor = \"shell\"\n  [runners.cache]\n\n[[runners]]\n  name = \"docker-ruby-2.5\"\n  url = \"https://mygitlabinstance.com/\"\n  token = \"THETOKEN\"\n  executor = \"docker\"\n  [runners.docker]\n    tls_verify = false\n    image = \"ruby:2.5\"\n    privileged = false\n    disable_cache = false\n    volumes = [\"/cache\"]\n    shm_size = 0\n    extra_hosts = [\"myhost.local:XX.XX.XX.XX\"]\n  [runners.cache]\n\nBut the test still failed. The cat /etc/hosts shows that it's unchanged:\n# Your system has configured 'manage_etc_hosts' as True.\n# As a result, if you wish for changes to this file to persist\n# then you will need to either\n# a.) make changes to the master file in /etc/cloud/templates/hosts.tmpl\n# b.) change or remove the value of 'manage_etc_hosts' in\n#     /etc/cloud/cloud.cfg or cloud-config from user-data\n#\n127.0.1.1 ip-172-31-2-54.ec2.internal ip-172-31-2-54\n127.0.0.1 localhost\n\n# The following lines are desirable for IPv6 capable hosts\n::1 ip6-localhost ip6-loopback\nfe00::0 ip6-localnet\nff00::0 ip6-mcastprefix\nff02::1 ip6-allnodes\nff02::2 ip6-allrouters\nff02::3 ip6-allhosts\n\nI figured I could just add the entry myself in a before_script line, but I don't seem to be able to execute anything with root privileges in the container:\nbefore_script:\n  - echo 'XX.XX.XX.XX myhost.local' >> /etc/hosts\n  ...\n\nBut that just fails because the gitlab-runner user doesn't have permissions to write to that file. I tried to use sudo, but gitlab-runner can't do that either (echo 'XX.XX.XX.XX myhost.local' | sudo tee --non-interactive --append /etc/hosts --> sudo: a password is required)\nSo in summary, how can I get my container to have the host entry I need (or how can I execute a before_script command as root)?"}, {"role": "assistant", "content": "The following statement is incorrect:\n\n\"But that just fails because the gitlab-runner user doesn't have permissions to write to that file.\"\n\nThe gitlab-runner is not the user executing your before_script, it is the user that runs the container in which your job is executed.\nYou are using the ruby:2.5 Docker image as far as I can tell and that does not contain any USER reference in its or its parents Dockerfile.\nTry adding a whoami command right before your echo 'XX.XX.XX.XX myhost.local' >> /etc/hosts command to verify you are root.\nUpdate\nIf gitlab-runner is shown as the result of whoamithe docker-executor is not used and instead a shell-executor has picked up the job."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Is there a way to use OR condition with needs in GitLab CI job\n\nI am trying to create a job dependency with \"OR\" condition for previous stage jobs using \"needs\" in \".gitlab.ci.yml\" file but unable to find a solution for this.\n.gitlab-ci.yml file ->\nstages:\n  - build\n  - test\n  - deploy\n\n\nBuild_job:      \n  stage: build\n  script:\n    - echo \"hello from build job\"\n\nTest_job1:\n  stage: test\n  script:\n    - echo \"Start test 1\"\n  when: manual\n\nTest_job2:\n  stage: test\n  script:\n    - echo \"Start test 2\"\n  when: manual\n\nDeploy_job:\n  stage: deploy\n  script:\n    - echo \"Start deploying the job\"\n  when: manual\n    needs:\n      - job: Test_job1\n        optional: true\n      - job: Test_job2\n        optional: true\n\nMy aim is either of Test_job1 or Test_job2 is passed Deploy_job should be enabled.\nBut with the above code, I am unable to do so as Deploy_job is getting enabled only when both previous two test jobs are passed.\n\nIs there a way if something can be used like needs: [Test_job1 or Test_job2]?"}, {"role": "assistant", "content": "The needs:optional:  keyword is confusingly named. It is for setting up needs: requirements when jobs might not exist in the pipeline due to other pipeline/job logic (the jobs can optionally exist).\nHowever, any optional needs:job: names that do exist in the pipeline will all be required.\nI see a few options to get close to your desired pipeline:\nautomation path\nYou could use the rules: keyword in your Test_job jobs to conditionally add them to the pipeline.\nThe humans that are deciding which Test_job to run (an assumption based on the fact that you're using when: manual) are likely following decision logic of some sort--or a preset decision logic can be decided on by the team.  You would then build that logic into your needs:if: condition to determine whether or not your Test_job# jobs exist in the pipeline--then only the Test_jobs that are added to the pipeline will be required by the Deploy_job:.\nFor example, if one test should run on your default branch and the other on feature branches, you could use the following to automatically run the relevant Test_job and have the Deploy_job depend on it:\nTest_job1:\n  stage: test\n  script:\n    - echo \"Start test 1\"\n  # this job is only added for pipelines on the default branch\n  rules:\n    - if $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH\n      when: on_success\n    - when: never\n\nTest_job2:\n  stage: test\n  script:\n    - echo \"Start test 2\"\n  # this job is only added for pipelines NOT on the default branch\n  rules:\n    - if $CI_COMMIT_REF_NAME != $CI_DEFAULT_BRANCH\n      when: on_success\n    - when: never\n\nDeploy_job:\n  stage: deploy\n  script:\n    - echo \"Start deploying the job\"\n  # this is the default value, it's added here to show the automation difference from the question's pipeline\n  rules:\n    - when: on_success\n  # depend on Test_job1 AND Test_job2 if they individually exist in the pipeline\n  needs:\n    - job: Test_job1\n      optional: true\n    - job: Test_job2\n      optional: true\n\nmanual path\nYou could swap when:manual back in place for when:on_success if you still need humans in the loop on triggering the test jobs or deploy job.\nreally manual path\nAlternatively, if you really just want your humans to manually make the Test_job: decisions ad-hoc, then just remove the needs: keyword from your Deploy_job: and use the existing Stage dependency structure.  The when: manual key implicitly sets allow_failure: true, so your jobs are already optional as is.  If your humans can't be trusted to manage the \"Test before Deploy\" dependency on their own with manual jobs, then take the humans out of the loop and see the \"automation path\" above."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Embed a PDF in github/gitlab wiki\n\nI'm using gitlab to manage my repositories which has been quite pleasant so far. However the wiki could use a fair amount of improvement IMO.\nIt's really annoying when you already have documentation that you simply want to add to the wiki. Translating a table or pdf to gitlab flavored markdown can be time consuming and non-trivial.\nMy question is two-fold.\n\nHas anyone had luck embedding files (specifically pdf's) into their github/gitlab wiki? This should definitely be possible on gitlab but is their an easy way to do it? I have a documentation repo set up, it would be awesome to embed files linked from the documentation repo.\nIf not embedding files into the pages. How do you efficiently translate a document to gitlab flavored markdown?"}, {"role": "assistant", "content": "Had the same issue and landed here, maybe this helps somebody.\nI didn't find a way to embed the .pdf into a page but what I did was to add the .pdf to the wiki folder (like a normal page). Initially this didn't show up in the sidebar nor was it searchable from Github.\nIt is possible however to link it directly from other pages or a custom sidebar (see for example osquery's wiki for a nice sidebar). Clicking on the link allows you to download the .pdf (didn't find a way to preview it in the browser)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to customise config.toml on Kubernetes?\n\nI'm have a Gitlab cloud connected to a k8s cluster running on Google (GKE).\nThe cluster was created via Gitlab cloud.\nI want to customise the config.toml because I want to fix the cache on k8s as suggested in this issue.\nI found the config.toml configuration in the runner-gitlab-runner ConfigMap.\nI updated the ConfigMap to contain this config.toml setup:\n  config.toml: |\n    concurrent = 4\n    check_interval = 3\n    log_level = \"info\"\n    listen_address = '[::]:9252'\n    [[runners]]\n      executor = \"kubernetes\"\n      cache_dir = \"/tmp/gitlab/cache\"\n      [runners.kubernetes]\n        memory_limit = \"1Gi\"\n        [runners.kubernetes.node_selector]\n          gitlab = \"true\"\n        [[runners.kubernetes.volumes.host_path]]\n          name = \"gitlab-cache\"\n          mount_path = \"/tmp/gitlab/cache\"\n          host_path = \"/home/core/data/gitlab-runner/data\"\n\nTo apply the changes I deleted the runner-gitlab-runner-xxxx-xxx pod so a new one gets created with the updated config.toml.\nHowever, when I look into the new pod, the /home/gitlab-runner/.gitlab-runner/config.toml now contains 2 [[runners]] sections:\nlisten_address = \"[::]:9252\"\nconcurrent = 4\ncheck_interval = 3\nlog_level = \"info\"\n\n[session_server]\n  session_timeout = 1800\n\n[[runners]]\n  name = \"\"\n  url = \"\"\n  token = \"\"\n  executor = \"kubernetes\"\n  cache_dir = \"/tmp/gitlab/cache\"\n  [runners.kubernetes]\n    host = \"\"\n    bearer_token_overwrite_allowed = false\n    image = \"\"\n    namespace = \"\"\n    namespace_overwrite_allowed = \"\"\n    privileged = false\n    memory_limit = \"1Gi\"\n    service_account_overwrite_allowed = \"\"\n    pod_annotations_overwrite_allowed = \"\"\n    [runners.kubernetes.node_selector]\n      gitlab = \"true\"\n    [runners.kubernetes.volumes]\n\n      [[runners.kubernetes.volumes.host_path]]\n        name = \"gitlab-cache\"\n        mount_path = \"/tmp/gitlab/cache\"\n        host_path = \"/home/core/data/gitlab-runner/data\"\n\n[[runners]]\n  name = \"runner-gitlab-runner-xxx-xxx\"\n  url = \"https://gitlab.com/\"\n  token = \"<my-token>\"\n  executor = \"kubernetes\"\n  [runners.cache]\n    [runners.cache.s3]\n    [runners.cache.gcs]\n  [runners.kubernetes]\n    host = \"\"\n    bearer_token_overwrite_allowed = false\n    image = \"ubuntu:16.04\"\n    namespace = \"gitlab-managed-apps\"\n    namespace_overwrite_allowed = \"\"\n    privileged = true\n    service_account_overwrite_allowed = \"\"\n    pod_annotations_overwrite_allowed = \"\"\n    [runners.kubernetes.volumes]\n\nThe file /scripts/config.toml is the configuration as I created it in the ConfigMap.\nSo I suspect the /home/gitlab-runner/.gitlab-runner/config.toml is somehow updated when registering the Gitlab-Runner with the Gitlab cloud.\nIf if changing the config.toml via the ConfigMap does not work, how should I then change the configuration? I cannot find anything about this in Gitlab or Gitlab documentation."}, {"role": "assistant", "content": "Inside the mapping you can try to append the volume and the extra configuration parameters:\n# Add docker volumes\ncat >> /home/gitlab-runner/.gitlab-runner/config.toml << EOF\n\n      [[runners.kubernetes.volumes.host_path]]\n        name = \"var-run-docker-sock\"\n        mount_path = \"/var/run/docker.sock\"\nEOF\n\nI did the runner deployment using a helm chart; I guess you did the same, in the following link you will find more information about the approach I mention: https://gitlab.com/gitlab-org/gitlab-runner/issues/2578\nIf after appending the config your pod is not able to start, check the logs, I did test the appending approach and had some errors like \"Directory not Found,\" and it was because I was appending in the wrong path, but after fixing those issues, the runner works fine."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab and HTML documentation\n\nMy development environment consists of Git repository, GitLab repository manager and Jenkins. During build process a documentation is generated with Doxygen in HTML format.\nIs it possible to store that documentation on GitLab project's wiki? I know that HTML is not supported in Gollum, which is the Gitlab's wiki engine. Converting HTML to Markdown is not satisfactory because of internal links in HTML files that point to other HTML files.\nShould I store documentation in a separate wiki instead and only commit a link to GitLab project wiki?"}, {"role": "assistant", "content": "I guess the answer depends on what you use your HTML documentation for and how much you distribute it.\nFirst of all, which version of Gitlab are you using ?\n\nIf it is only for your developers to get access to (aka these are private documents), then on Gitlab >= 8.1.2 there is a service called External Wiki that allows you to substitute the Wiki link of the project by any URL of your choice. Just set up a web server serving your html documentation, have your build server upload the newest version after each build and call it a day.\nIf your documentation is a code that you want to version control and distribute, then do so.\n\nWhether you go for 1. or 2., it is still a good idea to have a the whole documentation in a separate git repository, because you get compression for free and using git pull is much better than using any rsync to synchronise any local or remote directories. Then is just a matter of setting up shell script or git hooks to automatically do all of it for you; either at commit or build time.\nHope this helps !"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "curl command not found on .gitlab-ci.yml\n\nI have a .gitlab-ci.yml file. Its creating some docker images and pushing it to AWS ECR.\nWhen I am running curl command to push some artifacts to remote repository it says curl: not found. I am already using openjdk image to do ./gradlew build. Don't know how to install curl on Gitlab runner.\nPlease guide."}, {"role": "assistant", "content": "I was able to resolve it by using apk utility.\napk add --update curl && rm -rf /var/cache/apk/*\n\nOr more recently using no-cache:\napk add --no-cache curl"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "why did gitlab 6 switch back to unicorn?\n\nGitlab 6.0 was released yesterday. I am curious to know why they switched to Unicorn from Puma.\nVersions prior to 5 were using Unicorn. I thought switch to Puma was for the better. \nIs there a technical reason for this switch?"}, {"role": "assistant", "content": "Update April 2020, GitLab 12.10:\n\nPuma will become the default application server\nGitLab will be switching default application servers from Unicorn to Puma in 13.0.  \n\nAnd with GitLab 13.0 (May 2020):\n\nReduced memory consumption of GitLab with Puma\n\nRead the last sections below.\n\nOriginal answer 2013\nThe commit 3bc484587 offers some clues from Mathieu 'OtaK' Amiot:\n\nWe switched from Puma in GitLab 5.4 to unicorn in GitLab 6.0.\n\nwhy switch back to Unicorn again?\n\nPuma caused 100% CPU and greater memory leaks when running mult-ithreaded on systems with many concurrent users.\n  That's because people used MRI. You MUST use JRuby or Rubynius when using Puma. Or else the world breaks apart.\n\nMathieu adds in the comments:\n\nYes, Unicorn is better (but more memory-eager) on MRI setups.\n  Puma is better on Rubinius & JRuby, that's all. \nThey can't force people to use other implementations of the Ruby Runtime, so they just fell back to the best setup for most setups :) \u2013\n\n\nLight controversy ensues around:\n\nPuma: Hongli comments:\n\n\nPuma's multithreading works just fine with MRI.\n  I say this as one of the authors behind Ruby Enterprise Edition, so I know Ruby's threading system inside-out.\nEvan Phoenix, Puma's author, has also stated that using Puma with MRI works just fine. \nIf there are issues then they are likely in Gitlab's code.\n\nThat being said, in Apr. 2020, Puma is now available as an alternative web server to Unicorn with GitLab 12.9\n(mentioned by mbomb007 in the comments)\n\nPhusion Passenger Enterprise:\n\nMathieu 'OtaK' Amiot comments:\n\nPassenger is not as stable as most people think. A nginx + Unicorn is more stable IMHO. \u2013 \n\nHongli answers:\n\nWe have lots and lots of large users using Phusion Passenger, both open source and Enterprise, on a daily basis with great stability and success.\n  Think New York Times, 37signals, Motorola, UPS, Apple, AirBnB. Some of them even switched away from Unicorn in favor of Passenger (either open source or Enterprise)\n\n\nUpdate August 2014: there is an article on \"Running GitLab 7.1 using Puma instead of a Unicorn\"\n\nUpdate April 2020, GitLab 12.10:\n\nPuma will become the default application server\nGitLab will be switching default application servers from Unicorn to Puma in 13.0.\n  Puma is a multithreaded application server, allowing GitLab to reduce it\u2019s memory consumption by about 40%.\n\nA> s part of the GitLab 13.0 upgrade, users who have customized Unicorn settings will need to manually migrate these settings to Puma.\nIt will also be possible to remain on Unicorn, by disabling Puma and re-enabling Unicorn until Unicorn support is removed in a future release.\nThis is thanks to Dmitry Chepurovskiy, who has made a major contribution adding the Puma web server to the GitLab unicorn Helm chart (soon to be the webservice chart). \n\nThis work provides users of the GitLab Helm chart with the option to use Puma instead of Unicorn.\n  In testing, we have observed a 40% reduction in memory usage when using Puma as the web server.\n\nSee Epic.\n\nWith GitLab 13.0 (May 2020):\n\nReduced memory consumption of GitLab with Puma\nPuma is now the default web application server for both the Omnibus-based and Helm-based installations. Puma reduces the memory footprint of GitLab by about 40% compared to Unicorn, increasing the efficiency of GitLab and potentially saving costs for self-hosted instances.\n\n\n\nInstallations which have customized the number of Unicorn processes, or use a slower NFS drive, may have to adjust the default Puma configuration.\n  See the Important notes on upgrading and GitLab chart improvements for additional details.\n\nSee documentation and Epic."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Error installing charlock_holmes : Error installing GITLAB\n\nI am trying to install GITLAB. I get this error executing \"sudo gem install charlock_holmes --version '0.6.9'\" (section Install Gems) \nGEOGIT:/geogit/Administrative_Tools # sudo gem install charlock_holmes --version '0.6.9'\nBuilding native extensions.  This could take a while...\nERROR:  Error installing charlock_holmes:\n        ERROR: Failed to build gem native extension.\n\n        /usr/bin/ruby1.9 extconf.rb\nchecking for main() in -licui18n... no\nwhich: no brew in (/usr/sbin:/bin:/usr/bin:/sbin)\nchecking for main() in -licui18n... no\n\n***************************************************************************************\n*********** icu required (brew install icu4c or apt-get install libicu-dev) ***********\n***************************************************************************************\n*** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of\nnecessary libraries and/or headers.  Check the mkmf.log file for more\ndetails.  You may need configuration options.\n\nProvided configuration options:\n        --with-opt-dir\n        --without-opt-dir\n        --with-opt-include\n        --without-opt-include=${opt-dir}/include\n        --with-opt-lib\n        --without-opt-lib=${opt-dir}/\n        --with-make-prog\n        --without-make-prog\n        --srcdir=.\n        --curdir\n        --ruby=/usr/bin/ruby1.9\n        --with-icu-dir\n        --without-icu-dir\n        --with-icu-include\n        --without-icu-include=${icu-dir}/include\n        --with-icu-lib\n        --without-icu-lib=${icu-dir}/\n        --with-icui18nlib\n        --without-icui18nlib\n        --with-icui18nlib\n        --without-icui18nlib\n\nGem files will remain installed in /usr/lib64/ruby/gems/1.9.1/gems/charlock_holmes-0.6.9 for inspection.\nResults logged to /usr/lib64/ruby/gems/1.9.1/gems/charlock_holmes-0.6.9/ext/charlock_holmes/gem_make.out\n\nSomeone, can help me debug those logs and error?"}, {"role": "assistant", "content": "This looks like issue 1952\n\nIt was actually weirdness with the way my ubuntu VPS is commissioned. Mine did not come with a C compiler or libdev obviously.\nThe problem fix I found was to install libdev first, then the GCC\nThen apt-get install libicu-dev.\n\nUpdate 2015: additional comments include:\n\nyum install libicu-devel worked for me\nYou just need to make sure \"patch\" is installed (yum install patch) then it should work"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab 7.2.1 with Apache Server instead of Nginx\n\nI have installed GitLab 7.2.1 with the .deb package from GitLab.org for Debian 7 on a virtual server where I have root access.\nOn this virtual server I have already installed Apache, version 2.2.22 and I don't want to use Ngnix for GitLab.\nNow I have no idea where the public folders of GitLab are or what I have to do or on what I have to pay attention. \nSo my question is: How do I have to configure my vhost for apache or what do I have to do also that I can use a subdomain like \"gitlab.example.com\" on my apache web server?"}, {"role": "assistant", "content": "With two things in mind:\n\nUnicorn is listening on 8080 (you can check this with sudo netstat -pant | grep unicorn)\nYour document root is /opt/gitlab/embedded/service/gitlab-rails/public\n\nYou can create a new vhost for gitlab in apache with the following configuration:\n<VirtualHost *:80>\n  ServerName gitlab.example.com\n  ServerSignature Off\n\n  ProxyPreserveHost On\n\n  <Location />\n    Order deny,allow\n    Allow from all\n\n    ProxyPassReverse http://127.0.0.1:8080\n    ProxyPassReverse http://gitlab.example.com/\n  </Location>\n\n  RewriteEngine on\n  RewriteCond %{DOCUMENT_ROOT}/%{REQUEST_FILENAME} !-f\n  RewriteRule .* http://127.0.0.1:8080%{REQUEST_URI} [P,QSA]\n\n  # needed for downloading attachments\n  DocumentRoot /opt/gitlab/embedded/service/gitlab-rails/public\n\n</VirtualHost>"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Unable to publish jar to Gitlab package registry with gradle\n\nI am trying to publish some jar artefacts on gitlab package registry but I get this error from the server :\nReceived status code 415 from server: Unsupported Media Type\n\nHere is the publishing section of my build.gradle.kts :\npublishing {\n    publications {\n        create<MavenPublication>(\"maven\"){\n            artifact(tasks[\"bootJar\"])\n        }\n    }\n    repositories {\n        maven {\n            url =  uri(\"https://gitlab.com/api/v4/groups/my-group/-/packages/maven\")\n            name = \"Gitlab\"\n            credentials(HttpHeaderCredentials::class) {\n                name = \"Token\"\n                value = System.getenv(\"CI_JOB_TOKEN\")\n            }\n            authentication {\n                create<HttpHeaderAuthentication>(\"header\")\n            }\n        }\n    }\n}\n\nIn my gitlab-ci, I added a task for publish the artefacts :\ndeploy:\n  stage: deploy\n  script: gradle publish\n  only:\n    - master\n\nAny help would be appreciated"}, {"role": "assistant", "content": "Quick answer\nReplace your publishing url pointing to the group-scope with the one pointing to the specific-package-repository, e.g. on gitlab.com:\nhttps://gitlab.com/api/v4/projects/<your-project-id>/packages/maven\nYou need to replace <your-project-id> with your specific project-id of course.\nRelated to this a quote from docs.gitlab:\n\nNote: In all cases, you need a project specific URL for uploading a package in the distributionManagement section.\n\nOr in other words: Only the general repositories section can use your groups-url for searching other already published artifacts! (I also had to understand that). So:\n\nyou cannot publish to the group-package-store on gitlab, you can just search there.\nPublication goes always to the project-specific package-store, which will then be visible at group-scope too.\n\nExample gradle config (kotlin-dsl)\nrepositories {\n    mavenCenter()\n    jcenter()\n\n    // Here you USE the group api/v4 url for SEARCHING packages\n    maven {\n        name = \"GitLab\"\n\n        url = uri(\"https://gitlab.com/api/v4/groups/my-group/-/packages/maven\")\n        credentials(HttpHeaderCredentials::class) {\n            name = \"Job-Token\"\n            value = System.getenv(\"CI_JOB_TOKEN\")\n        }\n        authentication {\n            create<HttpHeaderAuthentication>(\"header\")\n        }\n    }\n\n}\n\npublishing {\n    publications {\n        create<MavenPublication>(\"maven\"){\n            artifact(tasks[\"bootJar\"])\n        }\n    }\n    repositories {\n        maven {\n            \n            // here your PROVIDE the PROJECT-URI for publishing your package\n            // in the project-specific package-space which is also visible at\n            // the group scope above\n            url =  uri(\"https://gitlab.com/api/v4/projects/<your-project-id>/packages/maven\")\n            name = \"Gitlab\"\n            credentials(HttpHeaderCredentials::class) {\n                name = \"Job-Token\"\n                value = System.getenv(\"CI_JOB_TOKEN\")\n            }\n            authentication {\n                create<HttpHeaderAuthentication>(\"header\")\n            }\n        }\n    }\n}\n\nMore Info\nThere are multiple scenarios on how you may interact with the maven-repository-space on GitLab. The three switches are:\n\nThe place where you want to look for existing published packages\n\nproject-scope (https://.../api/v4/projects/<project-id>/packages/maven)\ngroup-scope (https://.../api/v4/groups/<group-id>/-/packages/maven)\ninstance-scope (https://.../api/v4/packages/maven)\n\n\nThe authorization-method you want to use\n\nPERSONAL_ACCESS_TOKEN\nDEPLOY_TOKEN\nCI_JOB_TOKEN\n\n\nThe place where your want to publish your package\n\nthis must always be a specific project-url (https://.../api/v4/projects/<project-id>/packages/maven)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab.com SSH connection timed out\n\ni try to get Gitlab with SSH working, but it won't.\nI have done following steps:\n1 ) generate ssh-key\nssh-keygen -t rsa -C \"[email\u00a0protected]\" -b 4096\n\n2 ) named the key \"id_rsa\" in folder /Users/myUserName/.ssh/\n3) copied the key via\npbcopy < ~/.ssh/id_rsa.pub\n\n4) insert the key into gitlab\nWhen i now try to clone a repository i receive the following error:\n$ git clone [email\u00a0protected]:myName/repositoryName/ repoName\nCloning into 'repoName'...\nssh: connect to host gitlab.com port 22: Operation timed out\nfatal: Could not read from remote repository.\n\nPlease make sure you have the correct access rights\nand the repository exists.\n\nWhat is going wrong?"}, {"role": "assistant", "content": "I found myself with the same problem.\nAs Adrian Dymorz describe you can check if you have access to Gitlab through SSH with the following command:\nssh [email\u00a0protected]\n\nYou should receive a response like this:\n...\nWelcome to GitLab, <Gitlab ID Account>!\nShared connection to altssh.gitlab.com closed.\n\nIf not, then betarrabara should solve your issues BUT you should not provide your id_rsa but your id_rsa.pub instead:\nHost gitlab.com\nHostname altssh.gitlab.com\nUser git\nPort 443\nPreferredAuthentications publickey\nIdentityFile ~/.ssh/id_rsa.pub"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab push. You are not allowed to access master\n\nI have set up my own server (at home) and i am reaching it via putty on my main PC.\nGitlab is installed and configured, i can reach gitlab and log in.\nBut when i try to push files (through HTTP) to my own project i get this message:\nPOST git-receive-pack (381 bytes)\nremote: GitLab: You are not allowed to access master![K\nremote: error: hook declined to update refs/heads/master[K\nTo http://myserver.com/root/push2jump.git\n ! [remote rejected] master -> master (hook declined)\nerror: failed to push some refs to 'http://myserver.com/root/push2jump.git'\n\nI am using HTTP instead of SSH because there i get \"Access denied\", so basically neither is working.\nWhen i run \nsudo bundle exec rake gitlab:check RAILS_ENV=production\n\nIt tells me that the Sidekiq script is not running (which i can't seem to fix, not sure if it's related to this problem)\nOfcourse it tells me that the repository is empty. The rest seems fine.\nI checked \n.ssh/authorized_keys\n\nWhich seem correct as well, the key there is the same as my saved key.\nAnd my repos_path in gitlab-shell/config.yml looks good, not using symlink:\nrepos_path: /home/git/repositories/\n\nI have run the official gitlab installation guide.\nCan anyone help me with this problem?\nThanks in advance\nUPDATE \nSystem information\nSystem:         Ubuntu 12.04\nCurrent User:   git\nUsing RVM:      no\nRuby Version:   2.0.0p481\nGem Version:    2.0.14\nBundler Version:1.6.2\nRake Version:   10.3.1\nSidekiq Version:2.17.0\n\nGitLab information\nVersion:        6.9.2\nRevision:       e46b644\nDirectory:      /home/git/gitlab\nDB Adapter:     mysql2\nURL:            ***\nHTTP Clone URL: ***/some-project.git\nSSH Clone URL:  ***:some-project.git\nUsing LDAP:     no\nUsing Omniauth: no\n\nGitLab Shell\nVersion:        1.9.4\nRepositories:   /home/git/repositories/\nHooks:          /home/git/gitlab-shell/hooks/\nGit:            /usr/local/bin/git"}, {"role": "assistant", "content": "I had this problem because I had master as a protected branch\n\nOnce I unprotected the branch I was able to push fine"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "denied: requested access to the resource is denied when pushing image to gitlab registry\n\nI'm trying to push an image to gitlab registry.\nI've done it many times, so I wonder why I get this error.\nI build the image with latest tag: \nSuccessfully tagged registry.gitlab.com/mycompany/rgpd_api:latest\n\nThen I login and I push:\ndocker login registry.gitlab.com -u gitlab+deploy-token-91931 \ndocker push registry.gitlab.com/mycompany/rgpd_api:latest\n\nBut I get:\nThe push refers to repository [registry.gitlab.com/mycompany/rgpd_api]\nbe679cc302b9: Preparing \ndenied: requested access to the resource is denied\n\nI gave gitlab+deploy-token-91931 token both read_repository and read_registry rights.\nMy repo is: \nhttps://gitlab.com/mycompany/rgpd_api\n\nI checked with docs page: https://docs.gitlab.com/ee/user/project/container_registry.html\nBut when I do it through Gitlab CI, with gitlab-ci-token\nI can push it normally.\nI also tried to regenerate a new token, but still same issue.\nHow can I fix it ?"}, {"role": "assistant", "content": "I've stumbled upon this question as well and it turns out that\n\nGroup level Deploy tokens can be used to push images to group level container registry similarly to a PAT token with API access or other applicable scopes.\nThe image must to be tagged with the tag that matches an existing project within the group.\nAny image tagged differently will be rejected with the denied: requested access to the resource is denied error message.\n\nSo, with the setup below:\n\nGitLab group called mytest\nProject within that group called hello-world\nDocker image tagged as registry.gitlab.com/mytest/hello-world\nDeploy token created for an entire group\nDocker daemon authorized to push to that registry by cat \"<deploy_token>\" | docker login -u \"<token_username>\" --password-stdin registry.gitlab.com\n\nYou will get the following results:\n\nSuccessful push for docker push registry.gitlab.com/mytest/hello-world because such project exists within the group\ndenied: requested access to the resource is denied if you try to push an image tagged with the name of the project that does not exist in the group like docker push registry.gitlab.com/mytest/no-project\n\nSo, again, image must be tagged to match an existing path within te group, like an existing project within the group or a subgroup."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab:Peer's Certificate issuer is not recognized\n\nI get this error on a fresh install of gitlab. The message looks like: \nfatal: unable to access 'https://gitlab-ci-\ntoken:[email\u00a0protected]/something.git/': Peer's \nCertificate issuer is not recognized.ERROR: Job \nfailed: exit status 1\n\nAny suggestions on how to fix it?"}, {"role": "assistant", "content": "Had faced the same problem after enabling verbose mode by following command \nexport GIT_CURL_VERBOSE=1 and found the following issue:\nNSS error -8179 (SEC_ERROR_UNKNOWN_ISSUER)\nFound this following site helpful,But its good when you have entire control for \nthe proxy server as well to enter the certificates.\nhttp://dropbit.com/?p=168\nI instead ran following command to bypass ssl verification by porxy server and it worked \ngit config --global http.sslVerify \"false\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Git Clone Fails with sslRead() error on OS X Yosemite\n\nI'm currently on OS X Yosemite 10.10.3, and trying to git clone an existing repo which works fine on Windows.  I've tried a combo of installing git through homebrew with curl/openssl with no luck.  When i run the git clone, i get the following ssl read error:\nGIT_CURL_VERBOSE=1 git clone http://myURL/gitlab/project/project.git\n\n> remote: Counting objects: 1641, done. remote: Compressing objects:\n> 100% (1588/1588), done.\n> * SSLRead() return error -98061641), 136.73 MiB | 1.71 MiB/s    \n> * Closing connection 2 remote: Total 1641 (delta 910), reused 0 (delta 0) error: RPC failed; result=56, HTTP code = 200 Receiving objects:\n> 100% (1641/1641), 137.48 MiB | 1.64 MiB/s, done. Resolving deltas:\n> 100% (910/910), done.\n\nI've tried using both the Https & Http with no luck. Has anyone else hit something similar to this?\nBelow are outputs of git, curl, & openssl versions if that helps.\ncurl --version\ncurl 7.37.1 (x86_64-apple-darwin14.0) libcurl/7.37.1 SecureTransport zlib/1.2.5\nProtocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtsp smtp smtps telnet tftp \nFeatures: AsynchDNS GSS-Negotiate IPv6 Largefile NTLM NTLM_WB SSL libz \n\ngit --version\ngit version 2.4.1\n\nopenssl version\nOpenSSL 0.9.8zd 8 Jan 2015\n\nThanks in advance for any direction!"}, {"role": "assistant", "content": "Javabrett's link got me to the answer, it revolves around Yosemite using an incorrect SSL dependency, which Git ends up using.  \nInstalling Git via homebrew with these flags works:\nbrew install git --with-brewed-curl --with-brewed-openssl\n\nOr:\nbrew reinstall git --with-brewed-curl --with-brewed-openssl"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI/CD cannot git push from .gitlab-ci.yml\n\nI'm writing GitLab CI/CD pipeline script in .gitlab-ci.yml\nI want to check if a specific file changed in another repo and if so I would like to copy the file, commit and push to the current repo.\neverything works until I get to the 'git push' part\nI tried several ways to fixed it:\nstages:\n    - build\n\nbuild:\n  stage: build\n  script:\n    - echo \"Building\"\n    - git checkout -b try\n    - git remote add -f b https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.{otherRepo}.git\n    - git remote update\n    - CHANGED=$(git diff try:mobile_map.conf b/master:mobile_map.conf)\n    - if [ -n \"${CHANGED}\" ]; then\n        echo 'changed';\n        FILE=$(git show b/master:mobile_map.conf > mobile_map.conf);\n        git add mobile_map.conf;\n        git commit -m \"updating conf file\";\n        git push;\n      else\n        echo 'not changed';\n      fi\n    - git remote rm b\n\nfor this code I get :\nfatal: unable to access 'https://gitlab-ci-token:[MASKED]@gitlab.{curr_repo}.git/': The requested URL returned error: 403\n\nalso I tried to add this line in the beginning :\ngit remote set-url origin 'https://{MY_USER_NAME}:\"\\\"${PASSWORD}\\\"\"@gitlab.{curr_repo}.git'\n\nand I get this error message:\nfatal: Authentication failed for 'https://{MY_USER_NAME}:\"\\\"${PASSWORD}\\\"\"@{curr_repo}.git/'\n\nalso I added:\n - git config --global user.name {MY_USER_NAME}\n - git config --global user.email {MY_EMAIL}\n\nplease help me,\nThanks"}, {"role": "assistant", "content": "Job-tokens only have read-permission to your repository.\n\nA unique job token is generated for each job and provides the user read access all projects that would be normally accessible to the user creating that job. The unique job token does not have any write permissions, but there is a proposal to add support.\n\nYou can't use deploy-tokens because they can't have write-access to a repository (possible tokens).\nYou could use a project-access-token with read-write-access to your repository.\n\nYou can use project access tokens:\n\nOn GitLab SaaS if you have the Premium license tier or higher. Project\naccess tokens are not available with a trial license.\n\nOn self-managed instances of GitLab, with any license tier. If you\nhave the Free tier: [...]\n\n\n\n\nThen you can use your project-access-token as an environment variable in the url.\ngit push \"https://gitlab-ci-token:$PROJECT_ACCESS_TOKEN@$CI_SERVER_HOST/$CI_PROJECT_PATH.git\"\n\nAt least that's how we use it in our pipelines.\nI hope this helps you further."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Can you and is it advisable to use the same ssh key for github and gitlab/gitbucket\n\nCan you use the same ssh key for different version control hosting services? \nAnd if you can, what are the pros and cons?\nScenario: I have ssh keys that I am using on my computer, can I and should I use the same ssh keys with gitlab/gitbucket on the same computer?"}, {"role": "assistant", "content": "No, it is not advisable: a private key should remain used for only one service, that way you can revoke/change it just for that service.\nWhat you can do is set up a ~/.ssh/config file in which you can associate the right private key with the right host, as explained here."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "git post-receive hook \"empty ident name\"\n\nI have built the following post-receive hook:\n#!/bin/sh\ncd /var/node/heartbeat/ || exit\nunset GIT_DIR\necho $USER\ngit pull --no-edit\n\nWhen I'm pushing to the repository the following error is returned:\nremote:\nremote: From server.net:chris/heartbeat\nremote:    c0df678..5378ade  master     -> origin/master\nremote:\nremote: *** Please tell me who you are.\nremote:\nremote: Run\nremote:\nremote:   git config --global user.email \"[email\u00a0protected]\"\nremote:   git config --global user.name \"Your Name\"\nremote:\nremote: to set your account's default identity.\nremote: Omit --global to set the identity only in this repository.\nremote:\nremote: fatal: empty ident name (for <[email\u00a0protected]>) not allowed\n\nWhen running git config -l from the git user:\nuser.name=server\n[email\u00a0protected]\ncore.autocrlf=input\ncore.repositoryformatversion=0\ncore.filemode=true\ncore.bare=false\ncore.logallrefupdates=true\nremote.origin.fetch=+refs/heads/*:refs/remotes/origin/*\n[email\u00a0protected]:chris/heartbeat.git\nbranch.master.remote=origin\nbranch.master.merge=refs/heads/master\n\nI don't understand why it's still thinking that my user.email and user.name are empty as git config -l tells me it's not. Does anyone know a solution/workaround for this problem?"}, {"role": "assistant", "content": "To make sure this work, a git config --local -l needs to return the user name and email.\nIf it doesn't, go to that repo on the server, and type;:\ngit config user.name server\ngit config user.email [email\u00a0protected]"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI secret variables for Gradle publish\n\nHow to setup Gradle publish task user credentials with GitLab CI secret variables? I am using gradle maven publish plugin, and here is snippet from build.gradle\nrepositories {\n    maven {\n      credentials {\n        username artifactUser\n        password artifactPass\n      }\n      url \"...\"\n    }\n  }\n\nI've tried to use gradle.properties as below\nartifactUser=${env.MAVEN_REPO_USER}\nartifactPass=${env.MAVEN_REPO_PASS}\n\nAnd several ways of accessing secret variables in .gitlab-ci.yml file (because gradle.properties is not picked up from gradle or variables are not transformed correctly, it is in root project dir)\nMethod 1\n'./gradlew publish -x test -PartifactUser=${env.MAVEN_REPO_USER} -PartifactPass=${env.MAVEN_REPO_PASS}'\n\nError: /bin/bash: line 56: -PartifactUser=${env.MAVEN_REPO_USER}: bad substitution\nMethod 2\n    before_script:\n      - chmod +x ./gradlew\n      - export REPO_USER=${env.MAVEN_REPO_USER}\n      - export REPO_PASS=${env.MAVEN_REPO_PASS}\n    ...\n    deploy:\n  stage: deploy\n  script:\n    - ./gradlew publish -x test -PartifactUser=$REPO_USER -PartifactPass=$REPO_PASS\n\nI am using openjdk:8-jdk-slim image for build using gradle wrapper. Seems like there are several issues with this kind of variable usage, do we have any workaround?"}, {"role": "assistant", "content": "You don't need env. prefinx in your .gitlab-ci.yml. You don't need to re-export the variables as well.\nIf you have defined a variables named MAVEN_REPO_USER and MAVEN_REPO_PASS in Gitlab CI/CD settings for the project, you can just use them in Gradle script:\nrepositories {\n    maven {\n        credentials {\n            username System.getenv(\"MAVEN_REPO_USER\")\n            password System.getenv(\"MAVEN_REPO_PASS\")\n        }\n        url \"\u2026\"\n    }\n}"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I check if an image:tag exists in gitlab container registry\n\nI know that this can be done with dockerhub. I want to know if there is something similar available for gitlab registry. \nThe use case is that, I have written a fabric script to revert a deployment to a particular tag provided by the user. Before actually pulling in the images, I want to know whether an image with the specified tag exists in the registry and warn the user accordingly.\nI've searched in their documentation, but couldn't find anything.\nNote: User here is the person who is deploying the code."}, {"role": "assistant", "content": "Hint: Also have a look at @filiprafaj's answer using crane.\nOk, here is a solution I came up with using the docker:stable image by enabling the experimental client features.\nmkdir -p ~/.docker\n\"echo '{\\\"experimental\\\": \\\"enabled\\\"}' > ~/.docker/config.json\"\ndocker  login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY\ndocker  manifest inspect $IMGNAME:$IMGTAG > /dev/null && exit || true\n\nThe exit terminates the build script in case that tag already exists. Also you should be aware that ~/.docker/config.json is overwritten. That is also why the login must happen afterwards.\nUpdate: Instead of writing to the config one can also set the DOCKER_CLI_EXPERIMENTAL environment variable to enabled. Thus the first two lines can be replaced with export DOCKER_CLI_EXPERIMENTAL=enabled"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Multiple ssh keys are not working\n\nOS Description: Ubuntu 14.04.3 LTS\nssh: OpenSSH_6.6.1p1 Ubuntu-2ubuntu2.3, OpenSSL 1.0.1f 6 Jan 2014\n\nI am unable to use multiple ssh key for gitlab. The error I am getting is\nGitLab: The project you were looking for could not be found.\nfatal: Could not read from remote repository.\n\nPlease make sure you have the correct access rights\nand the repository exists. \n\nI am pretty much sure that I did everything right \nThis is my config file \nHost work gitlab.com\n    Hostname gitlab.com\n    IdentityFile ~/.ssh/ida_rsa\n    User git\n\nHost integrate gitlab.com\n    Hostname gitlab.com\n    IdentityFile ~/.ssh/ida_rsa_personal\n    User git\n\nThe keys are added automatically in ssh-agent, but to make sure I also added the key manually\n$ ssh-add -l\n2048 e7:08:d6:8c:00:28:31:f9:3f:21:4a:0f:4e:1e:ee:20 id_rsa (RSA)\n2048 ff:22:f6:90:2b:7c:9f:ed:45:41:df:79:06:de:fe:81 id_rsa_personal (RSA)\n\nMy ssh-agent is also running\n$ ssh-agent\nSSH_AUTH_SOCK=/tmp/ssh-uTC6tA5HMt1x/agent.4899; export SSH_AUTH_SOCK;\nSSH_AGENT_PID=4900; export SSH_AGENT_PID;\necho Agent pid 4900;\n\nPermissions of ssh key\n-rw-------  1 yogi yogi  1679 jun 25 15:38 id_rsa\n-rw-------  1 yogi yogi  1679 ago 25 10:53 id_rsa_personal\n-rw-r--r--  1 yogi yogi   404 ago 25 10:53 id_rsa_personal.pub\n-rw-r--r--  1 yogi yogi   391 jun 25 15:41 id_rsa.pub\n\nI added my ssh public key on gitlab.\nCould any one please tell me what I am missing ?\nNote :- \nI noticed that out of my two ssh keys, the ssh key which is on top( id_rsa - e7:08....) works fine.  \n$ ssh-add -l\n**2048 e7:08:d6:8c:00:28:31:f9:3f:21:4a:0f:4e:1e:ee:20 id_rsa (RSA)**\n2048 ff:22:f6:90:2b:7c:9f:ed:45:41:df:79:06:de:fe:81 id_rsa_personal (RSA)\n\nIf I add id_rsa_personal(ff:22..) after id_rsa, than id_rsa_personal starts working fine and id_rsa stops working.\n$ ssh-add -l\n**2048 ff:22:f6:90:2b:7c:9f:ed:45:41:df:79:06:de:fe:81 id_rsa_personal (RSA)**\n2048 e7:08:d6:8c:00:28:31:f9:3f:21:4a:0f:4e:1e:ee:20 id_rsa (RSA)\n\nI think , ssh-agent is unable to iterate through keys. It only reads first key and stops. \nIs this a bug in openssh ? If yes, any workaround ? \nThanks"}, {"role": "assistant", "content": "You need to have ~/.ssh/config file \nInside file \n# Default GitHub user\nHost github.com\n    HostName github.com\n    PreferredAuthentications publickey\n    IdentityFile ~/.ssh/personalid\n\n# Work user account\nHost bitbucket.org\n    HostName bitbucket.org\n    PreferredAuthentications publickey\n    IdentityFile ~/.ssh/workid\n\nDetails can be found in the link below \nhttps://confluence.atlassian.com/bitbucket/configure-multiple-ssh-identities-for-gitbash-mac-osx-linux-271943168.html\nIf the domain is same, use different Host \nHost work.gitlab.com\n    HostName gitlab.com\n    PreferredAuthentications publickey\n    IdentityFile ~/.ssh/id_rsa.work\n\nHost home.gitlab.com\n    HostName gitlab.com\n    PreferredAuthentications publickey\n    IdentityFile ~/.ssh/id_rsa.home\n\nClear the cache\nssh-add -D\n\nAdd all ssh keys\nssh-add ~/.ssh/id_rsa.work\nssh-add ~/.ssh/id_rsa.home\n\nAlso set your repos' url in (.git/config) accordingly as given:\nurl = [email\u00a0protected]:xxxxxxxxxx.git\nurl = [email\u00a0protected]:yyyyyyyyy.git \n\nIf your ssh config file is as what I suggested."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I publish a private npm package with gitlab ci?\n\nI want to publish a private npm package with Gitlab CI.\nI've created an auth token for my npm user and set it as a variable NPM_TOKEN in my Gitlab CI settings.\nThe job then creates an .npmrc file with the registry and the auth token.\n- npm run build && npm run build:es6\n- echo '//registry.npmjs.org/:_authToken=${NPM_TOKEN}'>.npmrc\n- npm publish\n\nThe job fails with this message:\nnpm ERR! code ENEEDAUTH\nnpm ERR! need auth auth required for publishing\nnpm ERR! need auth You need to authorize this machine using `npm adduser`\n\nIs it possible to publish with only an auth token?"}, {"role": "assistant", "content": "As @Amityo said, rather than manually editing the npmrc file,\nnpm config set //registry.npmjs.org/:_authToken ${NPM_TOKEN}\n\nis the way to go, because otherwise you may be editing the wrong npmrc file.\nIf you are still getting an authentication error, and are certain that the token is correct, check your registry URL. You can run\nnpm publish --verbose\n\nwhose output will includes lines like\nnpm verb getPublishConfig { registry: 'https://.......' }\nnpm verb mapToRegistry no registry URL found in name for scope @boxine\nnpm verb publish registryBase https://.......\n\nIf you are publishing to npmjs.org, the URL (....... above) should be https://registry.npmjs.org/ .\nIf this registry URL does not fit, look in your npmrc file for a different one. Also make sure you didn't override the registry in your package.json file! You can search for publishConfig in that file."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "use image from gitlab Registry in CI\n\nCould you tell me if I do it in correct way:\n\nI have create Docker image with all stuff which is need for running my tests in gitlab CI\nI push it to gitlab registry \nI can see on gitlab page in section Registry my image - gitlablogin/projectname\nI want to use this image for CI, so in .gitlab-ci.yml I add image: gitlablogin/projectname\n\nBefore I had had in .gitlab-ci.yml\nsame_task:\n  stage: deploy\n  image: python:3\n  script:\n    - python -V\n\nNow I have:\npep8:\n  stage: deploy\n  image: gitlablogin/projectname\n  script:\n    - python -V\n\nand after this change job failed:\nRunning with gitlab-runner 11.4.2 (cf91d5e1)\n  on docker-auto-scale 72989761\nUsing Docker executor with image gitlablogin/projectname ...\nPulling docker image gitlablogin/projectname ...\nERROR: Job failed: Error response from daemon: pull access denied for gitlablogin/projectname, repository does not exist or may require 'docker login' (executor_docker.go:168:0s)\n\nIs my usage of docker in context of gitlab CI and gitlab registry is correct? I also want to keep my docker file on same repo and build new image when samething change in Dockerfile, what will be the best way to do it?"}, {"role": "assistant", "content": "Right now it is possible to use images from your gitlab registry without any special steps. Just build and push an image to your gitlab project container registry\ndocker build -t registry.gitlab.com/gitlabProject/projectName:build .\ndocker push registry.gitlab.com/gitlabProject/projectName:build \n\nand then just specify this image in your pipeline settings:\nimage: registry.gitlab.com/gitlabProject/projectName:build\n\nGitlab is able to pull this image using it's credentials:\nPreparing the \"docker+machine\" executor\n00:46\n Using Docker executor with image registry.gitlab.com/gitlabProject/projectName:build ...\n Authenticating with credentials from job payload (GitLab Registry)\n Pulling docker image registry.gitlab.com/gitlabProject/projectName:build ...\n Using docker image sha256:e7e0f4f5fa8cff8a93b1f37ffd7dd0505946648246aa921dd457c06a1607304b for registry.gitlab.com/gitlabProject/projectName:build ...\n\nMore: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#support-for-gitlab-integrated-registry"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to upgrade to a new installed gitlab runner version?\n\nI try to update my single gitlab runner from 11.0 to 11.3.1\nand followed the instruction on the gitlab doc.\nsudo apt-get install gitlab-runner will confirm that I have the new version installed:\n\ngitlab-runner is already the newest version (11.3.1).\n\nThe last updates like 10.* to 11.0 worked absolutely fine but this time\nthe runner still stays on 11.0 (in -help and gitlab-ci web ui).\nA restart of the runner don't change anything so it looks like I miss a major step for the update some how.\nIt would be great to find out what I'm doing wrong, thanks in advance. :-)\nOS: Ubuntu 18.04.1\n(I'm relatively new in the linux and gitlab world so it could be something obvious)\nUsed update command:\n# For Debian/Ubuntu/Mint\nsudo apt-get update\nsudo apt-get install gitlab-runner"}, {"role": "assistant", "content": "Ok the problem was solved by using the manual update described at:\nhttps://docs.gitlab.com/runner/install/linux-manually.html\n\nStop the service (you need elevated command prompt as before):\nsudo gitlab-runner stop\nDownload the binary to replace Runner's executable:\nsudo wget -O /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-386\nsudo wget -O /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-amd64\n\nYou can download a binary for every available version as described in\n  Bleeding Edge - download any other tagged release.\nGive it permissions to execute:\nsudo chmod +x /usr/local/bin/gitlab-runner\n\nStart the service:\nsudo gitlab-runner start\n\n\n\"latest\" - may install a beta so it is important to select the right tag (also described in the link)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "install private npm package in gitlab pipelines\n\nIf one needs to install private repositories with npm the environment variable NPM_TOKEN needs to be set.\nNPM_TOKEN=00000000-0000-0000-0000-000000000000\n\nMy build stage in gitlab pipelines needs to install a private repository. Thus I put this NPM_TOKEN secret variable in my gitlab pipeline settings.\nMy current gitlab-ci configuration :\nimage: x/node\n\nbuild_job: \n  script:\n  - printenv NPM_TOKEN\n  - npm i @x/test\n\nThe docker image is one that I made it just sets a .npmrc file:\nFROM node:latest\nCOPY .npmrc .  \n\nwhere I have .npmrc in the same directory:\n//registry.npmjs.org/:_authToken=${NPM_TOKEN}\n\nI've tried the docker image by:\n run -it myimage bash\n export NPM_TOKEN=...\n npm i @x/test\n\nThat works, the private package is installed.\nHowever on gitlab pipelines it does not find the package (404). When the job runs I can clearly see the NPM_TOKEN env variable being printed. So I don't know what's up."}, {"role": "assistant", "content": "I changed gitlab-ci to this: \nimage: dasnoo/node\n\nbuild_job: \n  script:\n  - printenv NPM_TOKEN\n  - npm config set //registry.npmjs.org/:_authToken ${NPM_TOKEN}\n  - npm i @dasnoo/testpriv\n\nand it works. not sre why I had to do that though"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to use Gitlab CI/CD to deploy a meteor project?\n\nAs claimed at their website Gitlab can be used to auto deploy projects after some code is pushed into the repository but I am not able to figure out how. There are plenty of ruby tutorials out there but none for meteor or node.\nBasically I just need to rebuild an Docker container on my server, after code is pushed into my master branch. Does anyone know how to achieve it? I am totally new to the .gitlab-ci.yml stuff and appreciate help pretty much."}, {"role": "assistant", "content": "Brief: I am running a Meteor 1.3.2 app, hosted on Digital Ocean (Ubuntu 14.04) since 4 months. I am using Gitlab v. 8.3.4 running on the same Digital Ocean droplet as the Meteor app. It is a 2 GB / 2 CPUs droplet ($ 20 a month). Using the built in Gitlab CI for CI/CD. This setup has been running successfully till now. (We are currently not using Docker, however this should not matter.)\nOur CI/CD strategy:\n\nWe check out Master branch on our local laptop. The branch contains the whole Meteor project as shown below:\n\n\nWe use git CLI tool on Windows to connect to our Gitlab server. (for pull, push, etc. similar regular git activities)\n\nOpen the checked out project in Atom editor. We have also integrated Atom with Gitlab. This helps in quick git status/pull/push etc. within Atom editor itself. Do regular Meteor work viz. fix bugs etc.\nPost testing on local laptop, we then do git push & commit on master. This triggers auto build using Gitlab CI and the results (including build logs) can be seen in Gitlab itself as shown below:\n\n\nBelow image shows all previous build logs:\n\nPlease follow below steps:\n\nInstall meteor on the DO droplet.\nInstall Gitlab on DO (using 1-click deploy if possible) or manual installation. Ensure you are installing Gitlab v. 8.3.4 or newer version. I had done a DO one-click deploy on my droplet.\nStart the gitlab server & log into gitlab from browser. Open your project and go to project settings -> Runners from left menu\n\n\n\nSSH to your DO server & configure a new upstart service on the droplet as root:\nvi /etc/init/meteor-service.conf\n\n\nSample file:\n#upstart service file at /etc/init/meteor-service.conf\ndescription \"Meteor.js (NodeJS) application for eaxmple.com:3000\"\nauthor \"[email\u00a0protected]\"\n\n# When to start the service\nstart on runlevel [2345]\n\n# When to stop the service\nstop on shutdown\n\n# Automatically restart process if crashed\nrespawn\nrespawn limit 10 5\n\nscript\n    export PORT=3000\n    # this allows Meteor to figure out correct IP address of visitors\n    export HTTP_FORWARDED_COUNT=1\n    export MONGO_URL=mongodb://xxxxxx:[email\u00a0protected]:59672/meteor-db\n    export ROOT_URL=http://<droplet_ip>:3000\n    exec /home/gitlab-runner/.meteor/packages/meteor-tool/1.1.10/mt-os.linux.x86_64/dev_bundle/bin/node /home/gitlab-runner/erecaho-build/server-alpha-running/bundle/main.js >> /home/gitlab-runner/erecaho-build/server-alpha-running/meteor.log\nend script\n\n\nInstall gitlab-ci-multi-runner from here: https://gitlab.com/gitlab-org/gitlab-ci-multi-runner/blob/master/docs/install/linux-repository.md as per the instructions \nCheatsheet:\ncurl -L https://packages.gitlab.com/install/repositories/runner/gitlab-ci-multi-runner/script.deb.sh | sudo bash\nsudo apt-get install gitlab-ci-multi-runner\nsudo gitlab-ci-multi-runner register\n\nEnter details from step 2\nNow the new runner should be green or activate the runner if required\nCreate .gitlab-ci.yml within the meteor project directory\nSample file:\nbefore_script:\n  - echo \"======================================\"\n  - echo \"==== START auto full script v0.1 =====\"\n  - echo \"======================================\"\n\ntypes:\n  - cleanup\n  - build\n  - test\n  - deploy\n\njob_cleanup:\n  type: cleanup\n  script:\n  - cd /home/gitlab-runner/erecaho-build\n  - echo \"cleaning up existing bundle folder\"\n  - echo \"cleaning up current server-running folder\"\n  - rm -fr ./server-alpha-running\n  - mkdir ./server-alpha-running\n  only:\n  - master\n  tags:\n  - master\n\njob_build:\n  type: build\n  script:\n  - pwd\n  - meteor build /home/gitlab-runner/erecaho-build/server-alpha-running --directory --server=http://example.org:3000 --verbose\n  only:\n  - master\n  tags:\n  - master\n\njob_test:\n  type: test\n  script:\n  - echo \"testing ----\"\n  - cd /home/gitlab-runner/erecaho-build/server-alpha-running/bundle\n  - ls -la main.js\n  only:\n  - master\n  tags:\n  - master\n\njob_deploy:\n  type: deploy\n  script:\n  - echo \"deploying ----\"\n  - cd /home/gitlab-runner/erecaho-build/server-alpha-running/bundle/programs/server/ && /home/gitlab-runner/.meteor/packages/meteor-tool/1.1.10/mt-os.linux.x86_64/dev_bundle/bin/npm install\n  - cd ../..\n  - sudo restart meteor-service\n  - sudo status meteor-service\n  only:\n  - master\n  tags:\n  - master\n\nCheck in above file in gitlab. This should trigger Gitlab CI and after the build process is complete, the new app will be available @ example.net:3000\n\nNote: The app will not be available after checking in .gitlab-ci.yml for the first time, since restart meteor-service will result in service not found. Manually run sudo start meteor-service once on DO SSH console. Post this any new check-in to gitlab master will trigger auto CI/CD and the new version of the app will be available on example.com:3000 after the build is completed successfully.\nP.S.: gitlab ci yaml docs can be found at http://doc.gitlab.com/ee/ci/yaml/README.html for your customization and to understand the sample yaml file above. \nFor docker specific runner, please refer https://gitlab.com/gitlab-org/gitlab-ci-multi-runner"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to create a merge request at the end of a successful pipeline in Gitlab?\n\nI'm very new to gitlab and gitlab CI and I have put a pipeline in place that is successfully completing.\nMy master and development branches are protected so a merge request is required so that another dev in the group can review the code and comment before merging.\nI was wondering if it is possible to generate this merge request at the end of this pipeline. Is there a setting for this in the gitlab repository or do I have to create a script to achieve this?\nSide note : \nJust before posting this I came across this section of the gitlab docs \nI'm using gitlab-runner 11.0.0 on ubuntu 18.04"}, {"role": "assistant", "content": "In order to achieve my simple needs, I simply added a final stage to my pipeline which essentially executes a bash script adapted from this post.\nEDIT:\nAs requested by @Yuva\n# Create a pull request on pipeline success\ncreate_merge_request:\n  stage: createMR\n  tags:\n    - autoMR\n  script:\n    - 'echo Merge request opened by $GITLAB_USER_NAME '\n    - ~/commit.sh\n\n\nand in commit.sh\n#!/bin/bash\n# This script was adapted from:\n# https://about.gitlab.com/2017/09/05/how-to-automatically-create-a-new-mr-on-gitlab-with-gitlab-ci/\n\n# TODO determine URL from git repository URL\n[[ $HOST =~ ^https?://[^/]+ ]] && HOST=\"${BASH_REMATCH[0]}/api/v4/projects/\"\n\n# The branch which we wish to merge into\nTARGET_BRANCH=develop;\n\n# The user's token name so that we can open the merge request as the user\nTOKEN_NAME=`echo ${GITLAB_USER_LOGIN}_COMMIT_TOKEN | tr \"[a-z]\" \"[A-Z]\"`\n\n# See: http://www.tldp.org/LDP/abs/html/parameter-substitution.html search ${!varprefix*}, ${!varprefix@} section\nPRIVATE_TOKEN=`echo ${!TOKEN_NAME}`\n\n# The description of our new MR, we want to remove the branch after the MR has\n# been closed\nBODY=\"{\n\\\"project_id\\\": ${CI_PROJECT_ID},\n\\\"source_branch\\\": \\\"${CI_COMMIT_REF_NAME}\\\",\n\\\"target_branch\\\": \\\"${TARGET_BRANCH}\\\",\n\\\"remove_source_branch\\\": false,\n\\\"force_remove_source_branch\\\": false,\n\\\"allow_collaboration\\\": true,\n\\\"subscribed\\\" : true,\n\\\"title\\\": \\\"${GITLAB_USER_NAME} merge request for: ${CI_COMMIT_REF_SLUG}\\\"\n}\";\n\n# Require a list of all the merge request and take a look if there is already\n# one with the same source branch\n LISTMR=`curl --silent \"${HOST}${CI_PROJECT_ID}/merge_requests?state=opened\" --header \"PRIVATE-TOKEN:${PRIVATE_TOKEN}\"`;\n COUNTBRANCHES=`echo ${LISTMR} | grep -o \"\\\"source_branch\\\":\\\"${CI_COMMIT_REF_NAME}\\\"\" | wc -l`;\n\n# No MR found, let's create a new one\nif [ ${COUNTBRANCHES} -eq \"0\" ]; then\n    curl -X POST \"${HOST}${CI_PROJECT_ID}/merge_requests\" \\\n    --header \"PRIVATE-TOKEN:${PRIVATE_TOKEN}\" \\\n    --header \"Content-Type: application/json\" \\\n    --data \"${BODY}\";\n\n    echo \"Opened a new merge request: WIP: ${CI_COMMIT_REF_SLUG} for user ${GITLAB_USER_LOGIN}\";\n    exit;\nfi\n    echo \"No new merge request opened\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab Pages, docs generated with sphinx\n\nI want to host static page generated with Sphinx on GitLab Pages. Built index.html file is in:\nproject/docs/build/html\n\nHow  .gitlab-ci.yml should look like to deploy the page? I have something like that and it isn't working:\npages:\n  stage: deploy\n  script:\n  - echo 'Nothing to do...'\n artifacts:\n paths:\n - docs/build/html\n only:\n - master"}, {"role": "assistant", "content": "According to the documentation for .gitlab-ci.yml, the pages job has special rules it must follow:\n\n\nAny static content must be placed under a public/ directory\nartifacts with a path to the public/ directory must be defined\n\n\nSo the example .gitlab-ci.yml you gave would look something like this:\npages:\n  stage: deploy\n  script:\n    - mv docs/build/html/ public/\n  artifacts:\n    paths:\n    - public\n  only:\n  - master\n\nAnd of course, if you don't want to move the html folder for whatever reason, you can copy it instead.\nFor further reference, an example sphinx project for GitLab Pages was pushed around the time you originally posted this question."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab.com CI shared runner for Android projects\n\nI'd like to use GitLab CI system for my Android application gradle project. The project repository is hosted on GitLab.com, so I'd like to use one of the Shared Runners provided by Gitlab Inc.\nWhile the official tutorial provides an example for NodeJS project runner configuration and there are also shared runners for Ruby projects, I couldn't find any example or even a runner that supports Android applications.  \n\nIs there a shared runner provided by GitLab.com, which supports Android projects out of the box (by specifying image: android:4.2.2 or something like this)?\nIs there a way to configure existing shared runner provided by GitLab.com to support Android projects (by modifying the .gitlab-ci.yml file)?"}, {"role": "assistant", "content": "I'm using this docker image to run android build on gitlab-ci\nUpdate: \nMoved to Gitlab registry\nimage: registry.gitlab.com/showcheap/android-ci:latest\n\nbefore_script:\n    - export GRADLE_USER_HOME=`pwd`/.gradle\n    - chmod +x ./gradlew\n\ncache:\n  paths:\n     - .gradle/wrapper\n     - .gradle/caches\n\nbuild:\n  stage: build\n  script:\n     - ./gradlew assemble\n\ntest:\n  stage: test\n  script:\n     - ./gradlew check\n\nFull Guide can check in this Gitlab Repository:\nhttps://gitlab.com/showcheap/android-ci\nIf your Target SDK and Build Tools version are not listed, please make a pull request or fork my repo then make your custom target and build version."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What does colon in job name means when using Gitlab CI pipeline?\n\nUsing the following CI pipeline running on GitLab:\nstages:\n  - build\n  - website\n\ndefault:\n  retry: 1\n  timeout: 15 minutes\n\nbuild:website:\n  stage: build\n  ...\n  ...\n  ...\n  ...\n\nwebsite:dev:\n  stage: website\n  ...\n  ...\n  ...\n\nWhat does the first colon in job name in build:website: and in website:dev: exactly mean?\nIs it like we pass the second part after the stage name as a variable to the stage?"}, {"role": "assistant", "content": "Naming of jobs does not really change the behavior of the pipeline in this case. It's just the job name.\nHowever, if you use the same prefix before the : for multiple jobs, it will cause jobs to be grouped in the UI. It still doesn't affect the material function of the pipeline, but it will change how they show up in the UI:\n\nIt's a purely cosmetic feature.\nJobs can also be grouped using / as the separator or a space."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab to Jenkins webhook with parameters\n\nI'm trying to build a job on my jenkins using Gitlab webhook when pushing into a specific branch.\nThe only issue I have is that the jenkins job is parameterized. The parameter is the branch name.\nIs there an option to add the branch name (its a different branch every time) to the webhook so it will be inserted automatically into the parameter in the jenkins job parameter?\nThanks"}, {"role": "assistant", "content": "GitLab invokes the webhook URL with a JSON payload in the request body that carries a lot of information about the GitLab event that led to the webhook invocation. The JSON payload for the GitLab push event does have branch name information in it -- see the \"ref\" field in the GitLab webhook push event payload: \n{\n  \"object_kind\": \"push\",\n  \"before\": \"95790bf891e76fee5e1747ab589903a6a1f80f22\",\n  \"after\": \"da1560886d4f094c3e6c9ef40349f7d38b5d27d7\",\n  \"ref\": \"refs/heads/master\",\n  \"checkout_sha\": \"da1560886d4f094c3e6c9ef40349f7d38b5d27d7\",\n  \"user_id\": 4,\n  \"user_name\": \"John Smith\",\n  \"user_username\": \"jsmith\",\n  \"user_email\": \"[email\u00a0protected]\",\n  \"user_avatar\": \"https://s.gravatar.com/avatar/d4c74594d841139328695756648b6bd6?s=8://s.gravatar.com/avatar/d4c74594d841139328695756648b6bd6?s=80\",\n  \"project_id\": 15,\n  \"project\":{\n    \"id\": 15,\n    \"name\":\"Diaspora\",\n    \"description\":\"\",\n    \"web_url\":\"http://example.com/mike/diaspora\",\n    \"avatar_url\":null,\n    \"git_ssh_url\":\"[email\u00a0protected]:mike/diaspora.git\",\n    \"git_http_url\":\"http://example.com/mike/diaspora.git\",\n    \"namespace\":\"Mike\",\n    \"visibility_level\":0,\n    \"path_with_namespace\":\"mike/diaspora\",\n    \"default_branch\":\"master\",\n    \"homepage\":\"http://example.com/mike/diaspora\",\n    \"url\":\"[email\u00a0protected]:mike/diaspora.git\",\n    \"ssh_url\":\"[email\u00a0protected]:mike/diaspora.git\",\n    \"http_url\":\"http://example.com/mike/diaspora.git\"\n  },\n  \"repository\":{\n    \"name\": \"Diaspora\",\n    \"url\": \"[email\u00a0protected]:mike/diaspora.git\",\n    \"description\": \"\",\n    \"homepage\": \"http://example.com/mike/diaspora\",\n    \"git_http_url\":\"http://example.com/mike/diaspora.git\",\n    \"git_ssh_url\":\"[email\u00a0protected]:mike/diaspora.git\",\n    \"visibility_level\":0\n  },\n  \"commits\": [\n    {\n      \"id\": \"b6568db1bc1dcd7f8b4d5a946b0b91f9dacd7327\",\n      \"message\": \"Update Catalan translation to e38cb41.\",\n      \"timestamp\": \"2011-12-12T14:27:31+02:00\",\n      \"url\": \"http://example.com/mike/diaspora/commit/b6568db1bc1dcd7f8b4d5a946b0b91f9dacd7327\",\n      \"author\": {\n        \"name\": \"Jordi Mallach\",\n        \"email\": \"[email\u00a0protected]\"\n      },\n      \"added\": [\"CHANGELOG\"],\n      \"modified\": [\"app/controller/application.rb\"],\n      \"removed\": []\n    },\n    {\n      \"id\": \"da1560886d4f094c3e6c9ef40349f7d38b5d27d7\",\n      \"message\": \"fixed readme\",\n      \"timestamp\": \"2012-01-03T23:36:29+02:00\",\n      \"url\": \"http://example.com/mike/diaspora/commit/da1560886d4f094c3e6c9ef40349f7d38b5d27d7\",\n      \"author\": {\n        \"name\": \"GitLab dev user\",\n        \"email\": \"gitlabdev@dv6700.(none)\"\n      },\n      \"added\": [\"CHANGELOG\"],\n      \"modified\": [\"app/controller/application.rb\"],\n      \"removed\": []\n    }\n  ],\n  \"total_commits_count\": 4\n}\n\nYou may not bind any field in the webhook payload to a Jenkins job parameter automatically. However, there is still a way to access webhook payload information in the Jenkins job. The Jenkins GitLab plugin makes this webhook payload information available in the Jenkins Global Variable env. The available env variables are as follows and they do include branch information:\ngitlabBranch\ngitlabSourceBranch\ngitlabActionType\ngitlabUserName\ngitlabUserEmail\ngitlabSourceRepoHomepage\ngitlabSourceRepoName\ngitlabSourceNamespace\ngitlabSourceRepoURL\ngitlabSourceRepoSshUrl\ngitlabSourceRepoHttpUrl\ngitlabMergeRequestTitle\ngitlabMergeRequestDescription\ngitlabMergeRequestId\ngitlabMergeRequestIid\ngitlabMergeRequestState\ngitlabMergedByUser\ngitlabMergeRequestAssignee\ngitlabMergeRequestLastCommit\ngitlabMergeRequestTargetProjectId\ngitlabTargetBranch\ngitlabTargetRepoName\ngitlabTargetNamespace\ngitlabTargetRepoSshUrl\ngitlabTargetRepoHttpUrl\ngitlabBefore\ngitlabAfter\ngitlabTriggerPhrase\n\nJust as you would read Jenkins job parameters from Jenkins Global Variable params in your job pipeline script, you could read webhook payload fields from Jenkins Global Variable env:\nparams.MY_PARAM_NAME\nenv.gitlabBranch\n\nHope, the above information helps solve your problem."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI - Cache not working\n\nI'm currently using GitLab in combination with CI runners to run unit tests of my project, to speed up the process of bootstrapping the tests I'm using the built-in cache functionality, however this doesn't seem to work.\nEach time someone commits to master, my runner does a git fetch and proceeds to remove all cached files, which means I have to stare at my screen for around 10 minutes to wait for a test to complete while the runner re-downloads all dependencies (NPM and PIP being the biggest time killers).\nOutput of the CI runner:\nFetching changes...\n\nRemoving bower_modules/jquery/  --+-- Shouldn't happen!\nRemoving bower_modules/tether/    |\nRemoving node_modules/            |\nRemoving vendor/                --'\nHEAD is now at 7c513dd Update .gitlab-ci.yml\n\nCurrently my .gitlab-ci.yml\nimage: python:latest\n\nservices:\n  - redis:latest\n  - node:latest\n\ncache:\n  key: \"$CI_BUILD_REF_NAME\"\n  untracked: true\n  paths:\n  - ~/.cache/pip/\n  - vendor/\n  - node_modules/\n  - bower_components/\n\n\nbefore_script:\n  - python -V\n\n  # Still gets executed even though node is listed as a service??\n  - '(which nodejs && which npm) || (apt-get update -q && apt-get -o dir::cache::archives=\"vendor/apt/\" install nodejs npm -yqq)'\n  - npm install -g bower gulp\n\n  # Following statements ignore cache!\n  - pip install -r requirements.txt\n  - npm install --only=dev\n  - bower install --allow-root\n  - gulp build\n\ntest:\n  variables:\n    DEBUG: \"1\"\n  script:\n  - python -m unittest myproject\n\nI've tried reading the following articles for help however none of them seem to fix my problem:\n\nhttp://docs.gitlab.com/ce/ci/yaml/README.html#cache\nhttps://fleschenberg.net/gitlab-pip-cache/\nhttps://gitlab.com/gitlab-org/gitlab-ci-multi-runner/issues/336"}, {"role": "assistant", "content": "Turns out that I was doing some things wrong:\n\nYour script can't cache files outside of your project scope, creating a virtual environment instead and caching that allows you to cache your pip modules.\nMost important of all: Your test must succeed in order for it to cache the files. \n\nAfter using the following config I got a -3 minute time difference:\n\nCurrently my configuration looks like follows and works for me.\n# Official framework image. Look for the different tagged releases at:\n# https://hub.docker.com/r/library/python\nimage: python:latest\n\n# Pick zero or more services to be used on all builds.\n# Only needed when using a docker container to run your tests in.\n# Check out: http://docs.gitlab.com/ce/ci/docker/using_docker_images.html#what-is-service\nservices:\n- mysql:latest\n- redis:latest\n\ncache:\n    untracked: true\n    key: \"$CI_BUILD_REF_NAME\"\n    paths:\n    - venv/\n    - node_modules/\n    - bower_components/\n\n\n# This is a basic example for a gem or script which doesn't use\n# services such as redis or postgres\nbefore_script:\n\n# Check python installation\n- python -V\n\n# Install NodeJS (Gulp & Bower)\n# Default repository is outdated, this is the latest version\n- 'curl -sL https://deb.nodesource.com/setup_8.x | bash -'\n- apt-get install -y nodejs\n- npm install -g bower gulp\n\n# Install dependencie\n- pip install -U pip setuptools\n- pip install virtualenv\n\n\ntest:\n\n    # Indicate to the framework that it's being unit tested\n    variables:\n        DEBUG: \"1\"\n\n    # Test script\n    script:\n\n    # Set up virtual environment\n    - virtualenv venv -ppython3\n    - source venv/bin/activate\n    - pip install coverage\n    - pip install -r requirements.txt\n\n    # Install NodeJS & Bower + Compile JS\n    - npm install --only=dev\n    - bower install --allow-root\n    - gulp build\n\n    # Run all unit tests\n    - coverage run -m unittest project.tests\n    - coverage report -m project/**/*.py\n\nWhich resulted in the following output:\nFetching changes...\nRemoving .coverage                              --+-- Don't worry about this\nRemoving bower_components/                        |\nRemoving node_modules/                            |\nRemoving venv/                                  --`\nHEAD is now at 24e7618 Fix for issue #16\nFrom https://git.example.com/repo\n85f2f9b..42ba753  master     -> origin/master\nChecking out 42ba7537 as master...\nSkipping Git submodules setup\nChecking cache for master...                    --+-- The files are back now :)\nSuccessfully extracted cache                    --`\n\n...\n\nproject/module/script.py                  157      9    94%   182, 231-244\n---------------------------------------------------------------------------\nTOTAL                                          1084    328    70%\nCreating cache master...\nCreated cache\nUploading artifacts...\nvenv/: found 9859 matching files                   \nnode_modules/: found 7070 matching files           \nbower_components/: found 982 matching files \nTrying to load /builds/repo.tmp/CI_SERVER_TLS_CA_FILE ... \nDialing: tcp git.example.com:443 ...         \nUploading artifacts to coordinator... ok            id=127 responseStatus=201 Created token=XXXXXX\nJob succeeded\n\nFor the coverage report, I used the following regular expression:\n^TOTAL\\s+(?:\\d+\\s+){2}(\\d{1,3}%)$"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to set up gitlab CI runners?\n\nI am asking the question here, because documentation didn't help me.\nDuring runner's setup, 2 things are being asked: url of gitlab CI coordinator and registration token. I don't get what any of them should be.\nAs for url, it could be either url of gitlab CI web interface (ex: http://localhost:80/) ot url related to build, which is described in build's advanced properties.\nRegistration token could be something from documentation - but the link to it is dead (see:  http://gitlab-ci-domain.com/admin/runners) or registration token from build's advanced properties.\nHowever, when i try to supply to runner's setup url and registration token from build properties, i get access error which informs me that registration failed. Due to lack of understanding what those parameters should be, i cannot determine what is wrong."}, {"role": "assistant", "content": "the Url is your Gitci Url.\nthe token you mention its in your gitlabci under \"runners\" next to the line:\n\"To register new runner you should the following registration token. With this token the runner will request a unique runner token and use that for future communication\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Web access HTML file in my Gitlab repo\n\nI want to use Gitlab to manage web-application development. Is it possible to access the html file I have created in my Gitlab repo from the browser? \nCurrently there are ssh/http url for access to the repo like:\nssh: [email\u00a0protected]:balbal/web-app.git   \nhttp: (ht tps://something.some.ca:balbal/web-app.git)\n\nWhen I access https from a browser it will just jump into the git repo manage UI (like show you all the commits, branches and detail files)\nWhat I want is web access to a particular html file I have created in my repo (like if there is a index.html file in a folder called 'www' in my repo). I want some URL that I can type into the browser and which will show me the index.html content. \nIs it possible for me to set up an web access to these html files?"}, {"role": "assistant", "content": "As of now, Gitlab does not support this functionality. There's a feature request for this: http://feedback.gitlab.com/forums/176466-general/suggestions/5599145-preview-render-static-html-pages-pushed-to-repos\nCurrently, if you query Gitlab for the raw html file, it sets certain HTTP headers to make it render as text/plain instead:\n$ curl -I http://my-gitlab/user/project/raw/dev/doc/_book/index.html\nHTTP/1.1 200 OK\nServer: nginx\nDate: Mon, 20 Apr 2015 13:17:48 GMT\nContent-Type: text/plain; charset=utf-8\nConnection: keep-alive\nStatus: 200 OK\nX-Frame-Options: DENY\nX-XSS-Protection: 1; mode=block\nX-Content-Type-Options: nosniff\nX-UA-Compatible: IE=edge\nContent-Disposition: inline; filename=\"index.html\"\nContent-Transfer-Encoding: binary\nCache-Control: private\nETag: \"b81191c550c47eae1ab4adf72dfd0c92\"\nSet-Cookie: request_method=HEAD; path=/\nX-Request-Id: 04ae0499-2fdf-4f89-82ab-8392a8d6a076\nX-Runtime: 0.019857"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Reopen merge request in gitlab\n\nIs there a way to reopen a merge request within Gitlab once it's been merged like there is with an issue?\nIn this example a merge request was merged before a code review and has been reverted, but it would be great to reopen the original merge request to keep the original history/discussions"}, {"role": "assistant", "content": "There's Reopen merge request button in Gitlab (Checked with 10.3.4-ce, but appeared earlier). However it does absolutely nothing when pressed, even with commits added to the branch the merge request is tied with."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Merge Request approvals in GitLab CE\n\nWe would like to use Merge Request approvals similar to how it works in Stash where one person creates a PR and can assign multiple reviewers who can approve or decline. PR can be merged only when N reviewers approved (configurable per repository).\nIt seems that this feature is offered only in GitLab EE, is that right? Is there any free or cheap alternative to migrating from CE to EE?\nPerhaps a custom GitLab fork or an addon/plugin?"}, {"role": "assistant", "content": "Even though Merge Request Approvals are not part of the Free GitLab tier, the functionality is still available on the Merge Request user interface and data is available in the API, so as a workaround you can create a GitLab CI job that implements checking the number of approvals and fails if insufficient.\nFirst, ensure that in your project's Merge Request settings, Pipelines must succeed is enabled.\nThen create a new job in .gitlab-ci.yml that will fail when there are insufficient merge request approvals:\ncode_approved:\n  rules:\n    - if: $CI_MERGE_REQUEST_ID\n  script:\n    - apt-get update\n    - apt-get install -y jq curl\n    - >\n      curl --header \"JOB-TOKEN: $CI_JOB_TOKEN\"\n      \"$CI_API_V4_URL/projects/$CI_PROJECT_ID/merge_requests/$CI_MERGE_REQUEST_IID/approvals\" \n      | jq -e '.approved_by[0]'\n\n\napt-get ... : Install the curl and jq binaries.\ncurl --header \"JOB-TOKEN: $CI_JOB_TOKEN\": authenticates the call.\n\"$CI_API_V4_URL/projects/$CI_PROJECT_ID/merge_requests/$CI_MERGE_REQUEST_IID/approvals\" GitLab API endpoint returning approval data for the current merge request. Note that on GitLab Free, a lot of data returned by this resource is missing or misleading, but approved_by is properly populated.You can also visit this API URL in a browser window to preview, e.g. https://gitlab.com/api/v4/projects/blaisekal%2Fmr-approvals/merge_requests/1/approvals\n| jq -e '.approved_by[0]' pipes the output to jq, attempts to fetch the first approved_by item from the list. -e ensures that when it cannot find that item, the command will return with an error exit status, which causes the CI job to fail, which causes the option to merge to be blocked. If you require two approvals, use jq filter '.approved_by[1]'.\n\n\nDemo: https://gitlab.com/blaisekal/mr-approvals/-/merge_requests\n\nThe biggest disadvantages of this workaround are that you need to run a job to determine approved status, you have to re-run the job manually if the number of approvals changes, and a malicious member of your team could remove the CI job before merging."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Building merge requests in CI server\n\nWe are using GitLab to manage our repos. We are trying to follow GitFlow processes and as part of that we would like to be able to build and execute the tests against any merge request automatically in TeamCity.\nFrom what I can see this is possible in GitLab CI but moving over to that isn't a realistic option for us.\nI have seen tutorials about achieving this on GitHUB using a branch specification like +refs/pull/*/merge - does a similar branch specification get created by GitLAB?\nWe are using version 4.2 of GitLab but can upgrade if required for this feature and version 8 of TeamCity"}, {"role": "assistant", "content": "I have GitLab 6.3 and TeamCity 8 and I need build feature branches too. We have following workflow (it is based on git-flow, but slightly changed according to our release cycle).\nSo, we have development branch and one pushes feature branch with a specific name dev/feature-name-here. \nNext, one creating a Merge Request in GitLab from dev/feature-name-here to development.\nTeamCity is configured to automatically run builds for each branch with the following refspec: +:refs/heads/dev/(*) so we can see a build for branch feature-name-here is automatically started.\nNext, I have a custom script which is embedded to GitLab's merge request page. It do the following.\n\nDetects a source and target branch by looking at a MR page\nWith TeamCity REST API enumerates build which is belongs to a target branch (in TeamCity 8 we can assign custom build configuration ID to build so we using some semantic naming like devUnit, devIntegration, devWhatever, etc...)\nCreates a table witch contains build status images for source and target branches for each related build configuration.\n\nNow it looks like this:\n\nNow this approach has some drawbacks like if one updates a branch with another push I can't figure out from GitLab page is new commits is already built or I'm seeng old build status, so I need to click on a build link and check in TeamCity"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I exit a gitlab pipeline early without failure?\n\nI have a gitlab .gitlab-ci.yml pipeline where the first job makes a decision about whether the rest are executed. Neither choice is a \u201cfailure\u201d in the \u201csend email and alert everyone\u201d sense. It simply does or doesn\u2019t need to be done at that time.\nI\u2019m looking for the opposite of allow_failure: true which allows the pipeline to continue regardless of the exit status of the job. Instead, I want determine the continuation status.\nIs there an easy or common way to do this? Or am I, once again, stuck with generating yaml files?"}, {"role": "assistant", "content": "It seems like this is currently not possible to do so in \"easy\" way, see relevant issues:\n\nhttps://gitlab.com/gitlab-org/gitlab/-/issues/16733\nhttps://gitlab.com/gitlab-org/gitlab/-/issues/292816\n\nI personally was going to suggest going DAG route with needs: and artifacts, but i actually liked  Elan Ruusam\u00e4e approach, using dotenv to pass variables between stages. Here is his example:\n\nthis gave me an idea, that maybe combining dotenv and if\n$SOME_VARIABLE, you could run/skip a job. But it may not work if the\nall the evaluation is performed at pipeline creation time. this\nsnippet is not tested.\nhttps://docs.gitlab.com/ee/ci/variables/#inherit-cicd-variables\n\nbuild:\n  stage: build\n  script:\n    - echo \"SKIP_BUILD=true\" >> .env.skip\n  artifacts:\n    reports:\n      dotenv: .env.skip\n\ndocker build:\n  script: echo yadayada\n  rules:\n    - if: '$SKIP_BUILD != \"true\"'\n\nThis still requires to check for previous status in downstream pipelines and looks pretty hacky, but at least not as hacky as grepping through some text files.\nSince dotenv will likely not work in rules section, previous will have to be converted to something like:\nbuild:\n  stage: build\n  script:\n    - echo \"SKIP_BUILD=true\" >> .env.skip\n  artifacts:\n    reports:\n      dotenv: .env.skip\n\ndocker build:\n  script:\n    - [ \"$SKIP_BUILD\" = true ] && exit 0\n    - your_stuff_here\n  dependencies:\n    - build\n\n\nSee also: https://docs.gitlab.com/ee/ci/variables/README.html#pass-an-environment-variable-to-another-job"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab-CI, run on schedule but only if there are changes\n\nI'd like to deploy my project once per day, but only if there have been changes.\nThere is a specific hour each that I am able to deploy during and I am comfortable with using a scheduled pipeline to trigger and deploy.\nHowever, there aren't always changes that require deployment. Ideally, if there have been no changes to the code base since the last deployment, the pipeline wouldn't run that day.\nIs there any way to achieve this behaviour?"}, {"role": "assistant", "content": "This is similar to a 4 years old feature request gitlab-org/gitlab-foss issue 19813\n\nGitLab CI only execute when a certain folder has changed\nI have quite a large project, and I'm using GitLab CI with Pages to deploy it, however, when I change anything in the repo, it runs CI.\nI don't want this to happen, I want it to run only if the src folder changes.\nIs this possible?\n\nThe recent (July 2020) conclusion is to use only:changes/except:changes\n\nUsing the changes keyword with only or except makes it possible to define if a job should be created based on files modified by a Git push event.\n\nExample:\n\nI wanted this feature especially for package.json and package-lock.json because I can run npm install only if there is changes.\n\n  only:\n    changes:\n      - package.json\n      - package-lock.json\n\nWarning, as noted by Matthijs Bierman in the comments, and as documented here:\n\nNote that only: changes does not work with when: scheduled"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "git push fails with deny updating hidden ref\n\nI've a repository for my dotfiles and went to push changes from a branch only to encounter...\n$ git push\nEnumerating objects: 46, done.\nCounting objects: 100% (46/46), done.\nWriting objects: 100% (46/46), 3.20 MiB | 1.52 MiB/s, done.\nTotal 46 (delta 0), reused 0 (delta 0)\nTo gitlab.com:auser/dotfiles.git\n ! [remote rejected] kimura -> origin/kimura (deny updating a hidden ref)\n ! [remote rejected] master -> origin/master (deny updating a hidden ref)\nerror: failed to push some refs to '[email\u00a0protected]:auser/dotfiles.git'\n\nThis thread suggests its because pull requests made on origin and links to a blog post with solution of how to skip this, although I do not explicitly have refs/pull in the path thats being rejected so it may be a different issue but I couldn't find much info on this so figured I try the proposed solution and updated my config to...\n[core]\n    repositoryformatversion = 0\n    filemode = true\n    bare = false\n    logallrefupdates = true\n[remote \"origin\"]\n     url = [email\u00a0protected]:auser/dotfiles.git\n     fetch = +refs/heads/*:refs/heads/*\n     fetch = +refs/tags/*:refs/tags/*\n     fetch = +refs/change/*:refs/change/*\n     pushurl = [email\u00a0protected]:auser/dotfiles.git\n     push = +refs/heads/*:refs/remotes/origin/*\n[submodule \"oh-my-zsh/.oh-my-zsh\"]\n     url = https://github.com/robbyrussell/oh-my-zsh\n     active = true\n[branch \"master\"]\n     remote = origin\n     merge = refs/heads/master\n     pushRemote = origin\n[branch \"kimura\"]\n     remote = origin\n     merge = refs/heads/kimura\n     fetch = +refs/heads/*:refs/heads/*\n     fetch = +refs/tags/*:refs/tags/*\n     fetch = +refs/change/*:refs/change/*\n\nBut the problem persists.  My branches are...\n$ git branch -a\n* kimura\n  master\n  remotes/origin/kimura\n  remotes/origin/master\n\nThe host I'm trying to push from is where I started the repo before mirroring to Gitlab."}, {"role": "assistant", "content": "I had the same error\n[remote rejected] origin/myBranch   (deny updating a hidden ref)\n\nThe problem was:\nI cloned a remote repo mobile into a folder, then, I made modifications on the code, and when I tried to push, instead of pushing the local repo mobile to the remote one, I was trying to push its parent\n\nThe right way was to open git bash inside the local repo you have cloned and execute the right commands, this may be your problem too."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Install Gitlab runner on ECS Cluster\n\nWe are running AWS ECS/ECR with Gitlab CI as CI/CD.\nDue to load increase we are searching for the best way to autoscale the runner on AWS. \nI know Gitlab supports Autoscaling for its ci-runner. https://docs.gitlab.com/runner/configuration/runner_autoscale_aws/\nBut I'm wondering if it would be possible to leverage the ECS cluster on AWS for this purpose. Has anybody ever set up the runner on an ECS cluster with Loadbalancer and Autoscaling on ECS side and could provide some insights regarding such a setup?\nmerci in advance\nA"}, {"role": "assistant", "content": "Since each CI task is usually run in a container (or other isolated environment), this would require the GitLab runner to natively talk to ECS to spin up new containers for jobs\nI don't think it's gonna happen; GL supports Kubernetes, which is more versatile in that it's not tied to AWS, and also support EC2 autoscaling for AWS. ECS sounds like a lot of extra effort for a very narrow benefit."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to remove/uninstall gitlab-runner completely from centos\n\nMy gitlab-runner service is not running no matter what I do. I used to have same problem before and when I used to update, and it used to start running but now it\u2019s not starting at all. \nI have uninstalled and then again installed it\u2019s still the same. I guess I am not uninstalling/removing completely. How to uninstall gitlab runner completely or how to start service?\nI also don\u2019t get home dir of gitlab-runner. when I say gitlab-runner list I get following config details. \nConfigFile=/home/rohith/.gitlab-runner/config.toml\n\nbut I try cd to gitlab-runner user dir I don't find the dir at all."}, {"role": "assistant", "content": "If you install gitlab runner binary on Ubuntu  20.04 you can uninstall it completely by run below commands:\n# Stop and remove the service\nsudo gitlab-runner stop\nsudo gitlab-runner uninstall\nsudo systemctl daemon-reload\n\n# Remove gitlab-runner files and config\nsudo rm -rf /usr/local/bin/gitlab-runner\nsudo userdel gitlab-runner\nsudo rm -rf /home/gitlab-runner/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Same steps for multiple named environments with GitLab CI\n\nIs there a way to configure multiple specifically-named environments (specifically, test, stage, and prod)?\nIn their documentation (https://docs.gitlab.com/ce/ci/environments.html) they talk about dynamically-created environments, but they are all commit based.\nMy build steps are the same for all of them, save for swapping out the slug:\ndeploy_to_test:\n    environment:\n         name: test\n         url: ${CI_ENVIRONMENT_SLUG}.mydomain.com\n    scripts:\n         - deploy ${CI_ENVIRONMENT_SLUG}\n\ndeploy_to_stage:\n    environment:\n         name: stage\n         url: ${CI_ENVIRONMENT_SLUG}.mydomain.com\n    scripts:\n         - deploy ${CI_ENVIRONMENT_SLUG}\n\n deploy_to_prod:\n    environment:\n         name: prod\n         url: ${CI_ENVIRONMENT_SLUG}.mydomain.com\n    scripts:\n         - deploy ${CI_ENVIRONMENT_SLUG}\n\nIs there any way to compress this down into one set of instructions? Something like:\ndeploy:\n    environment:\n         url: ${CI_ENVIRONMENT_SLUG}.mydomain.com\n    scripts:\n         - deploy ${CI_ENVIRONMENT_SLUG}"}, {"role": "assistant", "content": "Yes, you can use anchors. If I follow the documentation properly, you would rewrite it using a hidden key .XX and then apply it with <<: *X.\nFor example this to define the key:\n.job_template: &deploy_definition\n    environment:\n         url: ${CI_ENVIRONMENT_SLUG}.mydomain.com\n    scripts:\n         - deploy ${CI_ENVIRONMENT_SLUG}\n\nAnd then all blocks can be writen using <<: *job_template. I assume environment will merge the name with the predefined URL.\ndeploy_to_test:\n   <<: *deploy_definition\n    environment:\n         name: test\n\ndeploy_to_stage:\n   <<: *deploy_definition\n    environment:\n         name: stage\n\n deploy_to_prod:\n   <<: *deploy_definition\n    environment:\n         name: prod\n\n\nFull docs section from the link above:\n\nYAML has a handy feature called 'anchors', which lets you easily duplicate content across your document. Anchors can be used to duplicate/inherit properties, and is a perfect example to be used with hidden keys to provide templates for your jobs.\nThe following example uses anchors and map merging. It will create two jobs, test1 and test2, that will inherit the parameters of .job_template, each having their own custom script defined:\n.job_template: &job_definition  # Hidden key that defines an anchor named 'job_definition'\n  image: ruby:2.1\n  services:\n    - postgres\n    - redis\n\ntest1:\n  <<: *job_definition           # Merge the contents of the 'job_definition' alias\n  script:\n    - test1 project\n\ntest2:\n  <<: *job_definition           # Merge the contents of the 'job_definition' alias\n  script:\n    - test2 project\n\n& sets up the name of the anchor (job_definition), << means \"merge the given hash into the current one\", and * includes the named anchor (job_definition again). The expanded version looks like this:\n.job_template:\n  image: ruby:2.1\n  services:\n    - postgres\n    - redis\n\ntest1:\n  image: ruby:2.1\n  services:\n    - postgres\n    - redis\n  script:\n    - test1 project\n\ntest2:\n  image: ruby:2.1\n  services:\n    - postgres\n    - redis\n  script:\n    - test2 project"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab key format issue\n\nI am facing a strange situation where I am using gitlab account to handle my code. I am using ssh protocol to access the repo. I am able to pull the code but I am receiving the following error while I try to push the code. This could be something silly on my side. But I have the keys stored in my gitlab profile and able to use it to pull the code.\nError :\n$ git push origin master\nkey_load_public: invalid format\nEnter passphrase for key '/c/Users/username/.ssh/id_rsa':\nAccess denied.\nfatal: Could not read from remote repository.\n\nPlease make sure you have the correct access rights\nand the repository exists."}, {"role": "assistant", "content": "Finally I have been able to resolve this issue and I am posting it for other users. If the keys generated by putty is not helping you to access the gitlab repo, try generating the keys from gitbash terminal using the command ssh-keygen and save the files in .ssh folder of your user account.\nThe linux style key generation made my life easy as I was trying to generate key in windows environment with putty keygen.\nHope this helps somebody."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Git remove remote history past certain commit\n\nI have a Git/Gitlab repository. We used to commit straight to master, but we decided to switch to using feature branches like the rest of the world for this release.\nWe need to reset our remote master to the state it was in immediately after the last release. If someone has already committed to the master directly, how can I reset it to a clean state, removing all history past the last release?\nI've spent about an hour googling now and can't find an answer to this specific question. Sorry if it seems redundant, it seems like such a simple task with no obvious answer!"}, {"role": "assistant", "content": "To reset a local branch,\ngit branch -f master last-release\n\nTo reset a remote branch,\ngit push -f origin last-release:master\n\nwhere last-release is the ref (commit id or branch) you want to reset master to.\n(Neither of these affect your working tree; you can even do these from a bare repo, if you wish.)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "vuejs history mode with github/gitlab pages\n\nHas anyone managed to figure out how to make Vue.js work with history mode with GitHub or GitLab Pages?\nIt works with hash mode, but I don't want to use hash mode for SEO related reasons.\nReference for router modes: https://router.vuejs.org/en/essentials/history-mode.html"}, {"role": "assistant", "content": "I found a solution that works for me in this article.\nTo summarize the solution, I created the following 404.html file and added it to the project's root folder.\n<!DOCTYPE html>\n<html>\n    <head>\n        <script>\n            // ====================================================================================================================\n            // This text is simply to make sure the 404.html file is bigger than 512 bytes, else, internet explorer will ignore it.\n            // Thank you internet explorer for requiring such awesome workarounds in order to work properly\n            // ====================================================================================================================\n            sessionStorage.redirect = location.href;\n        </script>\n        <meta http-equiv=\"refresh\" content=\"0;URL='/'\">\n    </head>\n</html>\n\nI then added this javascript in the index.html:\n(function(){\n    var redirect = sessionStorage.redirect;\n    delete sessionStorage.redirect;\n    if (redirect && redirect != location.href) {\n        history.replaceState(null, null, redirect);\n    }\n})();"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Migrate from bitbucket to GitLab\n\nI have multiple repositories in BitBucket. What is the most appropriate way to migrate from BitBucket to GitLab?\nFor an example, I maintain a repo on my system named \"SSSP\". What should be my steps to have a clean migration of that repository from BitBucket to GitLab?"}, {"role": "assistant", "content": "It is better to use an intermediate local bare repo in order to duplicate one remote repo and push it to a new remote one.\nAssuming you have an empty gitlab repo ready:\ngit clone --bare [email\u00a0protected]:old/old_repo.git\ncd old_repo\ngit remote add new-origin [email\u00a0protected]:new/new_repo.git\ngit push --mirror new-origin\ncd ..\ngit clone [email\u00a0protected]:new/new_repo.git repo\ncd repo\n# start working\n\nNote that this won't include the wiki (which you need to clone as well if you have some content there), or the issues.\n\nNote there is an import process more complete, and with GitLab 16.3 (August 2023), it includes:\n\nPreserve pull request reviewers when importing from BitBucket Server\nUntil now, the BitBucket Server importer did not import pull request (PR) reviewers and instead categorized them as participants. Information on PR reviewers is important from an audit and compliance perspective.\nIn GitLab 16.3, we added support for correctly importing PR reviewers from BitBucket. In GitLab, they become merge request reviewers.\nSee Documentation and Issue.\n\n\nMore recently (2024), regarding BitBucket Cloud, GitLab 17.0 (May 2024) comes with:\n\nImport from Bitbucket Cloud by using REST API\nIn this milestone, we added the ability to import Bitbucket Cloud projects by using the REST API.\nThis can be a better solution for importing a lot of projects than importing by using the UI.\nSee Documentation and Issue."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Forwarding to GitLab Subdomain with Existing Nginx Installation\n\nI've been following the instructions from the GitLab wiki, however, it seems as if some key pieces of information are missing. In the section \"Using a Non-Bundled Web Server\" it never explains how I need to reconfigure my Nginx installation to reverse proxy over to GitLab.\nBasically, I'd like to have GitLab installed under git.example.com, but I can't seem to find the configuration settings for my existing Nginx installation that'll do that. The wiki page goes on to talk about configuring an existing Passenger/Nginx installation, but I don't have Passenger, so I don't think that applies to my situation.\nI suppose the easiest solution would be if there were a way to tell Gitlab to use it's built-in Nginx and just listen on an internal port, and then have my other Nginx forward to that port, but I can't seem to figure out how to configure Gitlab to handle that.\nAny help would be greatly appreciated."}, {"role": "assistant", "content": "I got it working! So insanely excited!\nSo as I said, I was attempting to follow these instructions, but I wasn't getting anywhere, since it seemed to be lacking instructions on how to make your existing Nginx install link into Gitlab.\nWell, further down on the page they have a more complete explanation for Using an Existing Passenger / Nginx Installation, and while at first that didn't seem like what I wanted, researching Passenger a bit made it clear that it wasn't a Ruby-only thing(their easily-found install instructions require you to install it as a ruby gem) and their instructions for Ubuntu installation allowed me to integrate it into my existing Nginx reasonably easily.\nFrom there, it was just follow the steps in the wiki, although with a couple changes.\n\nThe Existing Passenger/Nginx Installation section fails to mention what the previous section on non-bundled Nginx install says, that you need to add www-data to the web_server['external_users'] line in the gitlab.rb file.\nSince I reconfigured my Gitlab installation to remove the bundled Nginx before I ran it the first time, the nginx log file at /var/log/gitlab/nginx/gitlab_access.log was non-existent, and this caused an error when Nginx tried to start up, simply creating that blank file and giving it proper read/write access made it work like a charm.\n\nI'm super psyched now, hope anyone who has as specific of a problem in the future comes across this, that Wiki should really be updated to simply remove/merge those two sections and explain/link to how to install Passenger into an existing Nginx installation. Would have saved me a lot of confusion and wasted time."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do you reuse a before_script from a shared yml file in Gitlab CI?\n\nI know that you can reuse blocks of code in a before script using yaml anchors:\n.something_before: &something_before\n- echo 'something before'   \n\n\nbefore_script:\n  - *something_before\n  - echo \"Another script step\"\n\nbut this doesn't seem to work when the .something_before is declared in a shared .yml file via the include:file. It also does not seem that extends works for before_script. Does anyone know a way of reusing some steps in a before_script from a shared .yml file?\nEDIT: My use case is that I have 2 gitlab projects with almost identical before_script steps. I don't want to have to change both projects whenever there's a change, so I have a third, separate Gitlab project that has a .yml template that I am including via include:file in both projects. I want to put all the common code in that shared template, and just have like two lines before_script for the git project that has the two extra steps."}, {"role": "assistant", "content": "You can use the !reference tag.\n.something:\n  before_script:\n    - echo 'something before'   \n\n\nbefore_script:\n  - !reference [\".something\", \"before_script\"]\n  - echo \"Another script step\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab account acces error: \"422 The change you requested was rejected.\"\n\nThis question asked by coderss but restarting the computer seems to noneffective.\n422\nThe change you requested was rejected.\nMake sure you have access to the thing you tried to change.\nPlease contact your GitLab administrator if you think this is a mistake.\nI have above error in Firefox under Linux but I have access in Chromium.\nThat's looks like typical cookie problem.\nI tried clear all Gitlab related cookies then restarted computer without any new sign in  attempt. and restarted computer  :) yeah I just try\nBut still same error, same browser.\nHow can I handle this problem?\nThis error also occurs at forgot password section and in private tab of Firefox.\nIs there another Gitlab related cookie?"}, {"role": "assistant", "content": "The issue should be fixed not only with cookies as discribed, but also with a correction of time system.\nI faced exactly the same problem: unable to connect with Firefox, even with a reset of cookies, but I was able to connect with Chrome. (That sounds strange because my clock system was false even on Chrome.)\nThe solution came with this very short explanation:\n\n\"it's was because my local time zone wasn't set up properly (and was messing with cookies)\"\nSource: https://www.reddit.com/r/gitlab/comments/cv7pov/422_error_on_wwwgitlabcomuserssignin_and/ey7l7lz?utm_source=share&utm_medium=web2x&context=3"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Get latest git tags on Gitlab CI/CD pipeline\n\nI want to set up a CI/CD pipelines in Gitlab that can read the latest tag and get that last tag to increment my next version application. I came with this configuration:\nstages:\n  - version\n\ncalculate_version:\n  image:\n    name: alpine/git:latest\n    entrypoint: [\"\"]\n  stage: version\n  script:\n    - VERSION=$(git tag);test -z \"$VERSION\" && echo \"no version tag found\" && exit 1\n    - CMDLINE=\"$VERSION\";\n    - echo $VERSION\n    - echo $CMDLINE > cmdline\n  artifacts:\n    paths:\n      - cmdline\n\nBut i get no tags listed there on $VERSION. Its look like Gitlab not passing the tags on the repository. However if I create and push a new tag, it shows just that new tag, not all tag list I expected.\nIs this the behaviour of the GitLab ci/cd? If yes, how can I get all of the tags in my repo inside the pipeline?"}, {"role": "assistant", "content": "You can obtain tags using Gitlab API\nBy default, results are ordered by the last updated tags, so if you want to get the last one, you can modify your script block like this:\nscript:\n  - VERSION=$(curl -Ss --request GET --header \"PRIVATE-TOKEN: <REPLACE_BY_A_VARIABLE>\" \"https://gitlab.com/api/v4/projects/${CI_PROJECT_ID}/repository/tags\" | jq -r '.[0] | .name')\n  - test -z \"$VERSION\" && echo \"no version tag found\" && exit 1"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab pull submodules inside CI\n\nI have a GitLab project that utilises GitLab CI.\nThe project also uses submodules, both the project and it's submodules are under the same GitLab account.\nHere is my .gitmodules file\n[submodule \"proto_contracts\"]\n    path = proto_contracts\n    url = https://gitlab.com/areller/proto_contracts.git\n\nI also have this piece in the .gitlab-ci.yml file\nvariables:\n  GIT_SUBMODULE_STRATEGY: recursive\n\nHowever, when i run the CI I get this error\nfatal: could not read Username for 'https://gitlab.com': No such device or address\n\nBoth the project and the submodules are in a private repository so you would expect to be prompted for authentication, but as I've mentioned, the project and the submodule are under the same account and one of the runner's jobs is to clone the original repository\n\nSo it's odd that it's unable to reach the submodule\nIs there a way around it?"}, {"role": "assistant", "content": "You must use relative URLs for submodules. Update your .gitmodules as follow:\n    [submodule \"proto_contracts\"]\n        path = proto_contracts\n        url = ../../areller/proto_contracts.git\n\nFurther reading: Using Git submodules with GitLab CI | GitLab Docs"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "ssh: connect to host gitlab.com port 22: Network is unreachable\n\nI'm trying to reach the Gitlab server to clone a repo in a Ubuntu 20.10 computer, but I always get the message:\nssh: connect to host gitlab.com port 22: Connection timed out\nfatal: Could not read from remote repository.\n\nPlease make sure you have the correct access rights\nand the repository exists.\n\n\nSo, I've tried to run the command ssh -T [email\u00a0protected], but I've got the message:\nssh: connect to host gitlab.com port 22: Network is unreachable\n\nI've tried in another computer with Ubuntu 20.04 and it worked.\nAnyone can help me with this?"}, {"role": "assistant", "content": "I had the same issue. I am connected to a remote machine via ssh (VPN turned on because it is located in the company). From the remote machine I tried to git clone (ssh) and got the following error message:\ngit clone [email\u00a0protected]:<project-name>.git\nCloning into '<project-name>'...\nssh: connect to host gitlab.com port 22: Network is unreachable\nfatal: Could not read from remote repository.\n\nPlease make sure you have the correct access rights\nand the repository exists.\n\nThe following solution worked. I added the following to the ssh-config of the remote machine, which was described here: https://about.gitlab.com/blog/2016/02/18/gitlab-dot-com-now-supports-an-alternate-git-plus-ssh-port/.\nHost gitlab.com\n  Hostname altssh.gitlab.com\n  User git\n  Port 443\n  PreferredAuthentications publickey\n  IdentityFile ~/.ssh/gitlab\n\nI am now able to git clone (ssh) projects from GitLab without any problems."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How can I make Gitlab runner merge code into a branch on a successful build\n\nWell the title is pretty much self-explanatory.\nIn summary, I want a branch (i.e. dev) to be merged to another branch (i.e. production) IF the build is successful."}, {"role": "assistant", "content": "I tried @jakub-kania solution but I was always getting id_rsa invalid format. I think that gitlab secret variables are screwed somehow.\nI made it working by directly passing the deployment key into ssh-add without creating ssh keys. Here is working solution:\nmerge to master:\n  stage: deploy\n  image: alpine\n  only:\n    - dev-branch\n  before_script:\n    - apk add --update git openssh-client\n    - mkdir ~/.ssh\n    - ssh-keyscan -p 2222 <gitlab.domain.com> > ~/.ssh/known_hosts\n    - eval `ssh-agent -s`\n    - ssh-add <(echo \"$GITLAB_DEPLOY_KEY\")\n    - ssh -T git@<gitlab.domain.com> -p 2222\n    - git config --global user.email \"$GITLAB_USER_EMAIL\"\n    - git config --global user.name \"$GITLAB_USER_ID\"\n    - git remote set-url origin ssh://git@<gitlab.domain.com>:2222/path/to/repo.git\n  script:    \n    - git checkout master\n    - git reset --hard origin/master\n    - git merge $CI_BUILD_REF\n    - git push origin master"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to reset / clean a GitLab repository\n\nI want to reset one of my repositories on gitlab, but without deleting the whole project.\nI've read on Gitlab Forums (on the post https://forum.gitlab.com/t/how-can-i-delete-a-repository-and-push-a-new-one/690) two different options:\nFirst: Deleting the physical repository from disk. I've tried renaming the folder (repo.git) but then, gitlab gives me a 404 error trying to access to it.\nSecond: Deleting all branches. This solution do not work too, because, I cannot delete the main branch (on my case master), and when I create a new one, the new branch requires to specify a \"original\" branch. I cannot create a clean branch without any data and change the main to it.\nSomeone know how to do it?\nThanks,"}, {"role": "assistant", "content": "Delete all branches except master, unprotect master in settings -> repository -> protected branches and execute:\ngit push -f master origin ."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to push multiple images needed for docker-compose to GitLab registry in GitLab CI?\n\nI recently got into CI/CD, and a good starting point for me was GitLab, since they provide an easy interface for that and i got started about what pipelines and stages are, but i have run into some kind of contradictory thought about GitLab CI running on Docker.\nMy app runs on Docker Compose. It contains (blah blah) that makes it easy to build & run containers. Each service in the Docker Compose creates a single Docker container, excepting the php-fpm one, which is able to do the thing called \"horizontal scale\", so I can scale it later.\nI will use that Docker Compose for production, I am currently using it in development and I want to use it too in CI/CD pipelines.\nHowever the .gitlab-ci.yml provides support for only one image, so I have to build it and push it to either their GitLab Registry or Docker Hub in order to pull it later in the CI/CD process.\nHow can I build my Docker Compose's service as a single image in order to push it to the Registry/Docker so I can pull it in the CI/CD?\nMy project contains a docker folder and a docker-compose.yml. In the docker folder, each service has its own separate directory (php-fpm, nginx, mysql, etc.) and each one (prepare yourself) contains a Dockerfile with build details, especially the php-fpm one (deps and libs are strong with this one)\nEach service in the docker-compose.yml has a build context in each of their own folder.\nIf I was unclear, I can provide additonal info."}, {"role": "assistant", "content": "However the .gitlab-ci.yml provides support for only one image\n\nThis is not true. From the official documentation:\n\nYour image will be named after the following scheme:\n<registry URL>/<namespace>/<project>/<image>\n\nGitLab supports up to three levels of image repository names.\nFollowing examples of image tags are valid:\nregistry.example.com/group/project:some-tag\nregistry.example.com/group/project/image:latest\nregistry.example.com/group/project/my/image:rc1\n\n\nSo the solution to your problem is simple - just build individual images and push them to GitLab container registry under different image name.\n\nIf you would like an example, my pipelines are set up like this:\n.template: &build_template\n  image: docker:stable\n  services:\n    - docker:dind\n  before_script:\n    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY\n  script:\n    - docker pull $CI_REGISTRY_IMAGE/$IMAGE_NAME:latest || true\n    - if [ -z ${CI_COMMIT_TAG+x} ];\n      then docker build\n        --cache-from $CI_REGISTRY_IMAGE/$IMAGE_NAME:latest\n        --file $DOCKERFILE_NAME\n        --tag $CI_REGISTRY_IMAGE/$IMAGE_NAME:$CI_COMMIT_SHA\n        --tag $CI_REGISTRY_IMAGE/$IMAGE_NAME:$CI_COMMIT_TAG\n        --tag $CI_REGISTRY_IMAGE/$IMAGE_NAME:latest . ;\n      else docker build\n        --cache-from $CI_REGISTRY_IMAGE/$IMAGE_NAME:latest\n        --file $DOCKERFILE_NAME\n        --tag $CI_REGISTRY_IMAGE/$IMAGE_NAME:$CI_COMMIT_SHA\n        --tag $CI_REGISTRY_IMAGE/$IMAGE_NAME:latest . ;\n      fi\n    - docker push $CI_REGISTRY_IMAGE/$IMAGE_NAME:$CI_COMMIT_SHA\n    - if [ -z ${CI_COMMIT_TAG+x} ]; then\n        docker push $CI_REGISTRY_IMAGE/$IMAGE_NAME:$CI_COMMIT_TAG;\n      fi\n    - docker push $CI_REGISTRY_IMAGE/$IMAGE_NAME:latest\n\nbuild:image1:\n  <<: *build_template\n  variables:\n    IMAGE_NAME: image1\n    DOCKERFILE_NAME: Dockerfile.1\n\nbuild:image2:\n  <<: *build_template\n  variables:\n    IMAGE_NAME: image2\n    DOCKERFILE_NAME: Dockerfile.2\n\nAnd you should be able to pull the same image using $CI_REGISTRY_IMAGE/$IMAGE_NAME:$CI_COMMIT_SHA in later pipeline jobs or your compose file (provided that the variables are passed to where you run your compose file)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "how to download single folder OR file in gitlab repository\n\ni have one repository. In this repository multiple folders are available.\ni have required only one folder in this repository.\ni am already try to following command but it's not working.\ngit clone"}, {"role": "assistant", "content": "If only the content of that folder is of interest (not its history), you can, since GitLab 1.11 (May 2019) download only a folder.\n\nDownload archives of directories within a repository\n\n\n\nDepending on the type of project and its size, downloading an archive of the entire project may be slow or unhelpful \u2013 particularly in the case of large monorepos.\nIn GitLab 11.11, you can now download an archive of the contents of the current directory, including subdirectories, so that you download only the files you need.\n\nFrom issue 24704: see documentation.\n\nWith GitLab 14.4 (Oct. 2021), you have:\n\nissue 28827 \"Download a (sub-)folder from a repository via the Repositories API\",\nresolved with MR 71431 and commit 1b4e0a1:\n\ncurl --header \"PRIVATE-TOKEN: <your_access_token>\" \\\n\"https://gitlab.com/api/v4/projects/<project_id>/repository/archive?sha=<commit_sha>&path=<path>\"\n\nIt was not somehow mentioned in the \"GitLab 1.44 released\" page though."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab ci cache/keep golang packages between stages\n\nI use gitlab-ci to test, compile and deploy a small golang application but the problem is that the stages take longer than necessary because they have to fetch all of the dependencies every time.\nHow can I keep the golang dependencies between two stages (test and build)?\nThis is part of my current gitlab-ci config:\ntest:\n    stage: test\n    script:\n        # get dependencies\n        - go get github.com/foobar/...\n        - go get github.com/foobar2/...\n        # ...\n        - go tool vet -composites=false -shadow=true *.go\n        - go test -race $(go list ./... | grep -v /vendor/)\n\ncompile:\n    stage: build\n    script:\n        # getting the same dependencies again\n        - go get github.com/foobar/...\n        - go get github.com/foobar2/...\n        # ...\n        - go build -race -ldflags \"-extldflags '-static'\" -o foobar\n    artifacts:\n        paths:\n            - foobar"}, {"role": "assistant", "content": "As mentioned by Yan Foto, you can only use paths that are within the project workspace. But you can move the $GOPATH to be inside your project, as suggested by extrawurst blog.\ntest:\n  image: golang:1.11\n  cache:\n    paths:\n      - .cache\n  script:\n    - mkdir -p .cache\n    - export GOPATH=\"$CI_PROJECT_DIR/.cache\"\n    - make test"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Migrate gitlab to gogs\n\nRecently, i found a Gitlab alternative called Gogs.\nAny suggestion for migrating repo in Gitlab to Gogs? I m not expecting all of it of course, just as much as possible."}, {"role": "assistant", "content": "The correct steps for mirroring a repo is:\n\n$ git clone --mirror [email\u00a0protected]/upstream-repository.git\n  $ cd upstream-repository.git\n  $ git push --mirror [email\u00a0protected]/new-location.git\n\nNote: Do not use git push --mirror if you did not clone the repo with git clone --mirror. Also, git clone --mirror is preferred over git clone --bare as it will clone all git notes and attributes as well.\nReference: http://blog.plataformatec.com.br/2013/05/how-to-properly-mirror-a-git-repository/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Run jobs in the same stage sequentially in Gitlab CI\n\nI want to run jobs in the same stage sequentially instead of parallel in GitLab CI. Currently this is what I have:\n\nI want unit-test to run before integration-test and not in parallel. I have looked into the docs and have encountered DAG but it needs the job to be in a prior stage and cannot be on the same stage. Is there a way to achieve this?"}, {"role": "assistant", "content": "Yes its already described in the documentation for stages, jobs are started in parallel in one stage.\nIt says:\n\nTo make a job start earlier and ignore the stage order, use the needs keyword.\n\nAs you said, this is not possible in GitLab < 14.2 within a stage (needs):\n\nneeds: is similar to dependencies: in that it must use jobs from prior stages, meaning it's impossible to create circular dependencies. Depending on jobs in the current stage is not possible either, but support is planned.\n\nAs an alternative, you could define several stages and use the keyword needs between jobs in these stages.\nSince GitLab 14.2 (issue) its possible."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Why can't I go to sign in page to Gitlab.com from Browser?\n\nI went to about.gitlab.com. from there I clicked on sign in. The browser keeps showing: \"Checking your browser before accessing gitlab.com.\". This has been going on for 10 hours. I have Already tried clearing my cookies and restarting my pc. This did not yield any result. My firewall is turned off so it isn't a firewall issue."}, {"role": "assistant", "content": "This is so extremely frustrating and makes me want to move everything back from GitLab to GitHub.\nIn my case, the addon that GitLab (actually cloudflare) didn't like was the Chameleon (Random Agent Spoofer) plugin, which I use to prevent tracking/fingerprinting across websites.\n\nhttps://addons.mozilla.org/en-US/firefox/addon/chameleon-ext/\n\nThanks Cloudflare for depending on fingerprinting and effectively issuing a DOS attack on GitLab customers that use tools to protect themselves."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to verify ssh key on Gitlab.com\n\nI'm setting up a SSH key for the first time on Gitlab.com. I'm stuck at verifying that you can connect: ssh -T [email\u00a0protected].\nThe gitlab.example.com you are supposed to replace with your Gitlab instance url but I keep getting \"ssh: Could not resolve hostname : Name or service not known\".\nI'm using the Gitlab SaaS solution and have tried various formats, such as:\nssh -T [email\u00a0protected]/my-workspace-name\nssh -T [email\u00a0protected]:my-workspace-name\nssh -T [email\u00a0protected]/my-workspace-name/project-name\n\nWhat is the correct format that should work?"}, {"role": "assistant", "content": "Correct format is ssh -T [email\u00a0protected].\nmy-workspace-name is not part of the instance url."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI pipeline to run jobs parallel in same stage and invoke/trigger other jobs of same stage\n\nI am trying to create a automation pipeline for data load.  I have a scenario  as explained below:\nstages\n - stage1\n - stage2\n\njob1:\n  stage: stage1\n  script:\n  - echo \"stage 1 job 1\"\n\n\njob2:\n  stage: stage1\n  script:\n   - echo \"stage 1 job 2\"\n\njob3:\n  stage: stage1\n  script:\n   - echo \"stage 1 job 3\"\n\njob4:\n  stage: stage1\n  script:\n   - echo \"stage 1 job 4\"\n\nI want to run the job1 and job2 parallel in the same stage. So, after Job1 and job2 success\n\njob1 will invoke/trigger the job3. that means job3 will start automatically when job1 successes\njob2 will invoke/trigger the job4 that means job4 will start automatically when job2 successes\n\nI am writing the pipeline in the .gitlab-ci.yml.\nCan anyone help me to implement this?"}, {"role": "assistant", "content": "Strict implementation of your requirements is not possible (according to my knowledge), the jobs 3 and 4 would need to be in a separate stage (although support for putting them in the same stage is planned). To be clear: the other functional requirements can be fulfilled, i.e:\n\njob1 and job2 start in parallel\njob1 will trigger the job3 (immediately, without waiting for the job2 to finish)\njob2 will trigger the job4 (immediately, without waiting for the job1 to finish)\n\nThe key is using needs keyword to convert the pipieline to a directed acyclic graph:\nstages:\n    - stage-1\n    - stage-2\n\njob-1:\n    stage: stage-1\n    needs: []\n    script: \n      - echo \"job-1 started\"\n      - sleep 5\n      - echo \"job-1 done\"\n\njob-2:\n    stage: stage-1\n    needs: []\n    script: \n      - echo \"job-2 started\"\n      - sleep 60\n      - echo \"job-2 done\"\n\njob-3:\n    stage: stage-2\n    needs: [job-1]\n    script: \n      - echo \"job-3 started\"\n      - sleep 5\n      - echo \"job-3 done\"\n\njob-4:\n    stage: stage-2\n    needs: [job-2]\n    script: \n      - echo \"job-4 started\"\n      - sleep 5\n      - echo \"job-4 done\"\n\n\nAs you can see on the screenshot, the job 3 is started, even though the job 2 is still running."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab: How to embed image from repo in the wiki?\n\nI have a GitLab repository with documentation in the attached wiki (i.e. NOT in the repo itself) and an image file inside the repository itself that I want to embed in wiki pages.\nHow can this be done?\nFrom a wiki page, I can successfully link to the image using\n[[../tree/master/pathto/myimage.jpg]] or [[../raw/master/pathto/myimage.jpg]] but \n\n![](../raw/master/pathto/myimage.jpg)\n \ndoesn't seem to work.\n(GitLab Community Edition 10.0.3)"}, {"role": "assistant", "content": "Embedding using the absolute path to the repo and image worked:\n![](https://url.of.my.repo/raw/master/pathto/myimage.jpg)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to use conditions in .gitlab-ci.yml variables?\n\nI want to know, if it's possible to set custom Gitlab CI variable from if-else condition statement.\nIn my .gitlab-ci.yml file I have the following:\nvariables:\n    PROJECT_VERSION: (if [ \"${CI_COMMIT_TAG}\" == \"\" ]; then \"${CI_COMMIT_REF_NAME}-${CI_PIPELINE_ID}\"; else ${CI_COMMIT_TAG}; fi);\n\nTrying to set project version:\n    image: php:7.1-cli\n    stage: test\n    script:\n        # this echoes correct string (eg. \"master-2794\")\n        - (if [ \"${CI_COMMIT_TAG}\" == \"\" ]; then echo \"${CI_COMMIT_REF_NAME}-${CI_PIPELINE_ID}\"; else echo ${CI_COMMIT_TAG}; fi);\n        # this echoes something like \"(if [ \"\" == \"\" ]; then \"master-2794\"; else ; fi);\"\n        - echo $PROJECT_VERSION\n\nCan this be done? If so, what have I missed? Thanks"}, {"role": "assistant", "content": "This is expected behavior.\nCI_COMMIT_TAG is only set to a value in a GitLab job. From https://docs.gitlab.com/ee/ci/variables/README.html\n\nCI_COMMIT_TAG - The commit tag name. Present only when building tags.\n\nTherefore in the variables section CI_COMMIT_TAG is not defined, hence equals to \"\".\nSo if you want to use CI_COMMIT_TAG use in job where tags are defined. See https://docs.gitlab.com/ee/ci/yaml/README.html#tags"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Continuous Deployment of a NodeJS using GitLab\n\nI have an API developed in NodeJS and have successfully set up continuous integration via a .gitlab-ci.yml file. The next stage is to set up continuous deployment to Heroku if all tests pass on the master branch.\nThere are plenty of tutorials covering the deployment of Ruby and Python apps but nothing on NodeJS. Currently my .gitlab-ci.yml file looks like this:\nimage: node:latest\n\njob1:\n  script: \"ls -l\"\n\ntest:\n  script: \"npm install;npm test\"\n\nproduction:\n  type: deploy\n  script:\n  - npm install\n  - npm start\n  - gem install dpl\n  - dpl --provider=heroku --app=my-first-nodejs --api-key=XXXXXXXXXX\n  only:\n  - master\n\nThe Ruby and Python tutorials use the dpl tool to deploy but how can I start the NodeJS script on the server once deployed?\nAfter adding the production section and pushing it the tests run and pass but the deploy stage gets stuck on pending. The console is blank. Has anyone set up a successful CD script for NodeJS?"}, {"role": "assistant", "content": "you could use a much more simple YAML script where you can define the stages for the CI (to run test before production deploy) you can then use a different image at the Heroku deploy stage. So for a node app you define the default image as node:latest. Then for the production deployment using dpl you can use the ruby image.\nimage: node:latest\n\nstages:\n  - job1\n  - test\n  - production\n\njob1:\n  stage: job1\n  script: \"ls -l\"\n\ntest:\n  stage: test\n  script: \n    - npm install\n    - npm test\n  artifacts:\n    paths:\n      - dist/\n\nproduction:\n  type: deploy\n  stage: production\n  image: ruby:latest\n  script:\n    - apt-get update -qy\n    - apt-get install -y ruby-dev\n    - gem install dpl\n    - dpl --provider=heroku --app=my-first-nodejs --api-key=XXXXXXXXXX\n  only:\n    - master"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to get subfolders and files using gitlab api\n\nI am using gitlab api to get the files and folders and succeded,\nBut I can able to get only directory names, not its subfolders and files.\nSo, how can i get full tree of my repository.\nPlease let me know.\nThanks in advance,\nMallikarjuna"}, {"role": "assistant", "content": "According to the Repositories API, we can use\nGET /projects/:id/repository/tree\n\nTo list files and directories in a project. But we can only get the files and directories in top-level of the repo in this way, and sub-directories of directories in top-level with param path.\nIf you wanna get directories of script/js/components, for example, you can use\nGET /projects/:id/repository/tree?path=script/js/components"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "SSH Host Key Verification Failed inside GitLab CI\n\nLocal Setup\nI created a public and private SSH key via the ssh-keygen command.\nI decided to setup the private key locally first, before setting it up on my repo's gitlab CI.\nI setup the public key on the server (in this case, another gitlab repo, but this may change in the future and shouldn't affect the question).\nI successfully communicated with the server locally via the following command  (in this case I am using SSH via git, but this again may change in the future):\ngit clone [email\u00a0protected]:...../......git\n\nGitLab CI Setup\nI then decided to setup the private key and communication on gitlab CI.\nInside my repo, I navigated to Settings -> Continuous Integration -> Variables, and added the following environment variables:\n\nSSH_DEPLOY_PRIVATE_KEY - I used to same private key that I used locally\nSSH_KNOWN_HOSTS\n\nI took the gitlab.com known host from my local computer's ~/.ssh/known_hosts file\ngitlab.com,35.231.145.151 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBFSMqzJeV9rUzU4kWitGjeR4PWSa29SPqJ1fVkhtj3Hw9xjLVXVYrU9QlYWrOLXBpQ6KWjbjTDTdDkoohFzgbEY=\n\n\nI then setup the SSH inside .gitlab-ci.yml:\nscript:\n  - apt-get install openssh-client -y\n  - eval $(ssh-agent -s)\n  - echo \"$SSH_DEPLOY_PRIVATE_KEY\" | tr -d '\\r' | ssh-add - > /dev/null\n  - mkdir -p /.ssh && touch /.ssh/known_hosts\n  - echo \"$SSH_KNOWN_HOSTS\" >> /.ssh/known_hosts\n  - mkdir -p ~/.ssh\n  - chmod 700 ~/.ssh\n\nThis seemed to work fine and I got the following message: Identity added: (stdin) (runner@....)\nI then added the same git clone command to communicate with the server, and it failed with the following error:\nCloning into '......'...\nHost key verification failed.\nfatal: Could not read from remote repository.\n\nPlease make sure you have the correct access rights\nand the repository exists.\n\nTesting locally still works. I used the same commands above to setup the SSH locally (except I used pacman -S openssh to install instead).\nHow do I fix this?\nEdit\nI'm aware that I can execute ssh-keyscan directly in the GitLab CI and this should in theory solve the problem, but from what I know, this is susceptible to man-in-the-middle attacks. I'm trying to find a more secure solution.\nEdit 2\nAfter running ssh-keyscan directly in the GitLab CI, I get the same error message.\nVerbose output is the same:\n$ GIT_SSH_COMMAND=\"ssh -vvv\" git clone [email\u00a0protected]:..../.....git deployed\nCloning into 'deployed'...\nHost key verification failed.\nfatal: Could not read from remote repository.\n\nPlease make sure you have the correct access rights\nand the repository exists.\n\nEdit 3\nSeems to be connected to the internet. Plus apt-get install wouldn't work otherwise.\n\nEdit 4\nI don't understand why this is such a difficult task. I followed this article and am doing everything correctly. There seems to be plenty of other similar questions, which also do not have any answers. Is this just an issue with GitLab CI that we have no control over?\nI'm also now thinking that it has something to do with the fact that the SSH server is another GitLab repo. Maybe GitLab CI blocks SSH connections within the same network. Not sure why but it's a possibility. Also don't know how you'd connect without SSH.\nEdit 5\nThe verbose output clearly was not working using GIT_SSH_COMMAND, so I tried an ssh connection without git:\nssh -vvvv [email\u00a0protected]\n\nLog output:\nOpenSSH_6.7p1 Debian-5+deb8u5, OpenSSL 1.0.1t  3 May 2016\ndebug1: Reading configuration data /etc/ssh/ssh_config\ndebug1: /etc/ssh/ssh_config line 19: Applying options for *\nPseudo-terminal will not be allocated because stdin is not a terminal.\ndebug2: ssh_connect: needpriv 0\ndebug1: Connecting to gitlab.com [35.231.145.151] port 22.\ndebug1: Connection established.\ndebug1: permanently_set_uid: 0/0\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_rsa type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_rsa-cert type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_dsa type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_dsa-cert type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_ecdsa type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_ecdsa-cert type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_ed25519 type -1\ndebug1: key_load_public: No such file or directory\ndebug1: identity file /root/.ssh/id_ed25519-cert type -1\ndebug1: Enabling compatibility mode for protocol 2.0\ndebug1: Local version string SSH-2.0-OpenSSH_6.7p1 Debian-5+deb8u5\ndebug1: Remote protocol version 2.0, remote software version OpenSSH_7.2p2 Ubuntu-4ubuntu2.8\ndebug1: match: OpenSSH_7.2p2 Ubuntu-4ubuntu2.8 pat OpenSSH* compat 0x04000000\ndebug2: fd 3 setting O_NONBLOCK\ndebug3: load_hostkeys: loading entries for host \"gitlab.com\" from file \"/root/.ssh/known_hosts\"\ndebug3: load_hostkeys: loaded 0 keys\ndebug1: SSH2_MSG_KEXINIT sent\ndebug1: SSH2_MSG_KEXINIT received\ndebug2: kex_parse_kexinit: [email\u00a0protected],ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group14-sha1,diffie-hellman-group-exchange-sha1,diffie-hellman-group1-sha1\ndebug2: kex_parse_kexinit: [email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,ssh-ed25519,ssh-rsa,ssh-dss\ndebug2: kex_parse_kexinit: aes128-ctr,aes192-ctr,aes256-ctr,[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],arcfour256,arcfour128,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,[email\u00a0protected]\ndebug2: kex_parse_kexinit: aes128-ctr,aes192-ctr,aes256-ctr,[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],arcfour256,arcfour128,aes128-cbc,3des-cbc,blowfish-cbc,cast128-cbc,aes192-cbc,aes256-cbc,arcfour,[email\u00a0protected]\ndebug2: kex_parse_kexinit: [email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],hmac-sha2-256,hmac-sha2-512,hmac-sha1,[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],hmac-md5,hmac-ripemd160,[email\u00a0protected],hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: [email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],hmac-sha2-256,hmac-sha2-512,hmac-sha1,[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],hmac-md5,hmac-ripemd160,[email\u00a0protected],hmac-sha1-96,hmac-md5-96\ndebug2: kex_parse_kexinit: none,[email\u00a0protected],zlib\ndebug2: kex_parse_kexinit: none,[email\u00a0protected],zlib\ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: first_kex_follows 0 \ndebug2: kex_parse_kexinit: reserved 0 \ndebug2: kex_parse_kexinit: [email\u00a0protected],ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group14-sha1\ndebug2: kex_parse_kexinit: ssh-rsa,rsa-sha2-512,rsa-sha2-256,ecdsa-sha2-nistp256,ssh-ed25519\ndebug2: kex_parse_kexinit: [email\u00a0protected],aes128-ctr,aes192-ctr,aes256-ctr,[email\u00a0protected],[email\u00a0protected]\ndebug2: kex_parse_kexinit: [email\u00a0protected],aes128-ctr,aes192-ctr,aes256-ctr,[email\u00a0protected],[email\u00a0protected]\ndebug2: kex_parse_kexinit: [email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],hmac-sha2-256,hmac-sha2-512,hmac-sha1\ndebug2: kex_parse_kexinit: [email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],[email\u00a0protected],hmac-sha2-256,hmac-sha2-512,hmac-sha1\ndebug2: kex_parse_kexinit: none,[email\u00a0protected]\ndebug2: kex_parse_kexinit: none,[email\u00a0protected]\ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: \ndebug2: kex_parse_kexinit: first_kex_follows 0 \ndebug2: kex_parse_kexinit: reserved 0 \ndebug2: mac_setup: setup [email\u00a0protected]\ndebug1: kex: server->client aes128-ctr [email\u00a0protected] none\ndebug2: mac_setup: setup [email\u00a0protected]\ndebug1: kex: client->server aes128-ctr [email\u00a0protected] none\ndebug1: sending SSH2_MSG_KEX_ECDH_INIT\ndebug1: expecting SSH2_MSG_KEX_ECDH_REPLY\ndebug1: Server host key: ECDSA f1:d0:fb:46:73:7a:70:92:5a:ab:5d:ef:43:e2:1c:35\ndebug3: load_hostkeys: loading entries for host \"gitlab.com\" from file \"/root/.ssh/known_hosts\"\ndebug3: load_hostkeys: loaded 0 keys\ndebug3: load_hostkeys: loading entries for host \"35.231.145.151\" from file \"/root/.ssh/known_hosts\"\ndebug3: load_hostkeys: loaded 0 keys\ndebug1: read_passphrase: can't open /dev/tty: No such device or address\nHost key verification failed.\n\nThe second-last line indicates that it's trying to communicate with the terminal using the /dev/tty file. Of course, this script is running in a non-interactive manor so it fails. Shouldn't it be using my key instead of requesting a passphrase from the terminal?"}, {"role": "assistant", "content": "You may need to try setting the mode to 644 rather than 700. 644 is what is suggested in the Verifying the SSH host keys documentation, and is also what SSH uses for this file by default. Some parts of SSH are very particular about this - I'm not sure if known_hosts is particular.  \nThe docs also mention you should set the value of SSH_KNOWN_HOSTS variable to the entire output of ssh-keyscan since there are multiple keys. \nEDIT:\nThe following .gitlab-ci.yml worked for me on GitLab.com. Note the use of ~/.ssh/ rather than /.ssh/. \nimage: ubuntu:latest\n\ntest_job:\n  script:\n  - apt-get update\n  - apt-get install openssh-client git-core -y\n  - eval $(ssh-agent -s)\n  - echo \"$SSH_DEPLOY_PRIVATE_KEY\" | tr -d '\\r' | ssh-add - > /dev/null\n  - mkdir -p ~/.ssh && touch ~/.ssh/known_hosts\n  - echo \"$SSH_KNOWN_HOSTS\" >> ~/.ssh/known_hosts\n  - git clone [email\u00a0protected]:gitlab-org/gitlab-ce.git"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to export issues on Gitlab?\n\nIs there an option to export all issues / TODOS to csv or pdf file in GitLab?"}, {"role": "assistant", "content": "As other users have commented, CSV export is built into paid versions of gitlab:\nhttps://docs.gitlab.com/ee/user/project/issues/csv_export.html\nHowever that does have issues - it emails the report to you and hence gitlab limit it to 20MB in size, and depending on the version of gitlab you're using some of the fields may not be present in the export.\nThankfully gitlab has a good API (including in the free version), so you can extract issues via the issues API instead, and once you have that data it's very simple to output it in CSV format.\nI wrote a very simple perl script that does this, it's available here and should work with free & paid versions of gitlab and also on gitlab.com:\nhttps://gitlab.com/emobix/get-all-gitlab-issues-as-csv"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Can you clone GitLab snippets?\n\nIt's easy enough to create them, but I can't find out how to clone them and edit offline.\nIs it possible?"}, {"role": "assistant", "content": "May 2020, for GitLab 13.0: yes!\n\nVersioned Snippets\nSnippets are useful for sharing small bits of code and text that may not belong in the main project\u2019s codebase.\nThese items are important to groups and users who rely on them for other tasks, like scripts to help generate diagnostic output or setup supporting services for testing and demo environments.\nUnfortunately, a lack of version control has made it hard to know if a snippet was the latest version or what changes may have happened and how to reconcile those.\nSnippets in GitLab are now version controlled by a Git repository.\n\n\n\nWhen editing a Snippet, each change creates a commit. Snippets can also be cloned to make edits locally, and then pushed back to the Snippet repository.\nThis is the first step in enabling more collaboration on Snippets.\nIn future releases we\u2019ll introduce support for multiple files, continue to expand features and expand permissions.\n\nSee documentation and issue.\n\nAnd with GitLab 13.5 (October 2020):\n\nSnippets with multiple files\nEngineers often use Snippets to share examples of code, reusable components, logs, and other items. These valuable pieces of information often require additional context and may require more than one file. Sharing a link to multiple files or multiple Snippets makes it challenging for users to piece this context together and understand the scope of what is being presented.\nIn GitLab 13.0, we laid a foundation for Snippets by giving them version control support based on a Git repository. Version control and the history it provides are an important piece of context when looking at code and understanding its purpose, but it may not be everything.\nGitLab now supports multiple files inside of a single Snippet, so you can create Snippets composed of multiple parts. It broadens its use to endless possibilities. For example:\n\nA snippet that includes a script and its output.\nA snippet that includes HTML, CSS, and JS code, from which the result can be easily previewed.\nA snippet with a docker-compose.yml file and its associated .env file.\nA gulpfile.js file coupled with a package.json file, which together are used to bootstrap the project and manage its dependencies.\n\nProviding all of these files in a single Snippet gives more options for the types of content that can be shared and the context that is provided when looking at them. We\u2019re excited to see the types of content you will create and share using Snippets with multiple files!\n\nSee Documentation and Issue.\n\n\n2015: original answer: Not directly.\nGitlab already have snippets section under each project.\nLike: http://gitabhq.com/project-name/snippets/\nBut it is not available for cloning.\nThere was a request for a GitHub Gist-like feature for GitLab (based on Gistie), also asked in GitLab suggestions.\nBut that was not implemented at the time.\n\nUpdate 2019, as commented by eli, and documented in \"Downloading snippets\" (GitLab 10.8+)\n\nFor now its just possible to download snippets, e.g.\nhttps://gitlab.com/snippets/SNIPPET_ID/raw?line_ending=raw \u2013"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to publish html report\n\nI am using a GitLab pipeline to run some tests and produce a coverage report.\nWhat I would like to do is be able to publish the produced coverage folder (that includes an html page and an src folder) to some internal GitLab static page, viewable by some team members.\nI am aware of the gitlab pages concept, but the steps indicate that I have to use a static site generator for this purpose.\nMy questions are the following:\n\nis the concept usable only when publishing on the official GitLab website (gitlab.io) or can I make use of my on-prem GetLab installation (i.e. so that my pages are available in my.local.gitlab.server/mynamespace/thepagesproject)?\ncan I just upload an index.html file with the folder of its contents and make it accessible?\nwhat is the optimal way of making use of an EXISTING project, so that just to add some html pages to it (ideally I would like to avoid creating a new project just for this purpose)"}, {"role": "assistant", "content": "Can I use GitLab Pages on self-hosted instance?\nYes, GitLab Pages works on self-hosted instances.  You may need to register a wildcard domain name for *.pages.<your-gitlab-domain-name>, and generate SSL certs if you are running gitlab over https only.\nOnce you have a domain, edit /etc/gitlab/gitlab.rb and add the extra settings, and run a gitlab-ctl reconfigure (leave out the pages_nginx settings if you are running over http only):\ngitlab_pages['enable'] = true\npages_external_url \"https://pages.<your-gitlab-domain-name>\"\npages_nginx['redirect_http_to_https'] = true\npages_nginx['ssl_certificate'] = \"/etc/gitlab/ssl/pages.<your-gitlab-domain-name>.crt\"\npages_nginx['ssl_certificate_key'] = \"/etc/gitlab/ssl/pages.<your-gitlab-domain-name>.key\"\n\nOnce that is done you will be able to access per-project pages via <group>.pages.<your-gitlab-domain-name>/<project>\nCan I upload whatever I want to pages?\nYes.  Each GitLab CI job can create content to publish in GitLab pages by writing it into a public folder, and registering public as an artifact directory.  A final pages job should be added to the CI pipeline which causes the pages content to be published (overwriting anything that was there before).  All the content of the public directory will be available via the <group>.pages.<your-gitlab-domain-name>/<project> URL, which means you have full control over content.\nNote that the pages job in CI doesn't need to have any script, it just needs to be present with the job name \"pages\".  This is a magic job name that triggers the pages publish.  You may want to add job restrictions so that this only runs on master branch pipelines.\nCan I add pages publish to an existing project?\nYes. Any steps that create content you want to publish should write the content to a public subdirectory, and register the public directory as an artifact directory.\nmy job:\n  stage: build\nscript:\n  - echo \"Do some things and write them to public directory\" > public/index.html\nartifacts:\n  paths:\n  - public\n    expire_in: 2 weeks\n\nNote: I like to add expire_in: 2 weeks to limit the length of time artifacts are kept around.  Once the pages have been published the artifacts aren't really needed.\nFinally you need to add a pages job to trigger the pages publish:\n# This job does nothing but collect artifacts from other jobs and triggers the pages build\n# The artifacts are picked up by the pages:deploy job.\npages:\n  stage: deploy\n  script:\n    - ls -l public\n  artifacts:\n    paths:\n      - public\n  only:\n    - master\n\nUsually you will only want to publish on master branch, but you have freedom to choose when you want the pages publish to run.  It is important to note that when the pages publish runs it will fully replace any content that was previously published, so you can't append to existing content (although there are some hacks that allow you to achieve something similar)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GIT: How to protect the branch from being removed by other developers?\n\nAfter the first release of our product, we will be switching to a different branches for the main development and feature development. Is there a way to create a branch in such a way, so that we can protect it from being removed (accidentally or on purpose) unless you're a specific user (based on role or username)? \nI tried to create a sample git repository in our local gitlab machine, then protected one of the branches from the option on the website, but then I was able to remove it with git push origin :branch_name. Thanks in advance!\nWill the solution work on github.com?"}, {"role": "assistant", "content": "There are many ways to tackle this: \n\nMake another repo that's a sand box, and give readonly access to the master one. If they delete by accident they can get the branch from the master repo. This assumes you are only using github for your repos aside the local dev repos.\nSetup hooks in the repository that don't allow branches to be deleted unless you are a specific user. You can't do that on github as they won't allow arbitrary code to be executed on their servers. If you get a local repo instead, you can do this.\nSetup a local gitolite install to manage branches with permissions."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to use custom variables in gitlab ci/cd?\n\nI'm struggling with gitlab ci/cd variables. I see so many conflicting examples. Anyhow, what I would like to know is how to use variables outside and within scripts.\nFor example, in a job config, can I assign a variable in the script section with a bash command?\nsome-job:\n   variables:\n      SOME_VAR: ''\n   script:\n      - SOME_VAR = $(<file_with_a_line_of_text.txt)\n\nIn the above case, I'm not sure if I can do this. But I need to populate a variable with the file contents (i.e. artifact). Also, when do I use '$' in front of the variable? Some examples I see using these formats:\n\"SOME_VAR\" #in quotes, no dollar sign\n\"${SOME_VAR}\" #in quotes, with dollar sign and wrapped with curly braces\n${SOME_VAR} #no quotes, with dollar sign and wrapped with curly braces\n$SOME_VAR #i.e. without the double quotes or curly braces\nSOME_VAR #i.e. without the double quotes, dollar sign, and curly braces\n\nSo many variations of usage that I can see in examples but don't really know when to use each style. And I can't find one example online of a custom variable being set in a script using a bash command."}, {"role": "assistant", "content": "When I'm setting variables in bash, I always do it without the spaces around the =:\nVAR1=\"some string\"\nVAR2=23\nVAR3=true\nVAR4=$(cat /path/to/file.txt)\n\nLet's go through these examples one at a time:\n\nYou can set a variable as a string by using quotes around the string.\nYou can set it to an int (probably a float too, but haven't personally used it)\nYou can set it to a bool\nYou can set it to the output of a command. The command is inside the command: $(#command).\n\nNow let's use them:\necho $VAR1\n# some string\necho \"This is my variable $VAR1\"\n# This is my variable some string\necho \"This is my variable ${VAR1}\"\n# This is my variable some string\necho ${VAR1}\n# some string\necho \"Error code ${VAR2}A\"\n# Error code 23A\necho \"Error code $VAR2A\"\n# Error code --- Note: the variable $VAR2A dosn't exist\necho \"Error code ${VAR2}${VAR1}\"\n# Error code 23some string\necho VAR1\n# VAR1\necho \"VAR1\"\n# VAR1\n\nThis illustrates the difference between the different forms, but in general, you reference a variable's value with $+variable-name. Doing \"SOME_VAR\" or SOME_VAR just prints out the string \"SOME_VAR\" (ie, not referencing a variable at all).\nThe difference between $SOME_VAR and ${SOME_VAR} is that the latter lets you use it when there is other content directly before or after the variable without erroring."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab 'Gateway Timeout' behind traefik proxy\n\nSo I'm trying to set up a gitlab-ce instance on docker swarm using traefik as reverse proxy.\nThis is my proxy stack;\nversion: '3'\n\nservices:\n  traefik:\n    image: traefik:alpine\n    command: --entryPoints=\"Name:http Address::80 Redirect.EntryPoint:https\" --entryPoints=\"Name:https Address::443 TLS\" --defaultentrypoints=\"http,https\" --acme --acme.acmelogging=\"true\" --acme.email=\"[email\u00a0protected]\" --acme.entrypoint=\"https\" --acme.storage=\"acme.json\" --acme.onhostrule=\"true\" --docker --docker.swarmmode --docker.domain=\"mydomain.com\" --docker.watch --web\n    ports:\n      - 80:80\n      - 443:443\n      - 8080:8080\n    networks:\n      - traefik-net\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n    deploy:\n      placement:\n        constraints:\n          - node.role == manager\n\nnetworks:\n  traefik-net:\n    external: true\n\nAnd my gitlab stack\nversion: '3'\n\nservices:\n  omnibus:\n    image: 'gitlab/gitlab-ce:latest'\n    hostname: 'lab.mydomain.com'\n    environment:\n      GITLAB_OMNIBUS_CONFIG: |\n        external_url 'https://lab.mydomain.com'\n        nginx['listen_port'] = 80\n        nginx['listen_https'] = false\n        registry_external_url 'https://registry.mydomain.com'\n        registry_nginx['listen_port'] = 80\n        registry_nginx['listen_https'] = false\n        gitlab_rails['gitlab_shell_ssh_port'] = 2222\n        gitlab_rails['gitlab_email_from'] = '[email\u00a0protected]'\n        gitlab_rails['gitlab_email_reply_to'] = '[email\u00a0protected]'\n    ports:\n      - 2222:22\n    volumes:\n      - gitlab_config:/etc/gitlab\n      - gitlab_logs:/var/log/gitlab\n      - gitlab_data:/var/opt/gitlab\n    networks:\n      - traefik-net\n    deploy:\n      labels:\n        traefik.enable: \"port\"\n        traefik.frontend.rule: 'Host: lab.mydomain.com, Host: registry.mydomain.com'\n        traefik.port: 80\n      placement:\n        constraints:\n          - node.role == manager\n\n  runner:\n    image: 'gitlab/gitlab-runner:v1.11.4'\n    volumes:\n      - gitlab_runner_config:/etc/gitlab-runner\n      - /var/run/docker.sock:/var/run/docker.sock\n\nvolumes:\n  gitlab_config:\n  gitlab_logs:\n  gitlab_data:\n  gitlab_runner_config:\n\nnetworks:\n  traefik-net:\n    external: true\n\n\ntraefik-net is an overlay network\n\nSo when I deploy using docker stack deploy and visit lab.mydomain.com, i get the Gateway Timeout error. When I execute curl localhost within the gitlab container, it seems to work fine. Not sure what the problem is, any pointers would be appreciated"}, {"role": "assistant", "content": "Turns out all I had to do was set the traefik label, traefik.docker.network to traefik-net, see https://github.com/containous/traefik/issues/1254"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to backup/export Gitlab CI environment variables?\n\nWe have a continuously growing collection of Gitlab CI variables (around 40-50) in our current project. All these variables are used during our CI/CD pipeline and are crucial for our production environment.\nI want to generate backups in regular intervals in case someone messes with these variables.\nUnfortunately, I do not see any options to export the variables in Project -> Settings -> CI / CD -> Environment variables. All I can do is viewing / editing / deleting the variables. \nIs there maybe a hidden export function for these variables? We are self-hosting our Gitlab instance (GitLab Community Edition 11.8.1)."}, {"role": "assistant", "content": "You can use the API in order to query all variables. For example:\ncurl --header \"PRIVATE-TOKEN: <your_access_token>\" \"https://gitlab.example.com/api/v4/projects/1/variables/TEST_VARIABLE_1\"\n\nSee: https://docs.gitlab.com/ce/api/project_level_variables.html#show-variable-details"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What does the \"Next\" flag indicate on GitLab top bar?\n\nThis morning when I logged into GitLab I noticed this \"Next\" flag on the top bar: \n\nIt appears whether I am logged in or not. What does \"Next\" indicate? \nA Google search turns up nothing. It doesn't appear in any GitLab screen shots I am able to find either."}, {"role": "assistant", "content": "This is the canary version of Gitlab you are being served, you can find out more here: https://about.gitlab.com/handbook/engineering/#canary-testing\nYou can swap the version of Gitlab you see here: https://next.gitlab.com/?nav_source=navbar\nThe reasoning behind providing the Canary versions to users either at random or by those who have opt-ed in:\n\nGitLab makes use of a 'Canary' stage. Production Canary is a series of\n  servers running GitLab code in production environment. The Canary\n  stage contains code functional elements like web, container registry\n  and git servers while sharing data elements such as sidekiq, database,\n  and file storage with production. This allows UX code and most\n  application logic code to be consumed by smaller subset of users under\n  real world scenarios before being made available to all users on\n  GitLab.com."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab requires git@localhost password to push to a repo\n\nI'm trying to get GitLab up and running on my server. I followed the installation instructions at the gitlab github page and everything went well.\nThe issue is, when I create a repo and try to\nsudo git push -u origin master\n\nI am prompted for 'git@localhost's password: '\nThe git user doesn't have a password, so this is a problem.\nOther people who have run into this problem suggested adding git to AllowedUsers in my sshd conf but I don't have an AllowedUsers field in there, so that doesn't seem to be an issue.\nI'm still pretty new to ssh stuff so I believe its some sort of ssh key issue, though I tried to add all relevant ssh keys to /home/git/.ssh/authorized_keys and verified that there are no line breaks in the file.\nJust FYI, my install completely passes the test provided in the gitlab wiki:\nsudo -u gitlab bundle exec rake gitlab:app:status RAILS_ENV=production\n\nAny suggestions much appreciated!\nEDIT\nSo, I finally got around this by just committing to a repo from a different machine.  As it was, I was SSHed into the same machine that gitlab was running on.  As soon as I tried to commit from a machine other than the host, it worked great.  So, that may be a solution for some people (it is for us, since we develop on seperate machines than our servers).  \nThis is still an open-ended issue for anyone trying to host and develop on the same machine who has run into this."}, {"role": "assistant", "content": "TL;DR\nKeys store on both gitlab DB and gitolite side.\nYou should use the factory build gitolite-admin.git folder, don't use your backup!\nAnd rebuild the Keys for gitolite later with the update keys command.\n(update those keys already saved inside the gitlab db to gitolite)\nsudo -u gitlab -H bundle exec rake gitlab:gitolite:update_keys RAILS_ENV=production\n\n\nMost likely it's because there is something issue about the gitolite keys not save properly.\nThose keys (for login) are actually keep separately by gitlab & gitolite.\nFor pull/push is actually using the keys saved inside gitolite.\n(git/repositories/gitolite-admin.git/index, git/.gitolite/keydir, git/.ssh/authorized_keys)\ngitlab normally should help on saving those imported keys on web to the gitolite files.\nHowever, for some reasons it failed.\nAs the keys are not saved properly inside gitolite, the client/server fail to use the keys and fallback to password.\nYou have to check and fix those keys saved inside gitolite to correct the problems.\ncheck out for more\nhttps://groups.google.com/forum/?fromgroups=#!topic/gitlabhq/X0z_9l7L7A8"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Is there a program like GITLAB written in PHP? [closed]\n\nClosed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.\n                                \n                            \n\n\n\n\n\n\n\n\n\n\n\n Questions asking us to recommend or find a tool, library or favorite off-site resource are off-topic for Stack Overflow as they tend to attract opinionated answers and spam. Instead, describe the problem and what has been done so far to solve it.\n\n\nClosed 10 years ago.\n\n\n\n\n\n\n\n                        Improve this question\n                    \n\n\n\nI'm looking for a program to run on my company's intranet to help sort out projects. GitHub it out of the question because I'm not going to pay money for private repos, but I love the way GitHub looks. \nGITLAB is also nice and I would have chosen it except my servers are running PHP not Ruby. Is there a solution?"}, {"role": "assistant", "content": "There are some projects for PHP but all are not that actively developed compared to GitLab\n\ngitphp - http://gitphp.org/projects/gitphp/wiki ... kind-of dislike that the project's website is based on Redmine ... 18 contributors - only 1 seems to be active http://www.ohloh.net/p/gitphp/contributors\nmtrack - http://mtrack.wezfurlong.org/features.html ... 9 contributors - 2 active http://www.ohloh.net/p/mtrack/contributors\nRedmine-Php seems to be dead (homepage is down ... git-repo not updated since 1 year)\ntraq also seems interesting ... http://traq.io/\n\nAnd of course, many more I don't know of :)\nFeel free to search for similar projects on https://www.ohloh.net for trac, redmine, gitlab and other known systems.\nIn my opinion mtrack seems like the most promising as it provides functions like forking projects in the UI."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI cannot pull image from private docker registry\n\nI'd like to create a Docker based Gitlab CI runner which pulls the docker images for the build from a private Docker Registry (v2). I cannot make the Gitlab Runner to pull the image from a local Registry, it tries to GET something from a /v1 API. I get the following error message:\n\nERROR: Build failed: Error while pulling image: Get http://registry:5000/v1/repositories/maven/images: dial tcp: lookup registry on 127.0.1.1:53: no such host\n\nHere's a minimal example, using docker-compose and a web browser.\nI have the following docker-compose.yml file:\nversion: \"2\"\n\nservices:\n  gitlab:\n    image: gitlab/gitlab-ce\n    ports:\n      - \"22:22\"\n      - \"8080:80\"\n    links:\n      - registry:registry\n\n  gitlab_runner:\n    image: gitlab/gitlab-runner\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n    links:\n      - registry:registry\n      - gitlab:gitlab\n\n  registry:\n    image: registry:2\n\nAfter the first Gitlab login, I register the runner into the Gitlab instance:\nroot@130d08732613:/# gitlab-runner register\nRunning in system-mode.                            \n\nPlease enter the gitlab-ci coordinator URL (e.g. https://gitlab.com/ci):\nhttp://192.168.61.237:8080/ci         \nPlease enter the gitlab-ci token for this runner:\ntE_1RKnwkfj2HfHCcrZW\nPlease enter the gitlab-ci description for this runner:\n[130d08732613]: docker\nPlease enter the gitlab-ci tags for this runner (comma separated):\n\nRegistering runner... succeeded                     runner=tE_1RKnw\nPlease enter the executor: docker-ssh+machine, docker, docker-ssh, parallels, shell, ssh, virtualbox, docker+machine:\ndocker\nPlease enter the default Docker image (eg. ruby:2.1):\nmaven:latest\nRunner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded!\n\nAfter this, I see the Gitlab runner in my Gitlab instance:\n\nAfter this I push a simple maven image to my newly created Docker repository:\nvilmosnagy@vnagy-dell:~/$ docker tag maven:3-jdk-7 172.19.0.2:5000/maven:3-jdk7\nvilmosnagy@vnagy-dell:~/$ docker push 172.19.0.2:5000/maven:3-jdk7 \nThe push refers to a repository [172.19.0.2:5000/maven]\n79ab7e0adb89: Pushed \nf831784a6a81: Pushed \nb5fc1e09eaa7: Pushed \n446c0d4b63e5: Pushed \n338cb8e0e9ed: Pushed \nd1c800db26c7: Pushed \n42755cf4ee95: Pushed \n3-jdk7: digest: sha256:135e7324ccfc7a360c7641ae20719b068f257647231d037960ae5c4ead0c3771 size: 1794\n\n(I got the 172.19.0.2 IP-address from a docker inspect command's output)\nAfter this I create a test project in the Gitlab and add a simple .gitlab-ci.yml file:\nimage: registry:5000/maven:3-jdk-7\n\nstages:\n  - build\n  - test\n  - analyze\n\nmaven_build:\n  stage: build\n  script:\n    - \"mvn -version\"\n\nAnd after the build the Gitlab gives the error in seen in the beginning of the post.\nIf I enter into the running gitlab-runner container, I can access the registry under the given URL:\nvilmosnagy@vnagy-dell:~/$ docker exec -it comptest_gitlab_runner_1 bash\nroot@c0c5cebcc06f:/# curl http://registry:5000/v2/maven/tags/list\n{\"name\":\"maven\",\"tags\":[\"3-jdk7\"]}\nroot@c0c5cebcc06f:/# exit\nexit\nvilmosnagy@vnagy-dell:~/$\n\nBut the error still the same:\n\nDo you have any idea how to force the gitlab-runner to use the v2 api of the private registry?"}, {"role": "assistant", "content": "Current Gitlab and Gitlab Runners support this, see: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#use-a-private-container-registry\nOn older Gitlab I've solved this with copying an auth key into ~/.docker/config.json\n{\n        \"auths\": {\n                \"my.docker.registry.url\": {\n                        \"auth\": \"dmlsbW9zLm5hZ3k6VGZWNTM2WmhC\"\n                }\n        }\n}\n\nI've logged into this container from my computer and copied this auth key into the Gitlab Runner's docker container."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Deploy Code from GitLab Repository to Azure Web App using PowerShell\n\nI would like to setup continuous deployment from a GitLab repository to an Azure App using a PowerShell script. I'm aware that you can do this manually as per:\nhttps://christianliebel.com/2016/05/auto-deploying-to-azure-app-services-from-gitlab/\nHowever, I'm trying to automate this with Powershell. I've looked at this sample script for GitHub:\nhttps://learn.microsoft.com/en-us/azure/app-service/scripts/app-service-powershell-continuous-deployment-github\nBut as there is no provider for GitLab, and none of the existing providers accept a GitLab URL, I'm unsure of how to proceed. I've looked at setting up a manual deployment with GitLab in the Azure Portal (using the External Repository option) and exporting the resource group template to get details of how the repository is connected to the App, but I get the error:\nCould not get resources of the type 'Microsoft.Web/sites/sourcecontrols'. \nResources of this type will not be exported. (Code: ExportTemplateProviderError, Target: Microsoft.Web/sites/sourcecontrols)\n\nAt the minute, I'm working around this by mirroring my GitLab repository in GitHub, and using the continuous deployment pipeline from there to Azure. Note, this is for a repository hosted in GitLab.com, not in a self-hosted GitLab server. There is no Windows Runner setup for the project.\nHow can I use a PowerShell script to setup a Continuous Deployment directly from GitLab to Azure? Once the setup script is run, each subsequent commit/merge to the GitLab repository should then automatically be deployed to Azure. Preferably, this PowerShell script should use the AzureRM modules, but I'm willing to accept a solution that uses PowerShell Core and the new Az module (based on the Azure CLI). The specific test repository I'm using is public (https://gitlab.com/MagicAndi/geekscode.net), but it isn't a specific requirement for the solution to work with private repositories (but if it does, even better!).\nUpdate 17/12/2018\nI've awarded the bounty to the-fish as his answer best met my specific needs. However, given that Windows Powershell and the Azure RM module are being deprecated in favour of PowerShell Core and the new Az module (using the Azure CLI), I've created a new question asking specificially for a canonical answer using the Azure CLI and Powershell Core. I plan on offering a bounty for this question when it is open to me in 2 days. Thanks."}, {"role": "assistant", "content": "It sounds like you are looking for a direct deploy from GitLab to Azure Apps, however I'd suggest using a deployment pipeline tool to give you far more options.\nAzure DevOps Services Pipelines would likely be a safe option and has a free tier and here's a very brief getting started guide for Web Apps deploys.\nHowever it doesn't have built in support for GitLab, but there appears to be a marketplace tool for integrations with GitLab.\nThis doesn't appear to have the capability of release triggers, but could be triggered manually. Someone else has the question about release triggers in the marketplace Q&A so perhaps it will be in the roadmap."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI Failed: NPM command not found\n\nI have been playing around Gitlabl CI but for some reason I can't get my tests to \"passed\". It always says npm: command not found\nMy Gitlab CI config looks like this:\nimage: node:latest\n# This folder is cached between builds\n# http://docs.gitlab.com/ce/ci/yaml/README.html#cache\ncache:\n  paths:\n    - node_modules/\n\nbefore_script:\n  - npm install\n  - npm install eslint -g\n  - npm install eslint-plugin-react -g\n  - npm install babel-eslint -g\n\ntest:lint:\n  script:\n    - eslint src/*\n\nI keep getting the error below and I have No Idea why:\n\nBy the way, Im NOT using the gitlab shared runner. Not sure if that contributes to the problem but just to make sure, the machine that has my gitlab runner has all the necessary packages to run nodejs.\nYour help is greatly appreciated\nBest regards,"}, {"role": "assistant", "content": "The image tag specifies a docker image, hence you must specify the executor of your runner to be docker. Did you perhaps set it to be something else, like shell, when you created the runner?"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Search for a particular file in all the gitlab repositories\n\nSimple and very much needed feature, just would like to know if it's possible to search for a particular file in GITLAB  in all the repositories instead of a particular repository.  There's a  huge search icon on the right corner of the GITLAB  which will search corresponding maching repository names BUT NOT the files.\nI would like to search for a particular file through all the repositories which I have access to in GITLAB.\nPlease note that the GITLAB is hosted in the private domain of my organization.  So googling filename:something.txt   or  something.txt in:path   doesn't work (this was suggested by one of the user in some post for GITHUB)."}, {"role": "assistant", "content": "Yes it's possible using Advanced Search feature by enabling Elastic Search integration.\nOnce that is configured you can use Advanced Syntax Search with search filters to find what you need.\nFor example, you could search the .gitlab-ci.yml files of all projects for the text tags.yml inside of it typing this in global search bar:\ntags.yml filename:gitlab-ci\n\nAnother example to search abc.txt file in all repositories (ensure Group and Project dropdown menu are set to Any) :\n* filename:abc.txt"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Can't clone gitlab's repo via ssh, via http - OK\n\nI'm new to gitlab and CI so i had tons of questions but some of them solved via google, SO, git mans, but not the last ...\nI can't clone repo via ssh =(\nIf i try to clone repo via http:\nlesha@lesha-SeoTeam:/var/www$ git clone http://gitlab.vbox/root/virtualboxgitlab.git\nCloning into 'virtualboxgitlab'...\nUsername for 'http://gitlab.vbox': root\nPassword for 'http://[email\u00a0protected]':\nwarning: You appear to have cloned an empty repository.\n\nThat's OK!\nBut via ssh ...\nlesha@lesha-SeoTeam:/var/www$ git clone [email\u00a0protected]:root/virtualboxgitlab.git\nCloning into virtualbox 'gitlab'\n[email\u00a0protected]'s password:<br />   \n\nIt prompts me git's password which I didn't create during install (as I had in man)\nrsa keys\n\nI added my key via gitlab's web (to account root, actually I didn't create any other accounts)\nAnd also I added key by \"cat my_rsa.pub >> authorized_keys\"\nI read few posts here about ssh troubles, but most have gitolite installed\nI installed gitlab 5.3 without gitolite (as in manual), may be I should ?\nAlso I tried ssh -vT [email\u00a0protected] and it outputs :\n....\ndebug1: Server host key: ECDSA 48:83:ba:b3:37:72:a0:dc:ca:2c:a3:b8:78:a1:c4:ad\ndebug1: Host 'gitlab.vbox' is known and matches the ECDSA host key.\ndebug1: Found key in /home/lesha/.ssh/known_hosts:2\ndebug1: ssh_ecdsa_verify: signature correct\ndebug1: SSH2_MSG_NEWKEYS sent\ndebug1: expecting SSH2_MSG_NEWKEYS\ndebug1: SSH2_MSG_NEWKEYS received\ndebug1: Roaming not allowed by server\ndebug1: SSH2_MSG_SERVICE_REQUEST sent\ndebug1: SSH2_MSG_SERVICE_ACCEPT received\ndebug1: Authentications that can continue: publickey,password\ndebug1: Next authentication method: publickey\ndebug1: Offering RSA public key: /home/lesha/.ssh/id_rsa\ndebug1: Authentications that can continue: publickey,password\ndebug1: Trying private key: /home/lesha/.ssh/id_dsa\ndebug1: Trying private key: /home/lesha/.ssh/id_ecdsa\ndebug1: Next authentication method: password\n[email\u00a0protected]'s password:\n\n\nroot@seotm-server:/home/git/.ssh# ls -l\n\u0438\u0442\u043e\u0433\u043e 4\n-rw------- 1 git git 922 \u0418\u044e\u043b 18 21:05 authorized_keys\n\nenvironmetnt: \ndebian 7, nginx + passenger, gitlab 5.3, ruby 2.0.0p247 , without gitolite, puma against unicorn\nplease help!=) i'm stuck ...\n\nsome additions (20.07.2013):\nI created user git as in manual install\nsudo adduser --disabled-login --gecos 'GitLab' git\n\nThe next day, I tried to kill git and re-add simply by useradd command, after that my keys are working but i'm still not happy because:\nlesha@lesha-SeoTeam:/var/www$ git clone [email\u00a0protected]:root/virtualboxgitlab.git\nCloning into 'virtualboxgitlab'...\nfatal: 'root/virtualboxgitlab.git' does not appear to be a git repository\nfatal: The remote end hung up unexpectedly\n\nand http works as well as previous:\nlesha@lesha-SeoTeam:/var/www$ git clone http://gitlab.vbox/root/virtualboxgitlab.git\nCloning into 'virtualboxgitlab'...\nUsername for 'http://gitlab.vbox': root\nPassword for 'http://[email\u00a0protected]': \nwarning: You appear to have cloned an empty repository.\n\nSo, now I don't have auth problems but have another one.\nHow would you troubleshoot this issue from there?"}, {"role": "assistant", "content": "GitLab 5.x doesn't use gitolite anymore, but gitlab-shell.\nI would advise to create a dedicated account, as recommended in the installation process.  \nssh [email\u00a0protected]\n\nThat ssh commands means you are asking for a secure shell on 'gitlab.vbox' as user 'git'. If that user doesn't exist... it won't work.\nThere is no need to try and clone repo is the tests doesn't run properly:\nsudo -u git -H bundle exec rake gitlab:check RAILS_ENV=production\n\nThe OP reports ssh works better after creating the git user and adding the keys, but:\n\nfirst make sure you create your keys on a 'client' account', not in ~git/.ssh/id_rsa: you are trying to open a session as git, from a client account. git is the account in which gitlab is installed.\nYou should then register your public key in the ssh page of the user account you declare through the gitlab gui. You should not \"useradd\" an ssh to root.\n\nIf you see this:\nlesha@lesha-SeoTeam:/var/www$ git clone [email\u00a0protected]:root/virtualboxgitlab.git\nCloning into 'virtualboxgitlab'...\nfatal: 'root/virtualboxgitlab.git' does not appear to be a git repository\nfatal: The remote end hung up unexpectedly\n\nThat also means you shouldn't specify the path of the repo (root/):\n git clone [email\u00a0protected]:virtualboxgitlab.git\n\nIt is gitlab job to know where virtualboxgitlab.git is stored (as specified in its gitlab.yml config file)\nBasically, forget root, and do the full installation of gitlab as it was intended: in a 'git' account.\nThe OP made it work, commenting that:\n\n\"root\" is administrators namespace, gitlab creates this url automatically and without it clone doesn't work, now everything clones and I begin to install gitlab CI,\n\nThe OP had to:\n\nadd my user to sudo group, made clean install, received error \n\n/usr/local/lib/ruby/2.0.0/net/http.rb:878:in initialize': getaddrinfo: \n  Name or service not known (SocketError)\n\nwhich can't resolve hostname, added gitlab.vbox to /etc/hosts"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab: how can I disable email notifications for new commits pushed to merge requests?\n\nIn Gitlab my notification settings are set to \"participate\". I am getting tons of emails from Gitlab.\nI would like to receive emails regarding new comments on merge requests that I'm participating in. But I would not like to receive an email for every time somebody pushes a commit to an MR that is assigned to me. That results in a huge amount of emails that I simply ignore.\nI also wouldn't mind getting an email notification for a commit pushed on a merge request opened by me, but that's just a nice to have.\nLooking in the Gitlab notification settings I haven't found a setting to support this. \"Custom\" settings are simply an extension of \"particiapte\", which means I still get an email for every little thing that happens on an MR I'm participating in (i.e., every commit). Any ideas?"}, {"role": "assistant", "content": "Gitlab -> Preferences -> Notifications\nThis list shows all custom notifications in Gitlab\n\nBut if you force others to mention you in comments, you can use this notification feature:"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How can I override the title of a GitLab wiki page?\n\nI'm am editing pages in a GitLab project wiki.\nIf I name a page \"first-last\", the URL is \"project/wikis/first-last\" and the page title is rendered in sentence case as \"First last\". If I name a page \"first-(last)\", the URL is \"project/wikis/first-(last)\" and the page title is rendered in sentence case as \"First (last)\".\nI want the URL to be \"project/wikis/first-last\" and the page title to be \"First (last)\". Thus, I want to override the page title.\nMy understanding is that GitLab project wikis run on Gollum. According to the Gollum docs page titles can be overridden with one of two methods:\n\nEnable --h1-title. The first H1-level title on the page will override the page title.\nUse the metadata directive. If the first line of the page is <!-- --- title: My page title -->, the given value will override the page title.\n\nI don't have access to option 1. I tried option 2 and nothing happened.\nHow can I override the title of a GitLab wiki page?"}, {"role": "assistant", "content": "From what I can find, there might not be a way to do it. I haven't tried using that Gollum flag, yet.\nThe GitLab documentation has this section:\n\nNotes on Gollum\nWe only use Gollum as a storage abstraction layer, to handle the mapping between wiki page slugs and files in the repository.\nWhen rendering wiki pages, we don\u2019t use Gollum at all and instead go through a custom Banzai pipeline. This adds some wiki-specific markup, such as Gollum\u2019s [[link]] syntax.\nBecause we do not make use of most of Gollum\u2019s features, we plan to move away from it entirely at some point. See this epic for reference."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "libxslt is missing while installing ruby gem nokogiri\n\nI recognize that this is a duplicate question however all the other answers I've found related to this issue have not seemed to help me...\nI'm installing GitLab and running through the gem dependencies when it hits the NokoGiri gem requirement and fails with the following info:\nERROR:  Error installing nokogiri:\nERROR: Failed to build gem native extension.\n\n/usr/local/bin/ruby extconf.rb\nextconf.rb:10:in `<main>': Use RbConfig instead of obsolete and deprecated Config.\nextconf.rb:10:in `<main>': Use RbConfig instead of obsolete and deprecated Config. \nextconf.rb:11:in `<main>': Use RbConfig instead of obsolete and deprecated Config.\nchecking for libxml/parser.h... yes\nchecking for libxslt/xslt.h... yes\nchecking for libexslt/exslt.h... yes\nchecking for iconv_open() in iconv.h... yes\nchecking for xmlParseDoc()... -lxml2\nchecking for xsltParseStylesheetDoc()... -lxslt\n-----\nlibxslt is missing.  please visit http://nokogiri.org/tutorials/installing_nokogiri.html for help with installing dependencies.\n-----\n\nSo, this error leads me down the path of attempting to install libxslt with the following command:\n$ sudo apt-get install libxslt-dev\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nNote, selecting 'libxslt1-dev' instead of 'libxslt-dev'\nlibxslt1-dev is already the newest version.\n0 upgraded, 0 newly installed, 0 to remove and 146 not upgraded.\n\nSo what gives?  NokoGiri is needing this package, but the package is already installed!! I can't seem to get past this issue, any help out there?"}, {"role": "assistant", "content": "first make sure you have all the dependencies, as mentioned in \"Installing Nokogiri with RVM on Ubuntu\" (which mentions the very same error message)\n\nI have no idea why it can't find the package \"libxslt\". Instead of worrying about that, I'm going to install the dependencies listed on Nokogiri GitHub page: \n\n$ sudo apt-get install libxslt-dev libxml2-dev\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nNote, selecting 'libxslt1-dev' instead of 'libxslt-dev'\nlibxslt1-dev is already the newest version.\nlibxml2-dev is already the newest version.\n\n\nThat appears to have worked well enough, so I press on. The next step is install the actual Nokogiri gem. The instructions say to use \"sudo gem install nokogiri\", but because I'm using RVM, I drop the \"sudo\" part: \n\n$ gem install nokogiri\n\n\nConsidering \"Fresh install of RVM in Ubuntu isn't letting me install gems (zlib error)\", since you have libxslt1-dev (and not libxslt-dev), you might considering recompiling your ruby.\n(a bit like in \"How to get Readline support in IRB using RVM on Ubuntu 11.10\")"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "MySQL2 gem won't install\n\nI have been trying to install Gitlab on my Ubuntu 12.04 server for a long time, and all goes well until I run bundle install.\nIt says it is unable to install MySQL2 but gives no reason or corrective action.\nhome/gitlab/gitlab$ sudo -u gitlab -H bundle install --deployment --without development test postgres\nFetching gem metadata from http://rubygems.org/.......\nFetching gem metadata from http://rubygems.org/..\nUsing rake (10.0.1) \nUsing i18n (0.6.1) \nUsing multi_json (1.3.7) \nUsing activesupport (3.2.9) \nUsing builder (3.0.4) \nUsing activemodel (3.2.9) \nUsing erubis (2.7.0) \nUsing journey (1.0.4) \nUsing rack (1.4.1) \nUsing rack-cache (1.2) \nUsing rack-test (0.6.2) \nUsing hike (1.2.1) \nUsing tilt (1.3.3) \nUsing sprockets (2.2.1) \nUsing actionpack (3.2.9) \nUsing mime-types (1.19) \nUsing polyglot (0.3.3) \nUsing treetop (1.4.12) \nUsing mail (2.4.4) \nUsing actionmailer (3.2.9) \nUsing arel (3.0.2) \nUsing tzinfo (0.3.35) \nUsing activerecord (3.2.9) \nUsing activeresource (3.2.9) \nUsing bundler (1.2.3) \nUsing rack-ssl (1.3.2) \nUsing json (1.7.5) \nUsing rdoc (3.12) \nUsing thor (0.16.0) \nUsing railties (3.2.9) \nUsing rails (3.2.9) \nUsing acts-as-taggable-on (2.3.3) \nUsing backports (2.6.5) \nUsing bcrypt-ruby (3.0.1) \nUsing blankslate (3.1.2) \nUsing sass (3.2.3) \nUsing bootstrap-sass (2.2.1.1) \nUsing carrierwave (0.7.1) \nUsing charlock_holmes (0.6.9) \nUsing chosen-rails (0.9.8) \nUsing coffee-script-source (1.4.0) \nUsing execjs (1.4.0) \nUsing coffee-script (2.2.0) \nUsing coffee-rails (3.2.2) \nUsing colored (1.2) \nUsing daemons (1.1.9) \nUsing orm_adapter (0.4.0) \nUsing warden (1.2.1) \nUsing devise (2.1.2) \nUsing diff-lcs (1.1.3) \nUsing draper (0.18.0) \nUsing escape_utils (0.2.4) \nUsing eventmachine (1.0.0) \nUsing multipart-post (1.1.5) \nUsing faraday (0.8.4) \nUsing ffaker (1.15.0) \nUsing sass-rails (3.2.5) \nUsing font-awesome-sass-rails (2.0.0.0) \nUsing foreman (0.60.2) \nUsing gemoji (1.2.1) \nUsing git (1.2.5) \nUsing posix-spawn (0.3.6) \nUsing yajl-ruby (1.1.0) \nUsing pygments.rb (0.3.2) from https://github.com/gitlabhq/pygments.rb.git (at master) \nUsing github-linguist (2.3.4) \nUsing github-markup (0.7.4) \nUsing gitlab_meta (4.0) \nUsing gratr19 (0.4.4.1) \nUsing grit (2.5.0) from https://github.com/gitlabhq/grit.git (at 7f35cb9) \nUsing hashery (1.5.0) \nUsing gitolite (1.1.0) \nUsing grack (1.0.0) from https://github.com/gitlabhq/grack.git (at ba46f3b) \nUsing hashie (1.2.0) \nUsing multi_xml (0.5.1) \nUsing rack-accept (0.4.5) \nUsing rack-mount (0.8.3) \nUsing virtus (0.5.2) \nUsing grape (0.2.2) \nUsing grit_ext (0.6.1) from https://github.com/gitlabhq/grit_ext.git (at 8e6afc2) \nUsing haml (3.1.7) \nUsing haml-rails (0.3.5) \nUsing httparty (0.9.0) \nUsing httpauth (0.2.0) \nUsing jquery-atwho-rails (0.1.7) \nUsing jquery-rails (2.1.3) \nUsing jquery-ui-rails (2.0.2) \nUsing jwt (0.1.5) \nUsing kaminari (0.14.1) \nUsing kgio (2.7.4) \nUsing libv8 (3.3.10.4) \nUsing modernizr (2.6.2) \nInstalling mysql2 (0.3.11) with native extensions \nGem::Installer::ExtensionBuildError: ERROR: Failed to build gem native extension.\n\n        /usr/local/bin/ruby extconf.rb \nchecking for rb_thread_blocking_region()... yes\nchecking for rb_wait_for_single_fd()... yes\nchecking for mysql_query() in -lmysqlclient... no\nchecking for main() in -lm... yes\nchecking for mysql_query() in -lmysqlclient... no\nchecking for main() in -lz... yes\nchecking for mysql_query() in -lmysqlclient... no\nchecking for main() in -lsocket... no\nchecking for mysql_query() in -lmysqlclient... no\nchecking for main() in -lnsl... yes\nchecking for mysql_query() in -lmysqlclient... no\nchecking for main() in -lmygcc... no\nchecking for mysql_query() in -lmysqlclient... no\n*** extconf.rb failed ***\nCould not create Makefile due to some reason, probably lack of\nnecessary libraries and/or headers.  Check the mkmf.log file for more\ndetails.  You may need configuration options.\n\nProvided configuration options:\n    --with-opt-dir\n    --without-opt-dir\n    --with-opt-include\n    --without-opt-include=${opt-dir}/include\n    --with-opt-lib\n    --without-opt-lib=${opt-dir}/lib\n    --with-make-prog\n    --without-make-prog\n    --srcdir=.\n    --curdir\n    --ruby=/usr/local/bin/ruby\n    --with-mysql-config\n    --without-mysql-config\n    --with-mysql-dir\n    --without-mysql-dir\n    --with-mysql-include\n    --without-mysql-include=${mysql-dir}/include\n    --with-mysql-lib\n    --without-mysql-lib=${mysql-dir}/lib\n    --with-mysqlclientlib\n    --without-mysqlclientlib\n    --with-mlib\n    --without-mlib\n    --with-mysqlclientlib\n    --without-mysqlclientlib\n    --with-zlib\n    --without-zlib\n    --with-mysqlclientlib\n    --without-mysqlclientlib\n    --with-socketlib\n    --without-socketlib\n    --with-mysqlclientlib\n    --without-mysqlclientlib\n    --with-nsllib\n    --without-nsllib\n    --with-mysqlclientlib\n    --without-mysqlclientlib\n    --with-mygcclib\n    --without-mygcclib\n    --with-mysqlclientlib\n    --without-mysqlclientlib\n\n\nGem files will remain installed in /home/gitlab/gitlab/vendor/bundle/ruby/1.9.1/gems/mysql2-0.3.11 for inspection.\nResults logged to /home/gitlab/gitlab/vendor/bundle/ruby/1.9.1/gems/mysql2-0.3.11/ext/mysql2/gem_make.out\nAn error occurred while installing mysql2 (0.3.11), and Bundler cannot continue.\nMake sure that `gem install mysql2 -v '0.3.11'` succeeds before bundling.\nroot@Server:/home/gitlab/gitlab$"}, {"role": "assistant", "content": "It does tell you a generic possible problem:\n\nCould not create Makefile due to some reason, probably lack of\n  necessary libraries and/or headers.  Check the mkmf.log file for more\n  details.  You may need configuration options.\n\nThat's your clue.\nMake sure you've installed the MySQL client repo, along with the associated \"devel\" package. Languages like Ruby, Python, Perl, etc., need the libraries and headers installed so they can compile native modules providing the interface from the language to the drivers.\nAlso, you'll need mysql_config, which is installed by:\nsudo apt-get install libmysqlclient-dev\n\nI was able to duplicate your problem with my Ubuntu VM, and fix it after installing libmysqlclient-dev.\nIt places mysql_config in /usr/bin/mysql_config, and both gem install mysql and gem install mysql2 were able to install successfully."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab-ci docker-in-docker access to insecure registry\n\nWhen configuring a gitlab-ci for building docker images and pushing them to my gitlab's insecure registry, I encountered several errors.  My gitlab-ci.yaml is laid out below:\nstages:\n  - build\n  - deploy\n\nvariables:\n  GIT_SUBMODULE_STRATEGY: recursive\n  CONTAINER_IMAGE: XXX:$CI_COMMIT_REF_NAME\n\n# The insecure-registry flag \nservices:\n  - docker:dind\n\nbuild_container:\n  image: docker:latest\n  stage: build\n  before_script:\n    - echo \"$CI_REGISTRY_PASSWORD\" | docker login -u \"$CI_REGISTRY_USER\" \"$CI_REGISTRY\" --password-stdin\n\n  script:\n    - docker build --pull -t $CONTAINER_IMAGE .\n    - docker push $CONTAINER_IMAGE\n\nThe first error was:\n  $ docker login -u gitlab-ci-token -p $CI_JOB_TOKEN myregistry.gitlab.com\n  WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n  Warning: failed to get default registry endpoint from daemon (Cannot connect \n  to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon \n  running?). Using system default: https://index.docker.io/v1/\n  Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the \n  docker daemon running?\n\nThis was resolved by updating the login command to \necho \"$CI_REGISTRY_PASSWORD\" | docker login -u \"$CI_REGISTRY_USER\" myregistry.gitlab.com --password-stdin\n\nUnfortunately after updating, I encountered another error:\n$ echo \"$CI_REGISTRY_PASSWORD\" | docker login -u \"$CI_REGISTRY_USER\" myregistry.gitlab.com --password-stdin\nError response from daemon: Get https://myregistry.gitlab.com/v2/: dial tcp XX.XX.XXX.XXX:443: getsockopt: connection refused\n\nHow Can I resolve this?"}, {"role": "assistant", "content": "Like any other docker installation, it is necessary to instruct the docker daemon to allow connections to insecure registries.  In order to do this in the context of the docker-in-docker service, one must pass this configuration to the service.  This can be done by updating your gitlab-ci.yaml to specify the service as:\nservices:\n  - name: docker:dind\n    command: [\"--insecure-registry=myregistry.gitlab.com\"]"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "direct access to to gitlab database\n\nI am running the AWS AMI from gitlab. I am trying to access the postgres database directly using psql. I thought I could just use the credentials in database.yml, since the rails application is working fine:\n/opt/gitlab/embedded/bin/psql -U gitlab -d gitlabhq_production\n\nBut I get:\npsql: FATAL:  Peer authentication failed for user \"gitlab\"\n\nHow can the rails app be connecting to the database while psql cannot?"}, {"role": "assistant", "content": "sudo -u gitlab-psql /opt/gitlab/embedded/bin/psql -h /var/opt/gitlab/postgresql/ gitlabhq_production"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI runner job failed exit status 1 when changing directory\n\nI am using my personal machine as a runner for an iOS project using Fastlane. This is mainly due to the fact that shared runners aren't setup for iOS as they don't have Xcode installed.\nMy jobs fail immediately when changing directory.\nIt's a shell runner, no other custom config at all.\nAny suggestions?\n\nThis is the output when running gitlab-runner --debug run and starting a job.\nChecking for jobs... received                       job=59131527 repo_url=https://gitlab.com/nickfarrant/aqualog-asset-collection.git runner=159b2b59\nFailed to requeue the runner:                       builds=1 runner=159b2b59\nRunning with gitlab-ci-multi-runner 9.0.2 (fa8b86d)\n  on Nicks-Bink-iMac (159b2b59)  job=59131527 project=5134442 runner=159b2b59\nShell configuration: environment: []\ndockercommand:\n- sh\n- -c\n- \"if [ -x /usr/local/bin/bash ]; then\\n\\texec /usr/local/bin/bash --login\\nelif [\n  -x /usr/bin/bash ]; then\\n\\texec /usr/bin/bash --login\\nelif [ -x /bin/bash ]; then\\n\\texec\n  /bin/bash --login\\nelif [ -x /usr/local/bin/sh ]; then\\n\\texec /usr/local/bin/sh\n  --login\\nelif [ -x /usr/bin/sh ]; then\\n\\texec /usr/bin/sh --login\\nelif [ -x /bin/sh\n  ]; then\\n\\texec /bin/sh --login\\nelse\\n\\techo shell not found\\n\\texit 1\\nfi\\n\\n\"\ncommand: bash\narguments:\n- --login\npassfile: false\nextension: \"\"\n  job=59131527 project=5134442 runner=159b2b59\nUsing Shell executor...                             job=59131527 project=5134442 runner=159b2b59\nWaiting for signals...                              job=59131527 project=5134442 runner=159b2b59\nWARNING: Job failed: exit status 1                  job=59131527 project=5134442 runner=159b2b59"}, {"role": "assistant", "content": "I hit the same situation, and I solve it.\nI guess you used rvm.\nPlease follow below:\n\nOpen terminal\necho 'unset cd'>>~/.bash_profile; source ~/.bash_profile\nretry pipeline.\n\nRefer to: https://juejin.im/post/5a65977bf265da3e4e25bfb8"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI scheduled pipeline not running on default branch\n\nI have a scheduled pipeline that copies some data from one server to another once a day.\nThe pipeline works fine on all branches but doesn't start if I select master branch (default branch) as the target branch.\nI have tried on an exact copy of master and it worked fine.\nI though it could be because master is protected but I tried on a protected copy of master and it worked.\nI'm really not sure what's going on. When I click the \"play\" button next to the scheduled pipeline and it says that the job was successfully scheduled, but I cannot see any job in the job list.\nHere some details on the .gitlab-ci.yml\nstages:\n  - copy_data\n  - linting\n  - test\n  - deploy\n\n\nlint:\n  needs: []\n  stage: linting\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"schedule\"\n      when: never\n    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH || $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == $CI_DEFAULT_BRANCH'\n      changes:\n        - \"my_project/**/*.py\"\n  script:\n    - ...\n\ntest:\n  stage: test\n  script:\n    - ...\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"schedule\"\n      when: never\n    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH || $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == $CI_DEFAULT_BRANCH'\n\ncopy_database:on-schedule:\n  stage: copy_data\n  needs: []\n  only:\n    - schedules\n    - $COPY_DB # this is set in the pipeline menu on gitlab\n  script:\n    - ...\n  timeout: 3h"}, {"role": "assistant", "content": "I finally figured out the problem! The issue is that gitlab was saying Successfully scheduled a pipeline to run. Go to the Pipelines page for details. while in reality there was an error.\nTo debug it I used the trick described here that is to run a manual pipeline and set CI_PIPELINE_SOURCE = \"schedule\". Running the pipeline in this way returned the error message and I was able to fix the issue.\n\nIf you are wondering what the error was, here is some more detail.\nI had two pipelines optionally running on the master branch:\nprepare_release:\n  stage: prepare_release\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"schedule\"\n      when: never\n    - if: $CI_COMMIT_TAG\n      when: never\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n      when: manual\n  script:\n    - ...\n\ncreate_release:\n  image: registry.gitlab.com/gitlab-org/release-cli:latest\n  stage: release\n  needs:\n    - job: prepare_release\n      artifacts: true\n  rules:\n     // HERE THERE SHOULD BE A RULE TO PREVENT THIS FROM RUNNING ON SCHEDULE\n       // - if: $CI_PIPELINE_SOURCE == \"schedule\"\n    //  when: never\n    - if: $CI_COMMIT_TAG\n      when: never\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n  script:\n    - ...\n\nThe second pipeline did not have a\n    - if: $CI_PIPELINE_SOURCE == \"schedule\"\n      when: never\n\nAnd therefore tried running on the schedule. However since it needs the previous one and that wasn\u2019t created, it errors.\nMi mistake was to assume that the \"needs\" would take into account this rule from the parent job."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Git on the server(windows server 2012) [closed]\n\nClosed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.\n                                \n                            \n\n\n\n\n\n\n\n\n\n\n\n Questions asking us to recommend or find a book, tool, software library, tutorial or other off-site resource are off-topic for Stack Overflow as they tend to attract opinionated answers and spam. Instead, describe the problem and what has been done so far to solve it.\n\n\nClosed 9 years ago.\n\n\n\n\n\n\n\n                        Improve this question\n                    \n\n\n\nWe want to install Git in our dedicated server to mange our code version and code revision. Our dedicated server has Windows server 2012. We thought about GitLab, but it is not supported in windows. Suggest me which one should I use, there is Gitprep for windows."}, {"role": "assistant", "content": "You could use Bonobo Git Server, it is designed to run on Windows in IIS."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab issue while running helm command as - Error: unknown command \"sh\" for \"helm\"\n\nI have a packge script which needs to run on alpina:helm image . I have used this before but for some reason this is always giving me error as - Error: unknown command \"sh\" for \"helm\"\npackage:\n  <<: *artifacts\n  stage: package\n  image: alpine/helm\n  variables:\n    GIT_STRATEGY: none\n  script:\n    - echo $VERSION\n    - helm package ./keycloak --app-version=$VERSION\n  artifacts:\n    paths: \n    - \"*.tgz\"\n\nCan anybody tell me what is the issue here I am not very sure . Helm command should be running as per my assumption but not sure why isnt it ."}, {"role": "assistant", "content": "As explained in the docs, the runner in gitlab is started this way\n\nthe runner starts the docker container specified in image and uses the entrypoint of this container\nthe runner attaches itself to the container\nthe runner combines before_script, script and after_script into a single script\nthe runner sends the combined script to the container's shell\n\nIf you take a look at the entrypoint of the alpine/helm image, you see that the entrypoint is helm and when the container starts it runs helm. The gitlab runner expects no entrypoint or that the entrypoint is set to start a shell so you get the Error: unknown command \"sh\" for \"helm\" as there is no running shell.\nWith overriding the entrypoint we make sure the runner finds a shell in the container which can execute the script.\npackage:\n  stage: package\n  image: \n    name: alpine/helm\n    entrypoint: [\"\"] \n  variables:\n    GIT_STRATEGY: none\n  script:\n    - echo $VERSION\n    - helm package ./keycloak --app-version=$VERSION\n  artifacts:\n    paths: \n    - \"*.tgz\"\n\nEDIT:\nBy reading the docs again I changed the entrypoint to an empty entrypoint for docker 17.06 and later (entrypoint: [\"\"]) as this is more concise."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "git push was rejected due to missing or corrupt local objects git-lfs\n\nI am new to git-lfs, Following are the steps I configured and tried to push git-lfs\ngit clone [email\u00a0protected]:group/project.git\ncopied a tar.gz lfs file from different repo to my current repo, then\ngit lfs install                      \ngit lfs track \"*.tar.gz\"\ngit add .gitattributes\ngit commit -m \"message\"\n\n\nwhile git push origin master:\nError I am facing:\n(missing) code.tar.gz (f2b4bf22bcb011fef16f80532247665d15edbb9051***)\nUploading LFS objects:   0% (0/1), 0 B | 0 B/s, done.\nhint: Your push was rejected due to missing or corrupt local objects.\nhint: You can disable this check with: 'git config lfs.allowincompletepush true'\nerror: failed to push some refs to '[email\u00a0protected]:group/project.git'\n\nFor your reference: when I run ls .git/lfs/objects/f2/b4 I'm not able to find anything inside.\nbut for other tar files if I run ls .git/lfs/objects/g3/8a i am able to see c5a9a2e024875718b6377bb15a42fac872a3**** value"}, {"role": "assistant", "content": "I solved it by downloading the lfs objects referenced from that specific branch:\ngit lfs fetch --all <remote-name> <branch-name>\n\nit will populate the missing files .git/lfs/objects folder"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GItlab: has there any way we can select the variable values as drop down menu\n\nIn Gitlab ci We have declared our variables like below\n USER_NAME:\n    value: \"\"  \n    description: \"Enter Username\"\n  File_Name:\n    description: \"Enter the file name\"\n\nIt only give a text box where We can enter the value.\nCan I make a drop down select box is there any option available to make it a select box.Then we can select the value from drop down."}, {"role": "assistant", "content": "GitLab 15.7 (December 2022) has finally implemented this:\n\nSelect predefined CI/CD variables values from a dropdown list\nPreviously, you could pre-fill CI/CD variables in the \u201cRun pipeline\u201d page, with a specific value.\nUnfortunately, if you had multiple options for the variable\u2019s value, you still had to manually input the option you wanted. This was an error-prone process because you could easily input an invalid value, or just mistype it.\nIn this release, we\u2019ve added the ability to set a list of values which are surfaced in a drop-down list in the \u201cRun pipeline\u201d page.\nNow you can define the exact list of values that are valid for each CI/CD variable when running a pipeline manually, greatly simplifying your workflow when using manually-triggered pipelines.\n\nSee Documentation and Issue."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab-CI rules If/Changes do not work as expected\n\nWe are working with GitLab CI and a strange behaviour just happened. We are trying to only run a given job (e.g, lint here below) if *.py files are changed and we are in a merge request, not a simple git branch. If, for example, I am going to push a change on the Readme.MD, the pipeline's job Lint here will be executed where it should have not.\n.gitlab-ci.yml configuration:\nimage: python:3.7\n\nstages:\n  - pre-build\n  - test\n\n.ci_rules:\n  rules:\n    - if: '$CI_PIPELINE_SOURCE == \"merge_request_event\" && $CI_MERGE_REQUEST_IID'\n      changes:\n        - tests/*.py\n        - tests/*/*.py\n        - src/*.py\n        - src/*/*.py\n    - if: $CI_COMMIT_REF_NAME == \"develop\"\n    - if: $CI_COMMIT_REF_NAME == \"main\"\n\nlint:\n  stage: pre-build\n  script:\n    - pip install flake8\n    - flake8\n  rules:\n    - !reference [ .ci_rules, rules ]\n\n# [... other jobs not relevant for the issue]"}, {"role": "assistant", "content": "The problem is in your job rules. Below are your numbered rules for better orientation:\n1. $CI_PIPELINE_SOURCE == \"merge_request_event\" && $CI_MERGE_REQUEST_IID && changes\n2. $CI_COMMIT_REF_NAME == \"develop\"\n3. $CI_COMMIT_REF_NAME == \"main\"\n\nLet's consider some examples, variables values and job evaluation result with your rules. Remember if you don't use when keyword in your rule definifon then the job evaluation needs only one rule from the rules set to trigger a job.\n\nCreate MR develop -> main with file change\n\n1. rule \u2705\n2. rule \u2705\n3. rule \u274c\n---\njob evaluation = \u2705 \n\n\nCreate MR develop -> main without file change\n\n1. rule \u274c\n2. rule \u2705\n3. rule \u274c\n---\njob evaluation = \u2705 \n\n\nCreate MR test1 -> main without file change\n\n1. rule \u274c\n2. rule \u274c\n3. rule \u274c\n---\njob evaluation = \u274c\n\n\nPush to the develop branch\n\n1. rule \u274c\n2. rule \u2705\n3. rule \u274c\n---\njob evaluation = \u2705 \n\n\nPush to the main branch\n\n1. rule \u274c\n2. rule \u274c\n3. rule \u2705\n---\njob evaluation = \u2705 \n\nDo you see it already? \ud83d\ude42  I think your problem is that you have rules 2. and 3. mixed with rule 1. Therefore if you create MR without file changes, but your source branch is  develop, the job rule is evaluated as true (second example). I will suggest to have rule 1. in separated job (or template). Or use rules with when keyword and control it manually for example."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GKE Cluster can't pull (ErrImagePull) from GCR Registry in same project (GitLab Kubernetes Integration): Why?\n\nSo after googling a little bit (which is polluted by people having trouble with Pull Secrets) I am posting this here \u2014\u00a0and to GCP Support (will update as I hear).\nI created a Cluster from GitLab Kubernetes integration (docs: https://about.gitlab.com/solutions/kubernetes) within the same project as my GCR registry / images.  \nWhen I add a new service / deployment to this Cluster using Kubectl (which relies on a private image within the GCR Registry in this project) the pods in the GitLab created cluster fail to pull from GCR with: ErrImagePull.\nTo be clear \u2014 I am NOT pulling from a GitLab private registry, I am attempting to pull from a GCR Registry within the same project as the GKE cluster created from GitLab (which should not require a Pull Secret).\nOther Clusters (created from GCP console) within this project can properly access the same image so my thinking is that there is some difference between Clusters created via an API (in this case from GitLab) vs Clusters created from the GCP console.\nI am hoping someone has run into this in the past \u2014 or can explain the differences in the Service Accounts etc that could be causing the problem.  \n\nI am going to attempt to create a service account and manually grant it Project Viewer role to see if that solves the problem.\n\nUpdate: manually configured Service Account did not solve issue.\nNote: I am trying to pull an image into the Cluster NOT into a GitLab Runner that is running on the Cluster.  Ie. I want a separate Service / Deployment to be running along side my GitLab infrastructure."}, {"role": "assistant", "content": "TL;DR \u2014 Clusters created by GitLab-Ci Kubernetes Integration will not be able to pull an image from a GCR Registry in the same project as the container images \u2014 without modifying the Node(s) permissions (scopes).\n\nWhile you CAN manually modify the permissions on an Individual Node machine(s) to grant the Application Default Credentials (see: https://developers.google.com/identity/protocols/application-default-credentials) the proper scopes in real time \u2014\u00a0doing it this way would mean that if your node is re-created at some point in the future it WOULD NOT have your modified scopes and things would break.\n\nInstead of modifying the permissions manually \u2014 create a new Node pool that has the proper Scope(s) to access your required GCP services.\nHere are some resources I used for reference:\n\nhttps://medium.com/google-cloud/updating-google-container-engine-vm-scopes-with-zero-downtime-50bff87e5f80\nhttps://adilsoncarvalho.com/changing-a-running-kubernetes-cluster-permissions-a-k-a-scopes-3e90a3b95636\n\nCreating a properly Scoped Node Pool Generally looks like this\ngcloud container node-pools create [new pool name] \\\n --cluster [cluster name] \\\n --machine-type [your desired machine type] \\\n --num-nodes [same-number-nodes] \\\n --scopes [your new set of scopes]\n\nIf you aren't sure what the names of your required Scopes are \u2014\u00a0You can see a full list of Scopes AND Scope Aliases over here: https://cloud.google.com/sdk/gcloud/reference/container/node-pools/create\nFor me I did  gke-default (same as my other cluster)  and sql-admin.  The reason for this being that I need to be able to access an SQL Database in Cloud SQL during part of my build and I don't want to have to connect to a pubic IP to do that.\ngke-default Scopes (for reference)\n\nhttps://www.googleapis.com/auth/devstorage.read_only (allows you to pull)\nhttps://www.googleapis.com/auth/logging.write\nhttps://www.googleapis.com/auth/monitoring\nhttps://www.googleapis.com/auth/service.management.readonly\nhttps://www.googleapis.com/auth/servicecontrol\nhttps://www.googleapis.com/auth/trace.append\n\nContrast the above with more locked down permissions from a GitLab-Ci created cluster ( ONLY these two: https://www.googleapis.com/auth/logging.write, https://www.googleapis.com/auth/monitoring):\nObviosuly configuring your cluster to ONLY the minimum permissions needed is for sure the way to go here.  Once you figure out what that is and create your new properly scoped Node Pool...\nList your nodes with:\nkubectl get nodes\n\nThe one you just created (most recent) is has the new settings while the older option is the default gitlab cluster that can pull from the GCR.\nThen: \nkubectl cordon [your-node-name-here]\n\nAfter that you want to drain:\nkubectl drain [your-node-name-here] --force\n\nI ran into issues where the fact that I had a GitLab Runner installed meant that I couldn't drain the pods normally due to the local data / daemon set that was used to control it.   \nFor that reason once I cordon'd my Node I just deleted the node from Kubectl (not sure if this will cause problems \u2014\u00a0but it was fine for me).  Once your node is deleted you need to delete the 'default-pool' node pool created by GitLab.\nList your node-pools:\ngcloud container node-pools list --cluster [CLUSTER_NAME]\n\nSee the old scopes created by gitlab:\ngcloud container node-pools describe default-pool \\\n    --cluster [CLUSTER_NAME]\n\nCheck to see if you have the correct new scopes (that you just added):\ngcloud container node-pools describe [NEW_POOL_NAME] \\\n    --cluster [CLUSTER_NAME]\n\nIf your new Node Pool has the right scopes your deployments can now delete the default pool with:\ngcloud container node-pools delete default-pool \\\n   --cluster <YOUR_CLUSTER_NAME> --zone <YOUR_ZONE>\n\nIn my personal case I am still trying to figure out how to allow access to the private network (ie. get to Cloud SQL via private IP) but I can pull my images now so I am half way there.  \nI think that's it \u2014\u00a0hope it saved you a few minutes!"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Add GitLab private repository as Maven dependency\n\nI have a private repository in GitLab (it's in a group, and I have a Developer role) which I want to add as a dependency for my Maven project.\nI've been looking for a while and all I found was that I have to add the following to my pom.xml:\n<repositories>\n  <repository>\n    <id>gitlab-maven</id>\n    <url>https://gitlab.com/api/v4/projects/.../packages/maven</url>\n  </repository>\n</repositories>\n\n<distributionManagement>\n  <repository>\n    <id>gitlab-maven</id>\n    <url>https://gitlab.com/api/v4/projects/.../packages/maven</url>\n  </repository>\n  <snapshotRepository>\n    <id>gitlab-maven</id>\n    <url>https://gitlab.com/api/v4/projects/.../packages/maven</url>\n  </snapshotRepository>\n</distributionManagement>\n\nHowever, I have no idea how to add the dependency itself (with the groupId and stuff) and I'm not sure how to do authentication to allow Maven to download the project. I've seen something about Personal Access Tokens in GitLab, but I'm not sure how to set that up (I assume I'd only need read-only access?)."}, {"role": "assistant", "content": "First, a few pre-requisites. Since you mentioned you're using a private repository, you'll need to have at least GitLab Silver (hosted on gitlab.com) or GitLab Premium (self-hosted) in order to use the GitLab Maven Packages repository. Also, if you're self-hosted, you'll need to be on GitLab 11.3 or later (should be out this time next week), and have packages_enabled set to true (see Enabling the Packages repository).\nFor private projects, you'll need a Personal Access Token. The token should have the api scope for Maven to upload artifacts to GitLab. Once you have the token, you configure your settings.xml like this.\n<settings>\n  <servers>\n    <server>\n      <id>gitlab-maven</id>\n      <configuration>\n        <httpHeaders>\n          <property>\n            <name>Private-Token</name>\n            <value>REPLACE_WITH_YOUR_PERSONAL_ACCESS_TOKEN</value>\n          </property>\n        </httpHeaders>\n      </configuration>\n    </server>\n  </servers>\n</settings>\n\nIn pom.xml, where you have the ellipses, you need to fill in your project ID. To find the ID, just visit the front page of your project on GitLab. It's shown near the top of the pages, just after the name and description of your project. For example, take a look at the mvn-example sample project. Its project ID is 8377576. That goes in the URL.\n<repositories>\n  <repository>\n    <id>gitlab-maven</id>\n    <url>https://gitlab.com/api/v4/projects/8377576/packages/maven</url>\n  </repository>\n</repositories>\n\nThe mvn-example project's pom.xml file shows a completed example.\nWith all that set up, you should be able to upload artifacts with mvn deploy."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How can I have multiple git accounts on a single development machine?\n\nI am trying to work simultaneously on more than one (two or three) GitLab (or even GitHub) projects on a single development machine. Because upon configuration the IDEs and the git service has the data of my primary user when I try to checkout or clone another project with a different username / password the system says either project is not found or I do not have permissions to do that.\nHow can I configure and use more than one git user on a single development machine?"}, {"role": "assistant", "content": "By default, git is using a system-wide configuration file or the one stored at top of your home directory.\nBut you can also set a file .git/config inside each repository, either by editing manually or using git config. Inside, you may specify the following sections :\n[user]\n    name = Your name\n    email = [email\u00a0protected]\n\n\u2026\n\n[credential \"<your_project_hoster_url>\"]\n    username = <username to log in with>\n\nYou can check git config in general or git credentials in particular for more information about it."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Login to Gitlab with username and password using cURL\n\nFor testing a command line tool against a Gitlab instance in Docker, I would like to login to Gitlab using username and password and grab the created session to authenticate my API requests.\nTherefore I do the following:\n\ncurl the user login page with curl -i http://localhost:8080/users/sign_in -s\nget me the _gitlab_session from the headers\nget me the authenticity_token from the login form\nsend a second curl request with\n\n\ncurl 'http://localhost:8080/users/sign_in' \\\n  -H \"_gitlab_session=${cookie}\" \\\n  -H 'Origin: http://localhost:8080' \\\n  -H 'Content-Type: application/x-www-form-urlencoded' \\\n  -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8' \\\n  -H 'Referer: http://localhost:8080/users/sign_in' \\\n  -H 'Connection: keep-alive' \\\n  --data-urlencode \"authenticity_token=${token}\" \\\n  --data-urlencode \"user[login]=root\" \\\n  --data-urlencode \"user[password]=12341234\" \\\n  --data-urlencode \"user[remember_me]=0\"\n\nBut instead of a valid user login, I get a \n422 - The change you requested was rejected.\n\nAnd in the logfiles, I see\n==> gitlab-rails/production.log <==\nStarted POST \"/users/sign_in\" for 172.17.0.1 at 2017-12-23 00:22:16 +0000\nProcessing by SessionsController#create as HTML\nParameters: {\"authenticity_token\"=>\"[FILTERED]\", \"user\"=>{\"login\"=>\"root\", \"password\"=>\"[FILTERED]\", \"remember_me\"=>\"0\"}}\nCan't verify CSRF token authenticity\nCompleted 422 Unprocessable Entity in 125ms (ActiveRecord: 7.8ms)\n\n==> gitlab-rails/production_json.log <==\n{\"method\":\"POST\",\"path\":\"/users/sign_in\",\"format\":\"html\",\"controller\":\"SessionsController\",  \n\"action\":\"create\",\"status\":422,\"error\":\" \nActionController::InvalidAuthenticityToken:ActionController::InvalidAuthenticityToken\",\n\"duration\":126.29,\"view\":0.0,\"db\":7.78,\"time\":\"2017-12-23T00:22:16.039Z\",\n\"params\":{\"authenticity_token\":\"[FILTERED]\",\"user\":{\"login\":\"root\",\"password\":\"\n[FILTERED]\",\"remember_me\":\"0\"}},\"remote_ip\":\"172.17.0.1\",\n\"user_id\":1,\"username\":\"root\"}\n\n==> gitlab-rails/production.log <==\n\nActionController::InvalidAuthenticityToken (ActionController::InvalidAuthenticityToken):\n  lib/gitlab/middleware/multipart.rb:93:in `call'\n  lib/gitlab/request_profiler/middleware.rb:14:in `call'\n  lib/gitlab/middleware/go.rb:18:in `call'\n  lib/gitlab/etag_caching/middleware.rb:11:in `call'\n  lib/gitlab/middleware/read_only.rb:31:in `call'\n  lib/gitlab/request_context.rb:18:in `call'\n  lib/gitlab/metrics/requests_rack_middleware.rb:27:in `call'\n\nI assume that I forgot to pass a necessary ingredient in the second request - but I can't figure out, which one."}, {"role": "assistant", "content": "With some helpful tips by other answers and comments, I finally came up with this solution:\ngitlab_host=\"http://localhost:8080\"\ngitlab_user=\"root\"\ngitlab_password=\"12341234\"\n\n# curl for the login page to get a session cookie and the sources with the auth tokens\nbody_header=$(curl -c cookies.txt -i \"${gitlab_host}/users/sign_in\" -s)\n\n# grep the auth token for the user login for\n#   not sure whether another token on the page will work, too - there are 3 of them\ncsrf_token=$(echo $body_header | perl -ne 'print \"$1\\n\" if /new_user.*?authenticity_token\"[[:blank:]]value=\"(.+?)\"/' | sed -n 1p)\n\n# send login credentials with curl, using cookies and token from previous request\ncurl -b cookies.txt -c cookies.txt -i \"${gitlab_host}/users/sign_in\" \\\n    --data \"user[login]=${gitlab_user}&user[password]=${gitlab_password}\" \\\n    --data-urlencode \"authenticity_token=${csrf_token}\"\n\n# send curl GET request to personal access token page to get auth token\nbody_header=$(curl -H 'user-agent: curl' -b cookies.txt -i \"${gitlab_host}/profile/personal_access_tokens\" -s)\ncsrf_token=$(echo $body_header | perl -ne 'print \"$1\\n\" if /authenticity_token\"[[:blank:]]value=\"(.+?)\"/' | sed -n 1p)\n\n# curl POST request to send the \"generate personal access token form\"\n# the response will be a redirect, so we have to follow using `-L`\nbody_header=$(curl -L -b cookies.txt \"${gitlab_host}/profile/personal_access_tokens\" \\\n    --data-urlencode \"authenticity_token=${csrf_token}\" \\\n    --data 'personal_access_token[name]=golab-generated&personal_access_token[expires_at]=&personal_access_token[scopes][]=api')\n\n# Scrape the personal access token from the response HTML\npersonal_access_token=$(echo $body_header | perl -ne 'print \"$1\\n\" if /created-personal-access-token\"[[:blank:]]value=\"(.+?)\"/' | sed -n 1p)\n\nAccording to the GitLab API documentation you can now use the session cookie to authenticate API requests:\ncurl --header \"Private-Token: ${personal_access_token}\" https://gitlab.example.com/api/v4/projects\n\nSome hints:\n\nI first got confused with the curl -c file (which reads cookies from the headers and writes them to the file) vs. the curl -b file (which uses the cookies in the file and sends them with the request)\nUnfortunately I did not find a regex that worked with sed so I have to use perl here.\nUsing the developer console in Chrome and copying a POST request as curl command was very helpful: https://www.alexkras.com/copy-any-api-call-as-curl-request-with-chrome-developer-tools/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How can I change the url for a project in GitLab?\n\nI have a project in Gitlab that is available over HTTP/SSH:\n[email\u00a0protected]:MyGroup/MyProject.git\n\nI want to change that using another IP, i.e.:\n[email\u00a0protected]:MyGroup/MyProject.git\n\nWhere or how can I change that?"}, {"role": "assistant", "content": "You can use below command to set new URL for your repository.\ngit remote set-url origin git://[email\u00a0protected]:MyGroup/MyProject.git"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Git magic keywords in commit messages (Signed-off-by, Co-authored-by, Fixes, ...)\n\nGit command itself supports the Signed-off-by: Person's name <persons@email> line.\nGitHub adds Co-authored-by: line, which then shows both the committer and the referenced person as commit authors in the UI. (See Q: GitHub co-authored-by with private noreply address for discussion how to avoid exposing email addresses.)\nFuthermore, GitHub and GitLab each recognize a set of keywords to close issues when a commit is merged.\nIs the list of Git magic keywords above complete? Is there a standardization process for adding these lines and keywords? Are these defined to be case insensitive?"}, {"role": "assistant", "content": "From the OP:\n\nThe git command itself supports the Signed-off-by: Person's name <persons@email> line.\n\nStarting with Git 2.32 (Q2 2021), the git command itself supports... any trailer you want!\n\"git commit\"(man) learned --trailer <key>[=<value>] option; together with the interpret-trailers command, this will make it easier to support custom trailers.\nSee commit 2daae3d (23 Mar 2021) by ZheNing Hu (adlternative).\n(Merged by Junio C Hamano -- gitster -- in commit 68e15e0, 07 Apr 2021)\n\ncommit: add --trailer option\nSigned-off-by: ZheNing Hu\n\n\nHistorically, Git has supported the 'Signed-off-by' commit trailer using the '--signoff' and the '-s' option from the command line.\nBut users may need to provide other trailer information from the command line such as \"Helped-by\", \"Reported-by\", \"Mentored-by\",\nNow implement a new --trailer <token>[(=|:)<value>] option to pass other trailers to interpret-trailers and insert them into commit messages.\n\ngit commit now includes in its man page:\n\n--trailer <token>[(=|:)<value>]\nSpecify a (<token>, <value>) pair that should be applied as a\ntrailer.\nFor instance:\ngit commit --trailer \"Signed-off-by:C O Mitter <[email\u00a0protected]>\" \\\n           --trailer \"Helped-by:C O Mitter <[email\u00a0protected]>\"\n\nThat will add the \"Signed-off-by\" trailer and the \"Helped-by\" trailer to the commit message.\nThe trailer.* configuration variables\n(git interpret-trailers) can be used to define if\na duplicated trailer is omitted, where in the run of trailers\neach trailer would appear, and other details.\n\n\nRegarding that trailer.xxx configuration, consider an initial commit that you want to amend with additional trailers:\nSigned-off-by: C O Mitter <[email\u00a0protected]>\nSigned-off-by: C1 E1\nReported-by: C3 E3\nMentored-by: C4 E4\nHelped-by: C3 E3\n\nA trailer.ifexists=\"replace\" config would, if you amend it by adding the same Reported-by, keep the message unchanged:\ngit -c trailer.ifexists=\"replace\" \\\n    commit   --trailer \"Mentored-by: C4 E4\" \\\n             --trailer \"Helped-by: C3 E3\" \\\n             --amend\n\nBut if you amend the same commit with trailer.ifexists=\"add\" would means:\nSigned-off-by: C O Mitter <[email\u00a0protected]>\nSigned-off-by: C1 E1\nHelped-by: C2 E2\nReported-by: C3 E3\nMentored-by: C4 E4\nReported-by: C3 E3  <<<< added twice\nMentored-by: C4 E4  <<<< added twice\n\nAnd using trailer.ifexists=\"addIfDifferent\"\ngit -c trailer.ifexists=\"addIfDifferent\" \\\n    commit  --trailer \"Reported-by: C3 E3\" \\\n            --trailer \"Mentored-by: C5 E5\" \\\n            --amend\n\nAnd you get:\nSigned-off-by: C O Mitter <[email\u00a0protected]>\nSigned-off-by: C1 E1\nHelped-by: C2 E2\nReported-by: C3 E3\nMentored-by: C4 E4\nMentored-by: C5 E5  <<<< Only C5 E5 is added\n\n\nAnd, still With Git 2.32 (Q2 2021), the way the command line specified by the trailer.<token>.command configuration variable receives the end-user supplied value was both error prone and misleading.\nAn alternative to achieve the same goal in a safer and more intuitive way has been added, as the trailer.<token>.cmd configuration variable, to replace it.\nSee commit c364b7e, commit 57dcb65 (03 May 2021) by ZheNing Hu (adlternative).\n(Merged by Junio C Hamano -- gitster -- in commit 2cd6ce2, 11 May 2021)\n\ntrailer: add new .cmd config option\nHelped-by: Junio C Hamano\nHelped-by: Christian Couder\nSigned-off-by: ZheNing Hu\n\n\nThe trailer.<token>.command configuration variable specifies a command (run via the shell, so it does not have to be a single name or path to the command, but can be a shell script), and the first occurrence of substring $ARG is replaced with the value given to the interpret-trailer command for the token in a '--trailer <token>=<value>' argument.\nThis has three downsides:\n\nThe use of $ARG in the mechanism misleads the users that\nthe value is passed in the shell variable, and tempt them to use $ARG more than once, but that would not work, as the second and subsequent $ARG are not replaced.\nBecause $ARG is textually replaced without regard to the\nshell language syntax, even '$ARG' (inside a single-quote pair), which a user would expect to stay intact, would be replaced, and worse, if the value had an unmatched single quote (imagine a name like \"O'Connor\", substituted into NAME='$ARG' to make it NAME='O'Connor'), it would result in a broken command that is not syntactically correct (or worse).\nThe first occurrence of substring $ARG will be replaced with the empty string, in the command when the command is first called to add a trailer with the specified <token>.\nThis is a bad design, the nature of automatic execution causes it to add a trailer that we don't expect.\n\nIntroduce a new trailer.<token>.cmd configuration that takes higher precedence to deprecate and eventually remove trailer.<token>.command, which passes the value as an argument to the command.\nInstead of \"$ARG\", users can refer to the value as positional argument, $1, in their scripts.\nAt the same time, in order to allow git interpret-trailers(man) to better simulate the behavior of git command -s, 'trailer.<token>.cmd' will not automatically execute.\n\ngit interpret-trailers now includes in its man page:\n\nThis option behaves in the same way as 'trailer.<token>.cmd', except\nthat it doesn't pass anything as argument to the specified command.\nInstead the first occurrence of substring $ARG is replaced by the\nvalue that would be passed as argument.\nThe 'trailer.<token>.command' option has been deprecated in favor of\n'trailer.<token>.cmd' due to the fact that $ARG in the user's command is\nonly replaced once and that the original way of replacing $ARG is not safe.\nWhen both 'trailer.<token>.cmd' and 'trailer.<token>.command' are given\nfor the same <token>, 'trailer.<token>.cmd' is used and\n'trailer.<token>.command' is ignored.\ntrailer.<token>.cmd\n\ngit interpret-trailers now includes in its man page:\n\nof these arguments, if any, will be passed to the command as its\nfirst argument.\nThis way the command can produce a  computed\nfrom the <value> passed in the '--trailer <token>=<value>' argument.\n\ngit interpret-trailers now includes in its man page:\n\n\nConfigure a 'help' trailer with a cmd use a script glog-find-author\nwhich search specified author identity from git log in git repository\nand show how it works:\n\n$ cat ~/bin/glog-find-author\n#!/bin/sh\ntest -n \"$1\" && git log --author=\"$1\" --pretty=\"%an <%ae>\" -1 || true\n$ git config trailer.help.key \"Helped-by: \"\n$ git config trailer.help.ifExists \"addIfDifferentNeighbor\"\n$ git config trailer.help.cmd \"~/bin/glog-find-author\"\n$ git interpret-trailers --trailer=\"help:Junio\" --trailer=\"help:Couder\" <<EOF\n> subject\n>\n> message\n>\n> EOF\nsubject\n\nmessage\n\nHelped-by: Junio C Hamano <[email\u00a0protected]>\nHelped-by: Christian Couder <[email\u00a0protected]>\n\n\nConfigure a 'ref' trailer with a cmd use a script glog-grep\nto grep last relevant commit from git log in the git repository\nand show how it works:\n\n$ cat ~/bin/glog-grep\n#!/bin/sh\ntest -n \"$1\" && git log --grep \"$1\" --pretty=reference -1 || true\n$ git config trailer.ref.key \"Reference-to: \"\n$ git config trailer.ref.ifExists \"replace\"\n$ git config trailer.ref.cmd \"~/bin/glog-grep\"\n$ git interpret-trailers --trailer=\"ref:Add copyright notices.\" <<EOF\n> subject\n>\n> message\n>\n> EOF\nsubject\n\nmessage\n\nReference-to: 8bc9a0c769 (Add copyright notices., 2005-04-07)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I find the gcloud Kubernetes api url for gitlab integration\n\nI'm using the hosted version of gitlab and gitlab-ci and following the kubernetes integration setup https://docs.gitlab.com/ce/user/project/integrations/kubernetes.html.\nI'm struggling to find what to enter as the Kubernetes API URL for my gcloud hosted kubernetes instance. I assume I'm missing something obvious :-("}, {"role": "assistant", "content": "kubectl cluster-info\n\nor\ncat ~/.kube/config | grep server"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Is there a way to add coverage report to gitlab?\n\nI understand that gitlab has support to Jenkins CI, but what I need is a lot less than that. \nI have a Rails application and get the coverage from the tests using simplecov. It generates HTML output in a directory by running a rake task. I would like to see the current coverage through gitlab. Is there a simple way to integrate this report with gitlab?"}, {"role": "assistant", "content": "See Publish Code Coverage Report with GitLab Pages"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Escape char in Gitlab Secret Variables\n\nI have a secret var :\n\nBut when I do - echo %MySecretVar%, runner displays foo only\nHow can i escape special chars like ! in Gitlab Secret Vars ?"}, {"role": "assistant", "content": "I had the same problems with Gitlab, job running on windows, but I assume it will reproduce on Linux as well, because it seems Gitlab parsing issue or relay weird escaping.\nSo I have set environment variable\nAPPPOOL_PWD: 'blabla!foo$bar'\n\nand output of echo %APPPOOL_PWD% or echo $APPPOOL_PWD was 'blabla'\nThe Gitlab seems to be was eating out the exclamation mark sign ! and dollar sign $. To avoid it as proposed in comment for exclamation mark I have used ^^ and for dollar sign I have used $$ as proposed in the Gitlab variables documentation.\nSo following variable works well:\nAPPPOOL_PWD: 'blabla^^!foo$$bar'\nand output of the echo command in this case would be 'blabla!foo$bar'."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Git : How to delete a remote branch whose name starts with a hashtag '#'?\n\nI've created a remote branch whose name starts with a hashtag mark and I've quickly learnt it's a bad idea as # is considered as a comment mark by git.\nTherefore, I would like to delete that branch now but I can't find a proper way to do so\u2026 I've tried :\ngit push origin --delete <#branch_name>\ngit push origin --delete -- <#branch_name>\n\nBut git always returns this error message \n\nfatal: --delete doesn't make sense without any refs.\n\nSo how can I walk around that issue ?"}, {"role": "assistant", "content": "Escape the #:\ngit push origin --delete \\#branch_name\n                         \u2191"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI/CD pre-filled variables on manual job\n\nI'm looking for the right way to set up a variable when I launch a job manually.\nI tried :\nstages:\n  - test \n\nmy_job:\n  stage: test \n  script:\n    - echo \"HEY\"\n  variables:\n    FIRST_VARIABLE: \"my_variable\"\n    SECOND_VARIABLE: \n      value: \"a\"\n      description: \"b\"\n  when: manual\n\nI want my SECOND_VARIABLE to appear into the following VARIABLES field, with a pre-field value : a.\n\nUnfortunatly, I got some error trying \"variables config should be a hash of key value pairs\" error.\nI tried with the gitlab documentation (cf variables), but it fails.\nCan you help me to solve this problem ?"}, {"role": "assistant", "content": "This is currently not implemented, it is supported on the New Pipeline Form but not for manual steps - https://gitlab.com/gitlab-org/gitlab/-/issues/30101 is a good resource, where you can easily track the progress.\nThere are tickets in the backlog like https://gitlab.com/gitlab-org/gitlab/-/issues/22629 - but as said currently this is not possible to be prefilled."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI in multiple platforms simultaneously\n\nI have a C++ project that is compiled and packaged for multiple OS (Linux, Windows, MacOS) as well as multiple CPU architectures (i386, x86_64, arm, Aarch64)\nFor this I'm using Jenkins to grab the source code and run the build script in parallel on each system. It's a simple working solution, since my build script deals with the system differences.\nNow I'm looking into Gitlab CI/CD, and it has many things I find appealing ( being able to keep the build script as part of the repository, very well integrated with the git repo and ticketing system, natural use of Docker containers, etc), but I cannot find any way to run the same pipeline in multiple architectures/systems parallel to each other.\nSo, say that my build script is:\nbuild:\n  stage: build\n  script: \n    - uname -m > arch.txt\n  artifacts:\n    paths:\n      - arch.txt\n\nHow can I tell Gitlab that I want to run this job in multiple runners/Docker containers/systems at the same time?  All the documentation I've read so far deals with running multiple tests on one build, integrating multiple projects or deploying in different environments depending on branches. Nothing I've read so far tries to do many separate builds, test and package them individually and report on their independent results. Is this feasible on Gitlab CI/CD?"}, {"role": "assistant", "content": "GitLab uses \"runners\" to execute CI jobs.  Runners are installed wherever you want to run a CI job, so if you want to run on multiple architectures then you will need to install runners on systems for each architecture.  Runner install documentation can be found here:\nhttps://docs.gitlab.com/runner/install/index.html\nFor Linux-based jobs it is common to use Docker for job execution - this doesn't give architectural flexibility, but it does allow you to test on different flavors and with different software using containerisation.  For other architectures you may need to install runners yourself, or use other peoples shared runners.\nWhile you are installing the runner software there are some keys steps:\n\nyou have the opportunity to link each runner to your GitLab project, which means it will show up in the runners list under Project > Settings > CI/CD.\nyou will have the opportunity to assign \"tags\" to the runners.  Tags can be used to help identify a runner or group of runners by an arbitrary name (e.g. you could add \"Windows x86_64\" as a tag, or \"Windows\" and \"x86_64\" tags).  These tags can be used in jobs to select a runner.\n\nOnce you have your runners installed you can get editing your .gitlab-ci.yml file.\nGitLab CI files are broken up into \"stages\".  Jobs in each stage can run in parallel.  Stage names are defined at the top of the file.\nstages:\n  - build\n  - deploy\n\nEach CI job can be attached to a stage by using the stage: entry:\nbuild job:\n  stage: build\n  script:\n    - echo \"I am a build stage job\"\n\nIn your case you will need to create multiple jobs for each architecture you want to build for. Attaching these to the same stage will allow them to run in parallel.\nTo control where each job runs you have two main mechanisms:\n\nTags - tags allow you to pin a job to a runner tag.  You can specify multiple tags using the tags: entry which forms an AND list (e.g. win tag AND x86_64 tag).  When that job runs GitLab will find a runner that has all the required tags, and run the job there.\nImage - When running on Docker / Kubernetes you can specify a docker image to use for the runner.  To use a docker image you first need to specify a runner that can run docker images (e.g. a docker-in-docker or kubernetes runner), which might, for example, be tagged with docker or kubernetes.  Then you use the image: entry to specify the docker image.\n\nHere's an example showing both tags and images:\nbuild win x86_64:\n  stage: build\n  tags:\n    - win\n    - x86_64\n  script:\n    - echo \"I am a build stage job for win x86_64\"\n\nbuild win 32:\n  stage: build\n  tags:\n    - win\n    - 32-bit\n  script:\n    - echo \"I am a build stage job for win 32\"\n\nbuild debian:\n  stage: build\n  tags:\n    - docker\n  image: debian:stretch\n  script:\n    - echo \"I am a build stage job for debian, running on docker using debian:stretch image\"\n\nThere is currently no support for dynamic jobs, or running one job on multiple runners / architectures, so this involves a bit of manual effort.  On the positive side it makes GitLab CI files easy to read, and easy to see what will run during CI execution."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Can you set Gitlab CI stage so other stages don't wait for it to finish?\n\nLet's say I have these stages defined in .gitlab-ci.yml:\nstages:\n    - build\n    - analysis\n    - tests\n    - deploy\n    - post-deploy\n\nSince analysis takes a lot of time and I don't really care about the result (I also have allow_failure: true set) - is it possible to somehow define to start analysis and then immediately launch the next stage tests?\nI didn't find any reference to similar topic on official docs.\nEDIT:\nThe main idea is that all other stages can be run as if the analysis didn't even exist. If i put analysis to same stage as tests, then both analysis and tests will run at the same time, however deploy won't be launched until both of them finish. This is no good. I want tests to finish and then launch deploy, after deploy finishes I want to launch post-deploy. I really don't care about analysis result, I simply want to trigger it and continue with the deployment."}, {"role": "assistant", "content": "Since v12.8, you can use needs: [] to start jobs start immediately. Docs: https://docs.gitlab.com/ee/ci/yaml/#needs"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I use PowerShell with Gitlab CI in Gitlab Pages?\n\nHow do I use PowerShell commands/scripts with Gitlab CI in a .gitlab-ci.yml file which is used to deploy to gitlab pages?\nI am trying to execute the build.ps1 file from .gitlab-ci.yml, but when it reaches the build.ps1 line, it gives an error saying\n/bin/bash: line 5: .build.ps1: command not found\nI am trying to use the PowerShell script to convert a file in my repo and have the converted file deployed to gitlab pages using .gitlab-ci.yml\nHere is my code:\n.gitlab.yml\npages:\n  stage: deploy\n  script:\n  - mkdir .public\n  - .\\build.ps1\n  - cp -r * .public\n  - mv .public public\n  artifacts:\n    paths:\n    - public\n  only:\n  - master"}, {"role": "assistant", "content": "I have been able to figure out a solution to my own question.\nSolution\nTo Run PowerShell Command/Script from a .gitlab-ci.yml file on a gitlab.com using the Gitlab CI, you need to make sure that the contents of your .gitlab-ci.yml file is as shown below. \nNote: The .gitlab-ci.yml below works without having to install a Gitlab Runner on your own machine and has been tested on the http://gitlab.com website.\nimage: philippheuer/docker-gitlab-powershell\n\npages:\n  stage: deploy\n  script:\n  - mkdir .public\n  # run PowerShell Script\n  - powershell -File build.ps1\n  # run PowerShell Command\n  - powershell -Command \"Get-Date\"\n  - cp -r * .public\n  - mv .public public\n  artifacts:\n    paths:\n    - public\n  only:\n  - master"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Exclude a directory from GitLab's merge request diff\n\nis it possible to exclude a directory from displaying a diff of merge request in GitLab?\nWe started to version the bower_components folder (1 - to speed up app build, 2 - because bower has no .lock mechanism), but it makes trouble when doing code review - many changed files appear inside bower_components which makes the diff harder to read.\nThanks in advance"}, {"role": "assistant", "content": "Since gitlab 8.8, gitlab support the .gitattributes.\nSo if your project does not have  .gitattributes add it,\nand to exclude files for diff, append:\n*.<whatever> -diff\n\nand to exclude directories from a diff:\n<mydir> -diff"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "how to set http as the project default url in gitlab\n\nwhen opening a project in gitlab, you will see SSH and HTTP(or HTTPS) url on the top of project home page, the SSH url is as default, but I want to set  HTTP(or HTTPS) as default, so how should I do? Thanks"}, {"role": "assistant", "content": "infact, you have to modify 2 other lines above the default_clone_protocol.\ndef default_url_to_repo(project = nil)\n  project = project || @project\n  current_user ? project.http_url_to_repo : project.url_to_repo\nend\n\ndef default_clone_protocol\n  current_user ? \"http\" : \"ssh\"\nend"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Defining parallel sequences of jobs in GitLab CI\n\nIn my gitlab-ci.yml file, I have defined 3 stages, and the 2nd and 3rd stages have 3 jobs each, resulting in the following structure:\n\nThe 1st and 2nd stage works as I intended, however, for the 3rd stage what I'd actually like to have is something like this (the image is a mockup of course), i.e. \"parallel sequences\" of jobs if you will:\n\nThat is, I want \"deploy-b\" to start if \"build-b\" is done, and not waiting for the other build tasks to complete.\nIs that possible with GitLab pipelines? (Apart from the obvious solution of defining just 2 stages, the second being \"Build-and-Deploy\", where I just \"merge\" the script steps of the current build-* and deploy-* jobs.)"}, {"role": "assistant", "content": "This feature was added in the new GitLab release (v12.2)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI - Reuse rules with !reference tag\n\nAccording to GitLab's CI documentation about !reference tag, it says:\n\nUse the !reference custom YAML tag to select keyword configuration from other job sections and reuse it in the current section. Unlike YAML anchors, you can use !reference tags to reuse configuration from included configuration files as well.\n\nCan we use the !reference tag to reuse rules or any other allowed keyword?"}, {"role": "assistant", "content": "See GitLab 14.3 (September 2021):\n\nSupport merging CI/CD rules arrays with !reference\nThe YAML !reference tag introduced earlier this year helps you reuse and combine configuration.\nThis is a very flexible way to combine frequently reused configuration with job-specific configuration in one or more jobs.\nHowever, using it with the rules keyword was not supported yet.\nIn 14.3, we\u2019ve added !reference support to the rules keyword, so you can now mix and match rules more easily, including with configuration from different files.\nYou can use the CI/CD pipeline editor to view the merged configuration.\n\nSee Documentation and Issue."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to pull NPM dependency from private GitLab Git repo during GitLab CI build\n\nI have a job in my .gitlab-ci.yml file which does an npm install like so:\ntest:\n  image: node:10\n  script:\n    - npm install\n    - npm test\n\nThe problem is that I'm referencing a private GitLab repo in my package.json:\n\"dependencies\": {\n  \"internal-dep\": \"git+https://gitlab.com/Company/internal-dep.git\",\n  ...\n\nThe npm install command works locally, since I'm already authed against GitLab, but fails on GitLab CI. How do I get internal-dep to resolve successfully on GitLab CI?"}, {"role": "assistant", "content": "There are two approaches I've found that allow Git to auth successfully against GitLab during the npm install step (which uses Git under the hood to access this dependency).\nFirst approach, as shown in this .gitlab-ci.yml job:\ntest:\n  image: node:10\n  script:\n    - echo -e \"machine gitlab.com\\nlogin gitlab-ci-token\\npassword ${CI_JOB_TOKEN}\" > ~/.netrc\n    - npm install\n    - npm test\n\nSecond approach, which also seems to work:\ntest:\n  image: node:10\n  script:\n    - git config --global url.\"https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.com/\".insteadOf https://gitlab.com/\n    - npm install\n    - npm test"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab repository vs project vs submodule\n\nI started exploring Gitlab for version control management and I got an issue at the first step itsself. When ever I create a project its creating a new repository. I have few webapplications  which are independent to each other. In that case do I need to use different repository for every project.\nWhat I am looking for is what is what and when to use what but not able to find what is repository and what is project in gitlab website as well as through other sources as well.\nAlso I came across a term submodule, when can it be used. Can I create one global project and have all the webapplications as different submodules.\nCan any one please help me in understanding the difference between those 3 and when to use what based on their intended way of usage. Also please help me by pointing to a good learning site where I can get the information of doing basic version control operations in gitlab. \nThanks."}, {"role": "assistant", "content": "Gitlab manages projects: a project has many features in addition of the Git repo it includes:\n\nissues: powerful, but lightweight issue tracking system.\nmerge requests: you can review and discuss code before it is merged in the branch of your code.\nwiki: separate system for documentation, built right into GitLab\nsnippets: Snippets are little bits of code or text.\n\nSo fear each repo you create, you get additional features in its associated project.\nAnd you can manage users associated to that project.\nSee GitLab documentation for more.\nThe Git repo and Git submodule are pure Git notions.\nIn your case, a submodule might not be needed, unless you want a convenient way to remember the exact versions of different webapp repo, recorded in one parent repo.\nBut if that is the case, then yes, you can create one global project and have all the webapplications as different submodules.\nEach of those submodules would have their own GitLab project (and Git repo)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab get tar of a specific branch via command line\n\nI'm using gitlab. When I go into the interface, on each branch I can download the source code as a zip, tar or whatsoever.\nI am making rpm spec files for which I would need the possibility to download the tar ball using command line. since I added my rsa key i can do git clone without problems:\ngit clone http://gitlab/group/project.git\nCloning into 'project'...\nremote: Counting objects: 1885, done.\nremote: Compressing objects: 100% (826/826), done.\nremote: Total 1885 (delta 1194), reused 1496 (delta 954)\nReceiving objects: 100% (1885/1885), 1.30 MiB | 0 bytes/s, done.\nResolving deltas: 100% (1194/1194), done.\nChecking connectivity... done\n\nHowever doing \nwget http://gitlab/group/project/repository/archive.zip\n\ngets me these errors:\nResolving gitlab (gitlab)... 10.1.253.75\nConnecting to gitlab (gitlab)|10.1.253.75|:80... connected.\nHTTP request sent, awaiting response... 401 Unauthorized\nAuthorization failed."}, {"role": "assistant", "content": "Since GitLab 6.2 and issue 5253, it should be:\nGET /projects/:id/repository/archive\n\nBut that seems for internal use only, since you cannot know the id of a project as a user (only its name).\nDon't forget, as shown in ability.rb, that downloading an archive is linked to a permission. Make sure you have that \"download_code\" permission set for your project.\nHere, it must be a permission issue, because, for instance:\nwget http://demo.gitlab.com/gitlab/gitlab-recipes/repository/archive.zip\n\nThat works just fine, and get the content of that project without any issue.\n\nHowever, as the OP Chris Maes comments and mentions in issue 6645, as as illustrated by app/models/ability.rb:\n if project && project.public?\n\n... that \"dowload_code\" feature is only for public projects."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab-runner + Docker + Windows - Invalid volume specification\n\nI'm trying to run my Gitlab CI locally using Gitlab-runner and docker before committing to make sure they work okay. But I'm having some strange issues!\nUnfortunately I have no choice but to use windows (I've had success in the past on Linux).\nEvery time I run a job in powershell:\nC:/Gitlab-runner/gitlab-runner exec docker npm\nI get an error:\nJob failed (system failure): Error response from daemon: invalid volume specification: '/host_mnt/c/builds/project-0/Users/Lewsmith/api:C:/Users/Lewsmith/api:ro' (executor_docker.go:921:0s)\nI've tried setting docker volumes (nemerous combinations) and builds-dir:\nC:/Gitlab-runner/gitlab-runner exec docker --builds-dir /builds --docker-privileged --docker-volumes \"/builds:C:/Gitlab-runner/builds\" npm\nThat fails with Error response from daemon: invalid mode: /Gitlab-runner/builds because of the colon after the C..\nCan anyone point me in the right direction as I'm stumped? \nUsing gitlab-runner version 11.5.0"}, {"role": "assistant", "content": "Docker is not fully supported by GitLab Runner on Windows yet.\nThe workaround is to use Windows Subsystem for Linux and install gitlab-runner there:\ncurl -L https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.deb.sh | sudo bash\nsudo apt-get install gitlab-runner\ngitlab-runner exec docker build"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Difference between projects and subgroups in GitLab\n\nI want to understand the difference between projects and subgroups in GitLab.\nPlease help me on understanding the above."}, {"role": "assistant", "content": "Project\nA project manages one git repository and adds an issue tracker, a wiki, etc: \nSee: https://docs.gitlab.com/ee/user/project/index.html#doc-nav\nGroups\nGroups can be used to combine several projects under one topic. Examples:\n\nYou could put all your JavaScript projects in a group called \"js\"\nYou could create one group for each of your developer teams; then if somebody new joins a team, you can just add them to the group instead of having to grant developer access for every project.\nGroups can be referred in issues or commit discussions. \n\nSee: https://docs.gitlab.com/ee/user/group/index.html#doc-nav\nDifferent groups may have different permissions \nSubgroups\nSubgroups are only available in GitLab 9 and above; they allow you to create additional groups inside of groups, e.g. \"js/frontend\"; this is useful if you are working on a large project with several sub-projects. See the official documentation for some examples:\nhttps://docs.gitlab.com/ee/user/group/subgroups/index.html"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab docker executor - cache image after before_script\n\nIn gitlab-ci there's an option in the .gitlab-ci.yml file to execute commands before any of the actual script runs, called before_script. .gitlab-ci.yml examples illustrate installing ancillary programs here. However, what I've noticed is that these changes are not cached in Docker when using a docker executor. I had naively assumed that after running these commands, docker would cache the image, so for the next run or test, docker would just load the cached image produced after before_script. This would drastically speed up builds.\nAs an example, my .gitlab-ci.yml looks a little like:\nimage: ubuntu\n\nbefore_script:\n    - apt-get update -qq && apt-get install -yqq make ...\n\nbuild:\n    script:\n        - cd project && make\n\nA possible solution is to go to the runner machine and create a docker image that can build my software without any other installation and then reference it in the image section of the yaml file. The downside of this is that whenever I want to add a dependency, I need to log in to the runner machine and update the image before builds will succeed. It would be much nicer if I just had to add the dependency to to the end of apt-get install and have docker / gitlab-ci handle the appropriate caching.\nThere is also a cache command in .gitlab-ci.yml, which I tried setting to untracked: true, which I thought would cache everything that wasn't a byproduct of my project, but it didn't seem to have any effect.\nIs there any way to get the behavior I desire?"}, {"role": "assistant", "content": "You can add a stage to build the image in first place. If the image doesn't have any change, the stage will be very short, under 1 second.\nYou can use that image on the following stages, speeding up the whole process.\nThis is an example of a .gitlab-ci.yml:\nstages:\n  - build_test_image\n  - test\n\nbuild_test:\n  stage: build_test_image\n  script:\n    - docker login -u gitlab-ci-token -p $CI_BUILD_TOKEN $CI_REGISTRY\n    - docker build -t $CI_REGISTRY_IMAGE:test -f dockerfiles/test/Dockerfile .\n    - docker push $CI_REGISTRY_IMAGE:test\n  tags:\n    - docker_build\n\ntest_syntax:\n  image: $CI_REGISTRY_IMAGE:test\n  stage: test\n  script:\n    - pip install flake8\n    - flake8 --ignore=E501,E265 app/\n\nLook at the tag docker_build. That tag is used to force the execution of the stage on the runner which has that tag. The executor for that runner is shell, and it's used only to build Docker images. So, the host where the runner lives should have installed Docker Engine. I found this solution suits better my needs than docker in docker and another solutions.\nAlso, I'm using a private registry, that's why I'm using $CI_REGISTRY* variables, but you can use DockerHub without need to specify the registry. The problem would be to authenticate on DockerHub, though."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to upload projects on gitlab by user?\n\nWe are using Gitlab (7.5.3).\nI created a Repository, but I want to upload my project to it.\nI've looked on the repository page for an upload button of some kind but I haven't seen anything of the sort.\nI've looked at the links provided so far but I'm still getting nowhere. They mention command line, is that Windows command line ?\nI am able to upload through Git GUI, how to upload without Git GUI?\nAnd when I login to user account through putty ,it shows\nlogin as: root\n[email\u00a0protected]'s password:\nLast login: Tue May 26 12:20:10 2015 from 192.168.1.12\n![grep: write error]\n\nDoes anyone knows how we can solve these issue?"}, {"role": "assistant", "content": "If you have Git GUI, you probably also have Git Bash which provide command line support for git inside Windows. \nYou can use this Git Bash to upload your project. For this, you just need some git command, and you don't have to log in the Gitlab's server (I supposed it's why you tried). This command are provided by Gitlab when you create a new project and want to upload it.\nFirst open Git Bash. Then : \ncd c:\\Users\\Me\\..\\my_project\\   # Go to your project directory in Windows\ngit init                        # Initialize this directory as a git repo\ngit remote add origin git@your_gitlab_server_ip:your_username/your_project_name.git\ngit push -u origin master`      # Send your code to your Gitlab instance\n\nIt's also a good idead to provide to git some info about you. This infos will be displayed by Gitlab : \ngit config --global user.name \"Your Name\"\ngit config --global user.email \"your_name@your_mail.com\"\n\nRemember that with Gitlab the only interaction between your git's repo and Gitlab should happend through the git command, and not with login to this server."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Clone a github repo into a private gitlab repo\n\nI am trying to pull a repo from github and push it up to a private repo on a gitlab server that I am running.\nI cloned the github repo to my local machine\ngit clone  https://github.com/somepage/someproject\n\nat that point I added a new remote (my gitlab)\ngit remote add gitlab https://mygitlabserver/mypage/myproject\n\nthen I pushed (in this case only branch on githab was develop)\ngit push gitlab develop\n\nNow I am running into problems when I try to clone from my gitlab repo:\ngit clone https://mygitlabserver/mypage/myproject\nCloning into 'myproject'...\nremote: Counting objects: 140, done.\nremote: Compressing objects: 100% (85/85), done.\nremote: Total 140 (delta 40), reused 140 (delta 40)\nReceiving objects: 100% (140/140), 2.75 MiB | 1.85 MiB/s, done.\nResolving deltas: 100% (40/40), done.\nChecking connectivity... done.\nwarning: remote HEAD refers to nonexistent ref, unable to checkout.\n\nNot 100% what that warning is about, but I am sure its not good.  If I list the contents of that cloned dir its empty.\nWhat did I do wrong?"}, {"role": "assistant", "content": "I suspect you are getting that error because the default configuration of a repository in gitlab is to have a default branch name of master.  You have only pushed a branch named develop, and when you clone the repository git is attempting to checkout the nonexistent master branch.\nYou can:\n\ngo into the repository settings in gitlab and set the default branch to develop, \nor you can just name the branch master, \nor you can provide -b develop to the git clone command, \nor after cloning you can simply git checkout develop."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Stop gitlab runner to not remove a directory\n\nI have a directory which is generated during a build and it should not be deleted in the next builds. I tried to keep the directory using cache in .gitlab-ci.yml:\ncache:\n  key: \"$CI_BUILD_REF_NAME\"\n  untracked: true\n  paths:\n    - target_directory/\nbuild-runner1:\n  stage: build\n  script:\n    - ./build-platform.sh target_directory\n\nIn the first build a cache.zip is generated but for the next builds the target_directory is deleted and the cache.zip is extracted which takes a very long time. Here is a log of the the second build:\nRunning with gitlab-ci-multi-runner 1.11.\n  on Runner1\nUsing Shell executor...\nRunning on Runner1...\nFetching changes...\nRemoving target_directory/\nHEAD is now at xxxxx Update .gitlab-ci.yml\nFrom xxxx\nChecking out xxx as master...\nSkipping Git submodules setup\nChecking cache for master...\nSuccessfully extracted cache\n\nIs there a way that gitlab runner not remove the directory in the first place?"}, {"role": "assistant", "content": "What you need is to use a job artifacts:\n\nArtifacts is a list of files and directories which are attached to a\njob after it completes successfully.\n\n.gitlab-ci.yml file:\nyour job:\n    before_script:\n        - do something\n    script:\n         - do another thing\n         - do something to generate your zip file (example: myFiles.zip)\n  artifacts:\n    paths:\n         - myFiles.zip\n\nAfter a job finishes, if you visit the job's specific page, you can see that there is a button for downloading the artifacts archive.\nNote\n\nIf you need to pass artifacts between different jobs, you need to use dependencies.\nGitlab has a good documentation about that if you really have this need http://docs.gitlab.com/ce/ci/yaml/README.html#dependencies"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "using mattermost api via gitlab oauth as an end-user with username and password (no client_secret)\n\nIn our team we use gitlab (https://git.example) and the bundled mattermost chat (https://chat.example).\nFor mattermost we'd like to have a dedicated bot-user (the web hooks have limitations wrt. private channels etc.), which actually logs in exactly like a normal user.\nWe created that user in gitlab, and can log into our chat with it via chrome (chat login redir --> gitlab oauth, type in username and pw --> redir back to chat --> authed).\nNow i searched for python libraries that can actually do this, but i can only find some which require a client_id and client_secret... From my understanding (please correct me if i'm wrong) this is not what we're searching for, as we don't want to create another application to auth via gitlab, but login to our chat (which already has an id (known) and a secret (unknown)) as a user via gitlab.\nAs we couldn't find such a lib, we also inspected the network requests in chrome and tried to re-create it in python via requests, but can't get it to work (needless to say it involves parsing html and csrf tokens)...\nTaking yet another attempt and a lot of guesswork we tried to acquire an access_token manually via\nclient_id = 'the one of mattermost in our gitlab'\nuser = 'username'\npw = 'password'\nr = requests.post(\n    'https://git.example/oauth/token',\n    data={\n        \"grant_type\": \"password\",\n        \"username\": user,\n        \"password\": pw,\n        \"client_id\": client_id,\n    }\n)\naccess_token = r.json()['access_token']\n\nThis seems to work (and the token looks good), but using it in the mattermost API only results in a 401:\nri = requests.get(\n    'https://chat.example/api/v1/users/me',\n    headers={'Authorization': 'Bearer ' + access_token}\n)\n\nri.status_code, ri.json()\n(401,\n {u'detailed_error': u'token=...xxx...',\n  u'id': u'api.context.session_expired.app_error',\n  u'is_oauth': False,\n  u'message': u'Invalid or expired session, please login again.',\n  u'request_id': u'...yyy...',\n  u'status_code': 401})\n\nSadly http://docs.mattermost.com/developer/web-service.html#oauth2 currently doesn't shed more light into this, which is why I'm asking here. Did i maybe miss something obvious to \"activate\" that access_token in mattermost?"}, {"role": "assistant", "content": "Actually i finally got this running by imitating the browser's behavior as follows, but i'd still be interested in a more generic solution that doesn't involve parsing any of the gitlab server's html...:\nimport requests\nfrom pyquery import PyQuery as pq\n\nclient_id = '...your_mattermost_client_id...'\nuser = '...username...'\npw = '...userpass...'\n\ngitlab = 'https://git.example'\nchat = 'https://chat.example'\nteam = '/your_team'\n\nr = requests.get(\n    chat + team + '/login/gitlab'\n)\nq = pq(r.content)\ncsrf_token = q('#new_ldap_user input[name=\"authenticity_token\"]')[0].value  # watch out, several tokens for ldap vs. normal login, inspect the page to find correct one\n\nr2 = requests.post(\n    gitlab + '/users/auth/ldapmain/callback',  # or whatever the browser callback for your auth-method was\n    cookies=r.cookies,\n    data={\n        'authenticity_token': csrf_token,\n        'username': user,\n        'password': pw,\n    }\n)\n\n# print [h.url for h in r2.history] + [r2.url]  # to check the redirects\n\nme = requests.get(\n    chat + '/api/v1/users/me',\n    cookies=r2.cookies,\n)\nprint me.json()  # if everything went well you're now authorized\n\n# remember to set cookies in the follow-up requests"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "/bin/sh: eval: line 98: bash: not found\n\ni got this\n/bin/sh: eval: line 98: bash: not found \n\nmessage by executing the gitlabb .yml file.\nI added in the before script section the line\n- apk update && apk add openssh\n\nwhich was not helpful.\nbefore_script:\n  - apk update && apk add openssh\n  - bash docker_install.sh > /dev/null\n\nstages:\n  - build\n  - deploy\n  - loadtest-local\n\nbuild:\n  stage: build\n  script:\n    - echo \"building my application in ubuntu container...\"\n\ndeploy:\n  stage: deploy\n  image: php:7.4\n  script: \n    - phpunit Unittest.php\n    \n\nloadtest-local:\n  image: \n    name: loadimpact/k6:latest\n    entrypoint: [\"\"]\n  stage: loadtest-local\n  script:\n    - k6 run ./loadtests/performance-test.js\n    - k6 run ./loadtests/inttest.js\n\nHow can I resolve this issue?"}, {"role": "assistant", "content": "That means one of the images used in your pipeline doesn't have bash installed.\nTry changing the line on before_script to ./docker_install.sh > /dev/null (make sure the docker_install.sh has execution permissions set beforehand)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to create hierarchical wiki in git lab\n\nHow to create a hierarchical wiki pages in GitLab\nHome\n    <Wiki Page 1>\n    <Wiki Page 2>\n    <Wiki Page 3>\n       <Wiki Page 3 - 1>\n       <Wiki Page 3 - 2>\n    <Wiki Page 4>"}, {"role": "assistant", "content": "You can specify wiki page path in page title field, for example section/section/wiki page.\nSee https://docs.gitlab.com/ee/user/project/wiki/#move-a-wiki-page for details."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Stopping a started background service (phantomjs) in gitlab-ci\n\nI'm starting phantomjs with specific arguments as part of my job.\nThis is running on a custom gitlab/gitlab-ci server, I'm currently not using containers, I guess that would simplify that.\nI'm starting phantomjs like this:\n- \"timeout 300 phantomjs --ssl-protocol=any --ignore-ssl-errors=true vendor/jcalderonzumba/gastonjs/src/Client/main.js 8510 1024 768 2>&1 >> /tmp/gastonjs.log &\"\n\nThen I'm running my behat tests, and then I'm stopping that process again:\n- \"pkill -f 'src/Client/main.js' || true\"\n\nThe problem is when a behat test fails, then it doesn't execute the pkill and the test-run is stuck waiting on phantomjs to finish. I already added the timeout 300 but that means I'm still currently waiting 2min or so after a fail and it will eventually stop it while test are still running when they get slow enough.\nI haven't found a way to run some kind of post-run/cleanup command that also runs in case of fails.\nIs there a better way to do this? Can I start phantomjs in a way that gitlab-ci doesn't care that it is still running? nohup maybe?"}, {"role": "assistant", "content": "TL;DR; - spawn the process in a new thread with & but then you have to make sure the process is killed in successfull and failure builds.\ni use this (with comments):\n'E2E tests':\n  before_script:\n    - yarn install --force >/dev/null\n    # if there is already an instance running kill it - this is ok in my case - as this is not run very often\n    - /bin/bash -c '/usr/bin/killall -q lite-server; exit 0'\n    - export DOCKERHOST=$(ifconfig | grep -E \"([0-9]{1,3}\\\\.){3}[0-9]{1,3}\" | grep -v 127.0.0.1 | awk '{ print $2 }' | cut -f2 -d ':' | head -n1)\n    - export E2E_BASE_URL=\"http://$DOCKERHOST:8000/#.\"\n    # start the lite-server in a new process\n    - lite-server -c bs-config.js >/dev/null &\n  script:\n    # run the tests\n    - node_modules/.bin/protractor ./protractor.conf.js --seleniumAddress=\"http://localhost:4444/wd/hub\" --baseUrl=\"http://$DOCKERHOST:8000\" --browser chrome\n    # on a successfull run - kill lite server\n    - killall lite-server >/dev/null\n  after_script:\n    # when a test fails - try to kill it in the after_script. this looks rather complicated, but it makes sure your builds dont fail when the tests succeedes and the lite-server is already killed. to have a successfull build we ensure a non-error return code (exit 0)\n    - /bin/bash -c '/usr/bin/killall -q lite-server; exit 0'\n  stage: test\n  dependencies:\n    - Build\n  tags:\n    - selenium\n\nhttps://gist.github.com/rufinus/9ee8f04fc1f9248eeb0c73ad5360a006#file-gitlab-ci-yml-L7"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI / Docker: Use custom image for job\n\nThis is how I do some linter test (eslint).\nlinter:\n  image: ubuntu:16.04\n  stage: test\n  tags:\n    - testing\n  before_script:\n    - apt-get update -y\n    - apt-get install nodejs-legacy -yqq\n    - apt-get install curl -yqq\n    - curl https://install.meteor.com/ | sh\n    - meteor npm install eslint eslint-plugin-react\n  script:\n    - ./node_modules/.bin/eslint --ext .js --ext .jsx .\n\nBut with this every test will have to install the packages to the ubuntu image, which takes time.\nSo I thought to build a image with exact this. I came up with this Dockerfile:\nFROM ubuntu:16.04\nRUN apt-get update -y\nRUN apt-get install nodejs-legacy -yqq\nRUN apt-get install curl -yqq\nRUN apt-get clean && apt-get autoclean && apt-get autoremove\nRUN curl https://install.meteor.com/ | sh\n\nThen I do\n$ docker build -t linter-testing:latest .\n\nand this yml file:\nlinter:\n  image: linter-testing:latest\n  stage: test\n  tags:\n    - testing\n  before_script:\n    - meteor npm install eslint eslint-plugin-react\n  script:\n    - ./node_modules/.bin/eslint --ext .js --ext .jsx .\n\nBut it fails with this error:\nERROR: Job failed: Error response from daemon: repository linter-testing not found: does not exist or no pull access\n\nSo why is this image not existing, althoug docker images shows me exact that image..."}, {"role": "assistant", "content": "You need to edit your config.toml file which is in /etc/gitlab-runner on your runner machine with the following \n[runners.docker]\n  pull_policy = \"if-not-present\"\n\nSee related issue here."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI - find the pipeline variables used\n\nWhen you run a pipeline from the Gitlab UI, you are open to add variables to the run:\n\n\n\nFrom the overview of finished pipelines, is there a way to find the set variables and values of specific runs?"}, {"role": "assistant", "content": "As far as I know, these are one time variables you set by running a pipeline manually. You cannot view the the variables in the UI. Instead, like @Origin said you can echo the variable in the job.\nexample:\nscript:\n    - '& echo \"$MY_VARIABLE\"'\n\nI would recommend you to save your variables in the default CI/CD Settings. (Settings -> CI/CD -> Variables). There you can set, save, protect (from other user roles) and view them for sure. These variables will be used in any pipeline run you do."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab cannot open git-upload-pack error\n\nI have been using Gitlab without problems for a couple of months now.\nBut, since yesterday, I can not \"reach\" (fetch, push,...) Gitlab from my Eclipse IDE anymore.\nNo matter whether I'm working in my firm (could have been a proxy problem) or at home.\nI get the following error message :\nhttps://gitlab.com/XXX/XXX.git: \n    cannot open git-upload-pack\n    cannot open git-upload-pack\n\nLooking at my Eclipse .log, the cause is :\nCaused by: javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure\n    at sun.security.ssl.Alerts.getSSLException(Unknown Source)\n    at sun.security.ssl.Alerts.getSSLException(Unknown Source)\n    at sun.security.ssl.SSLSocketImpl.recvAlert(Unknown Source)\n    at sun.security.ssl.SSLSocketImpl.readRecord(Unknown Source)\n    at sun.security.ssl.SSLSocketImpl.performInitialHandshake(Unknown Source)\n    at sun.security.ssl.SSLSocketImpl.startHandshake(Unknown Source)\n    at sun.security.ssl.SSLSocketImpl.startHandshake(Unknown Source)\n    at sun.net.www.protocol.https.HttpsClient.afterConnect(Unknown Source)\n    at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(Unknown Source)\n    at sun.net.www.protocol.http.HttpURLConnection.getInputStream(Unknown Source)\n    at java.net.HttpURLConnection.getResponseCode(Unknown Source)\n    at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(Unknown Source)\n    at org.eclipse.jgit.transport.http.JDKHttpConnection.getResponseCode(JDKHttpConnection.java:98)\n    at org.eclipse.jgit.util.HttpSupport.response(HttpSupport.java:168)\n    at org.eclipse.jgit.transport.TransportHttp.connect(TransportHttp.java:460)\n    ... 10 more\n\nAdding http.sslVerify=false in my Eclipse/Git configuration did not help...\nAny idea why this is (suddenly) happening?"}, {"role": "assistant", "content": "I've encountered a similar error with another Gitlab server. I dug into it and discovered that all of the available ciphers on the server were at least 256 bits. Standard Oracle Java ships with crypto that's restricted to 128 bits for some algorithms. After installing the unlimited strength crypto package from Oracle the issue went away.\nAlmost forgot, the unlimited strength package is only legally available in the US. If you're outside of the US then I think that OpenJDK will work instead."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Is there a way to show build status/code coverage per branch\n\nWe are setting the CI on our GitLab and we are able to show build status and code coverage on master using the following:\nREADME.md in root directory of myproject:\n[![build status](http://mygitlab/mygroup/myproject/badges/master/build.svg)](http://mygitlab/mygroup/myproject/commits/master) \n[![coverage report](http://mygitlab/mygroup/myproject/badges/master/coverage.svg)](http://mygitlab/mygroup/myproject/commits/master)\n\nSomething we would like is show build status/code coverage of current branch when viewing the README.md in the branch. Right now, the links have master hardcoded so the branches show the status of the master. \nIs there a way to use relative URL (or something else) so the build status / code coverage automatically adapt to the branch you're viewing? Looking at the documentation, it looks like it's impossible, because you have to specify the branch."}, {"role": "assistant", "content": "Starting in GitLab 9.3 (available only in Starter/Bronze and higher), code quality will be evaluated as part of the CI/CD pipeline and the results will display in the merge request. \nYou can see an example of how this looks in a merge request in the documentation at GitLab Code Quality. \nThis works 'automatically' via Auto DevOps or you can configure Code Quality manually by using the Code Quality examples\nThis doesn't address showing code quality and pipeline status for a given branch in the README. As mentioned, it does show the pipeline status and code quality in the MR itself. However, when viewing a particular branch, the commit at the top of the page does show the overall pipeline status. Click on that status to go to the pipeline for more detailed job information, including the Code Quality job itself. \n\nIt's not quite as handy as what you're looking for, but it is a workaround. Usually, concerns about quality and build status are most important on the proposed merge request itself, where fixes can be made prior to merging them into the master/target branch."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Is it possible in Gitlab UI to run a skipped item of the pipeline?\n\nI have a pipeline on Gitlab that have multiple steps. One step in the middle is optional but configured as mandatory and today it started to fail.\nIn Gitlab UI when it fails all next pipeline items are marked as skipped and greyed out.\nIs it possible to run manually in UI a next step after the failed one?"}, {"role": "assistant", "content": "Why it's not directly possible\nCI pipelines are designed with a strong emphasis on dependency management. When a job in a pipeline fails, subsequent jobs are marked as skipped because they may rely on the output or success of the failed job. (Forcing execution could lead to unexpected errors.)\nWorkaround using allow_failure\nYou can mark a job as \"allowed to fail\" in your config. This way, subsequent jobs are not influenced by the status of this job.\nallow_failure: true \n\nImportant: Subsequent jobs should obviously not strictly depend on the job's successful completion and/or have built-in error handling.\nhttps://docs.gitlab.com/ee/ci/yaml/#allow_failure"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab auto merge when build succeeds not working\n\nI have a quite simple question. We have setup Gitlab CI and want to allow auto merge as soon as the build succeeds for some of our branches. \nThing is, we see that the build passes, but the merge does not actually happen and the status stays at \"to be merged automatically once the build succeeds\".\nDo you have any idea why? \nI attached a screenshot of the bogus behaviour.\n\nEDIT: Some additional information that was requested: \n\nIt looks like no background job is put in the queue where I activate a \"automatic merge when build succeeds\nWhen a build finishes running, no background jobs is triggered as far as I can see. Nothing new being scheduled, dead or in progress.         \nI also don't see anything crazy or ERROR like in the logs. \nTwo screenshots of my dashboard as a MR with an automated build runs : \n\n\n\nThanks, \nJulien"}, {"role": "assistant", "content": "Maybe your merge job is scheduled or dead.\n\nUse your admin account and click the Admin Area button.\nClick Monitoring -> Background Jobs\n\nThen,click the dashboard and check the if your merge job is in the Scheduled queue or Dead queue."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "test after build would run in new environment on gitlab-ci\n\nI have the following configuration as .gitlab-ci.yml\nbut I found out after successfully pass build stage (which\nwould create a virtualenv called venv), it seems that \nin test stage you would get a brand new environment(there's\nno venv directory at all). So I wonder should I put setup\nscript in before_script therefor it would run in each phase(build/test/deploy). Is it a right way to do it ?\nbefore_script:\n  - uname -r \n\ntypes:\n  - build\n  - test\n  - deploy\n\njob_install:\n  type: build\n  script:\n    - apt-get update\n    - apt-get install -y libncurses5-dev\n    - apt-get install -y libxml2-dev libxslt1-dev\n    - apt-get install -y python-dev libffi-dev libssl-dev \n    - apt-get install -y python-virtualenv\n    - apt-get install -y python-pip\n    - virtualenv --no-site-packages venv\n    - source venv/bin/activate\n    - pip install -q -r requirements.txt\n    - ls -al\n  only:\n    - master\n\njob_test:\n  type: test\n  script:\n    - ls -al\n    - source venv/bin/activate\n    - cp crawler/settings.sample.py crawler/settings.py\n    - cd crawler \n    - py.test -s -v \n  only:\n    - master\n\nadasd"}, {"role": "assistant", "content": "Gitlab CI jobs supposed to be independent, because they could run on different runners. It is not issue. There two ways to pass files between stages:\n\nThe right way. Using artefacts.\nThe wrong way. Using cache. With cache key \"hack\". Still need same runner.\n\nSo yes, supposed by gitlab way to have everything your job depends on in before script.\nArtifacts example:\n  artifacts:\n   when: on_success\n   expire_in: 1 mos\n   paths:\n    - some_project_files/\n\nCache example:\ncache:\n  key: \"$CI_BUILD_REF_NAME\"\n  untracked: true\n  paths:\n   - node_modules/\n   - src/bower_components/\n\nFor correct running environment i suggest using docker with image containing apt-get dependencies. And use artefacts for passing job results between jobs. Note that artefact also uploaded to gitlab web interface and being able to download them. So if they are quite heavy use small expire_in time, for removing them after all jobs done."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Removing missing LFS objects from git repository\n\nI am missing a bunch of LFS objects in my git repository*, both on the clients and the server. I am aware that those objects are lost and that's okay. Unfortunately this means that git lfs fetch --all or even git lfs push --all origin will fail.\nI would like to purge the \"broken pointers\" from the repository, either by replacing the binary with a dummy text file or by removing the pointer altogether. I am also aware that this involves rewriting history and that's also fine.\nWhat would be the best way to proceed?\n*To clarify, I am missing some LFS files on the server but not all of them and not for all revisions of those files.\nFor example, I have foo.png that has been modified in 3 commits:\n\nfoo.png (Version 1, LFS Sha: 03cfd743)\nfoo.png (Version 2, LFS Sha: 661f0797)\nfoo.png (Version 3, LFS Sha: 5fa2f122)\n\nThe LFS server no longer has foo.png version 2, so I would like to remove that commit from history. Unfortunately git lfs does not tell me which commit is broken, it simply tells me that 661f0797 is missing.\n(For the record, I have found the missing files so I no longer have this issue but the solution should still be interesting!)"}, {"role": "assistant", "content": "This script worked for me - it removes all blobs that look like LFS files.\ngit filter-repo --force --blob-callback \"\nif blob.data.split(b'\\n', 1)[0] == b'version https://git-lfs.github.com/spec/v1':\n  blob.skip()\n\"\n\nExplanation:\n\ngit filter-repo rewrites git history\n--force is needed to skip safety checks\nif blob.data.split(b'\\n', 1)[0] == b'version https://git-lfs.github.com/spec/v1': blob.skip()\nThis script checks if the first line of the file contains an LFS signature and skips adding this file in such a case."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "TeamCity gitlab integration [closed]\n\nClosed. This question is seeking recommendations for software libraries, tutorials, tools, books, or other off-site resources. It does not meet Stack Overflow guidelines. It is not currently accepting answers.\n                                \n                            \n\n\n\n\n\n\n\n\n\n\n\n We don\u2019t allow questions seeking recommendations for software libraries, tutorials, tools, books, or other off-site resources. You can edit the question so it can be answered with facts and citations.\n\n\nClosed 6 years ago.\n\n\n\n\n\n\n\n                        Improve this question\n                    \n\n\n\nAFAIK there are not official TeamCity and Gitlab integration plugins, but is there any unofficial project doing this? I need to dynamically build merge requests created on Gitlab on TeamCity and provide feedback of the build status on merge request section.\nAnybody have achieved this? Is there any alternative using other CI server?"}, {"role": "assistant", "content": "Have you checked out Team Citys rather extensive REST API?https://confluence.jetbrains.com/display/TCD10/REST+API\nMaybe you can find what you're looking for there?"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "eb awscli cant deploy from git directory\n\nI'm getting started with the ElasticBeanstalk AWS CLI and I've changed some of my workflow around. Previously I deployed from a directory above my git repository (which is a clone of a private GitLab directory), and shifted things around.\nBefore it was structured like this:\n-- some_dir\n |-- .ebextensions\n | |- some_files \n |\n |-- my_git_directory\n   |- .git \n   |- some_files \n\nAnd when I run eb deploy:\n[some_dir] $ eb deploy\n... Everything is awesome.\n\nBut now, I've moved to try and deploy from the git directory, but things aren't working:\n-- some_dir\n |-- my_git_directory\n   |-- .ebextensions\n   | |- some_files \n   |- .git \n   |- some_files \n\n[some_dir/my_git_directory] $ eb deploy\n... Everything sucks.\nERROR: An error occurred while handling git command.\nError code: 128 Error: fatal: Not a git repository (or any of the parent directories): .git\n\nNow its all busted, and deploy no longer works. I've tried adding a branch and deploying a staged version:\n$ eb branch\nusage: eb (sub-commands ...) [options ...] {arguments ...}\neb: error: unrecognized arguments: branch\n\n$ eb deploy\nERROR: This branch does not have a default environment. \nYou must either specify an environment by typing \"deploy my-env-name\" or set a default environment by typing \"eb use my-env-name\".\n$ eb use  django-env2\n\n$ eb deploy --staged\n... Nope, still busted"}, {"role": "assistant", "content": "So I got it solved and it is surprisingly basic, but it might help others.\nIf you move where you are deploying from you need to re-initialise something (not sure what), and it was fixed by running:\neb init\n\nThen everything worked fine again."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab Self-Hosted: ERROR: Uploading artifacts as \"archive\" to coordinator... too large archive\n\nSome time ago, our Gitlab (self-hosted) instance started to throw errors that the archives are too big:\n\nERROR: Uploading artifacts as \"archive\" to coordinator... too large\narchive  id=something responseStatus=413 Request Entity Too Large\nstatus=413 token=something FATAL: too large\nERROR: Job failed: exit code 1\n\nThe only resolution ideas we found was to set the max build artifact size (it's under /admin/application_settings). This did not work for us, the error still occurred.\nReference articles:\n\nhttps://gitlab.com/gitlab-com/gl-infra/infrastructure/-/issues/3813\nhttps://dzone.com/articles/gitlab-ci-runner-artifacts-size-error-quottoo-larg\nhttps://www.kevinhooke.com/2018/07/30/gitlab-ci-runner-artifacts-size-error-too-large-archive/\nhttps://forum.gitlab.com/t/uploading-artifacts-too-large-archive-error-413/4867\nHow to increase maximum artifacts size for Gitlab on-premises"}, {"role": "assistant", "content": "From gitlab official docs:\nThe maximum size of the job artifacts can be set at:\n\nThe value is in MB and the default is 100MB per job.\n\nTo change it at the instance level:\nOn the top bar, select Menu > Admin.\nOn the left sidebar, select Settings > CI/CD.\nChange the value of maximum artifacts size (in MB).\nSelect Save changes for the changes to take effect.\nGroup level (this overrides the instance setting):\nTo change it at the group level:\nGo to the group\u2019s Settings > CI/CD > General Pipelines.\nChange the value of maximum artifacts size (in MB).\nSelect Save changes for the changes to take effect.\nProject level (this overrides the instance and group settings):\nTo change it at the project level:\nGo to the project\u2019s Settings > CI/CD > General Pipelines.\nChange the value of maximum artifacts size (in MB).\nSelect Save changes for the changes to take effect.\nRef: Maximum artifacts size"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Is it possible to have one Git repo placed on Github and Gitlab?\n\nIs it possible to have one git repo placed on both github and gitlab?\nSo that if you push to a remote repo that its both on Github and Gitlab."}, {"role": "assistant", "content": "You have misunderstood how Git works. Or how content hosting works.\nFirst of all, your repo is not on GitHub nor GitLab. Your repo is on your hard disk, right there where you cloned or created it. This is a repository. Local one. This is where you do the work *)\nOn GitHub and on GitLab you can setup remote copy of your repository. Then, after you did some work on your local repo, you can instruct your local repo to send those new bits of work to that remote copy. Or to another remote copy. Or to 50 remote copies held in different places.\nSecond fact is, GitHub and GitLab are separate. In fact, there is one GitHub, but there is no single GitLab. There are many GitLabs out there, you can even buy a server and host your own GitLab. This only emphasises that they are all separate. Whatever you send to GitHub will NOT magically show up on GitLab1, nor GitLab2, nor (..)\nThird fact, they are all separate, but they all allow you to host copies of your git repo. Since you can instruct your local repo to send things to multiple remotes, you can have them all in sync.\nHowever, pasting all the URLs to all servers each time you want to do a push would be cumbersome, so your local git repo can be taught to know the remote locations and remember them for you. This called remotes and you probably saw it already in form:\ngit push origin master\n          \\        \\\n           \\        branch to be pushed\n            name of the remote\n\norigin is the typical name for the-single-remote-server you work with. But if you want to have many, you probably want to set some meaningful names, like:\ngit remote add remote-github (url-to-repo-on-github)\ngit remote add remote-gitlab1 (url-to-repo-on-gitlab1)\ngit remote add remote-gitlab2 (url-to-repo-on-gitlab2)\n...\n\nThis sets up 3+ remotes with different names. Now you can:\ngit push remote-github master\ngit push remote-gitlab1 master\n\nand so on. That will work - basically, do code changes, commit, push them to 3+ servers, and you have \"same things on GitHub and GitLab\". Keep in mind that if you are not alone and if you let someone work on your code on GitHub/GitLab separately, everyone would need to push to all remotes at the same time and in the same order, or else it can diverge quickly.\nManually pushing to 2+ remotes can be somewhat cumbersome too, even if they are remembered by their names. That's why recent Git versions allow to set multiple push URLs under single name of a remote.\nAlso, Git repositories, and some Git hostings, support \"triggers\" or \"hooks\". These things allow you to set a script that will be executed every time something happens. Something like a commit or push. Using that you could instruct your hosting to, for example, at every received push do a push to the other remote repo. But I won't cover it, here&now, I think you already have enough keywords to search for!\n*) well, except for some semi-automated things like PRs/MRs/Reviews/Issues/etc - but that's specific to your workflow and support for it on the hosting site. Obviously, since sites are separate, and since support for features may differ, PRs/MRs/Reviews/../etc performed on one site will not magically transfer to other sites. If the specific feature is implemented via branches, then you can sync that via some hooks&scripting. Otherwise, you'd need to find a proper plugin for the site. Or, well, write it yourself. IIRC, at least GitLab has an API for that."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Use Gitlab Pipeline to push data to ftpserver\n\nI want to deploy to a ftp server using a Gitlab pipeline. \nI tried this code:\ndeploy: // You can name your task however you like\n    stage: deploy\n    only:\n        - master\n        deploy:\n  script:\n    - apt-get update -qq && apt-get install -y -qq lftp\n\nBut I get a error message. What is the best way to do this? :)"}, {"role": "assistant", "content": "Then add the following code in your .gitlab-ci.yml file.\nvariables:\n  HOST: \"example.com\"\n  USERNAME: \"yourUserNameHere\"\n  PASSWORD: \"yourPasswordHere\"\n\ndeploy:\n  script:\n    - apt-get update -qq && apt-get install -y -qq lftp\n    - lftp -c \"set ftp:ssl-allow no; open -u $USERNAME,$PASSWORD $HOST; mirror -Rnev ./public_html ./ --ignore-time --parallel=10 --exclude-glob .git* --exclude .git/\"\n  only:\n    - master\n\nThe above code will push all your recently modified files in your Gitlab repository into public_html folder in your FTP Server root.\nJust update the variables HOST, USERNAME and PASSWORD with your FTP Credentials and commit this file to your Gitlab Repository, you are good to go.\nNow whenever you make changes in your master branch, Gitlab will automatically push your changes to your remote FTP server."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to set a dynamic gitlab job tag with a variable?\n\nI am trying to create a dynamic job that can switch between two gitlab runners depending on which tag it is given.  I would like to do this with an environmental variable, but it seems this cannot be used.  The following job:\nrunner_test:\n  image: alpine\n  tags:\n    - $MY_RUNNER\n  stage: deploy_main\n  script:\n    - echo foobar\n  retry: 2\n\nResults in a paused pipeline with the error: This job is stuck because you don't have any active runners online or available with any of these tags assigned to them: $MY_RUNNER"}, {"role": "assistant", "content": "Dynamic job tags is achievable now (originally tested on 14.10, updated & tested on 16.2).  Variable interpolation works for job tags, however, an un-documented limitation is that variable changes within the job's YAML won't apply (even though the rules: keywords are supposed to be interpreted before anything else.)  This means that we need to set dynamic runner tags at the global level with the workflow:rules:variables key.\nThe following example would result in a default job tag of \"staging\" for most branches, and an override value of \"production\" for pipelines running against the project's default branch.\n# global pipeline variable for the default value\nvariables:\n  RUNNER_TAG: \"staging\"  # default CI variable value\n\n# global workflow:rules:variables can change variables outside of jobs\nworkflow:\n  rules:\n    # if the pipeline is on the default branch, then change the RUNNER_TAG variable\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n      variables:\n        RUNNER_TAG: \"production\"\n    # ensure pipeline still runs if above conditions are not met\n    - when: always \n\n# ci job using the dynamic runner tag\njob:\n  tags:\n    - $RUNNER_TAG\n  script:\n    - hello world from runner matching $RUNNER_TAG\n\nNOTE: workflow:rules:variables was added in version 13.11 via a feature flag, and made available without a feature flag in version 14.1"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab Cannot start runsv is not running\n\nI just upgraded my gitlab-ce version to the latest version using this command\nsudo yum install gitlab-ce-12.1.3-ce.0.el7.x86_64\n\nthe upgrade works well, but after restart the gitlab service won't start,\nwhen I run this command \nsudo gitlab-ctl start\n\nfail: alertmanager: runsv not running\nfail: gitaly: runsv not running\nfail: gitlab-monitor: runsv not running\nfail: gitlab-workhorse: runsv not running\nfail: grafana: runsv not running\nfail: logrotate: runsv not running\nfail: nginx: runsv not running\nfail: node-exporter: runsv not running\nfail: postgres-exporter: runsv not running\nfail: postgresql: runsv not running\nfail: prometheus: runsv not running\nfail: redis: runsv not running\nfail: redis-exporter: runsv not running\nfail: sidekiq: runsv not running\nfail: unicorn: runsv not running\n\nand then I try to start the gitlab-runsv by using this command \nsystemctl start gitlab-runsvdir.service\n\nBut it freezes and not doing anything!!, I must use the CTRL+C to quit\nand when I run the journal-ctl it don't showing anything.\njournalctl -u gitlab-runsvdir.service\n-- No entries --\n\nMy Environment is Centos 7."}, {"role": "assistant", "content": "I faced the problem on my ubuntu-20. Previously i had disabled my gitlab-runsvdir.service. That was the reason for my problem. so what i did\nsudo systemctl enable gitlab-runsvdir.service\nsudo systemctl start gitlab-runsvdir.service"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab API: How to generate the private token\n\nThis is what I tried:\ncurl http://git.ep.petrobras.com.br/api/v3/session --data-urlencode 'login=myUser&password=myPass'\n\nAnswer:\n{\"message\":\"401 Unauthorized\"}"}, {"role": "assistant", "content": "The problem is the data-urlencode CURL option. Since it's an HTTP POST you don't need to URL encode the data, and is actually encoding the & into &amp; and causing your issue. Instead use the --data option.\ncurl http://git.ep.petrobras.com.br/api/v3/session --data 'login=myUser&password=myPass'\n\nAlso, be careful sending credentials over plain HTTP. It could be easily sniffed."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Visual Studio - Remote: HTTP Basic: Access denied Error encountered while cloning the remote repository: Git failed with a fatal error\n\nI'm working with Visual Studio and am trying to clone a online repo from a  server where gitlab is running. Let's call the server https://gitlab.example.com\nI get the following error when I try to clone the repo \nRemote: HTTP Basic: Access denied\nError encountered while cloning the remote repository: Git failed with a fatal error.\nAuthentication failed for 'https://gitlab.example.com/username/test.git/'\n\nWhen I try it, I get promted to enter a username and password for the server. I entered the user credentials of the user which created the repo. \nI've found a similar problem with an answer here on stackoverflow, but this didn't work for me.\nI am using Visual Studio 2017 Enterprise 15.7.2"}, {"role": "assistant", "content": "Windows must have saved your git credentials which needs to be updated/remove. Below steps worked for me in VS2017.\nGo to \"Credential Manager\" from Windows \"Start\" and under \"Generic Credentials\" select your git url. Click on the right side arrow, it should expand and you should see two links \"Edit\" & \"Remove from vault\". \nClick on latter link (recommendable), restart VS, open your project & do a sync/pull request, it should ask your credentials to enter and you should be good to go. Thanks"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab Runner Docker login not working error during connect: Post http://docker:2375/v1.40/auth: dial tcp: lookup docker on 67.207.67.3:53\n\nI am using docker executor on gitlab runner as an image I am using docker:stable\nI am getting this error:\n$ docker login gitlab.mydomain.com:5050 -u myusername-p mytoken\nWARNING! Using --password via the CLI is insecure. Use --password-stdin.\nerror during connect: Post http://docker:2375/v1.40/auth: dial tcp: lookup docker on 67.207.67.3:53: no such host\nCleaning up project directory and file based variables\n00:01\nERROR: Job failed: exit code 1\n\nHere is my config.toml\nconcurrent = 1\ncheck_interval = 0\n\n[session_server]\n  session_timeout = 1800\n\n[[runners]]\n  name = \"dev-env\"\n  url = \"https://gitlab.mydomain.com/\"\n  token = \"REDACTED\"\n  executor = \"docker\"\n  [runners.custom_build_dir]\n  [runners.cache]\n    [runners.cache.s3]\n    [runners.cache.gcs]\n    [runners.cache.azure]\n  [runners.docker]\n    tls_verify = false\n    image = \"docker:stable\"\n    privileged = false\n    disable_entrypoint_overwrite = false\n    oom_kill_disable = false\n    disable_cache = false\n    volumes = [\"/cache\"]\n    shm_size = 0\n\nHere is my ci file\ndeploy-dev:\n  stage: deploy\n  before_script:\n    - apk add make\n  script:\n    - docker login gitlab.mydomain.com:5050 -u myusnerma -p mytoken\n  only:\n    - mybranch\n  tags:\n    - dev"}, {"role": "assistant", "content": "You must add the docker:dind service to your job configuration:\ndeploy-dev:\n  variables:\n    # these values may need to be different if using TLS, k8s, etc.\n    # You can alternatively set defaults in your runner config\n    DOCKER_TLS_CERTDIR: \"\"\n    DOCKER_HOST: \"tcp://docker:2375\"\n  services:\n    - docker:dind\n  # ...\n\nFor the dind container to work, your runner must allow privileged containers:\n  [runners.docker]\n    privileged = true\n    # ..."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab-ce 12.X : how do I find the hashed storage path of a repository on the server?\n\nWith gitlab-ce-12.x, Geo requires the storage path to be hashed (https://docs.gitlab.com/ee/administration/repository_storage_types.html) \nFor a given repository, the data will therefore be stored in :\n\"@hashed/#{hash[0..1]}/#{hash[2..3]}/#{hash}.git\"\nFrom a practical point of view, say I have a repository whose URL is \n\nhttps://my-gitlab-server/Group1/project1.git\n\nHow do I work out the path to the storage on the server ?\ni.e. how do i find the value of \n\n#{hash[0..1]}/#{hash[2..3]}/#{hash}\n\nThanks"}, {"role": "assistant", "content": "I found the answer to my question.\nIn order to get the hashed storage location of a project, you first need to get the project id of the project repository.\nOnce you get that project id, say your project id is 1, \nyou get the hash this way :\nSay project.id is 1\n\necho -n 1 | sha256sum\n\n=> You get the HASH\n6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b\nThe hashed storage location of your repository on the server will therefore be :\n\nserver/@hashed/6b/86/6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b.git\n\nThis has been discussed by gitlab developers in \nhttps://gitlab.com/gitlab-org/gitlab-ce/issues/63250"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to detect if test is running on GitLab CI server\n\nI have a test, which is using MySQL database configured and running on gitlab CI server (gitlab-ci.yml). I want that test to be disabled when it's running locally (it's using in-memory database instead). Is there any way to check if the test is running on GitLab Ci server? Something like:\nif(isRunningOnGitlabCi()) {\n  Assert.assertThat(...);\n}\n\nMaybe there's environmental variable, which I can check ?"}, {"role": "assistant", "content": "Gitlab CI defines a large number of environment variables; you could use e.g. GITLAB_CI.\nSomething like:\nif(System.getenv(\"GITLAB_CI\") != null) {\n  Assert.assertThat(...);\n}"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I change the default home page of my gitlab installation\n\nBy default my gitlab homepage starts www.mydomain.com/users/sign_in. I would like to change this to show 'www.mydomain.com/public' instead. How do I configure this?"}, {"role": "assistant", "content": "Setting custom startpage for non-logged in users:\n\nFrom \"Admin Area\" goto the gear on the left and choose \"Settings\"\nFind parameter \"Home page URL\" and set it to www.mygitlab.com/explore.\nOptional set \"After sign out path\" to same url\nClick save\n\nTested with version is 8.14.4 CE"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab Pages deployment step fails after successfull build\n\nI am trying to host a reveal.js presentation via gitlab pages. The repository can be found here: https://gitlab.com/JanGregor/demo-slides\nMy .gitlab-ci.yml is fairly simple:\nimage: node:4.2.2\n\npages:\n  cache:\n    paths:\n    - node_modules/\n  script:\n  - npm install\n  - node_modules/.bin/gulp\n  artifacts:\n    paths:\n    - build\n  only:\n  - master\n\nAfter a commit to master though, something goes wrong. The pages task itself is executed and runs just fine. It even shows in the logs that my build directory has been scanned and that the artefacts have been found.\nOddly, the subsequent pages:deploy task fails. It only says :\n\npages failed to extract\n\nAny help would be greatly appreciated, since I have no clue where to look to next. The documentation itself isn't really helpful when trying to implement an deployment flow with npm.\nThanks in advance folks !"}, {"role": "assistant", "content": "Apparently a page can only be published from a folder in under the artifacts that is called \"public\"."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab custom domain, failed to verify domain ownership\n\nI don't think I need to use the subdomain. I have created a A record and a TXT record as the doc suggests on namecheap.com. After wait for 24 hours, I sill get a failed to verify domain ownership error."}, {"role": "assistant", "content": "Remove your CNAME record. Also, remove the URL redirection and your first TXT record. You shouldn't be using both CNAME and A records together.\n\nIf using a DNS A record, you can place the TXT record directly under the domain. If using a DNS CNAME record, the two record types won't co-exist, so you need to place the TXT record in a special subdomain of its own. [source]\n\nSo your final configuration would be:\nA Record        @   35.185.44.232\nTXT Record      @   gitlab-pages-verification-code=XXXXXX"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Ruby Gems with Gitlab no such file to load -- rb-inotify\n\nI am using Gitlab and I am trying to follow these instructions to upgrade my gitolite v2 to v3:\n\"If this issue occurs in 2.9.x you should reinstall gitolite.\n1) backup all repositories. Just copy /home/git/repositories/* elsewhere.\n2) Install new gitolite. See https://github.com/gitlabhq/gitlabhq/blob/master/doc/installation.md\n3) copy repositories back.\n4) sudo -u gitlab -H bundle exec rake gitlab:gitolite:update_keys && sudo -u gitlab -H bundle exec rake gitlab:gitolite:update_repos\nThat's all.\nThat steps also related to users who wants to update gitolite v2 to v3\"\nMy Gemfile and Gemfile.lock have rb-inotify in them as shown below:\ngitlabhq@build:~/gitlabhq$ grep notify Gemfile\ngem 'rb-inotify', :require => linux_only('rb-inotify')\ngitlabhq@build:~/gitlabhq$ grep notify Gemfile.lock\nrb-inotify (0.8.8)\nrb-inotify\n\nI am trying to update my keys and repos using the following commands but I always get the error \"no such file to load --rb-inotify\"\ngitlabhq@geminibuild:~/gitlabhq$ sudo -u gitlabhq -H bundle exec rake gitlab:gitolite:update_keys\nrake aborted!\nno such file to load -- rb-inotify\n(See full trace by running task with --trace)\n\nI've tried to do a bundle install , and the list of 'Using \" does not contain the rb-notify gem.\nI've tried to install the rb-inotify gem like so:\nsudo -u gitlabhq gem install rb-inotify\n\nI've wiped the Gemfile.lock file and then run:\nsudo -u gitlabhq bundle install\n\nStill no luck.\nHow can I get Gitlab to recognize and use rb-inotify. Thank you -"}, {"role": "assistant", "content": "Recognizing that this is a bit old, I thought I'd leave something for posterity. In order to make these calls work you simply need to append:\n\nRAILS_ENV=production\n\nto your command. This is listed in the trouble shooting guide under the \"Gitlab\" section."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to combine rules in gitlab ci/cd\n\nI would like to create rule for:\nchanges in folder foo && branch = master && tag pushed\nMy current rules not working:\n  rules:\n    - if: $CI_COMMIT_TAG && '$CI_COMMIT_BRANCH == \"master\"'\n    - changes:\n        - foo/**/*\n\nLooks like gitlab take like a OR.\nWhat is wrong?"}, {"role": "assistant", "content": "As stated in the gitlab documentation:\n\nTo conjoin if, changes, and exists clauses with an AND, use them in the same rule.\n\nSo it should be:\n    rules:\n      - if: $CI_COMMIT_TAG && '$CI_COMMIT_BRANCH == \"master\"'\n        changes:\n          - foo/**/*"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Setup CI on Gitlab for Flutter\n\nI am trying to setup CI for my flutter project on gitlab but I don't understand where to start or what I have to do.\nCan anyone help me?\nThanks"}, {"role": "assistant", "content": "I suggest to setup your GitLab CI integration for flutter treating the android and ios project folder by their own in order to build your APK or IPA or doing test with your GitLab CI.\nTo start having a clue on how to setup a CI for Android and iOS projects on GitLab I'll suggest you these readings:\nAndroid:\n\nhttps://about.gitlab.com/2018/10/24/setting-up-gitlab-ci-for-android-projects/\n\niOS\n\nhttps://about.gitlab.com/2016/03/10/setting-up-gitlab-ci-for-ios-projects/\nhttps://medium.com/flawless-app-stories/how-to-set-up-gitlab-continuous-integration-for-ios-projects-without-a-hustle-53c2b642c90f\n\nUPDATE: using Fastlane\nI've the above solutions running on my apps and so I know they work. But I've found these interesting official docs for flutter using Fastlane (they seem quite easier):\n\nhttps://flutter.io/docs/deployment/fastlane-cd\nhttps://docs.fastlane.tools/best-practices/continuous-integration/gitlab/\n\nSo I suggest to give them a try too."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Tagging docker image with tag from git repository\n\nI am using Gitlab for repository and ci/cd.\nCurrently trying to set up pipeline that creates a docker image from a build stage.\nAll examples I have seen have a simple naming of image where e.g. the branch is used(master)\nMy question is if I want to tag the image based on the current tag in the repository how do I do this?\nI am presuming I can use a Gitlab runner variable but do not see one to us"}, {"role": "assistant", "content": "There are a lot of predefined variables in Gitlab CI. I think you are looking for CI_COMMIT_TAG.\nSo you could use it this way:\ndocker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_TAG\n\nSo the image would look like registry.example.com/group/project:tag"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to have a \"cache per package.json\" file in GitLab CI?\n\nI have a Vue web application that is built, tested and deployed using GitLab CI. \nGitLab CI has a \"Cache\" feature where specific products of a Job can be cached so that future runs of the Job in the same Pipeline can be avoided and the cached products be used instead.\nI'd like to improve my workflow's performance by caching the node_modules directory so it can be shared across Pipelines.\nGitLab Docs suggests using ${CI_COMMIT_REF_SLUG} as the cache key to achieve this. However, this means \"caching per-branch\" and I would like to improve on that.\nI would like to have a cache \"per package.json\". That is, only if there is a change in the contents of package.json will the cache key change and npm install will be run.\nI was thinking of using a hash of the contents of the package.json file as the cache key. Is this possible with GitLab CI? If so, how?"}, {"role": "assistant", "content": "This is now possible as of Gilab Runner v12.5\ncache:\n  key:\n    files:\n      - Gemfile.lock\n      - package-lock.json // or yarn.lock\n  paths:\n    - vendor/ruby\n    - node_modules\n\nIt means cache key will be a SHA checksum computed from the most recent commits (up to two, if two files are listed) that changed the given files. Whenever one of these files changes, a new cache key is computed and a new cache is created. Any future job runs using the same Gemfile.lock and package.json with cache:key:files will use the new cache, instead of rebuilding the dependencies.\nMore info: https://docs.gitlab.com/ee/ci/yaml/#cachekeyfiles\nAlso make sure to use always --frozen-lockfile flag in your CI jobs. (or npm ci) Regular npm install or yarn install / yarn commands generate new lock files and you wouldn't usually notice it until you install packages again. Thus makes your build artifacts and caches inconsistent."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "how do i create a merge request from a fork in gitlab\n\nI joined a project on which I've done some work. The work has now been validated and I need to create a merge request (back to master) from the changes I have pushed to my fork. But I don't understand how I can do this in gitlab...Can anybody help?"}, {"role": "assistant", "content": "To create a merge request to merge branch from forked repo into the branch of the upstream repo, you can use below steps:\nIn the forked repo -> Merge Requests -> select the branch from forked repo as the source branch, and select branch from the upstream repo as target branch -> Compare branches -> Specify the user Assign to -> Submit merge request.\nMore details, you can refer the document Merging upstream."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab-runner:Pipeling is pending infinitely\n\nI install a Specific Runners,and the status is actived.\nmy .gitlab-ci.ymi file code:\nstages:\n  - build\n\nbuild_maven:\n  stage: build\n  only:\n    - master\n  script:\n    - echo \"hello CI/CD\"\n  tags: \n    - vue-dev-pub\n\nwhen I push the master branch,the gitlab-runner is running,but it's pending infinitely\u3002\nthe job page show:\n\nThis job has not started yet\nThis job is in pending state and is waiting to be picked by a runner\n\nif I excute the runner manually,the job can pass.\nthe command of gitlab-runner verify shows:\nRuntime platform                                    arch=amd64 os=linux pid=24616 revision=d0b76032 version=12.0.2\nWARNING: Running in user-mode.                     \nWARNING: The user-mode requires you to manually start builds processing: \nWARNING: $ gitlab-runner run                       \nWARNING: Use sudo for system-mode:                 \nWARNING: $ sudo gitlab-runner...                   \n                                                   \nVerifying runner... is alive                        runner=T4iKvsT3\n\n\nI am waiting for you respond,thanks!"}, {"role": "assistant", "content": "If you run the runner manually in debug mode gitlab-runner --debug run you may see the actual error message, in my case it was:\nWARNING: Failed to process runner builds=0 error=failed to update executor: missing Machine options executor=docker+machine runner=pSUsX4yR\nThat's because on runner creation, I selected option docker+machine rather than docker.\nAfter amending /etc/gitlab-runner/config.toml to docker and running gitlab-runner restart followed by gitlab-runner verify, pipeline started running again."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab Pages custom domain allow www\n\nWhat do I need to do in order for my GitLab pages site (Jekyll) to be accessed under www.mydomain.com not just mydomain.com? I have SSL through CloudFlare.\nIn my DNS I have: \nmydomain.com A 104.208.235.32\nand CNAME points to myname.gitlab.io, and www points to myname.gitlab.io\nDo I need to create a subdomain of www and point those to GitLab as well? I'd like my site to be without www in the url, but if a user types in www they should still be able to access the site."}, {"role": "assistant", "content": "The configurations in the question are correct, what I didn't do is add both mydomain.com and www.mydomain.com as domains in GitLab (Settings icon > Pages > New Domain).\nGitLab then directs traffic to both www and the naked domain when both domains are listed."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "setting up gitlab LDAP-authentication without special gitlab user\n\nI want to set up Gitlab with our company's LDAP as a demo. But unfortunately I have to put in an admin password in gitlab.yml to make gitlab access the LDAP service. The problem actually is the administration, as they don't want to setup another account just for Gitlab. Is there any way to circumvent this without filling in my own password? Is there a way to make Gitlab establish the LDAP connection with only the provided user credentials?\nAny ideas beside logging in as anonymous?\nAlready posted here."}, {"role": "assistant", "content": "I haven't tried it yet, but from the things I've build so far authenticating against LDAP and the informations from the config-file this user-account seems only to be needed when your LDAP does not support anonymous binding and searching. \nSo I would leave the two entries bind_dn and password commented out and try whether it works or not.\nUPDATE\nI've implemented LDAP-Autehntication in Gitlab and it's fairly easy. \nIn the gitlab.yml-file there is a section called ldap.\nThere you have to provide the informations to connect to your LDAP. It seems that all fields have to be given, there seems to be no fallback default! If you want to use anonymous binding for retrieval of the users DN supply an empty string for bind_dn  and password. Commenting them out seems not to work! At least I got a 501 Error message.\nMore information can be found at https://github.com/patthoyts/gitlabhq/wiki/Setting-up-ldap-auth and (more outdated but still helpful) https://github.com/intridea/omniauth-ldap"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab runner fails to start. This job is stuck because you don't have any active runners online with any of these tags assigned to them: ios\n\nI have a remote runner: \n\nci$ gitlab-runner --version Version:      12.2.0\n\nThe .gitlab-ci.yml :\nstages:\n  - build\n  - deploy\n\nvariables:\n  LANG: \"en_US.UTF-8\"\n  LC_ALL: \"en_US.UTF-8\"\n\nbuild:\n  tags:\n    - ios\n  stage: build\n  script:\n    - bundle exec fastlane build\n  except:\n    - develop\n    - master\n    - /^rc\\/.*$/\n  environment:\n    name: production\n\ndeploy:\n  tags:\n    - ios\n  stage: deploy\n  before_script:\n    - 'which ssh-agent || ( apt-get update -y && apt-get install openssh-client git -y )'\n    - eval $(ssh-agent -s)\n    - echo \"$SSH_PRIVATE_KEY\" | tr -d '\\r' | ssh-add -\n    - mkdir -p ~/.ssh\n    - chmod 700 ~/.ssh\n    - ssh-keyscan gitlab.com >> ~/.ssh/known_hosts\n    - chmod 644 ~/.ssh/known_hosts\n    - ssh -vv [email\u00a0protected]\n    - git config --global user.email \"[email\u00a0protected]\"\n    - git config --global user.name \"username\"\n    - git branch\n    - git branch -r\n  script:\n    - bundle exec fastlane deploy\n  only:\n    - develop\n    - master\n    - /^rc\\/.*$/\n  environment:\n    name: production\n\npost:\n  stage: .post\n  when: always\n  script:\n    - bundle exec fastlane clear_data_CI\n\nGitlab CI fails to run, drops this warning first:\n\nThis job is stuck because the project doesn't have any runners online\n  assigned to it.\n\nGo to Runners page\nAnd later:\n\nThere has been a timeout failure or the job got stuck. Check your\n  timeout limits or try again\n\nSo tags are added, but it stopped running. Remote runner is working properly. Any issues?"}, {"role": "assistant", "content": "You have to make sure that the remote runner you are referring to is:\n\nActually running\nListed as an activated runner in your project's Runners section\nConfigured to follow/listen to the same tags\n\nGo to your repo's Gitlab project settings. Then find the section for CI / CD > Runners. You should see something like the image below:\n\nHere we see that there is a runner (df51f559) configured for the project, and it is running (green). If your repo's .gitlab-ci.yml is using tags, then that runner must also have the same tags. So here, if your job is expecting a runner with ios tag, then this UI should also show the runner to have an ios tag.\nYou can verify the runner token using gitlab-runner verify or list:\nroot@buildpc:~# gitlab-runner verify\n...\nVerifying runner... is alive             runner=df51f559\n\nroot@buildpc:~# gitlab-runner list\nmy-runner                                Executor=docker Token=df51f55995e68cccb3ada8c1458ec7 URL=http://192.168.1.61/\n\nHere my-runner's\n\nToken must match the token displayed in the Runners page\nURL must match the base URL of your Gitlab project\n\nIf you can't see an activated runner, that section has instructions on how to register a new runner for your project. You can also refer to Gitlab's Registering Runners help docs.\nIf you have admin access to your Gitlab instance, you can also go to the Admin dashboard, Runners, select a runner from the available ones, then manually add it to your project. You can also edit the tags.\n\nLastly, as mentioned in the comments, if you originally had no active runners then you successfully added one, you need to restart the job. AFAIK, when a job gets stuck because there is no runner, it does not automatically resume when a runner becomes available. You'll have to manually retry or re-trigger the job."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "A Gitlab \"import in progress\" never ends\n\nI was importing a Gitlab project from another repository to this new one, but for three days I see a message \"Import in progress\" and it never ends. I am not able to find any options to delete this repo as well. Has anyone come across a similar situation and knows how to delete this repo?"}, {"role": "assistant", "content": "(Answer added on behalf of the OP).\nJust click on the project and select the other settings from the left hand panel at the bottom. (Note: the usual settings available on the right top corner of the page will not be visible since the project is broken due to a bug in importing in gitlab). Then you can delete the project and recreate it again."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab / Redmine automatic close issue with commit\n\nWe are using Gitlab (7.10.2) and Redmine (3.0.2).\nAll issues are managed in Redmine and Gitlab manages all git-repositories.\nWe set up Gitlab via the UI so far that commits with the message 'Close #234' are clickable and pointing to the corresponding Redmine ticket website.\nWe now want to achieve that tickets in Redmine are directly linked with Gitlab commits.\nIf we are using the internal Gitlab issue system and set the commit-message to \u2018Close #234\u2019 the ticket 234 is automatic closed and linked with the commit.\nBut with Redmine as issue service system we are not able to automatic close issues with commits or have any information about this in Redmine.\nDoes anyone knows how we can modify Gitlab and/or Redmine to close Redmine tickets with Gitlab commits?"}, {"role": "assistant", "content": "You can use Redmine as an issue tracker with setting the redmine service in Gitlab (In your project -> Services -> Redmine -> fill the URLs, and set active). If this works, when you press \"new issue\" button in Gitlab, you are redirected to Redmine new issue page. In Gitlab you should have WebHook to inform the Redmine about new push into the repo. This can be set in the settings \"In your project -> Settings -> Web hooks\" (how, see here).\nIn Redmine go to Administration -> Settings -> Repositories. Check your referencing keywords. \"closes\" or \"close\" should be in the list. Finally in the same tab there is the table at the bottom, where you choose tracker, your fixing keyword (closes, close), set applied status to \"Closed\", and choose the appropriate amount of % Done (100%). \nSimilarly you can set other keywords to change status in Redmine tickets.\nUse the redmine_gitlab_hook to keep Redmine repo up-to date."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What's the purpose of actions/checkout@v3, when the repository is already checked out on job start?\n\nI've previously used GitLab, where I didn't checkout the repository explicitly. Instead it was done automatically by the pipeline.\nThus, I was surprised that almost all GitHub Actions workflows use e.g. actions/checkout@v3.\nBut what's the purpose besides checking out a different repository?\nAs seen from the below screenshot, my repository is already checked out, when the job starts:"}, {"role": "assistant", "content": "By default, this action will check-out to the SHA for that workflow\u2019s event (such as push and pull_request). Otherwise, uses the default branch (usually main or master in a standard repository).\n\nYou should use the checkout action any time your workflow will use the repository's code.\nhttps://docs.github.com/en/actions/learn-github-actions/understanding-github-actions#understanding-the-workflow-file\n\n\nThis action checks-out your repository under $GITHUB_WORKSPACE, so your workflow can access it.\nhttps://github.com/actions/checkout\n\nSo you can specify the repo, branch, path, submodule and so on to which you can checkout. Also you can use fetch-depth to include git history as necessary.\nAlso note, that it's cloning the files to $GITHUB_WORKSPACE."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "npm publish fails with GitLab NPM registry\n\nI have tried to make use of the new NPM registry that's now part of the free GitLab edition. I am attempting to create a NPM package and publish it on our company's GitLab instance. When attempting to run npm publish, the process exits with the error:\nnpm ERR! code E404\nnpm ERR! 404 Not Found - PUT https://gitlab.myemployer.com/api/v4/projects/1873/packages/npm/@sqt-klu%2fodysseus-nn-core\nnpm ERR! 404\nnpm ERR! 404  '@sqt-klu/[email\u00a0protected]' is not in the npm registry.\nnpm ERR! 404 You should bug the author to publish it (or use the name yourself!)\nnpm ERR! 404\nnpm ERR! 404 Note that you can also install from a\nnpm ERR! 404 tarball, folder, http url, or git url.\n\nThis problem appears when run through GitLab CI/CD as well as through the local command line.\nFor reference, our internal GitLab's URL is gitlab.myemployer.com/sqt-klu/odysseus/nn-core. As such, I presume @sqt-klu is the scope GitLab wants.\nThe CI/CD file (and what I have been trying to replicate locally) does this before npm publish during the before_script phase:\n    - npm config set @sqt-klu:registry https://gitlab.myemployer.com/api/v4/projects/${CI_PROJECT_ID}/packages/npm/\n    - npm config set https://gitlab.myemployer.com/api/v4/projects/${CI_PROJECT_ID}/packages/npm/:_authToken ${CI_JOB_TOKEN}\n\nLocally, my user-level npmrc is as following (actual token is removed but it is a personal access token that has been assigned all possible scopes):\naudit-level=high\npython=c:\\Python27\\python.exe\nhttps://gitlab.myemployer.com/api/v4/projects/1873/packages/npm/:_authToken=redacted\n@sqt-klu:registry=https://gitlab.myemployer.com/api/v4/projects/1873/packages/npm/\n\nAnd if it's relevant, here are the crucial contents of package.json (I've omitted contributors, dependencies, devDependencies, engine and author in this excerpt):\n{\n  \"name\": \"@sqt-klu/odysseus-nn-core\",\n  \"version\": \"0.0.1\",\n  \"license\": \"UNLICENSED\",\n  \"publishConfig\": {\n    \"@sqt-klu:registry\":\"https://gitlab.myemployer.com/api/v4/projects/1873/packages/npm/\"\n  }\n}\n\nI have also tried a few different package names as per this official guide, to no avail.\nI feel like I am missing something very trivial, but I am stuck on this. Any helpful pointers or ideas are appreciated.\nNote: I have replaced the FQDN of the endpoint in all mentions in case my employer gets grumpy about this."}, {"role": "assistant", "content": "404 errors can, confusingly perhaps, refer to problems with credentials in this situation.\nYou should replace\nhttps://gitlab.myemployer.com/api/v4/projects/${CI_PROJECT_ID}/packages/npm/:_authToken\n\nwith:\n//gitlab.myemployer.com/api/v4/projects/${CI_PROJECT_ID}/packages/npm/:_authToken\n\nAll other settings look okay* and should work. By default, a Gitlab project should have the package repository feature enabled. You can en/disable it in the project settings.\n\n* you could reduce the scope of your personal access token to just api.\nWhen/if you use project-level or org/group-level deploy tokens, they only need read_package_registry and/or write_package_registry."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to determine if GitLab installation is Omnibus or via source?\n\nI'm researching the process of migrating GitLab from an old server to a new server. One of the first things I need to do is determine which installation GitLab is in (Omnibus vs. source), and I'm unable to tell. \nThis post (omnibus or source - can't decide which one to use for gitllab backup/restore) mentions looking for a .git file in the GitLab root folder (/home/git/gitlab) - I don't see a .git file there. So, by that comment the installation was Omnibus.\nHowever, looking at this post (Checking of GitLab version), I'm unable to run: \nsudo gitlab-rake gitlab:env:info (shown for Omnibus installation)\nBut I can run: \nbundle exec rake gitlab:env:info RAILS_ENV=production (shown for source installation)\nI'm seeing conflicting answers. How can I tell which installation GitLab is in? \nIn any case, when I run the last command, I get the following results (if it helps): \n\nSystem information\n  System:     Debian 7.10\n  Current User:   git\n  Using RVM:  no\n  Ruby Version:   2.0.0p247\n  Gem Version:    2.0.3\n  Bundler Version:1.7.2\n  Rake Version:   10.1.0\nGitLab information\n  Version:    6.0.2\n  Revision:   10b0b8f\n  Directory:  /home/git/gitlab\n  DB Adapter: mysql2\n  URL:        http://107.178.218.39\n  HTTP Clone URL: http://107.178.218.39/some-project.git\n  SSH Clone URL:  [email\u00a0protected]:some-project.git\n  Using LDAP: no\n  Using Omniauth: no\nGitLab Shell\n  Version:    1.7.0\n  Repositories:   /home/git/repositories/\n  Hooks:      /home/git/gitlab-shell/hooks/\n  Git:        /usr/bin/git"}, {"role": "assistant", "content": "You should Check this file is available: \n/etc/gitlab/gitlab.rb\nIf not then it installed from source. My advice is to change your install to a omnibus install, it makes it much easier to upgrade.\nRead this for more info about upgrading to omnibus installation: https://docs.gitlab.com/omnibus/update/README.html#upgrading-from-a-non-omnibus-installation-to-an-omnibus-installation\nUpdate 1\n\nNote if MySQL is used as a database you have to do a conversion see the documentation https://gitlab.com/gitlab-org/gitlab-ce/blob/master/doc/update/mysql_to_postgresql.md\n\nTo upgrade a installation from source, you have 2 options:\n\nMake sure you have an omnibus-gitlab package matching your current GitLab version. (If possible I would upgrade for the last time from source)\n\n1. Install gitlab with omnibus on the same server. \n\nBefore you begin, make a snapshot from the server to be sure you can always return to a working point. Also make sure the shutdown gitlab.\n\nYou should install gitlab by using the omnibus option:\nsudo apt-get install curl openssh-server ca-certificates postfix\ncurl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.deb.sh | sudo bash sudo apt-get install gitlab-ce\n\nThe omnibus en the source install can be installed at the same time on the server. You can always change back yo the source install if something goes wrong.\nThen following the instruction in the documentation: https://docs.gitlab.com/omnibus/update/README.html#upgrading-from-non-omnibus-postgresql-to-an-omnibus-installation-in-place\n2. Install gitlab by backup. \nWhen you use a backup you can even transfer you gitlab installation to a new server. I used this way, and it was very easy.\n\nBefore you make your backup, shutdown gitlab so you can be sure there is nothing changed between your backup and restore process\n\nTo start, make a backup:\nsudo -u git -H bundle exec rake gitlab:backup:create RAILS_ENV=production\nSee also the documenation this coverage to much info to put here.\nAfter that you can move you backup to the new gitlab server or use it later to import it.\nTo import it in the omnibus install (in short, but read the documentation):\nsudo cp 1393513186_gitlab_backup.tar /var/opt/gitlab/backups/\nsudo gitlab-ctl stop unicorn\nsudo gitlab-ctl stop sidekiq\n# Verify\nsudo gitlab-ctl status\n\nsudo gitlab-rake gitlab:backup:restore BACKUP=1393513186\n\nsudo gitlab-ctl start\nsudo gitlab-rake gitlab:check SANITIZE=true\n\nSince you say it is about a live environment. You can do the following, setup a tiny server/ or on you local machine to do upgrade the process so you feel comfortable with it. After that you can do the same on the live env."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "In gitlab, how to set \"pipelines must succeed\" only for specific branches but not others for a merge request to merge?\n\nIn the merge checks settings, I have enabled the \"pipelines must succeed\" option:\n\nBut the branches without any jobs are stuck at merge by saying \"waiting for pipelines status\" and you can't merge without a successful pipeline.\nCan I enable the \"pipelines must succeed\" option only for some specific branches like master/production?"}, {"role": "assistant", "content": "As a workaround, you can trigger a merge request pipeline from the branches that don't currently have any jobs. The pipeline can have a single job that always passes. A merge request pipeline will only be created after a MR is created, not before.\nA simple job like this should work:\nprint-info:\n  stage: setup\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\" && $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH\n  script:\n    - 'echo \"Job start: $CI_JOB_STARTED_AT\"'\n    - 'echo \"Branch: $CI_COMMIT_BRANCH\"'\n    - 'echo \"Commit Author: $CI_COMMIT_AUTHOR\"'\n\n\nNote: I'm not sure what your current pipeline looks like, so you may have to change the rules section to suit your needs."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Getting docker error while using shell gitlab-runner ERRO[0000]\n\nHello I got this error at the installation,\nwhen I use the command \"gitlab-runner run\" or \"gitlab-runner start\":\nERRO[0000] Docker executor: prebuilt image helpers will be loaded from /var/lib/gitlab-runner\n\nThe strange thing about it is, I using a shell runner.\nI also tried on another server with no problems.\nEven I tried it with a docker build and without.\nI installed via\napt install gitlab-runner\n\nAlso I upgraded it and updated also. Rebuild the server (digitalocean droplet Ubuntu20.04)) and jep ... dont know what is going on.\nHere also some output og the gitlab-runner:\nroot@Server:~# gitlab-runner verify\nERRO[0000] Docker executor: prebuilt image helpers will be loaded from /var/lib/gitlab-runner.\nRunning in system-mode.\n\nVerifying runner... is alive                        runner=xVNzfox5\n\nroot@Server:~# gitlab-runner list\nERRO[0000] Docker executor: prebuilt image helpers will be loaded from /var/lib/gitlab-runner.\nListing configured runners                          ConfigFile=/etc/gitlab-runner/config.toml\ntest                                                Executor=shell Token=JustAToken\nURL=https://gitlab.com/\n\nAll I found about this error was about docker runner, but like I said I use a shell runner.\nThanks if someone can help."}, {"role": "assistant", "content": "Using this command apt-cache policy gitlab-runner, you will notice that only version 11.2.0 of gitlab-runner is available on the repositories, which is not supported by Gitlab.\nFollow the official documentation to install the latest version 14.2.0.\n$ sudo curl -L --output /usr/local/bin/gitlab-runner \"https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-amd64\"\n$ sudo chmod +x /usr/local/bin/gitlab-runner\n$ sudo useradd --comment 'GitLab Runner' --create-home gitlab-runner --shell /bin/bash\n$ # Optional sudo rm /etc/systemd/system/gitlab-runner.service\n$ sudo gitlab-runner install --user=gitlab-runner --working-directory=/home/gitlab-runner"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "how to use private GitLab repository as npm dependency with private token through https\n\nI'm trying to use a private GitLab repo as npm dependency in my node js app, with a private token key, something like this:\n\"dependencies\": {\n     \"my-module\": \"git+https://<privateToken>:x-oauth-basic@<myGitLabURL>/<MyUser>/my-module.git\"\n}\n\nwhen I run npm install I get errors about the git clone with fatal: unable to access <git repo path> with 443 Connection refused replies.\nI couldn't find a lot of documentation of how to do this through https and not through ssh.\nIt seems like it does work on GitHub\nAnybody have experience with this on GitLab with Https?"}, {"role": "assistant", "content": "This answer worked for me.\n\"my-module\": \"https://oauth2:<PersonalAccessToken>@gitlab.com/<group>/<repository-name>.git\n\nYou can create a Personal Access Token under User Settings->Access Tokens (GitLab.com Link)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Omnibus GitLab on IP without a domain-name and with custom relative_url_root\n\nI already know that you can download and install gitlab with the omnibus package(easy way). But I'm caught at the configuration of the IP / domain. Because I don't have a domain I want to use my static server IP like this:\nSudo gitlab-ctl reconfigure -> \"133.713.37.01/gitlab\"\nIs it even possible to set up gitlab without a domain or am I doing something wrong?\nI'm grateful for any help"}, {"role": "assistant", "content": "Using an IP directly seems to work, since most networking utilities accept either: just add external_url \"http://127.0.0.1\" to /etc/gitlab/gitlab.rb and run sudo gitlab-ctl reconfigure.\nWhat does not work is adding the /gitlab root path to the external_url: gitlab-ctl says:\nRuntimeError\n------------\nUnsupported external URL path: /gitlab\n\nServing from a relative URL root seems to be simply not implemented on Omnibus GitLab (since no template variable is inserted there).\nYou could work around that by modifying all the required configuration files manually as explained in the comment on gitlab.yml, but that would really be a lot of manual work and those configs would get overwritten if you reconfigure, so I recommend you request the feature on the GitLab forum and send a pull request implementing that."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Can Gerrit work in front of Gitlab or is it meant to replace it\n\nI don't think I'm really understanding how Gerrit can fit into my group's existing workflow. Is Gerrit intended to be the central \"hub\" of code? I have been imagining it as similar to Atlassian's Crucible, which fits in with Atlassian's Stash or Bitbucker.\nMy group currently uses a very active Gitlab installation but the built-in code review facility is lacking, and I absolutely must inspect code from contractors going into the repo.\nI need a behind-the-firewall solution, and cost is a big consideration. I have heard positive things about Gerrit, but not really an explanation of how it can fit into an existing process. I also like that it seems to have pretty good eclipse integration.\nCan someone help me out?"}, {"role": "assistant", "content": "Gerrit expects to \"own\" the repositories you use it with, i.e. it expects the git directories to be present in a mounted file system. If you want it to interact with GitLab (or GitHub) you can set up one way replication from Gerrit to GitLab so that changes made in Gerrit will be pushed to GitLab within a few seconds. For GitHub there's a Gerrit GitHub plugin to help with this.\nYou can continue to use the other features of GitLab but if you don't lock down the repositories (or at least block pushes into branches that Gerrit manages) you'll end up in trouble the next time Gerrit attempts to replicate to the GitLab repository.\nSo... Gerrit does replace GitLab's repository management and code review facilities but doesn't contain an issue tracker, wiki, or similar."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How can I get a gitlab pipeline to stop and ask me to input variables?\n\nI have created a pipeline in gitlab, with \nimage:\n  name: hashicorp/terraform:light\n  entrypoint:\n    - '/usr/bin/env'\n    - 'PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\n\nvariables:\n  PLAN: dbrest.tfplan\n  STATE: dbrest.tfstate\n\ncache:\n  paths:\n    - .terraform\n\nbefore_script:\n  - terraform --version\n  - terraform init\n\nstages:\n  - validate\n  - build\n  - deploy\n  - destroy\n\nvalidate:\n  stage: validate\n  script:\n    - terraform validate\n\nplan:\n  stage: build\n  script:\n    - terraform plan -state=$STATE -out=$PLAN\n  artifacts:\n    name: plan\n    paths:\n      - $PLAN\n      - $STATE\n\napply:\n  stage: deploy\n  environment:\n    name: production\n  script:\n    - terraform apply -state=$STATE -input=false $PLAN\n    - terraform state show aws_instance.bastion\n  dependencies:\n    - plan\n  when: manual\n  only:\n    - master\n\ndestroy:\n    stage: destroy\n    environment:\n      name: production\n    script:\n      - terraform destroy -state=$STATE -auto-approve\n    dependencies:\n      - apply\n    when: manual\n    only:\n      - master\n\nI have also created a variable under 'Settings. -> 'CI/CD' -> 'Variables' - I was under the impression that when I came to the manual stage deploy, gitlab should pause and ask me to input a value for that variable, but this does not happen - what is missing?"}, {"role": "assistant", "content": "You have mixed a job with when: manual to when you trigger a pipeline manually. This is the one you want:\nhttps://docs.gitlab.com/ee/ci/pipelines/#run-a-pipeline-manually\nYou could use this together with an only for some variable. Something like:\n...\napply:\n  stage: deploy\n  environment:\n    name: production\n  script:\n    - terraform apply -state=$STATE -input=false $PLAN\n    - terraform state show aws_instance.bastion\n  dependencies:\n    - plan\n  only:\n    refs:\n      - master\n    variables:\n      - $RELEASE == \"yes\" \n\ndestroy:\n    stage: destroy\n    environment:\n      name: production\n    script:\n      - terraform destroy -state=$STATE -auto-approve\n    dependencies:\n      - apply\n    only:\n      refs:\n        - master\n      variables:\n        - $RELEASE == \"yes\" \n\nWith something like this, you can have jobs that are never run normally, but only if you manually start a new pipeline on the master branch and set the variable $RELEASE to yes. I haven't tested this, so my apologies if it doesn't work!"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to set environmental variables properly Gitlab CI/CD and Docker\n\nI am new to Docker and CI/CD with Gitlab CI/CD. I have .env file in the root directory of my Django project which contains my environmental variable e.g SECRET_KEY=198191891. The .env file is included in .gitignore. I have set up these variables in Gitlab settings for CI/CD. However, the environment variables set in Gitlab CI/CD settings seem to be unavailable\nAlso, how should the Gitlab CI/CD automation process create a user and DB to connect to and run the tests? When creating the DB and user for the DB on my local machine, I logged into the container docker exec -it <postgres_container_name> /bin/sh and created Postgres user and DB. \nHere are my relevant files.\ndocker-compose.yml\nversion: \"3\"\nservices:\n  postgres:\n    image: postgres\n    ports:\n      - \"5432:5432\"\n    volumes:\n      - pgdata:/var/lib/postgresql/data/\n  web:\n    build: .\n    command: /usr/local/bin/gunicorn writer.wsgi:application -w 2 -b :8000\n    environment:\n      DEBUG: ${DEBUG}\n      DB_HOST: ${DB_HOST}\n      DB_NAME: ${DB_NAME}\n      DB_USER: ${DB_USER}\n      DB_PORT: ${DB_PORT}\n      DB_PASSWORD: ${DB_PASSWORD}\n      SENDGRID_API_KEY: ${SENDGRID_API_KEY}\n      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}\n      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}\n      AWS_STORAGE_BUCKET_NAME: ${AWS_STORAGE_BUCKET_NAME}\n    depends_on:\n      - postgres\n      - redis\n    expose:\n      - \"8000\"\n    volumes:\n      - .:/writer-api\n  redis:\n    image: \"redis:alpine\"\n  celery:\n    build: .\n    command: celery -A writer worker -l info\n    volumes:\n      - .:/writer-api\n    depends_on:\n      - postgres\n      - redis\n  celery-beat:\n    build: .\n    command: celery -A writer beat -l info\n    volumes:\n      - .:/writer-api\n    depends_on:\n      - postgres\n      - redis\n  nginx:\n    restart: always\n    build: ./nginx/\n    ports:\n      - \"80:80\"\n    depends_on:\n      - web\nvolumes:\n  pgdata:\n\n.gitlab-ci.yml\nimage: tmaier/docker-compose:latest\n\nservices:\n  - docker:dind\n\nbefore_script:\n  - docker info\n  - docker-compose --version\n\nstages:\n  - build\n  - test\n  - deploy\n\nbuild:\n  stage: build\n  script:\n    - echo \"Building the app\"\n    - docker-compose build\n\ntest:\n  stage: test\n  variables:\n  script:\n    - echo \"Testing\"\n    - docker-compose run web coverage run manage.py test\n\ndeploy-staging:\n  stage: deploy\n  only:\n    - develop\n  script:\n    - echo \"Deploying staging\"\n    - docker-compose up -d\n\ndeploy-production:\n  stage: deploy\n  only:\n    - master\n  script:\n    - echo \"Deploying production\"\n    - docker-compose up -d\n\nHere are my settings for my variables\n\nHere is my failed pipeline job"}, {"role": "assistant", "content": "The SECRET_KEY variable will be available to all your CI jobs, as configured. However, I don't see any references to it in your Docker Compose file to pass it to one or more of your services. For the web service to use it, you'd map it in like the other variables you already have.\n  web:\n    build: .\n    command: /usr/local/bin/gunicorn writer.wsgi:application -w 2 -b :8000\n    environment:\n      SECRET_KEY: ${SECRET_KEY}\n      DEBUG: ${DEBUG}\n      \u2026\n\nAs for creating the database, you should wrap up whatever you currently run interactively in the postgres container in a SQL file or shell script, and then bind-mount it into the container's initialization scripts directory under /docker-entrypoint-initdb.d. See the Initialization scripts section of the postgres image's description for more details."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to obtain GitLab Personal Access Token from command line\n\nIs there any possibility to get Personal Access Token for Gitlab API via command line rather than web interface? I'm working on some integration tests, and Gitlab deployment into the clean environment is a part of test session setup. After deployment test user is doing some work with Gitlab API. In order to access API, test user need to provide Personal Access Token.\nI managed to dump traffic, and I see that token is provided within a rendered HTML template in response to POST request:\n00:06:40.616996 IP6 localhost.amanda > localhost.53808: Flags [P.], seq 1:580, ack 1054, win 497, options [nop,nop,TS val 3133641719 ecr 3133641673], length 579\n`..U.c.@................................'`.0...y.eIz.....k.....\n........HTTP/1.1 302 Found\nServer: nginx\nDate: Tue, 21 Nov 2017 21:06:40 GMT\nContent-Type: text/html; charset=utf-8\nContent-Length: 119\nConnection: keep-alive\nCache-Control: no-cache\nLocation: http://localhost:10080/profile/personal_access_tokens\nX-Content-Type-Options: nosniff\nX-Frame-Options: DENY\nX-Request-Id: 88178813-95ad-419a-b56b-5a5ddb183885\nX-Runtime: 0.044209\nX-Ua-Compatible: IE=edge\nX-Xss-Protection: 1; mode=block\nX-Accel-Buffering: no\n\nDeep inside response:\n<input type=\"text\" name=\"created-personal-access-token\" id=\"created-personal-access-token\" value=\"j1WZujuaKVVEkh8h8Fej\" readonly=\"readonly\" class=\"form-control js-select-on-focus\" aria-describedby=\"created-personal-access-token-help-block\" />\n\nHowever, it seems too be dirty to POST HTML Form and then parse resulting HTML in order to get the token. Can anyone share the secret how to do it right?"}, {"role": "assistant", "content": "Workaround based on HTML parsing: https://github.com/vitalyisaev2/gitlab_token"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI: Cannot find output of build stage\n\nI have my .gitlab-ci.yml file set up in the typical three stages: test, build, deploy. During the build stage, I run a command that compiles my project and puts it in a tarball. The build stage appears to execute successfully because it moves on to the deploy stage, but the deploy stage then says it can't find the tarball. Is it in another directory? What happened to it? Thanks."}, {"role": "assistant", "content": "For each test gitlab-ci clean the build folder, therefore the output files of the build stage are not available in the deploy stage.\nYou need to rebuild your project also in the deploy stage.\nThe \"stages\" are only useful to order your tests, i.e. avoid to try to do a deploy test if a build test failed.\nEDIT:\nSince Gitlab 8.6, it is possible using dependencies feature"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab postfix configuration mail not sending\n\nI installed GitLab on my Ubuntu 12.04 server. Now I can login as an Administrator, do some stuffs, however, my question is the email seems to be not workin. I need to confirm the confirmation email sent to my address.\nI installed postfix as per instruction by our the readme. How can I test my postfix or configure GitLab configuration."}, {"role": "assistant", "content": "In case your ISP is blocking port 25 (this happens apparently quite often and was the case for me as well) you can use Gmail as a Relay. The following instructions are from here and walk you step-by-step through the process:\nIn /etc/postfix/main.cf add:\n# Relaying Postfix SMTP via GMAIL\nrelayhost = [smtp.gmail.com]:587\nsmtp_sasl_auth_enable = yes\nsmtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd\nsmtp_sasl_security_options = noanonymous\nsmtp_tls_CAfile = /etc/postfix/cacert.pem\nsmtp_use_tls = yes\n\nThen you need to setup the Gmail credentials. For this open/create /etc/postfix/sasl_passwd and write:\n[smtp.gmail.com]:587    [email\u00a0protected]:PASSWORD\n\nWhere (as you might have guessed) USERNAME and PASSWORD are your credentials. Then change permissions for the file:\n$ sudo chmod 400 /etc/postfix/sasl_passwd\n$ sudo postmap /etc/postfix/sasl_passwd\n\nNow we need to add the certificate to Postfix:\n$ cat /etc/ssl/certs/Thawte_Premium_Server_CA.pem | sudo tee -a /etc/postfix/cacert.pem\n\nJust restart postfix and you should be good:\n$ sudo service postfix restart\n\nIf you want to test:\n$ echo \"Hello World\" | mail -s \"Test Message\" [email\u00a0protected]\n\nAnd check what the mail log thinks about it:\n$ tail /var/log/mail.log\n\nNote: You only have 500 emails per day using Gmail's SMTP Server as Relay."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab email notifications not sending\n\nI just recently install GitLab v5.0 on an Ubuntu 12.04 server and am now having issues with email notifications.  I can't get GitLab to send any emails of any kind.\nI've got my config/environments/production.rb file setup to use sendmail as the transport service:\nconfig.action_mailer.delivery_method = :sendmail\nconfig.action_mailer.perform_deliveries = true\nconfig.action_mailer.raise_delivery_errors = true\n\nAnd I can manually use sendmail successfully from the shell as described here: http://scratching.psybermonkey.net/2011/03/sendmail-how-to-test-sending-email.html\nMy config/gitlab.yml file is setup with the following email setting:\nemail_from: [email\u00a0protected]\n\nI've read that it could be a problem with Sidekiq not running so I ran the following command but nothing has changed.. I still can't send emails:\n$ sudo -u git -H bundle exec rake sidekiq:start RAILS_ENV=production\n$ ps aux |grep -i sidekiq\ngit       2791  2.1  4.2 206476 86620 pts/0    Sl   14:45   0:23 sidekiq 2.7.5 gitlab [0 of 25 busy] \n\nWhich indicates to me that Sidekiq is indeed running... what else could be the issue here?  There doesn't seem to be much documentation on GitLab's wiki regarding email settings unfortunately...\nI found the following error being logged in sidekiq.log:\n2013-04-24T21:09:01Z 2791 TID-1jaur8 Sidekiq::Extensions::DelayedMailer JID-21bd3ec0f086351088992396 INFO: start\n2013-04-24T21:09:01Z 2791 TID-1jaur8 Sidekiq::Extensions::DelayedMailer JID-21bd3ec0f086351088992396 INFO: fail: 0.004 sec\n2013-04-24T21:09:01Z 2791 TID-1jaur8 WARN: {\"retry\"=>true, \"queue\"=>\"default\", \"timeout\"=>30, \"class\"=>\"Sidekiq::Extensions::DelayedMailer\", \"args\"=>[\"---\\n- !ruby/class 'Notify'\\n- :new_user_email\\n- - 4\\n - pSzzULp8\\n\"], \"at\"=>1366819034.5969028, \"jid\"=>\"21bd3ec0f086351088992396\", \"error_message\"=>\"Couldn't find User with id=4\", \"error_class\"=>\"ActiveRecord::RecordNotFound\", \"failed_at\"=>\"2013-04-24T15:57:19Z\", \"retry_count\"=>10, \"retried_at\"=>2013-04-24 21:09:01 UTC}\n2013-04-24T21:09:01Z 2791 TID-1jaur8 WARN: Couldn't find User with id=4\n2013-04-24T21:09:01Z 2791 TID-1jaur8 WARN: /home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/activerecord-3.2.13/lib/active_record/relation/finder_methods.rb:343:in `find_one'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/activerecord-3.2.13/lib/active_record/relation/finder_methods.rb:314:in `find_with_ids'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/activerecord-3.2.13/lib/active_record/relation/finder_methods.rb:107:in `find'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/activerecord-3.2.13/lib/active_record/querying.rb:5:in `find'\n/home/git/gitlab/app/mailers/notify.rb:23:in `new_user_email'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/actionpack-3.2.13/lib/abstract_controller/base.rb:167:in `process_action'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/actionpack-3.2.13/lib/abstract_controller/base.rb:121:in `process'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/actionpack-3.2.13/lib/abstract_controller/rendering.rb:45:in `process'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/actionmailer-3.2.13/lib/action_mailer/base.rb:459:in `process'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/actionmailer-3.2.13/lib/action_mailer/base.rb:453:in `initialize'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/actionmailer-3.2.13/lib/action_mailer/base.rb:439:in `new'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/actionmailer-3.2.13/lib/action_mailer/base.rb:439:in `method_missing'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/sidekiq-2.7.5/lib/sidekiq/extensions/action_mailer.rb:20:in `perform'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/sidekiq-2.7.5/lib/sidekiq/processor.rb:45:in `block (3 levels) in process'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/sidekiq-2.7.5/lib/sidekiq/middleware/chain.rb:109:in `call'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/sidekiq-2.7.5/lib/sidekiq/middleware/chain.rb:109:in `block in invoke'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/sidekiq-2.7.5/lib/sidekiq/middleware/server/timeout.rb:11:in `block in call'\n/usr/local/lib/ruby/1.9.1/timeout.rb:68:in `timeout'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/sidekiq-2.7.5/lib/sidekiq/middleware/server/timeout.rb:10:in `call'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/sidekiq-2.7.5/lib/sidekiq/middleware/chain.rb:111:in `block in invoke'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/sidekiq-2.7.5/lib/sidekiq/middleware/server/active_record.rb:6:in `call'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/sidekiq-2.7.5/lib/sidekiq/middleware/chain.rb:111:in `block in invoke'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/sidekiq-2.7.5/lib/sidekiq/middleware/server/retry_jobs.rb:49:in `call'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/sidekiq-2.7.5/lib/sidekiq/middleware/chain.rb:111:in `block in invoke'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/sidekiq-2.7.5/lib/sidekiq/middleware/server/logging.rb:11:in `block in call'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/sidekiq-2.7.5/lib/sidekiq/logging.rb:22:in `with_context'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/sidekiq-2.7.5/lib/sidekiq/middleware/server/logging.rb:7:in `call'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/sidekiq-2.7.5/lib/sidekiq/middleware/chain.rb:111:in `block in invoke'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/sidekiq-2.7.5/lib/sidekiq/middleware/chain.rb:114:in `call'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/sidekiq-2.7.5/lib/sidekiq/middleware/chain.rb:114:in `invoke'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/sidekiq-2.7.5/lib/sidekiq/processor.rb:44:in `block (2 levels) in process'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/sidekiq-2.7.5/lib/sidekiq/processor.rb:80:in `stats'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/sidekiq-2.7.5/lib/sidekiq/processor.rb:43:in `block in process'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/celluloid-0.12.4/lib/celluloid/calls.rb:23:in `call'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/celluloid-0.12.4/lib/celluloid/calls.rb:23:in `public_send'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/celluloid-0.12.4/lib/celluloid/calls.rb:23:in `dispatch'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/celluloid-0.12.4/lib/celluloid/future.rb:18:in `block in initialize'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/celluloid-0.12.4/lib/celluloid/internal_pool.rb:48:in `call'\n/home/git/gitlab/vendor/bundle/ruby/1.9.1/gems/celluloid-0.12.4/lib/celluloid/internal_pool.rb:48:in `block in create'\n\nAny ideas?"}, {"role": "assistant", "content": "This is my entries at the end in /config/environment/production.rb and that is working for me.\n\nComment out sendmail options and use external SMTP relays\n  ##config.action_mailer.delivery_method = :sendmail ## Comment out this\n  # Defaults to:\n  ## config.action_mailer.sendmail_settings = {\n  ##   :location => '/usr/sbin/sendmail',\n  ##   :arguments => '-i -t'\n  ## }\n\n  config.action_mailer.perform_deliveries = true\n  config.action_mailer.raise_delivery_errors = true\n\n  ## SMTP Settings\n  config.action_mailer.delivery_method = :smtp\n  config.action_mailer.smtp_settings = {\n      :address => '10.146.10.90', ## My SMTP Relay/Gateway\n      :port => 25, ## SMTP Port\n      :domain => 'gitlab.example.com', ## My Domain\n      :authentication => :plain, ## Let it be plain as it is inside my LAN\n      ##:user_name => '[email\u00a0protected]', ## This is not required as long as \n      ##:password => 'yourPassword', ## SMTP Gateway allows anonymous relay\n      ##:enable_starttls_auto => true ## In LAN\n      ##:user_name => '',\n      ##:password => '',\n      :enable_starttls_auto => true\n  }\nend"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to search for code in all projects simultaneously?\n\nI'm dealing with a GitLab Community Edition 13.10.1.\nAt the moment there are about a hundred small projects on this.\nBy selecting a project it is possible to search for specific code within all its files, but if instead I go to the GitLab search and select \"Any\" project, the \"Code\" tab is no longer visible.\n\nIs there a way to do a code search, but within all the existing existing projects?"}, {"role": "assistant", "content": "You can use GitLab Advanced Search to search for code if you are subscribed to the premium tier.\nAnother option would be to use the opensource gitlab-search tool if you are using the community edition."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Internal certificate used when installing Helm Tiller Kubernetes\n\nThe error below is triggered when executing kubectl -n gitlab-managed-apps logs install-helm. \nI've tried regenerating the certificates, and bypassing the certificate check. Somehow it is using my internal certificate instead of the certificate of the source.\nroot@dev # kubectl -n gitlab-managed-apps logs install-helm\n+ helm init --tiller-tls --tiller-tls-verify --tls-ca-cert /data/helm/helm/config/ca.pem --tiller-tls-cert /data/helm/helm/config/cert.pem --tiller-tls-key /data/helm/helm/config/key.pem\nCreating /root/.helm \nCreating /root/.helm/repository \nCreating /root/.helm/repository/cache \nCreating /root/.helm/repository/local \nCreating /root/.helm/plugins \nCreating /root/.helm/starters \nCreating /root/.helm/cache/archive \nCreating /root/.helm/repository/repositories.yaml \nAdding stable repo with URL: https://kubernetes-charts.storage.googleapis.com \nError: Looks like \"https://kubernetes-charts.storage.googleapis.com\" is not a valid chart repository or cannot be reached: Get https://kubernetes-charts.storage.googleapis.com/index.yaml: x509: certificate is valid for *.tdebv.nl, not kubernetes-charts.storage.googleapis.com\n\nWhat might be the issue here? Screenshot below is the error Gitlab is giving me (not much information either)."}, {"role": "assistant", "content": "After having the same issue I finally found the solution for it:\nIn the /etc/resolv.conf file on your Master and Worker nodes you have to search and remove the search XYZ.com entry.\nIf you are using Jelastic you have to remove this entry every time after a restart. It gets added by Jelastic automatically. I already contacted them so maybe they will fix it soon."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab error push files 413 Request Entity Too Large\n\nI have a problem with GIT when I attempt to push my files, this is what happens :\n$ git push -u origin dev\nCounting objects: 586, done.\nDelta compression using up to 2 threads.\nCompressing objects: 100% (506/506), done.\nWriting objects: 100% (586/586), 36.81 MiB | 1.58 MiB/s, done.\nTotal 586 (delta 267), reused 40 (delta 29)\nerror: RPC failed; HTTP 413 curl 22 The requested URL returned error: 413 Request Entity Too Large\nfatal: The remote end hung up unexpectedly\nfatal: The remote end hung up unexpectedly\nEverything up-to-date\n\nI've already done :\ngit config http.postBuffer 524288000, \nso that doesn't solve my poblem !\nI found that the solution is to modify nginx config but am not using nginx .. I am working on Windows 10 and I don't see where should I increase the value of client_max_body_size !! \nHave you any idea about this problem on windows ?"}, {"role": "assistant", "content": "You got this error because the size limit on GitLab side is too low.\nLogin to GitLab with admin account and change these below values under Settings / General / Account and limit:\n\nMaximum attachment size (MB)\nMaximum import size (MB)\n\nand save changes. It will fix this issue."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to use gitlab search criteria\n\nIn gitlab's doc, there is list projects API,\nhowever I wonder how to use the search field.\nI've tried with http://GITLAB_API/projects?search=QUERY&private_token=xxx, and it successfully returned projects those contain QUERY in their names, but I want to know if there is advanced search criteria available? For example, I want to get projects under certain namespace, is it possible to filter those projects through this api? Or any api else?\nThank you!"}, {"role": "assistant", "content": "It appears to search for projects that have a name, path, namespace, or description that match your query string. Sadly, it doesn't appear to be anything fancier.\nTracing the source code of 8.3 stable: lib/api/projects.rb calls a filter_projects helper in lib/api/helpers.rb which calls search in app/models/project.rb."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Update shared forked repository using git\n\nConsider repository A a github repository that is managed via Gerrit.\nI cloned repository A and I created a new branch starting from the master branch of repository A. I pushed this new branch on a new gitlab repository B. I am admin on repository B and I shared it with other developers. Developers cannot push on this branch, but I can merge theirs pull requests. \nI merged some pull requests on the master branch of repository B. So, repository B has the initial commits of repository A and new commits of the pull request: B commits on top of A commits (b a). \nThen, I want to update the repository B with new commits of repository A.   Call these commits a+.\nI see two options:\n\nIf I merge A on B, the result is: a+ b a. \nIf I rebase B on A+, the results is: b a+ a.\n\nOption 1: the developments commits are mixed with external ones. Difficult to debug and to highlight differences.\nOption 2: I have to push force the changes on the the remote B. The consequences, if I am not mistaken, may be:\n 1. if developers pull B and they have commits on local master of B, they will lose their local changes;\n 2. developers may face big troubles during rebase their local branches after the forced update of branch B.\nHow should I proceed to avoid any problems?"}, {"role": "assistant", "content": "If I understand it correctly, you have a single (local) repository which looks somewhat like this:\n            A/master\n               \u2193\n* -- * -- * -- a\n                \\\n                 * -- * -- b\n                           \u2191\n                       B/mybranch\n\nNow, A is updated, so it looks like this:\n                          A/master\n                              \u2193\n* -- * -- * -- a -- * -- * -- a+\n                \\\n                 * -- * -- b\n                           \u2191\n                       B/mybranch\n\nNote here that you have two diverged branches that are not in a straight line. So saying that you would get a+ b a when you merge A onto B is not correct. You do get a merge, but that keeps the history as it is:\n                          A/master\n                              \u2193\n* -- * -- * -- a -- * -- * -- a+\n                \\               \\\n                 * -- * -- b --- M\n                                 \u2191\n                            B/mybranch\n\nAs you can see, you still have the information where the commits came from: The ones between a and a+ came from one branch, and the other ones between a and b came from another. And M combines those tro branches. Usually, this is exactly the proper way to solve this.\nThe benefit of this over rebasing\u2014as you noticed yourself\u2014is that the commits stay the way they are. All users who have interacted with either repository can simply pull those changes in without any problems. If you rebased any of those commits, they would have to manually fix that (chances are that they don\u2019t even realize it, so they will just pull and actually create an even messier history with duplicate commits).\nSo a merge is definitely better to work with here. Yes, the history will not look as perfect as a straight line, but it properly conveys what has happened: There is a diverged development line which is independent and that has then been updated with the changes from the upstream repository A. This information can be useful and as such it makes sense to keep them in. And especially if you have users interacting with both those remotes, they will definitely prefer to keep their repository compatible with both remotes.\nIf you don\u2019t want the history to look like this, and don\u2019t care about compatibility with A, you could also squash all the changes from A onto your B:\n                          A/master\n                              \u2193\n* -- * -- * -- a -- * -- * -- a+\n                \\\n                 * -- * -- b -- [A]\n                                 \u2191\n                            B/mybranch\n\nHere, [A] is a squashed commit that contains all the changes between a and a+ in a single commit. You could get this result by rebasing A onto B while squashing all commits. In this case, you should clearly state where those changes come from in the commit message though."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Self-hosted Gitlab registry: Connection refused for localhost:5000\n\nI'm using traefik as a reverse proxy (and for management for the letsencrypt certificates) and I'm running a self hosted gitlab instance. GitLab image is a monolithic with all the services into it, both of the services (Registry and Git) need to be served in the same container.\nWith the configuration shown below gitlab is running well.\ndocker login registry.domain.com is also working.\nBut navigating to the registry in the gitlab frontend gives me a 500 error.\nThe gitlab logs:\nErrno::EADDRNOTAVAIL (Failed to open TCP connection to localhost:5000 (Cannot assign requested address - connect(2) for \"localhost\" port 5000)):\n\nIn the docs I read, that the port 5000 is default for gitlab registry.\nSo I went into the gitlab container and tried to call for localhost:5000:\n$ docker exec -it gitlab /bin/bash\n\nroot@gitlab:/# curl -v http://localhost:5000\n* Rebuilt URL to: http://localhost:5000/\n*   Trying 127.0.0.1...\n* TCP_NODELAY set\n* connect to 127.0.0.1 port 5000 failed: Connection refused\n*   Trying ::1...\n* TCP_NODELAY set\n* Immediate connect fail for ::1: Cannot assign requested address\n*   Trying ::1...\n* TCP_NODELAY set\n* Immediate connect fail for ::1: Cannot assign requested address\n* Failed to connect to localhost port 5000: Connection refused\n* Closing connection 0\ncurl: (7) Failed to connect to localhost port 5000: Connection refused\n\nFurthermore there is no 5000...\nroot@gitlab:/# netstat -tanpu | grep -i listen\ntcp        0      0 127.0.0.1:9093          0.0.0.0:*               LISTEN      -               \ntcp        0      0 127.0.0.11:33383        0.0.0.0:*               LISTEN      -               \ntcp        0      0 127.0.0.1:9100          0.0.0.0:*               LISTEN      -               \ntcp        0      0 127.0.0.1:9229          0.0.0.0:*               LISTEN      -               \ntcp        0      0 127.0.0.1:8080          0.0.0.0:*               LISTEN      -               \ntcp        0      0 127.0.0.1:9168          0.0.0.0:*               LISTEN      -               \ntcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      638/nginx       \ntcp        0      0 127.0.0.1:8082          0.0.0.0:*               LISTEN      -               \ntcp        0      0 127.0.0.1:9236          0.0.0.0:*               LISTEN      -               \ntcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      21/sshd         \ntcp        0      0 0.0.0.0:8060            0.0.0.0:*               LISTEN      638/nginx       \ntcp        0      0 127.0.0.1:9121          0.0.0.0:*               LISTEN      -               \ntcp        0      0 127.0.0.1:9090          0.0.0.0:*               LISTEN      -               \ntcp        0      0 127.0.0.1:9187          0.0.0.0:*               LISTEN      -               \ntcp6       0      0 :::9094                 :::*                    LISTEN      -               \ntcp6       0      0 :::22                   :::*                    LISTEN      21/sshd \n\nSo what am I missing in my configuration? How do I have to handle the 5000 port in traefik?\ndocker-compose.yml\nversion: '3.3'\n\nservices:\n  gitlab:\n    image: gitlab/gitlab-ce:latest\n    container_name: gitlab\n    environment:\n      GITLAB_OMNIBUS_CONFIG: |\n        external_url = 'https://gitlab.domain.com'\n        registry_external_url = 'https://registry.domain.com'\n        gitlab_rails['gitlab_shell_ssh_port'] = 2222\n        gitlab_rails['registry_enabled'] = true\n    ports:\n      - '2222:22'\n    networks:\n      - proxy\n    labels:\n      - traefik.enable=true\n      - traefik.gitlab.frontend.rule=Host:gitlab.domain.com\n      - traefik.gitlab.port=80\n      - traefik.reg.frontend.rule=Host:registry.domain.com\n      - traefik.reg.port=80\n      - traefik.docker.network=proxy\n  traefik:\n    image: traefik:1.7.3-alpine\n    restart: always\n    ports:\n      - 80:80\n      - 443:443\n    networks:\n      - proxy\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - /opt/traefik/traefik.toml:/traefik.toml\n      - /opt/traefik/acme.json:/acme.json\n    labels:\n      - traefik.frontend.rule=Host:monitor.domain.com\n      - traefik.port=8080\n    container_name: traefik\n\nnetworks:\n  proxy:\n    external: true\n\ntraefik.toml\ndefaultEntryPoints = [\"https\",\"http\"]\n\n[entryPoints]\n  [entryPoints.dashboard]\n  address = \":8080\"\n    [entryPoints.dashboard.auth]\n      [entryPoints.dashboard.auth.basic]\n        users = [\"admin:password\"]\n  [entryPoints.http]\n  address = \":80\"\n    [entryPoints.http.redirect]\n    entryPoint = \"https\"\n  [entryPoints.https]\n  address = \":443\"\n  [entryPoints.https.tls]\n\n[api]\nentrypoint=\"dashboard\"\n\n[docker]\ndomain = \"domain.com\"\nwatch = true\nnetwork = \"proxy\"\n\n[acme]\nemail = \"[email\u00a0protected]\"\nstorage = \"acme.json\"\nentryPoint = \"https\"\nOnHostRule = true\n  [acme.httpChallenge]\n  entryPoint = \"http\""}, {"role": "assistant", "content": "First: reading \"GitLab Container Registry administration \", make sure that:\n\ngitlab registry is activated in your Omnibus image: your gitlab.rb, by default, does not declare a registry.\nyou are using https, not http as an URL. \n\n\nThe container registry works under HTTPS by default. Using HTTP is possible but not recommended and out of the scope of this document. Read Test an insecure registry.\n\nSecond, regarding traefik, you can see an example in docker-gitlab issue 1688, which does declare a traefik front to the registry part of GitLab.\n\n- traefik.enable=true\n- traefik.backend=registry.demo.com\n- traefik.frontend.rule=Host:registry.demo.com\n- traefik.docker.network=traefik-00\n- traefik.port=5000\n\n\nIf you really need to expose your internal \"https port 5000\" registry through an external http URL with traefik, you have an example in this thread."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab Style Network Graphs on Github\n\nOne of the things i really liked on Gitlab was their network graphs\nIs there a way to get a similar look/feel in Github? \nI find the gitlab version much easier to work with"}, {"role": "assistant", "content": "We've just moved our client work from a self-hosted GitLab instance to private GitHub repositories and I feel the same pain - I live on the GitLab network graph page!\nSo I've gone ahead and got it working for any local repository. That's not quite GitHub of course, but you can locally clone any GitHub project to use it.\nThe code and instructions are at https://github.com/chromatixau/gitlab-network-graph. It's not perfect yet - there are issues with getting the right 'space' allocation on the graph for some merge strategies, but it works for most simpler situations. I'm continuing to work on it.\nThe steps were basically to copy the network related frontend JS files from the MIT-licensed GitLab CE repository, build a small webpack config based on GitLab's, and then put together some scripts to create the JSON that GitLab builds the graph from (I've used a shell script to basically run git log and format it as JSON, and then a Node.js script to further massage that JSON)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab 8 with nginx proxy can't download a zip, clone a public repo as guest, can't build in CI either\n\nI think all 3 problems are related to the same issue, so I'm going to put all of them here.\nGitlab itself is working, I even managed to update it from 8.2.2 to 8.2.3.\nI can create projects, push my code, pull it, reclone it when I have the proper ssh key, etc.\nBUT:\n\nI can't download the code as zip file, got a JSON instead:\n\n\n{\"RepoPath\":\"/var/opt/gitlab/git-data/repositories/me/myrepo.git\",\n\"ArchivePrefix\": \"...\n\n\nPeople can't clone my public repo (empty repository error).\n\nCI can't build my tests:\n\n\n\nwarning: You have cloned an empty repository. Checking out 12345 as\ndevelop... fatal: reference is not a tree :\n123456789mycommithash987654321\nERROR: Build failed with: exit status 1\n\nNB: I Translated error messages from French ones.\nI suppose the problem is in my Nginx configuration, but there is so much documentation I'm not sure which one is the good one: the ones with the workhorse, the ones when I have to change gitlab.rb's gitlab_git_http_server, etc.\nMy configuration is following:\n\nGitlab 8.2.3\nUbuntu Trusty (14.04)\nNginx 1.8\n\nMy gitlab is hosted on a subdomain using SLL so I added a Nginx proxy\n/etc/gitlab/gitlab.rb:\nexternal_url 'https://gitlab.mydomain.com'\nnginx['listen_addresses'] = ['127.0.0.1', \"[::1]\"]\nnginx['listen_port'] = 8080 \nnginx['listen_https'] = false \n\n/etc/nginx/site_enabled/gitlab:\nserver {\n  listen *:80 default_server;\n  listen [::]:80 ipv6only=on default_server;\n  server_name gitlab.mydomain.com;\n  return 301 https://$server_name$request_uri;\n\n  access_log  /var/log/nginx/gitlab_access.log;\n  error_log   /var/log/nginx/gitlab_error.log;\n}\n\nserver{\n  # listen 443 ssl;\n  listen 0.0.0.0:443 ssl default_server;\n  listen [::]:443 ipv6only=on ssl default_server; \n  server_name gitlab.mydomain.com;\n  server_tokens off;\n\n  location /{\n    proxy_pass http://localhost:8080;\n    proxy_redirect off;\n    proxy_set_header    Host                $http_host;\n    proxy_set_header    X-Real-IP           $remote_addr;\n    proxy_set_header    X-Forwarded-For     $proxy_add_x_forwarded_for;\n    proxy_set_header    X-Forwarded-Proto   $scheme;\n  }\n\n  location ~ ^/(assets)/ {\n    root /opt/gitlab/embedded/service/gitlab-rails/public;\n    gzip_static on; # to serve pre-gzipped version\n    expires max;\n    add_header Cache-Control public;\n  }\n\n  client_max_body_size 250m;\n\n  # ...\n  # A lot a of SSL stuff (HSTS, OCSP, dhparam, etc)\n  # ...\n\n  access_log  /var/log/nginx/gitlab_access.log;\n  error_log   /var/log/nginx/gitlab_error.log;\n  \n  error_page 502 /502.html;\n\nUPDATE :\nJust upgraded Gilab to 8.3.0.\nGit a 502 now.\nApplying : https://gitlab.com/gitlab-org/gitlab-ce/blob/master/doc/update/8.2-to-8.3.md.\nWe'll see.\nUPDATE 2:\nDid not finish instructions after all, stop everything and restarting everything twice (Gitlab and Nginx) Finally managed to get the thing working.\nStill same problems with CI/Zip/PublicCloning tough.\nUPDATE 3:\nJust update to 8.2.3\napt-get update\napt-get install gitlab-ce\n502.\nrestart nginx\ngitlab-ctl restart\ngitlab-rake gitlab:app:check\nChecking GitLab ...\n\nGit configured with autocrlf=input? ... yes\nDatabase config exists? ... yes\nDatabase is SQLite ... no\nAll migrations up? ... yes\nDatabase contains orphaned GroupMembers? ... no\nGitLab config exists? ... yes\nGitLab config outdated? ... no\nLog directory writable? ... yes\nTmp directory writable? ... yes\nUploads directory setup correctly? ... yes\nInit script exists? ... skipped (omnibus-gitlab has no init script)\nInit script up-to-date? ... skipped (omnibus-gitlab has no init script)\nprojects have namespace: ... \n\nRedis version >= 2.8.0? ... yes\nRuby version >= 2.1.0 ? ... yes (2.1.7)\nYour git bin path is \"/opt/gitlab/embedded/bin/git\"\nGit version >= 1.7.10 ? ... yes (2.6.1)\nActive users: 2\n\nChecking GitLab ... Finished\n\n\nIf someone can lead me to the proper documentation or changes to be made that would be awesome."}, {"role": "assistant", "content": "It looks as though downloading of ZIP-Files is now handled by the gitlab-workhorse.\nFor that there's some extra stuff in the nginx-configfile. You might want to have a look at https://gitlab.com/gitlab-org/gitlab-ce/blob/master/lib/support/nginx/gitlab where there is a section \nupstream gitlab-workhorse {\n  server unix:/home/git/gitlab/tmp/sockets/gitlab-workhorse.socket fail_timeout=0;\n}\n\nand a \nproxy_pass http://gitlab-workhorse;\n\nat the end of the configuration.\nI'm currently digging into the same issue and will report back, when I've solved it."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to store node modules between jobs and stages in gitlab with continuous integration\n\nI am fairly new to GitLab CI and I've been trying different approaches to use the node_modules directory in my entire pipeline. From what I've read in the official docs, cache and artifacts seem to be valid approaches to pass on files between jobs:\n\ncache is used to specify a list of files and directories which should\n  be cached between jobs. You can only use paths that are within the\n  project workspace.\n\nHowever, my issue with the caching method is that the node_modules would be persisted between pipelines by default:\n\n\ncache can be set globally and per-job.\nfrom GitLab 9.0, caching is enabled and shared between pipelines and jobs by default.\n\n\nI do not want to persist the node_modules between pipelines. What I actually want is to trigger a fresh install with npm in my setup stage and then allow all further jobs in the pipeline to use these modules. Hence, I started using artifacts instead of cache, which is described similarly:\n\nartifacts is used to specify a list of files and directories which\n  should be attached to the job after success. [...]\nThe artifacts will be sent to GitLab after the job finishes\n  successfully and will be available for download in the GitLab UI.\n  The dependency feature should be used in conjunction with artifacts\n  and allows you to define the artifacts to pass between different jobs.\n\nThe artifact-dependency method seems to be usable in my case. However, both cache and artifacts are extremely inefficient and slow. The node_modules are installed and usable, but the entire directory then gets uploaded somewhere and is re-downloaded between each job. (I would really love to know what happens here... Where do the modules go?)\nIs there a better approach to run npm install only once at the beginning of the pipeline and then keep the node_modules in the pipeline during its entire runtime? I do not want to keep the node_modules after all jobs are finished so they don't need to be uploaded or downloaded anywhere.\nSample pipeline configuration file to reproduce the behavior:\nimage: node:lts\n\nstages:\n  - setup\n  - build\n  - test\n\nnode:\n  stage: setup\n  script:\n    - npm install\n  artifacts:\n    paths:\n      - node_modules/\n\nbuild:\n  stage: build\n  script:\n    - npm run build\n  dependencies:\n    - node\n\ntest:\n  stage: test\n  script:\n    - npm run lint\n    - npm run test\n  dependencies:\n    - node"}, {"role": "assistant", "content": "Where do the modules go?\n\nBy default artifacts are saved on the main gitlab machine:\n/var/opt/gitlab/gitlab-rails/shared/artifacts\n\nIs there a better approach to run npm install only once at the beginning of the pipeline and then keep the node_modules in the pipeline during its entire runtime?\n\nThere are some options that you can try:\n\nMerge setup and build stages to one stage.\nLocal npm cache on builder machines. Faster npm install times. Or use private npm proxy registry (for example - Nexus/Artifactory)\nCheck if gitlab main machine and the builders are in the same network so the upload/download will be faster\nConsider packaging your build in docker. You will get reusable docker images between your gitlab stages. (Of course that there is an overhead of uploading the images to docker registry)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Docker: How to use selenium server to do nightwatchJS test?\n\nI don't know how to run a selenium server with my NodeJS application, whose files are located in the ./bundle folder of the custom e2e:latest docker image.\nI think I have to add the selenium server and webdriver chrome into the Dockerfile for the e2e:latest image, don't I?\nThis is what I have done so far:\nI've created a java:8-jre based docker image with NodeJS and nightwatchJS:\nDockerfile\nFROM java:8-jre\n\n## Node.js setup\nRUN curl -sL https://deb.nodesource.com/setup_4.x | bash -\nRUN apt-get install -y nodejs\n\n## Nightwatch\nRUN npm install -g nightwatch\n\nThis image is then used for the test:\ngitlab-ci.yml\nbuild:\n  stage: build\n  tags:\n    - deploy\n  script:\n    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY\n    - meteor npm install --production\n    - meteor build $PACKAGE_PATH --directory\n    # Maybe something like...? - docker build -t $CI_REGISTRY_IMAGE:e2e .\n\nnightwatch:\n  image: e2e:latest\n  stage: e2e\n  tags:\n    - e2e\n  before_script:\n    - cd ./bundle\n  script:\n    - nightwatch\n\nThe configuration looks like this:\nnightwatch.conf.js\nmodule.exports = {\n    'src_folders'           : ['test/e2e'],\n    'output_folder'         : 'reports',\n    'custom_commands_path'  : '',\n    'custom_assertions_path': '',\n    'page_objects_path'     : '',\n    'globals_path'          : '',\n    'test_runner'           : {\n        'type'   : 'mocha',\n        'options': {\n            'ui'      : 'bdd',\n            'reporter': 'list'\n        }\n    },\n\n    'selenium': {\n        'start_process': false,\n        'server_path'  : '',\n        'log_path'     : '',\n        'host'         : '127.0.0.1',\n        'port'         : 4444,\n        'cli_args'     : {\n            'webdriver.chrome.driver': './bin/chromedriver'\n        }\n    },\n\n    'test_settings': {\n        'default': {\n            'launch_url'   : 'http://localhost',\n            'selenium_port': 4444,\n            'selenium_host': 'localhost',\n            'silent'       : true,\n            'screenshots'  : {\n                'enabled': true,\n                'path'   : 'reports/error-screenshots'\n            },\n            'desiredCapabilities': {\n                'browserName'      : 'chrome',\n                'javascriptEnabled': true,\n                'acceptSslCerts'   : true\n            }\n        },\n\n        'chrome': {\n            'desiredCapabilities': {\n                'browserName'      : 'chrome',\n                'javascriptEnabled': true,\n                'acceptSslCerts'   : true\n            }\n        }\n    }\n}"}, {"role": "assistant", "content": "Not sure whether this is suitable for Gitlab CI but take a look at Selenoid project. This is a small (6 Mb) binary that launches browsers in separate Docker containers or by starting Webdriver process directly. So if container approach is not suitable for your needs try to pack Selenoid + e.g. Chromedriver + Chrome to the same container with Node.js. No need to install Java when using Selenoid."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "After git revert, merge showing no changes and already updated\n\nI have a dev branch which already merged with branches featureA and featureB.\nI merged that dev branch to master and pushed to remote. Later I identified featureB is not yet ready to merge with master as there is a faulty commit. So I revert that merge of  dev --> master. \ngit revert -m 1 <merge-commit-hash>\n\nThen I am trying to merge featureA to master. But I cannot merge. It will say Already up to date.\nI know the reason as Linus Torvalds said,\n\nLinus explains the situation:\nReverting a regular commit just effectively undoes what that commit\n      did, and is fairly straightforward. But reverting a merge commit also\n      undoes the data that the commit changed, but it does absolutely\n      nothing to the effects on history that the merge had.\nSo the merge will still exist, and it will still be seen as joining\n      the two branches together, and future merges will see that merge as\n      the last shared state - and the revert that reverted the merge brought\n      in will not affect that at all.\nSo a \"revert\" undoes the data changes, but it's very much not an\n      \"undo\" in the sense that it doesn't undo the effects of a commit on\n      the repository history.\nSo if you think of \"revert\" as \"undo\", then you're going to always\n      miss this part of reverts. Yes, it undoes the data, but no, it doesn't\n      undo history.\n\nIn this situation only solution to merge that dev again to master is revert the revert commit. But I only want to merge the one branch included in dev branch, that is featureA\nHow can I merge the branch (featureA) to mainline branch (master), that included in reverted merge branch (dev)  ?"}, {"role": "assistant", "content": "You should not do a revert of the whole develop to master merge here, but do a revert of the 1 specific branch instead. In your case it should be a revert of featureB to develop merge.\nIf your revert cannot be undone, simplest solution is to revert it back and do a new revert of featureB to develop merge only. Otherwise, I would recommend to get rid of the initial revert and follow the explanation below.\nLet's draw what happens here according to the description:\n  master   a------------------M3\n            \\                /    \n     dev     b-------M1-----M2\n             |\\     /      /\nfeatureA     | c---d      /\n              \\          /\nfeatureB       e--------f\n\nhere M3 is merge commit you're trying to revert by:\ngit checkout master\ngit revert -m 1 <M3-commit-hash>\n\nIf you did exactly what you said, by the command above you doing revert of the whole dev to master merge commit M3, which will produce revert commit and will put it after M3 in timeline:\n  master   a------------------M3---rvM3\n            \\                /    \n     dev     b-------M1-----M2\n             |\\     /      /\nfeatureA     | c---d      /\n              \\          /\nfeatureB       e--------f\n\nwhere rvM3 is the revert commit of the whole dev branch merge.\nThen you're trying to execute:\ngit checkout master\ngit merge featureA\n\nNow let's imagine the picture of expected result:\n  master   a------------------M3---rvM3---(M4)\n            \\                /            /\n     dev     b-------M1-----M2           /\n             |\\     /      /            /\nfeatureA     | c---d----- / -----------         \n              \\          /          \nfeatureB       e--------f\n\nIf take a look carefully on the last view we can found that commits c and d from the featureA are already a part of the master branch after M3 merge and they are reachable from M3 by the parent links.\nYou may expect that M4 with commits from featureA will be created, but it does not happen, since to Git there is nothing new to add from the featureA branch to master (from the commit perspective) as it was already merged before. It doesn't matter that in fact code changes from the featureA are not presented in master anymore as Git cares about commits only, not the changes itself and does not care what happens to them in the future commits.\nHaving that in mind we can come to a simple solution \u2014 what you really need is not a revert of whole M3 merge, but instead a revert of M2 only and picking the branch with M1 as revert destination for merge commit (assuming it has index 1 in the command):\ngit checkout master\ngit revert -m 1 <M2-commit-hash>\n\nWhich will do exactly what you wanted and you will end up with something like that:\n  master   a------------------M3---rvM2\n            \\                /    \n     dev     b-------M1-----M2\n             |\\     /      /\nfeatureA     | c---d      /\n              \\          /          \nfeatureB       e--------f\n\nwhere rvM2 holds changes from the M2 discarding ones that came from e and f commits.\nGenerally, every time we want to revert something it's better to be as specific as possible. I.e. if we want to revert 1 commit, we need to execute revert only for it, not the whole branch holding it, and if we want to revert 1 specific branch \u2014 we should not revert composite merge of several branches, like you did in M3 initially."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab: Is it possible to create a merge request from MY fork to Another fork of the same project\n\nScenario: we are 3 developers.\nDeveloper 1 (admin) created the main repo.\nDeveloper 2 forked admin's repo.\nDeveloper 3 forked admin's repo.\nDeveloper 2 created a feature branch \"Feature 1\"\nDeveloper 3 checked out \"Feature 1\" from developer 2 repo. \nWhen Developer 3 tries to create a Merge Request he only sees his own and admin's repos.\nSo I wonder, Is it possible to create a Merge Request to another remote different than my fork's?\"\nThe only work-around I have seen so far is:\nDeveloper 2 pushes the feature branch to admin's repo (through a merge request) and asks the admin to \"protect it\", then Developer 3 would have to create a merge request to admin's repo as well, the problem with this approach is that Developer 2 loses the ownership of the branch and they will have to create merge requests every time they want to push their changes.\nOn the other hand, it seems like this feature was added to GitLab but I can't find the official documentation about this feature."}, {"role": "assistant", "content": "No forks, maybe?\nYou may utilise the fact, that merge requests can be made within the same repository. So maybe all three may use the same repository as developers, the admin should set the crucial branches as protected.\nIf any change is made, anyone can create a merge request from one branch to another... and anyone can review, discuss, ..."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Project templates in Gitlab upon creation\n\nWhat is the cleanest way to create a project in a self hosted gitlab with predefined (dynamically generated) files?\nConcretely, I want to create a git repo on gitlab that upon creation contains all the files of a basic iOS project already. I just have to clone it and just start developing, instead of creating the project locally and then push it up to Gitlab.\nAnyone?\nI was looking into the gitlab-shell and the creation hook in gitlab-project: https://github.com/gitlabhq/gitlab-shell/blob/master/lib/gitlab_projects.rb\nAm I about to embark on a world of pain following this method? Is there something already out there that makes it easy to hook up at the application level?"}, {"role": "assistant", "content": "For GitLab CE (or EE too, if you need more features than the standard templates provide) I propose using this set of tools:\n\nconfigure system hooks in GitLab to make it fire a POST request on project_create events,\nset up adnanh/webhook as a server that will receive these POST requests and then run egnyte/gitlabform app to configure the new project,\ncreate configuration for gitlabform with any files you need. Example:\n\ngitlab:\n  url: https://gitlab.yourcompany.com\n  # You can also set in your environment GITLAB_TOKEN\n  # this can be both private token OR OAuth2 access token\n  token: \"<private token of an admin user>\"\n  api_version: 4\n\ngroup_settings:\n  # this assumes that you create your new iOS projects in a \"ios\" group in GitLab\n  ios:\n    files:\n      \"README.md\":\n        # this will prevent resetting the file to below contents if it has already been customized\n        overwrite: false\n        # this will prevent the commit that applies this file change triggering CI build\n        skip_ci: true\n        branches:\n          - develop\n        content: |\n          This is a default project README. Please replace it with a proper one!\n      \"other-file\":\n        branches:\n          - develop\n        # You can provide file contents with external file too. Both absolute and relative paths are supported.\n        # Relative paths are interpreted as relative to `config.yml` file location.\n        file: some-file.txt\n\nSee https://github.com/egnyte/gitlabform for more info about the features, more examples and a full config syntax description.\nDisclosure: I am the original author of egnyte/gitlabform app and I have contributed to adnanh/webhook and therefore I like them both. :)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How can I kick off a container instance using the Azure api?\n\nI have a container building in gitlab and registering itself with the gitlab custom registry.  Inside this container is a command that runs a very long time.  I would like to somehow deploy this container to azure, and only kick off this long running process inside a new container instance on demand from an administrative api service.  I don't want the container running all the time, only for the time it takes to run the command.\nI was thinking that this admin api could be a classic http rest api service hosted under Azure \"App Services\", or possibly using the new \"Function Apps\" feature of Azure.\nIn my research, I found that using the azure cli commands, I can start a container like so:\naz container create \\\n    --resource-group myResourceGroup \\\n    --name mycontainer2 \\\n    --image microsoft/aci-wordcount:latest \\\n    --restart-policy OnFailure \\\n    --environment-variables NumWords=5 MinLength=8\n\nhttps://learn.microsoft.com/en-us/azure/container-instances/container-instances-environment-variables\nI would like to do this from the admin api, preferably using what looks to me like the official Azure npm package located here:\nhttps://www.npmjs.com/package/azure\nIdeally, it would be a single command to create and start the instance, being able to set the environment variables like this example at the launch of the container is important to me.  I'm not interested in moving all my code over into Azure, I would like to continue using gitlab for the source code and container registry but if there is some reason I have to switch to using the Azure container registry, I need a way to somehow move the container registration over there using the gitlab ci yaml.\nIn all my searching, I couldn't find any way to do this but the closest documentation I found was here:\nhttps://learn.microsoft.com/en-us/javascript/api/azure-arm-containerservice/containerserviceclient?view=azure-node-latest"}, {"role": "assistant", "content": "At the current time there is no way to officially do this from the api, maybe in the future there will be"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Is it possible on gitlab ci build only on tag push event?\n\nwhen I have a project with continuous integration gitlab at the time of making the push automatically tasks that are within the gitlab-ci.yml file are released , what I want is that only in time to make the push of a tag ( git push --follow -tags ) , the tasks of file gitlab-ci.yml - run , is this possible (only git push --follow -tags)?\n\nI refer to this event , but with the build in gitlab ci."}, {"role": "assistant", "content": "Solved:\nAdd to .gitlab-ci.yml tags:\nmyjob:\n  script: test\n  only:\n  - tags"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Amazon cli image doesn't work with Gitlab CI\n\nI'm trying to run the aws command (to invalidate cloudfront) using official aws image and have the following config of .gitlab-ci.yml:\nstatic-invalidation:\n  <<: *production-env\n  stage: static_invalidation\n  image: amazon/aws-cli:latest\n  variables:\n    AWS_ACCESS_KEY_ID: $CLOUDFRONT_AWS_ACCESS_KEY_ID\n    AWS_SECRET_ACCESS_KEY: $CLOUDFRONT_AWS_SECRET_ACCESS_KEY\n  script:\n    - aws cloudfront create-invalidation --distribution-id $CLOUDFRONT_DISTRIBUTION --invalidation-batch file://deployment/configs/inv-batch.json\n\nThe job fails with the following error:\nUsing docker image sha256:00cf4f100b03d1b26e93cce377c1311c34efa753e379cd5c6ea5d458337cbaab for amazon/aws-cli:2.2.17 with digest amazon/aws-cli@sha256:39e9898fc43f618636a2190f82b9babcdc618d054e66b49c9959b9cd23285ade ...\nusage: aws [options] <command> <subcommand> [<subcommand> ...] [parameters]\nTo see help text, you can run:\n  aws help\n  aws <command> help\n  aws <command> <subcommand> help\naws: error: argument command: Invalid choice, valid choices are:\naccessanalyzer                           | acm                                     \nacm-pca                                  | alexaforbusiness\n...\nERROR: Job failed: exit code 252\n\nAny ideas why it's not working?\nWhen I run the command locally it works."}, {"role": "assistant", "content": "amazon/aws-cli docker has set entrypoint to aws as it's expected to be executed as\n$ docker run amazon/aws-cli cloudfront create-invalidation --distribution-id ...\n\nbut gitlab expects entry point to shell so it can then execute script commands.\nCheck out gitlab documentation: https://docs.gitlab.com/ee/ci/docker/using_docker_images.html#available-settings-for-image\nYou will find there how to override docker image entrypoint.\n\nWorking config is:\nimage:\n    name: amazon/aws-cli:2.2.18\n    entrypoint: [\"\"]"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do you specify Mermaid configuration within Gitlab Markdown?\n\nIn Gitlab, I've been able to render an Entity Relationship Diagram with Mermaid in a Markdown file as specified here.\nThis is the Markdown I used:\n```mermaid\nerDiagram\n        CUSTOMER }|..|{ DELIVERY-ADDRESS : has\n        CUSTOMER ||--o{ ORDER : places\n        CUSTOMER ||--o{ INVOICE : \"liable for\"\n        DELIVERY-ADDRESS ||--o{ ORDER : receives\n        INVOICE ||--|{ ORDER : covers\n        ORDER ||--|{ ORDER-ITEM : includes\n        PRODUCT-CATEGORY ||--|{ PRODUCT : contains\n        PRODUCT ||--o{ ORDER-ITEM : \"ordered in\"\n                    \n```\n\nThe mermaid interactive editor provides an example of configuration:\n{\n  \"theme\": \"default\"\n}\n\nBut I don't know where to locate that configuration information. I've tried putting it in the same directory, in a file called config.json or mermaid-config.json, but neither of those have worked. I also tried including it in the Markdown which defined the diagram, which only caused it to render incorrectly. Is there a way to specify the theme or other CSS elements for Gitlab?"}, {"role": "assistant", "content": "Just tried it out and it worked\n ```mermaid \n %%{init: { 'theme':'dark', 'sequence': {'useMaxWidth':false} } }%%\n sequenceDiagram \n   alice ->> mark: Sent a flower\n ```"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "RPC failed; HTTP 400 curl 22 The requested URL returned error: 400 Bad Request\n\nI am trying to push my code from an old repository to a new repository as my old repository seems to be currupted somehow\ngetting following error:\nCounting objects: 19815, done.\nCompressing objects: 100% (5264/5264), done.\nWriting objects: 100% (19815/19815), 44.91 MiB | 134.87 MiB/s, done.\nTotal 19815 (delta 14641), reused 19405 (delta 14283)\nerror: RPC failed; HTTP 400 curl 22 The requested URL returned error: 400 Bad Request\nfatal: The remote end hung up unexpectedly\nfatal: The remote end hung up unexpectedly\nEverything up-to-date\n\nI tried git config http.postBuffer 524288000 but it did not help I even tried to do git push --force origin and git push --all but am receiving same error"}, {"role": "assistant", "content": "I faced a similar issue on my Arch Linux machine. Apparently my issue was an HTTP buffer issue.\nI got it to work by using\ngit config http.postBuffer 524288000\n\nfollowed by\ngit pull && git push\n\nThis did the trick for me and I can push to my repositories. However I wonder if there is a better way of implementing this rather than running an extra command."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Python. How to solve \"setuptools must be installed to install from a source distribution\"\n\nI have a Continuous Integration that works with Gitlab. When I deploy, it installs everything in my requirements.txt file with pip. However, when it gets to installing a package named cffi, it throws the error:\n\nDownloading/unpacking cffi==1.10.0 (from -r requirements.txt (line\n  11)) Cleaning up... \nsetuptools must be installed to install from a\n  source distribution\n\nI am lost here. Tried adding \"setuptools\" to requirements.txt and adding a line that explicitly installs it, but it doesn't work.\ngitlab.ci looks like this:\nscript:\n        - \"cp tests/test_settings.py app/local_settings.py\"\n        - \"source /home/ci/misuper-venv/bin/activate\"\n        - pip install setuptools\n        - \"pip install -r requirements.txt\"\n        - \"python manage.py migrate --noinput\"\n\nI'm completely lost here. Please help."}, {"role": "assistant", "content": "It's a known problem.\npip install -U setuptools\npip install -U pip\n\nJust helped me.\nNote: a reasonable person would never sudo pip install anything.\nOS's Python should be managed by the OS's package manager; strong-arming your system Python installation has been many times seen to break your OS in interesting ways. \nTo pip install anything, use virtualenv or an equivalent."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Enable SSL on GitLab with Docker on Synology NAS\n\nI have a working installation of GitLab via the official GitLab Package on my Synology NAS (DSM 5.2) in a Docker container.\nI now like to access the Webinterface via https instead of just http. I have seen in several posts that it is possible to do with some docker magic, but\ndid not find any detailed instructions.\nCan anyone please explain how to achieve this?\nIt's a pity that this is not default."}, {"role": "assistant", "content": "With DSM6, the changes (except generation of the cert) are now possible using the dsm docker interface:\n1) Create a key/cert:\nmkdir /volume1/docker/gitlab/certs\ncd /volume1/docker/gitlab/certs\nopenssl genrsa -out gitlab.key 2048\nopenssl req -new -key gitlab.key -out gitlab.csr\nopenssl x509 -req -days 3650 -in gitlab.csr -signkey gitlab.key -out gitlab.crt\nopenssl dhparam -out dhparam.pem 2048\nchmod 400 gitlab.key\n\n2) Set up gitlab docker environment:\n\n3) Set gitlab docker port bindings:"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Not able to execute GitLab Runner in Kubernetes cluster: cannot create resource \"secrets\" in API group \"\" in the namespace \"gitlab\"\n\nCurrently I'm facing the issue:\nERROR: Job failed (system failure): \nprepare environment: \nsetting up credentials: \nsecrets is forbidden: \nUser \"system:serviceaccount:default:gitlab-runner\" cannot create\nresource \"secrets\" in API group \"\" in the namespace \"gitlab\" \n\nafter following the official documentation on how to integrate the GitLab Runner.\nI'm using the following runner-chart-values.yaml:\n# The GitLab Server URL (with protocol) that want to register the runner against\n# ref: https://docs.gitlab.com/runner/commands/README.html#gitlab-runner-register\n#\ngitlabUrl: http://example.domain/\n\n# The Registration Token for adding new runners to the GitLab Server. This must\n# be retrieved from your GitLab instance.\n# ref: https://docs.gitlab.com/ce/ci/runners/README.html\n#\nrunnerRegistrationToken: \"<token>\"\n\n# For RBAC support:\nrbac:\n    create: true\n    rules:\n      - apiGroups: [\"*\"]\n\n# Run all containers with the privileged flag enabled\n# This will allow the docker:dind image to run if you need to run Docker\n# commands. Please read the docs before turning this on:\n# ref: https://docs.gitlab.com/runner/executors/kubernetes.html#using-dockerdind\nrunners:\n    privileged: true\n\nAny clues what's going on?\nMany thanks!"}, {"role": "assistant", "content": "For me adding all necessary roles was the only solution that actually helped.\nHere the corresponding runner-chart-values.yaml file:\n## GitLab Runner Image\ngitlabUrl: http://example.domain/\nrunnerRegistrationToken: \"<token>\"\n\nrbac:\n  create: true\n  rules:\n    - apiGroups: [\"\"]\n      resources: [\"pods\"]\n      verbs: [\"list\", \"get\", \"watch\", \"create\", \"delete\"]\n    - apiGroups: [\"\"]\n      resources: [\"pods/exec\"]\n      verbs: [\"create\"]\n    - apiGroups: [\"\"]\n      resources: [\"pods/log\"]\n      verbs: [\"get\"]\n    - apiGroups: [\"\"]\n      resources: [\"pods/attach\"]\n      verbs: [\"list\", \"get\", \"create\", \"delete\", \"update\"]\n    - apiGroups: [\"\"]\n      resources: [\"secrets\"]\n      verbs: [\"list\", \"get\", \"create\", \"delete\", \"update\"]      \n    - apiGroups: [\"\"]\n      resources: [\"configmaps\"]\n      verbs: [\"list\", \"get\", \"create\", \"delete\", \"update\"]      \n\nrunners:\n  privileged: true"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "IntelliJ, unable to share Project on GitHub (Permission Denied)\n\nI'm new to Git and GitHub/GitLab. I try to share my project to GitHub but it throws this exception:\nCan't finish GitHub sharing process\n        Successfully created project 'LiveGame1' on GitHub, but initial push failed:\n        [email\u00a0protected]: Permission denied (publickey).\n        Could not read from remote repository.\n        Please make sure you have the correct access rights\n        and the repository exists.\n\nI'm also able to clone a repository via internet link, but not via \"[email\u00a0protected]:/username/repository_name\".\nHow can I fix this error and am I able to share my project directly to GitLab?"}, {"role": "assistant", "content": "This article helped me get things squared away on my Windows 10 box:\nhttps://richardballard.co.uk/ssh-keys-on-windows-10/\nNote:  The first section in the article should be titled \"Enable the SSH Client in Windows\" and should refer to getting the SSH Client enabled, not the server. \nIf you can get ssh -T [email\u00a0protected] working without prompting you for your password, as described in the above article, then you'll be able to push from IntelliJ just fine.\nThe keys were to:\n\nget the OpenSSH Authentication Agent service running in Windows \nmake sure ssh-add that is invoked is the one provided in C:\\Windows\\System32\\OpenSSH\nmake sure git is also configured to use the ssh provided by Windows:\n\ngit config --global core.sshCommand \"'C:\\Windows\\System32\\OpenSSH\\ssh.exe'\"\nWhen generating your keys with ssh-keygen consider using the ecdsa algorithm as described here:  https://www.ssh.com/ssh/keygen/ \nAlso important was cleaning up anything else that was trying to do ssh outside of windows (like Putty).  One problem I kept facing with 'invalid format' when trying to run ssh-add I believe was caused by a different ssh-add program on my path that was being used rather than the one from OpenSSH that ships with Windows."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to trigger fail CI/CD on eslint warning\n\nI would like to trigger fail CI/CD gitlab job on eslint warnings.\nEslint will fail on error, but in CI/CD I would like to fail on warnings too.\nHow can I do it?"}, {"role": "assistant", "content": "You can fail eslint on any warnings by adding the --max-warnings=0 flag. For example:\neslint '**/*.js' --max-warnings=0"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "[email\u00a0protected]: Permission denied (publickey). fatal: Could not read from remote repository\n\nI am using macOS Catalina. I already have a repository on GitLab and an SSH-key assigned. Now I want to create another repository from the terminal. I do the following:\ngit config user.name my_name\ngit config user.email my_email\ngit init\n\nThen I get this:\nInitialized empty Git repository in directory\n\nSo far so good.\ngit remote add origin [email\u00a0protected]:my_name/repo.git\ngit add .\ngit commit -m 'commit'\ngit push -u origin master\n\nThen I get the following error:\n[email\u00a0protected]: Permission denied (publickey).\nfatal: Could not read from remote repository.\n\nPlease make sure you have the correct access rights\nand the repository exists.\n\nThen I go to the repository I already had and try to push there, everything works so I guess I don't have a problem with SSH-key. I know this is a very common question on the internet but none of the answers solved my problem."}, {"role": "assistant", "content": "First, you should get \"Initialized empty Git repository in directory\" only after a git init ., not after a git remote add origin ...\nSecond, with GitLab, you can push to create a new project, as illustrated in this MR, starting with GitLab 10.5 (Q1 2018)\nThird, if the error persists, then the key is somehow at fault.\nTest it with:\nssh -Tv [email\u00a0protected]\n\nAlso\ngit -c core.sshCommand=\"ssh -v\" push -u origin master\n\nTo generate a valid key:\nssh-keygen -t rsa -P \"\" -m PEM\n\nAnd register your new id_rsa.pub to your GitLab profile."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI Read File from Other Repository\n\nIn the setup that I have, there are two repositories in GitLab, one of which has a version file that the other needs for naming the artifact produced by its CI/CD pipeline.\nRight now, I'm just cloning the entire other repository to access that VERSION file. I tried using git archive to pull only the VERSION file but the CI_JOB_TOKEN doesn't work with SSH access remotes (from my testing), and doing a curl to the raw file path doesn't work because its on a private GitLab instance.\nIs there a better way to do this?"}, {"role": "assistant", "content": "I had the same Problem and solved it by using an access token. Go to User Settings > Access Tokens and create one:\n\nUsing that you then can pull files from all repositories via gitlab-api.\nwget --header \"PRIVATE-TOKEN: <your_token>\" http://mygitlab.com/api/v4/projects/<project_id>/repository/files/path%2Fto%2Ffile/raw?ref=master\n\nTo pull that file in the GitLab CI you can set your access token as environment variable. Go to  > Settings > CI > Environment variables and add GITLAB_TOKEN with your access token:\n\nYou now can use that environment variable in your CI script to download that file with wget or curl if you prefer.\nwget --header \"PRIVATE-TOKEN: ${GITLAB_TOKEN}\" http://mygitlab.com/api/v4/projects/<project_id>/repository/files/path%2Fto%2Ffile/raw?ref=master\n\nor\ncurl --header \"PRIVATE-TOKEN: ${GITLAB_TOKEN}\" http://mygitlab.com/api/v4/projects/<project_id>/repository/files/path%2Fto%2Ffile/raw?ref=master"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to cache \"poetry install\" for Gitlab CI?\n\nIs there a way to cache poetry install command in Gitlab CI (.gitlab-ci.yml)?\nFor example, in node yarn there is a way to cache yarn install (https://classic.yarnpkg.com/lang/en/docs/install-ci/ Gitlab section) this makes stages a lot faster."}, {"role": "assistant", "content": "GitLab can only cache things in the working directory and Poetry stores packages elsewhere by default:\n\nDirectory where virtual environments will be created. Defaults to {cache-dir}/virtualenvs ({cache-dir}\\virtualenvs on Windows).\n\nOn my machine, cache-dir is /home/chris/.cache/pypoetry.\nYou can use the virtualenvs.in-project option to change this behaviour:\n\nIf set to true, the virtualenv wil be created and expected in a folder named .venv within the root directory of the project.\n\nSo, something like this should work in your gitlab-ci.yml:\nbefore_script:\n  - poetry config virtualenvs.in-project true\n\ncache:\n  paths:\n    - .venv"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Want to setup a hook that copies committed files to a particular folder\n\nBackground: Developing a Facebook app using PHP Laravel framework & MySQL for database.\nI have setup Gitlab on our development server and created a repository on it where the team has been added and is committing & pushing code.\nWhat I would like to do is, when I push code to a particular branch on GitLab (for example Master) I would like it to be available at /var/www/productname so that I can test it within the Facebook canvas as well (certain things happen there that can't be tested on your local machine).\nHowever, I don't want the hook to copy all the files over every time a push happens on master, just the files that were modified.\nCan anyone help out with such a hook?\nThank you."}, {"role": "assistant", "content": "You would need to add to the bare repo (managed by GitLab) a post-receive hook which would:\n\nmaintain a working tree (git checkout -f master)\ncopy the files you want from that working\n\nThat would be:\ncd ~git/repositories/yourRepo.git/hooks\ntouch post-receive\nchmod +x post-receive\n\nYou can make sure that hook will only be active if someone pushes on branch master:\n#!/bin/bash\nwhile read oldrev newrev refname\ndo\n    branch=$(git rev-parse --symbolic --abbrev-ref $refname)\n    if [ \"master\" == \"$branch\" ]; then\n        # Do something\n    fi\ndone\n\nFor the checkout done by that hook, see \"GIT post-receive checkout without root folder\", that is:\nmake sure you specify --git-dir and --git-work-tree:\ngit --git-dir=/path/to/project_root.git --work-tree=/path/to/your/workingtree checkout -f\n\nAgain, /path/to/your/workingtree can be:\n\nonly an intermediate working tree for you to extract from it the relevant files you want to copy.\nor the path to your app, if you want all the files from master to be updated in the destination directory of your wab app."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to enable code coverage output in job list for PHP project on gitlab.com\n\nFor a project hosted at https://www.gitlab.com I would like to setup code coverage in the CI setup, so it can be displayed in the job list\n\nMy configuration looks like this: \n.gitlab-ci.yml\nimage: php:7.1.1\n\ncache:\n  paths:\n  - vendor/\n\nbefore_script:\n# Install git, the php image doesn't have installed\n- apt-get update -yqq\n- apt-get install git -yqq\n\n# Install composer\n- curl -sS https://getcomposer.org/installer | php\n\n# Install all project dependencies\n- php composer.phar install\n\n# Run our tests\ntest:\n    only:\n        - master\n        - develop\n    script:\n        - vendor/bin/phpunit --configuration phpunit.xml --coverage-text --colors=never\n\nThe job succeeds, but shows the error message \nError:         No code coverage driver is available\n\nI have updated the setting for Test coverage parsing and set the regex to \n^\\s*Lines:\\s*\\d+.\\d+\\%\n\nthe example for PHP/PHPUnit.\nWhen I run the command \nvendor/bin/phpunit --coverage-text --colors=never\n\nlocally, I get the following output:\nCode Coverage Report:     \n  2017-06-21 14:52:55     \n\n Summary:                 \n  Classes: 100.00% (4/4)  \n  Methods: 100.00% (14/14)\n  Lines:   100.00% (43/43)\n\n\\Rodacker\\CartExample::Article\n  Methods: 100.00% ( 6/ 6)   Lines: 100.00% ( 11/ 11)\n\\Rodacker\\CartExample::ArticleLoader\n  Methods: 100.00% ( 2/ 2)   Lines: 100.00% ( 21/ 21)\n\\Rodacker\\CartExample::ArticleRepository\n  Methods: 100.00% ( 3/ 3)   Lines: 100.00% (  6/  6)\n\\Rodacker\\CartExample::Image\n  Methods: 100.00% ( 3/ 3)   Lines: 100.00% (  5/  5)"}, {"role": "assistant", "content": "The problem was the missing Xdebug installation in the docker image. I could not install a proper version using apt-get, so I had to add a pecl install xdebug call in the before_script section:\nimage: php:7.1.1\n\ncache:\n  paths:\n  - vendor/\n\nbefore_script:\n# Install git, the php image doesn't have installed\n- apt-get update -yqq\n- apt-get install git -yqq\n\n# Install Xdebug\n- pecl install xdebug\n- docker-php-ext-enable xdebug\n\n# Install composer\n- curl -sS https://getcomposer.org/installer | php\n\n# Install all project dependencies\n- php composer.phar install\n\n# Run our tests\ntest:\n    only:\n        - master\n    script:\n        - vendor/bin/phpunit --configuration phpunit.xml --coverage-text --colors=never"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How To Import Tags Into Gitlab\n\nI've just converted our repository from github to an internal gitlab. I started by getting a bare local repository and I have been able to get a new master into gitlab.\nIn my local repository, git tag shows a list of tags that I had on github. But none of the tags are showing up in gitlab.\nI have GitLab 6.6.0.pre fe6c534.\nSo I how do I import my tags into gitlab?"}, {"role": "assistant", "content": "You should push those tags to your remote gitlab:\ngit push --tags\n\nBy default, git push pushed only commits, not tags.\n(See \"Push git commits & tags simultaneously\" for more on that)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Run GitLab CI for a subdirectory in the same project\n\nI have three subprojects (Angular and Node.js) in the same GitLab project. Now I want to create the gitlab-ci.yml file for building and deploying one of this subprojects. Can I create three different gitlab-ci.yml files and run them inside subdirectories? Is it possible? Or should I push those into three different projects?"}, {"role": "assistant", "content": "My personal preference is to keep projects small. So I usually create one GitLab project per, e.g., module, library, program, design, etc.\nBut if you really wanted to, you could easily either:\n\nCreate a single .gitlab-ci.yml that goes something like:\nmy_job:\n  stage: test\n  script:\n    - |\n       cd \"$CI_PROJECT_DIR/folder1\"\n       < do stuff >\n       cd \"$CI_PROJECT_DIR/folder2\"\n       < do stuff>\n       ...\n\n\nCreate multiple gitlab-ci configurations inside the folders and include them in the root .gitlab-ci.yml file\ninclude:\n  - 'folder1/pipeline.yml'\n  - 'folder2/pipeline.yml'\n\n\n\nNote that when using the second option, you will still have to cd folderX since pipelines always start in the repository's root directory, no matter from where they are imported."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Find project in gitlab by ID\n\nHow i can find a project in Gitlab by ID?\nI found description to search by issue id #123 and MR !123 but not find by id"}, {"role": "assistant", "content": "As mentioned by Daly in the comments, you can browse to\nhttps://gitlab.com/projects/{id}\n\nand be redirected to the appropriate project."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab-runner failed to remove permission denied\n\nI'm setting up a CI/CD pipeline with Gitlab. I've installed gitlab-runner on a Digital Ocean Ubuntu 18.04 droplet and gave permissions in /etc/sudoers to the gitlab-runner as:\ngitlab-runner ALL=(ALL:ALL)ALL\n\nThe first commit to the associated repository correctly build the docker-compose (the app itself is Django+postgres), but following commits are not able to clean previous builds and fail:\nRunning with gitlab-runner 12.8.0 (1b659122)\non ubuntu-s-4vcpu-8gb-fra1-01 52WypZsE\nUsing Shell executor...\n00:00\nRunning on ubuntu-s-4vcpu-8gb-fra1-01...\n00:00\nFetching changes with git depth set to 50...\n00:01\n Reinitialized existing Git repository in /home/gitlab-runner/builds/52WypZsE/0/lorePieri/djangocicd/.git/\n From https://gitlab.com/lorePieri/djangocicd\n  * [new ref]         refs/pipelines/120533457 -> refs/pipelines/120533457\n    0072002..bd28ba4  develop                  -> origin/develop\n Checking out bd28ba46 as develop...\n warning: failed to remove app/staticfiles/admin/img/selector-icons.svg: Permission denied\n warning: failed to remove app/staticfiles/admin/img/search.svg: Permission denied\n warning: failed to remove app/staticfiles/admin/img/icon-alert.svg: Permission denied\n warning: failed to remove app/staticfiles/admin/img/tooltag-arrowright.svg: Permission denied\n warning: failed to remove app/staticfiles/admin/img/icon-unknown-alt.svg: Permission denied\n\nThis is the relevant portion of the .gitlab-ci.yml file:\nimage: docker:latest\nservices:\n  - docker:dind\n\nstages:\n  - test\n  - deploy_staging\n  - deploy_production\n\nstep-test:\n  stage: test\n  before_script:\n    - export DYNAMIC_ENV_VAR=DEVELOP\n  only:\n    - develop\n  tags:\n    - develop\n  script:\n    - echo running tests in $DYNAMIC_ENV_VAR\n    - sudo apt-get install -y python-pip\n    - sudo pip install docker-compose\n    - sudo docker image prune -f\n    - sudo docker-compose -f docker-compose.yml build --no-cache\n    - sudo docker-compose -f docker-compose.yml up -d\n    - echo do tests now\n    - sudo docker-compose exec -T web python3 -m coverage run --source='.' manage.py test\n\n...\n\nWhat I've tried:\nusermod -aG docker gitlab-runner\nsudo service docker restart"}, {"role": "assistant", "content": "The best solution for me was adding\npre_clone_script = \"sudo chown -R gitlab-runner:gitlab-runner .\"\n\ninto /etc/gitlab-runner/config.toml\nEven if you won't have permissions after a previous job it'll set correct permissions before cleaning up the workdir and cloning the repo."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to troubleshoot a url error with \"Port number ended with 'y'\"?\n\nWhile trying to clone an already existing repository from gitlab into my local drive. I used the format\n$ git clone https://github.com/libgit2/libgit2  mylibgit \n\nThe resulting folder e.g mylibgit was found somewhere outside the XAMPP web folder (i.e htdocs), I moved it there but it's not working as supposed. \nI moved it out to my desktop and got the error :\nfatal: unable to access 'https://[email\u00a0protected]:xxxxx/yyyyyy/':Port number ended with 'y'"}, {"role": "assistant", "content": "For gitlab, you don't need to specify the user.\nReplace it by an https url based on your GitLab account name.\ncd /path/to/your/repo\ngit remote set-url origin https://gitlab.com/<username>/<yourProjectName.git>\ngit push -u origin master\n\nNote:\n\ntrying to clone an already existing repository from gitla\n\nThis contradict \"git clone https://github.com/libgit2/libgit2\", since this is a GitHub url, not a GitLab one."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GITLAB CI Pipeline not triggered\n\nI have written this yml file for GitLab CI/CD. There is a shared runner configured and running.\nI am doing this first time and not sure where I am going wrong. The angular js project I am having\non the repo has a gulp build file and works perfectly on local machine. This code just has to trigger\nthat on the vm where my runner is present. On commit the pipeline does not show any job. Let me know what needs to be corrected!\nimage: docker:latest\n\ncache:\n  paths:\n    - node_modules/\n\ndeploy_stage:\n  stage: build\n  only:\n    - master\n  environment: stage\n  script:\n  - rmdir -rf \"build\"\n  - mkdir \"build\"\n  - cd \"build\"\n  - git init\n  - git clone \"my url\"\n  - cd \"path of cloned repository\"\n  - gulp build"}, {"role": "assistant", "content": "What branch are you commiting to? You pipeline is configured to run only for commit on master branch.\n...\n  only:\n    - master\n...\n\nIf you want to have triggered jobs for other branches as well then remove this restriction from .gitlab-ci.yml file.\nDo not forget to Enable shared Runners (they may not be enabled by default), setting can be found on GitLab project page under Settings -> CI/CD -> Runners.\nUpdate: Did your pipeline triggers ever work for your project?\nIf not then I would try configuring simple pipeline just to test if triggers work fine:\ntest_simple_job:\n  script:\n    - echo I should execute for any pipeline trigger."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to install Python on Gitlab-CI\n\nHow do you install various versions of Python on Gitlab-CI?\nIn my previous experience with Travis-CI, I simply run the normal Ubuntu/Debian commands to install the deadsnakes repo and then install whatever version I need like:\nsudo add-apt-repository -y ppa:fkrull/deadsnakes\nsudo apt-get -yq update\nsudo apt-get -yq install python2.7 python2.7-dev python3.4 python3.4-dev python3.6 python3.6-dev python3.7 python3.7-dev\n\nI've tried this similar configuration with Gitlab-CI:\nimage: ubuntu:latest\n\nbefore_script:\n  - add-apt-repository -y ppa:fkrull/deadsnakes\n  - apt-get -yq update\n  - apt-get -yq install python2.7 python2.7-dev python3.4 python3.4-dev python3.6 python3.6-dev python3.7 python3.7-dev\n  - python -V\n\ntest:\n  script:\n  - ./run_my_tests.sh\n\nbut this fails with:\n/bin/bash: line 82: add-apt-repository: command not found\n\nI can only assume that even though I'm running an Ubuntu image, Gitlab restricts the commands available. What's the equivalent way to install Python in Gitlab-CI?"}, {"role": "assistant", "content": "You should use a base image containing everything you need. Installing something by hand should work in principle, but will unnecessarily cost you GitLab CI pipeline minutes.\nFor python 3.7 you could do the following:\nimage: python:3.7-alpine3.9\n\nCheck DockerHub for a list of all available python images: https://hub.docker.com/_/python\nIf you need to test with different python versions, I recommend to split your tasks into different GitLab CI jobs, each using a different python base image:\ntest-python-3-7:\n  image: python:3.7-alpine3.9\n  script:\n  - ./run_my_tests.sh\n\ntest-python-2.7:\n  image: python:2.7.16-alpine3.8\n  script:\n  - ./run_my_tests.sh\n\nIf you absolutely need to install stuff by yourself, because there is no appropriate image, I would still suggest you create an image with everything you need, upload it to DockerHub or your own GitLab container registry, and then use it in your CI pipelines."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to deploy node app to remote host from Jenkins?\n\nThis is  Jenkins file in the root of node app directory:\npipeline {\n    agent any\n    triggers {\n        pollSCM('* * * * *')\n    }\n    stages {\n        stage(\"deploy\") {\n            steps {\n            sh \"scp\"\n            }\n        }\n    } \n}\n\nI configured Jenkins to connect to remote gitlab node proj repo to checkout  node project along with Jenkinsfile and run the project's Jenkinsfile. This part works fine but what to do now to perform (note that Jenkins server and the server on which node js is running as well as gitlab repo are all remote to each other):\nrun these commands on remote server on which node app is running\n\ncd ~/mynodeproj \n\npm2 stop mynodeproj \n\ncopy project source files from Jenkins server to remote server where \nnode app is running \n\nnpm install \n\nexport NODE_ENV=production \n\npm2 start mynodeproj\n\nHow to achieve this?\nDo I need to setup private/public keypair on server running jenkins so that jenkins server can do scp to copy file to remote server running node app?"}, {"role": "assistant", "content": "I'm suggest we can use Rocketeer for this case.\nHere is Rocketeer tree on my Jenkins Server for NodeJS App\n$ tree .rocketeer/\n.rocketeer/\n\u251c\u2500\u2500 config.php\n\u251c\u2500\u2500 hooks.php\n\u251c\u2500\u2500 logs\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 develop--20170613.log\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 develop--20170614.log\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 develop--20170616.log\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 staging--20180323.log\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 staging--20180324.log\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 staging--20180326.log\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 production--20180223.log\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 production--20180226.log\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 production--20180227.log\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 production--20180227.log\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 custom-environment--20180328.log\n\u251c\u2500\u2500 paths.php\n\u251c\u2500\u2500 remote.php\n\u251c\u2500\u2500 scm.php\n\u251c\u2500\u2500 stages.php\n\u2514\u2500\u2500 strategies.php\n\n\nYou can manage remote environment of NodeJS App: Develop, Staging, Production (at config.php file)\nIt's will pull newest source code on your Gitlab and keep releases version like Capistrano (at remote.php file)\nIt's can run your pm2 command line after deployed newest source code (at hooks.php file)\nIt's already help run npm install NodeJS packages.\n\n\nSo here is my Jenkins Job setting:\nSource Code Management\n\nBuild Triggers\n\nBuild\n\n#!/bin/bash -el\ncd $JENKINS_HOME/app-deploy/app-socketio\nrocketeer deploy --on=\"develop\"\n\ndevelop mean connect to Develop Remote Server (at .rocketeer\\config.php file)\n'connections'      => [\n    'develop' => [\n        'host'      => '35.xx.xx.xx',\n        'username'  => 'ec2-user',\n        'password'  => '',\n        'key'       => '/var/lib/jenkins/.ssh/foo.pem',\n        'keyphrase' => '',\n        'agent'     => '',\n        'db_role'   => true,\n    ],\n    'staging' => [\n        'host'      => '34.xx.xx.xx',\n        'username'  => 'ec2-user',\n        'password'  => '',\n        'key'       => '/var/lib/jenkins/.ssh/bar.pem',\n        'keyphrase' => '',\n        'agent'     => '',\n        'db_role'   => true,\n\n    ],\n    'production' => [\n        'host'      => '18.xx.xx.xx:63612',\n        'username'  => 'ec2-user',\n        'password'  => '',\n        'key'       => '/var/lib/jenkins/.ssh/woot.pem',\n        'keyphrase' => '',\n        'agent'     => '',\n        'db_role'   => true,\n    ],\n    'custom-environment' => [\n        'host'      => '13.xx.xx.xx:63612',\n        'username'  => 'ec2-user',\n        'password'  => '',\n        'key'       => '/var/lib/jenkins/.ssh/test.pem',\n        'keyphrase' => '',\n        'agent'     => '',\n        'db_role'   => true,\n    ],\n],\n\nAnd run pm2 command line configure at hooks.php file\n'after'  => [\n    'setup'   => [],\n    'deploy'  => [\n            \"pm2 delete mynodeproj\", //Delete old pm2 task\n            \"pm2 start src/mynodeproj.js\", //Start new mynodeproj\n    ],\n    'cleanup' => [],\n],\n\nHope this can help you!!"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "install gitlab on Windows with Docker\n\nI searched a lot and found that GitLab Community Edition is not installed on Windows so now I want to install it with the help of Docker. I do not know that is it possible and how I can do it ?"}, {"role": "assistant", "content": "You need to install Docker for Windows.\n\nShare drive for Docker (in Docker's settings > shared drives). For example, drive E:\n\n\n\n\nThen, you need to create 3 directories on drive E: (e:\\gitlab\\config, e:\\gitlab\\logs, e:\\gitlab\\data)\n\nFrom the Command Prompt, run:\ndocker run --detach --hostname gitlab.yourdomain.ru \n--publish 443:443 --publish 80:80 --publish 22:22 --name gitlab \n--restart always --volume e:\\gitlab\\config:/etc/gitlab \n--volume e:\\gitlab\\logs:/var/log/gitlab \n--volume e:\\gitlab\\data:/var/opt/gitlab gitlab/gitlab-ce:latest\n\n\n\nThat's it! You have now successfully run GitLab image."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Inject GitLab CI Variables into Terraform Variables\n\nI'm having a set of Terraform files and in particular one variables.tf file which sort of holds my variables like aws access key, aws access token etc. I want to now automate the resource creation on AWS using GitLab CI / CD. \nMy plan is the following:\n\nWrite a .gitlab-ci-yml file\nHave the terraform calls in the .gitlab-ci.yml file\n\nI know that I can have secret environment variables in GitLab, but I'm not sure how I can push those variables into my Terraform variables.tf file which looks like this now!\n# AWS Config\n\nvariable \"aws_access_key\" {\n  default = \"YOUR_ADMIN_ACCESS_KEY\"\n}\n\nvariable \"aws_secret_key\" {\n  default = \"YOUR_ADMIN_SECRET_KEY\"\n}\n\nvariable \"aws_region\" {\n  default = \"us-west-2\"\n}\n\nIn my .gitlab-ci.yml, I have access to the secrets like this:\n- 'AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}' \n- 'AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}' \n- 'AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}'\n\nHow can I pipe it to my Terraform scripts? Any ideas? I would need to read the secrets from GitLab's environment and pass it on to the Terraform scripts!"}, {"role": "assistant", "content": "Which executor are you using for your GitLab runners? \nYou don't necessarily need to use the Docker executor but can use a runner installed on a bare-metal machine or in a VM. \nIf you install the gettext package on the respective machine/VM as well you can use the same method as I described in Referencing gitlab secrets in Terraform for the Docker executor. \nAnother possibility could be that you set \njob:\n    stage: ...\n    variables: \n        TF_VAR_SECRET1: ${GITLAB_SECRET}\n\nor \njob:\n    stage: ...\n    script:\n        - export TF_VAR_SECRET1=${GITLAB_SECRET}\n\nin your CI job configuration and interpolate these. Please see Getting an Environment Variable in Terraform configuration? as well"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "\"Host key verification failed\" on Gitlab_ci although ssh_key is present\n\n\"Host key verification failed.\" on Gitlab_ci when running \"ssh name@server\"\nHere's a part of my gitlab_ci which is supposed to login to my server and run scripts from the repo:\nscript:\n  - which ssh-agent || ( apt-get update -y && apt-get install openssh-client -y )\n  - eval $(ssh-agent -s)\n  - ssh-add <(echo -e \"$SSH_PRIVATE_KEY\")\n\n\n  - echo \"debug\"\n  - echo \"$SSH_PRIVATE_KEY\" # all is ok here, it'll be printed\n  - echo \"debug\"\n\n\n  # - here comes an error\n  - (cat ./script/script1.sh) | ssh -t -t $SSH_USERNAME@$SSH_HOST\n\nAnd the errror:\n  Host key verification failed.\n  ERROR: Job failed: exit code 1\n\nWhy the error? The variables are set. \nThe private key does work when I'm doing the same thing manually from my local computer and Gitlab."}, {"role": "assistant", "content": "In addition of Git error: \u201cHost Key Verification Failed\u201d when connecting to remote repository, check your .known_hosts file.\nIf that same private key is working locally, that might be because, locally, your ~/.ssh/known_hosts file does include the ssh_keyscan of the remote server you want to connect to.\nMake sure your GitLab CI job does too."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to use Dockerfile in Gitlab CI\n\nUsing gitlab-ci for my node/react app, I'm trying to use phusion/passenger-nodejs as the base docker image\nI can specify this easily in .gitlab-ci.yml: \nimage: phusion/passenger-nodejs:latest\n\nvariables:\n  HOME: /root\n\ncache:\n  paths:\n  - node_modules/\n\nstages:\n  - build\n  - test\n  - deploy\n\nset_environment:\n  stage: build\n  script:\n    - npm install\n  tags:\n  - docker\n\ntest_node:\n  stage: test\n  script:\n    - npm install\n    - npm test\n  tags:\n    - docker\n\nHowever, Phusion Passenger expects you to make configuration changes, e.g. python support, using their special init process, etc. in the Dockerfile.\n#FROM phusion/passenger-ruby24:<VERSION>\n#FROM phusion/passenger-jruby91:<VERSION>\nFROM phusion/passenger-nodejs:<VERSION>\n#FROM phusion/passenger-customizable:<VERSION>\n\n# Set correct environment variables.\nENV HOME /root\n\n# Use baseimage-docker's init process.\nCMD [\"/sbin/my_init\"]\n\n# If you're using the 'customizable' variant, you need to explicitly opt-in\n# for features. \n#\n# N.B. these images are based on https://github.com/phusion/baseimage-docker, \n# so anything it provides is also automatically on board in the images below \n# (e.g. older versions of Ruby, Node, Python).  \n# \n# Uncomment the features you want:\n#\n#   Ruby support\n#RUN /pd_build/ruby-2.0.*.sh\n#RUN /pd_build/ruby-2.1.*.sh\n#RUN /pd_build/ruby-2.2.*.sh\n#RUN /pd_build/ruby-2.3.*.sh\n#RUN /pd_build/ruby-2.4.*.sh\n#RUN /pd_build/jruby-9.1.*.sh\n#   Python support.\nRUN /pd_build/python.sh\n#   Node.js and Meteor standalone support.\n#   (not needed if you already have the above Ruby support)\nRUN /pd_build/nodejs.sh\n\n# ...put your own build instructions here...\n\n# Clean up APT when done.\nRUN apt-get clean && rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*\n\nIs there a way to use a Dockerfile with gitlab-ci? Is there a good work around other than apt-get install and adding shell scripts?"}, {"role": "assistant", "content": "Yes, create a second Gitlab repository where you place your Dockerfile in. There you add a gitlab-ci.yml file with a script command that builds you modified image and push it to your private registry or the Gitlab embedded Docker registry, eg:\nscript:\n  docker build . -t http://myregistry:5000/mymodified image\n  docker push http://myregistry:5000/mymodified\nInside your other Gitlab repository, change the image: line accordingly:\nimage: http://myregistry:5000/mymodified\nInformation on the Gitlab embedded Docker registry can be found here -> here"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab Trigger API returns 404\n\nI created a trigger (using settings/ci_cd page). The instructions below the trigger tell me to call it using version 3 API (of course, I set the token variable to the token stated under the trigger section):\ncurl -X POST \\\n     -F token=${TOKEN} \\\n     -F ref=master \\\n     https://gitlab.com/api/v3/projects/2313008/trigger/builds\n\nWhich only returns:\n\n{\"error\":\"404 Not Found\"}\n\nI also tried to follow the API v4 documentation:\ncurl --request POST \\\n     --form token=${TOKEN} \\\n     --form ref=master \\\n     https://gitlab.com/api/v4/projects/2313008/trigger/pipeline\n\nwhich returns the same error.\nAre there any additional settings required?"}, {"role": "assistant", "content": "I had the same issue, but I was using Personal Access Token instead of Pipeline trigger token!!\nYou can generate this token inside your project repo CI/CD settings."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab: Search Commits per user\n\nAs an admin, I would like to find out how many commits are done per branch, per user, total commits by a user in last 3 months, total commits in last 3 months. etc.. How can I do this ?\nI could see this on Github like this: List commit by user\nI want to see the same thing for GitLab also. \nI am running Gitlab CE version: 7.2.1\nI thought of running git log --author='userid' but this will take forever to run for so many user / so many branches. Same would apply for running Gitstats because I have to sync all the branches locally first.\nAny pointers please?"}, {"role": "assistant", "content": "Gitstats is good to get html reports. It internally runs the git commands that you can easily change in its source to get your own kind of report.\nOn another note, I don't think git log should take long. You can try this sample and confirm how long it takes\ngit log --date=short --branches --since=3.months.ago --author=xyz\nRunning without using --author will give all the commits pushed in last three months. \nA list of authors can be used in a single command , it should be separated by a | \nAdditionally you can use --pretty option to print information in desired format. You can play around with pretty format option as it is rich in offering various formats.\nYou can also chose this to run on list of specific branches by having them in a iteration loop. Git is very fast in getting this information."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab in a subdirectory with apache and passenger\n\nI'm attempting to set up gitlab so that it is accessible through a subdirectory of an existing apache server, example.com/gitlab, for example. I am trying to use passenger, as this seems to be the easiest to set up, but other solutions would also be acceptable. Using a separate virtual host for gitlab is unfortunately not an option for me.\nMy Setup\nIn setting this up, I have followed the gitlab setup guide and the passenger documentation.\nI believe the most relevant parts of /etc/httpd/conf/httpd.conf are the following:\nDocumentRoot \"/home/.www\"\n\n# gitlab config\nRackBaseURI /gitlab\n<Directory \"/home/.www/gitlab\">\n    Options -MultiViews\n</Directory>\n\nThe DocumentRoot of apache contains a symlink to the gitlab public directory:\n$ ls -l /home/.www\nlrwxrwxrwx  1 root  http    23 Jul 29 12:35 gitlab -> ../gitlab/gitlab/public\n\nPassenger was installed using the passenger-install-apache2-module script, and the config lines output by the script are included in the apache config.\nI have played with the relative_url_root in config/gitlab.yml; that did not have any effect (judging from the the comments in the file, this mechanism seems to be discouraged or deprecated---it would be nice to avoid it).\nResults\nWhen accessing example.com/gitlab, I get the following output (a plain text document):\nNot Found: /\n\nApache's logs indicate that passenger has started, but that at least favicon.ico is being requested from the document root, when it should be be requested from the subdirectory as /gitlab/favicon.ico:\n[ 2013-07-29 14:14:12.1029 2037/7f3502e1e740 agents/HelperAgent/Main.cpp:597 ]: PassengerHelperAgent online, listening at unix:/tmp/passenger.1.0.2033/generation-0/request\n[ 2013-07-29 14:14:12.1150 2043/7fa24dbf3740 agents/LoggingAgent/Main.cpp:330 ]: PassengerLoggingAgent online, listening at unix:/tmp/passenger.1.0.2033/generation-0/logging\n[ 2013-07-29 14:14:12.1154 2034/7ff20a0cb740 agents/Watchdog/Main.cpp:635 ]: All Phusion Passenger agents started!\n[Mon Jul 29 14:14:12 2013] [notice] Digest: generating secret for digest authentication ...\n[Mon Jul 29 14:14:12 2013] [notice] Digest: done\n[ 2013-07-29 14:14:13.0297 2057/7f5380ee3740 agents/Watchdog/Main.cpp:452 ]: Options: { 'analytics_log_user' => 'nobody', 'default_group' => 'nobody', 'default_python' => 'python', 'default_ruby' => '/usr/bin/ruby', 'default_user' => 'nobody', 'log_level' => '0', 'max_instances_per_app' => '0', 'max_pool_size' => '6', 'passenger_root' => '/usr/lib/ruby/gems/2.0.0/gems/passenger-4.0.10', 'pool_idle_time' => '300', 'temp_dir' => '/tmp', 'union_station_gateway_address' => 'gateway.unionstationapp.com', 'union_station_gateway_port' => '443', 'user_switching' => 'true', 'web_server_pid' => '2055', 'web_server_type' => 'apache', 'web_server_worker_gid' => '33', 'web_server_worker_uid' => '33' }\n[ 2013-07-29 14:14:13.0367 2061/7f92eefef740 agents/HelperAgent/Main.cpp:597 ]: PassengerHelperAgent online, listening at unix:/tmp/passenger.1.0.2055/generation-0/request\n[ 2013-07-29 14:14:13.0485 2067/7f4cc5205740 agents/LoggingAgent/Main.cpp:330 ]: PassengerLoggingAgent online, listening at unix:/tmp/passenger.1.0.2055/generation-0/logging\n[ 2013-07-29 14:14:13.0490 2057/7f5380ee3740 agents/Watchdog/Main.cpp:635 ]: All Phusion Passenger agents started!\n[Mon Jul 29 14:14:13 2013] [notice] Apache/2.2.25 (Unix) mod_ssl/2.2.25 OpenSSL/1.0.1e DAV/2 Phusion_Passenger/4.0.10 configured -- resuming normal operations\n[ 2013-07-29 14:14:16.8354 2061/7f92eef2a700 Pool2/Spawner.h:738 ]: [App 2096 stdout] \n[ 2013-07-29 14:14:24.8814 2061/7f92eef2a700 Pool2/SmartSpawner.h:301 ]: Preloader for /home/.www/../gitlab/gitlab started on PID 2096, listening on unix:/tmp/passenger.1.0.2055/generation-0/backends/preloader.2096\n[Mon Jul 29 14:14:25 2013] [error] [client 129.241.220.221] File does not exist: /home/.www/favicon.ico\n\nIt seems to me that it should not be necessary to start any puma server or similar, so I have not run any bundle exec rake ... commands to start anything rails-related when generating the logs above (I have tried that but I'm not including the output here as it seems identical to me).\nDoes anyone see what I am doing wrong?"}, {"role": "assistant", "content": "I don't think that Passenger is the easiest way to configure Apache for GitLab. Using a local reverse proxy is actually more simple.\nThe lastest version of GitLab (6.0) is using Unicorn, but it almost the same with Puma.\nIn your config/unicorn.rb file, comment listen directive and add:\nlisten \"127.0.0.1:9242\"\n\nIn your Apache configuration, you can then add \nProxyPass         /gitlab http://127.0.0.1:9242\nProxyPassReverse  /gitlab http://127.0.0.1:9242\n\nRestart Apache and GitLab, and it should work."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to use rule in gitlab-ci\n\nI'm trying to build a job that can be conditionally executed depends on whether the files or subdirectories in WebClient is modified in develop branch, using rules. If there are changes found in the develop branch only, then a pipeline will be built.\nCurrently what I got in my .gitlab-ci.yml is\ndeploy_dev_client:\n  stage: client\n  tags:\n    - my tags\n  script:\n    - '& cd WebClient'\n    - 'npm rebuild node-sass'\n    - 'npm install @angular/[email\u00a0protected]'\n    - '& npm run build-release --max_old_space_size=$NODE_MEMORY_SIZE'\n\n  rules:\n    - changes:\n      - WebClient/**/*\n      when: always\n    - when: never\n\nHowever, after testing, I realized that the pipeline is executed whenever I push something from my local repo to gitlab, even at the other side branches.\nI have tried using only:-develop', however it results in yaml invalid error, maybe due to not being able to use only if rules has already been used. Is there anyway I can still using rules to target only develop branch?"}, {"role": "assistant", "content": "In this link:\nhttps://docs.gitlab.com/ee/ci/yaml/#ruleschanges\nThey write that rules: changes should work exactly like only/except. If you read about only/except, there are a few strange things with it:\nhttps://docs.gitlab.com/ee/ci/yaml/#using-onlychanges-without-pipelines-for-merge-requests\n\nWhen pushing a new branch or a new tag to GitLab, the policy always evaluates to true.\n\nTo get around this and only run your job on the development branch, you should be able to combine an if with changes:\ndeploy_dev_client:\n  stage: client\n  tags:\n    - my tags\n  script:\n    - '& cd WebClient'\n    - 'npm rebuild node-sass'\n    - 'npm install @angular/[email\u00a0protected]'\n    - '& npm run build-release --max_old_space_size=$NODE_MEMORY_SIZE'\n\n  rules:\n    - if: '$CI_COMMIT_REF_NAME== \"development\"'\n      changes:\n      - WebClient/**/*\n      when: always\n\n(I haven't tested this code, so let me know if it is all wrong!)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I collect the logs for all jobs in a gitlab pipeline?\n\nI have some gitlab CI pipelines that consist of dozens of jobs -- sometimes I need to find something that might appear in a job without knowing which one.  I can manually select each job in the web interface and review the associated log, but doing that for each job is infeasible.\nIs there some way (ideally as an unprivileged gitlab user) to retrieve/aggregate the output from all the jobs of a given pipeline?\nIn case it matters, I'm using version 12.5.X-ee."}, {"role": "assistant", "content": "You could use the GitLab Jobs API to aggregate all the job traces, and write a script with something along the lines of:\n\nAdd a final stage to your pipeline (aggregate job logs)\nList the current Pipeline ID jobs\nLoop over the JOB_IDs (apart from the aggregate job logs job), and get their job logs\nDump to a file and you can review all the logs in one file\n\nNote, that you will need to create a personal-access-token, and then use it in the CI job to access the API. There's not a great way with storing your access token apart from as a custom environment variable, and then accessing that variable in the .gitlab-ci.yml.\nHTH"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab test coverage visualization is not working\n\nHi guys I have a express application and I'm playing around with gitlab to add Gitlab test coverage visualization\nHere is my .gitlab-ci.yml\nstages:\n  - test\n  - dockerize\n  - staging\n  - production\n\nunit-tests:\n  stage: test\n  script:\n    - npm install\n    - npm run test\n    - npm run test-coverage\n    - cat coverage/cobertura-coverage.xml\n    - \"echo 'Code coverage: 90.90'\" \n  coverage: '/Code coverage: \\d+\\.\\d+/'\n  rules:\n    - if: '$CI_PIPELINE_SOURCE == \"merge_request_event\"'\n    - if: '$CI_COMMIT_BRANCH == \"master\"'\n    - if: '$CI_COMMIT_BRANCH == \"release-v1\"'\n  artifacts:\n    reports:\n      cobertura: coverage/cobertura-coverage.xml\n  tags:\n   - demo\n\ndockerize-application:\n  stage: dockerize\n  script:\n    - echo \"dockerizing application\"\n  rules:\n    - if: '$CI_PIPELINE_SOURCE == \"merge_request_event\"'\n    - if: '$CI_COMMIT_BRANCH == \"master\"'\n    - if: '$CI_COMMIT_BRANCH == \"release-v1\"'\n  tags:\n   - demo\n\n\ndeploy_to_staging:\n  stage: staging\n  script:\n    - echo \"deploying to staging\"\n  rules:\n    - if: '$CI_COMMIT_BRANCH == \"master\"'\n  tags:\n   - demo\n\ndeploy_to_production:\n  stage: staging\n  script:\n    - echo \"deploying to production\"\n  rules:\n    - if: '$CI_COMMIT_BRANCH == \"release-v1\"'\n  tags:\n   - demo\n\nIn my package json, here is the important part:\n\"scripts\": {\n    \"start\": \"node ./bin/www\",\n    \"debug\": \"nodemon ./bin/www\",\n    \"test\": \"npx nyc --reporter text mocha\",\n    \"test-coverage\": \"npx nyc --reporter cobertura mocha\"\n  }\n\nIn the logs, I can see that the coverage file is uploaded.\nRuntime platform                                    arch=amd64 os=windows pid=19548 revision=775dd39d version=13.8.0\ncoverage/cobertura-coverage.xml: found 1 matching files and directories \nUploading artifacts as \"cobertura\" to coordinator... ok  id=1097622443 responseStatus=201 Created token=6wcrN_d_\n\nI did a lot of research and I still can't figure out why! I figured that was a feature flag turning this feature off by default but not any more:\nhttps://gitlab.com/gitlab-org/gitlab/-/merge_requests/43711\nHere is the link to my project: I mainly created to experiment with gitlab ci/cd"}, {"role": "assistant", "content": "It's now working. The issue was that I needed to wait for the WHOLE pipeline to succeed before I could actually see the visualization.\nHere is an issue open in Gitlab:\nhttps://gitlab.com/gitlab-org/gitlab/-/issues/236248"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GITLAB-CI - Join network created by docker-compose\n\nI am creating a gitlab-ci to run e2e tests over my application, \nso, given I have this docker-compose.yml:\nservices:\n  chrome:\n    image: zenika/alpine-chrome:latest\n    command: [\n      chromium-browser,\n      \"--headless\",\n      \"--no-sandbox\",\n      \"--disable-gpu\",\n      \"--ignore-certificate-errors\",\n      \"--reduce-security-for-testing\",\n      \"--remote-debugging-address=0.0.0.0\",\n      \"--remote-debugging-port=9222\",\n      \"https://google.com/\",\n    ]\n    ports:\n      - \"9222:9222\"\n    networks:\n      - test-e2e\n\nnetworks:\n  test-e2e:\n    ipam:\n      driver: default\n      config:\n        - subnet: 172.28.0.0/16\n\nwhen I run docker-compose up everything just works fine,\nand on my local machine I am able to visit localhost:9222 and access the chrome debugger.\n\nHowever, when I run the same job on gitlab-ci I get a ECONNREFUSED error:\nF---F\n\nFailures:\n\n1) Scenario: List of Profiles # src/features/profile.feature:3\n   \u2716 Before # dist/node/development/webpack:/hooks/puppeteer.hooks.ts:17\n       Failed to fetch browser webSocket url from http://localhost:9222/json/version: connect ECONNREFUSED 127.0.0.1:9222\n       Error: connect ECONNREFUSED 127.0.0.1:9222\n           at TCPConnectWrap.afterConnect [as oncomplete] (net.js:1191:14)\n\n\nSo it is clear that I cannot join the docker-compose network and access localhost:9222 from the job\nMy gitlab-ci.yml is pretty straightforward and looks like this:\nE2E tests:\n  stage: test end-to-end\n  image:\n    name: docker/compose:1.24.1\n    entrypoint: [\"/bin/sh\", \"-c\"]\n  services:\n    - docker:dind\n  before_script:\n    - apk --update add nodejs yarn\n    - docker-compose -f test-e2e.yaml up -d\n  script:\n    - yarn test:cucumber\n  after_script:\n    - docker-compose -f test-e2e.yaml down\n\nyarn test:cucumber basically runs cucumber and puppeteer trying to access localhost:9222 to get chrome's metadata.\n\nHow can I join the network created by docker-compose from the gitlab-ci job?\n\nI don't have access to edit runner configurations"}, {"role": "assistant", "content": "TL; DR On CI your chrome container is reachable using docker:9222 (or more generally <name-of-the-dind-service-on-ci>:<exposed-port>), not localhost:9222\nExplanation\nAs per your gitlab-ci.yml, you will start 2 containers:\n\na docker/compose:1.24.1 container from which you will run docker-compose and yarn commands\na docker:dind on which a Docker Daemon will run. This container will be reachable from docker/compose:1.24.1 container via hostname docker (see GitlabCI doc on accessing services)\n\nWhen running a container in Docker, the container is actually started by the Docker daemon and will run and expose ports on the host on which the Daemon is running.\n\nOn your machine, the Docker daemon is running locally and will expose the container ports on your local network, allowing you to reach your chrome container via localhost\nOn the CI, you are running your commands from a docker/compose:1.24.1 container but the Docker daemon is running in another container (a different host): the docker:dind container. chrome container will be created inside docker:dind container and its port exposed from this same container. You simply need to access the docker:dind container which will expose chrome ports.\n\nBy using localhost from your docker/compose:1.24.1 container, you won't be able to reach chrome because its port is not exposed on docker/compose:1.24.1 container but from docker:dind container. You need to specify its host (docker) and the exposed port (9222)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I register/reregister a Gitlab Runner using a pre-made config.toml?\n\nI recently wanted to move a Gitlab runner that I had set up for my self-hosted Gitlab instance from being a project runner (i.e. running jobs only for a project) to being a group runner (so it could also run jobs for other projects in the same group). I wanted to retain the /etc/gitlab-runner/config.toml settings that I had painstakingly hand-written.\nLuckily I backed up config.toml, because sudo gitlab-runner unregister -t ... -u ... deleted the whole configuration from config.toml.\nIn order to get the same config registered under the group instead of the project, I had to:\n\nRegister the runner in a paused state with a dummy configuration, with the group's registration token:\n\nsudo gitlab-runner register \\\n  --non-interactive \\\n  --url <URL HERE>\n  --registration-token <TOKEN HERE> \\\n  --executor docker \\\n  --docker-image docker:dind \\\n  --paused\n\n\nGo into the new config.toml that this created and copy the runner's individual runner token.\n\nOverwrite config.toml with my desired configuration.\n\nEdit the config.toml and plug in the new individual runner token.\n\nStart the Gitlab runner service (sudo systemctl start gitlab-runner).\n\nUnpause the runner in the Gitlab web UI.\n\n\nEven after doing all this, the Gitlab instance still sees the runner under the name it registered with in the dummy config, rather than the name in the config.toml.\nTrying the --config option to gitlab-runner register didn't work at all; I think that just tells it where to save the config. It still prompted me for new settings to use instead of reading from the config.toml I pointed it at.\nThe Gitlab documentation on runner registration is all written around one shot gitlab-runner register commands with loads of options on them that essentially specify the whole config on the command line. I really don't want to translate my config.toml manually into a command line that turns around and rebuilds it (minus any comments, of course).\nI can't believe that this is really the right workflow to re-register a runner with a new project/group/Gitlab instance, or to create a copy of a runner from a saved config. What am I missing here? How can I create a new Gitlab runner from an existing config.toml file?"}, {"role": "assistant", "content": "There isn't an easy way to do what you want, from what I can find in the GitLab documentation and some open issues that they have.\nHere is an issue that describes something similar to what you want:\nhttps://gitlab.com/gitlab-org/gitlab-runner/issues/3540\nHere is what I think is GitLab's goal with how to register runners:\nhttps://gitlab.com/gitlab-org/gitlab-ce/issues/40693\nI believe that the only thing that you can't change from the .toml file is the name of the runner, and maybe not the tags either. Then name is only created when you register the runner. I read something somewhere that you can change the tags of a shared runner, but I can't find it now.\nHere is a workaround to make the process of registering a bit more automatic:\nhttps://gitlab.com/gitlab-org/gitlab-runner/issues/3553#note_108527430\nHe used this API:\ncurl --request POST \"https://gitlab.com/api/v4/runners\" --form \"token=<registration-token>\" --form \"description=test-1-20150125-test\" --form \"tag_list=ruby,mysql,tag1,tag2\"\n\nThen he got the following response back:\n{\"id\":401513,\"token\":\"<runner-token>\"}\n\nHe could then inject the runner-token into his already pre-made .toml file.\nFor you, it would have been possible to use the registration token for your group, and then to write in the description/name of the runner and the tags. You could then have re-used your config.toml and only changed the runner-token, and it should have worked."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI pipeline - continue to next stage only on a certain condition\n\nI am trying to build a Gitlab pipeline that is made up of 4 jobs. The stages I have are:\nstages:\n- compare\n- build\n- test\n- deploy\n\nThe compare stage is taking a dump from an API on another server, comparing it to the same dump from the last successful pipeline run (it's made available as an artifact) then comparing the two.\nIf there is any difference I would like the pipeline to move onto the next stage, if there is no difference then I would like it to exit gracefully. \nI have it working but rather than exiting gracefully if there are no differences it fails and the pipeline is marked as failed, here is how it looks.\n\nHere is the important code from my .gitlab-ci.yaml (with some identifying information removed )\nGet_inventory_dump:\n  stage: compare  \n  only:\n    - schedules\n  script: \n    - 'curl -k --output \"previous-inventory.json\" --header \"PRIVATE-TOKEN: $user_token\" \"https://url/to/get/artifact/from/last/successful/run\"'\n    - python3 auto_config_scripts/dump_device_inventory_api_to_json.py -p $pass -o /inventory.json -u https://url/for/inventory/dump -y\n    - /usr/bin/cmp previous-inventory.json inventory.json && echo \"No Change in inventory since last successful run\" && exit 1 || echo \"Inventory has changed since last run, continue\" && exit 0\n  artifacts:\n    when: on_success\n    expire_in: 4 weeks\n    paths:\n     - inventory.json\n\nGenerate_icinga_config:\n  stage: build\n  only:\n    - schedules\n  when: on_success\n  script: \n\nEverything is behaving as I would expect but I feel like there is a better way to do this. \nIs there a way, if the comparison is the same to simply skip the next stages of the pipeline but still have the pipeline completed as 'passed' rather than 'failed'?"}, {"role": "assistant", "content": "There are two solutions I can think of. Unfortunately, they either come slightly confusing UI behavior or you have to adapt all jobs.\nJob attributes like only or changes are only concerned with the state of or the files of the git repository (see https://docs.gitlab.com/ee/ci/yaml/) and therefore not of use here as the file is only created during CI and not part of the repository.\nSolution 1: You can allow_failure: true to the first job. This will mark the pipeline as successful despite the job failing and subsequent jobs will not be executed as the first job did not succeed. The drawback is that when you investigate the pipeline there will be an exclamation mark instead of a green check for this job.\nSolution 2: Instead of failing the first job when there are no changes the inventory.json file is removed. And all subsequent jobs directly terminate with exit code 0 when the file doesn't exist. Note that this only works because inventory.json is marked as an artifact."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Moving a docker-compose container to openshift V3\n\nI would like to move the Omnibus gitlab docker image to openshift V3,\nso I've got the dockerfile and docker-compose files @ https://gitlab.com/gitlab-org/omnibus-gitlab/tree/master/docker. \nWhat is the best way for having a scalable openshift v3 pod ? \nAs the command oc import docker-compose is experimental so I stuck and lost in the process of building a reliable solution.\nThanks\nHerve"}, {"role": "assistant", "content": "You should use https://kompose.io/\nRun kompose convert --provider=openshift in the same directory as your docker-compose.yaml file."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How is Gitlab different compared to Github?\n\nI'm trying to understand the pros and cons of the two from experienced developer's point of view. Of course Github is the more widely used of the two, but if someone could explain in general terms what they find better/lacking in either, that would be great. \n(I use Github at the moment, by the way)."}, {"role": "assistant", "content": "Gitlab is a self-hosted git server. I have used both (plus bitbucket) and I don't see much difference in terms of functionality. Github's UI is far more advanced, and they offer some custom features (e.g. Releases)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Building Go apps with private modules in Docker\n\nI'm trying to build a go project in a docker container that relies on private submodules.\nI was hoping that --mount=type=ssh would pass my ssh credentials to the container and it'd work. Currently I can build locally with just make the GOPRIVATE variable set and the git config update.\nHere is my relevant Dockerfile currently\n# syntax = docker/dockerfile:experimental\n\nFROM golang:1.14.3-alpine AS build\nRUN apk add --no-cache git \\\n                openssh-client \\\n                ca-certificates\n\nWORKDIR /src\nENV GIT_TERMINAL_PROMPT=1\nENV GOPRIVATE=\"gitlab.com/company_foo\"\nRUN git config --global url.\"ssh://[email\u00a0protected]\".insteadOf \"https://gitlab.com\"\n\n\n\n# Authorize SSH Host\n# Skip Host verification for git\nRUN mkdir -p /root/.ssh && \\\n    chmod 0700 /root/.ssh && \\\n    ssh-keyscan gitlab.com > /root/.ssh/known_hosts &&\\\n    chmod 644 /root/.ssh/known_hosts && touch /root/.ssh/config \\\n    && echo \"StrictHostKeyChecking no\" > /root/.ssh/config\n\nCOPY go.mod go.sum .\nRUN --mount=type=ssh mkdir -p /var/ssh && \\\n    GIT_SSH_COMMAND=\"ssh -o \\\"ControlMaster auto\\\" -o \\\"ControlPersist 300\\\" -o \\\"ControlPath /var/ssh/%r@%h:%p\\\"\" \\\n    go mod download\nCOPY . .\nRUN --mount=type=cache,target=/root/.cache/go-build go build -o api-server ./cmd/api-server\nRUN --mount=type=cache,target=/root/.cache/go-build go build -o migrations ./cmd/migrations\n\nI've also tried adding a CI_JOB_TOKEN with\nRUN echo -e \"machine gitlab.com\\nlogin gitlab-ci-token\\npassword ${CI_JOB_TOKEN}\" > ~/.netrc\n\nbut this also didn't work. Perhaps I did it wrong.\nAll of this results in the failure:\n revision v0.0.3: unknown revision v0.0.3\n\nrelating to one of our private repos.\nAny advice would be appreciate.\nI'm absolutely at a lost."}, {"role": "assistant", "content": "This workes for me.\nFROM golang:1.14\nARG USERNAME=user1\nARG PASSWORD=secret\n\nWORKDIR /app\nADD . .\nENV GOPRIVATE=private.git.local/*\nRUN echo \"machine private.git.local login $USERNAME password $PASSWORD\" > ~/.netrc\n\nRUN go build -o testGo main.go\nCMD [\"/app/testGo\"]"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab-ci-runner choose executer \"Please enter the executor:\"\n\nI have ran gitlab-ci-multi-runner in a container by docker.\nWhen I execute the gitlab-ci-multi-runner register in the container,it ask \n\nPlease enter the executor: docker...?\n\nIf I choose docker,does it mean a docker container will run on the current container?\nSorry for my poor english :)"}, {"role": "assistant", "content": "By choosing 'docker' as the CI runner executor a docker container will be created to run the builds. If you are unsure about which executor to use the 'shell' executor is probably your best choice. gitlab-ci-multi-runner configuration documentation has more information on how to configure the various executors."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to have a Gitlab CI Pipeline run some jobs always and other jobs only on merge-requests?\n\nTL/DR: \nMy goal is to have a Gitlab (CE-12.4.2) pipeline that executes some jobs only on merge-requests and other jobs always (on merge-requests and on all normal pushes). How must the .gitlab-ci.yml look to do this?\nMy use-case: \nI have a big pipeline running a lot of jobs (tests, validation, dep's, build, doc's, ...). Now I have added a staging environment (using kubernetes) and have the pipeline build a new image and deploy that in the staging-environment. This allows me to instantly open up the changed (web-)application and see how the changes behave and look without having to check them out locally. Now building an image and deploying it to staging would be much too resource-heavy to do for every push, so I only want deployments to staging when someone creates a merge-request for me to review.\nA very simplified example:\ninstall:\n  script: ...\n\ntest:\n  script: ...\n\nbuild-image:\n  script: ...\n  only: [merge_requests]\n\ndeploy-staging:\n  script: ...\n  only: [merge_requests]\n\nFor all normal pushes, the jobs install and test should be executed.\nFor merge-requests, the jobs install, test, build-image and deploy-staging should be executed.\nWhat i have tried: Gitlab has this feature to define only: [merge_requests] on a job, this causes that job to only be executed when the pipeline is executed for a merge-request. Sounds like exactly what I am looking for, but there is a big catch. Once that attribute is applied to one job in a pipeline, all other jobs in that pipeline that do not have that attribute will be removed from the pipeline when executed inside merge-requests. That seemed like a bug to me at first, but is actually documented behaviour:\nIn the above example, the pipeline contains only a test job. Since the build and deploy jobs don\u2019t have the only: [merge_requests] parameter, they will not run in the merge request.\n\nIn order to re-introduce all the other jobs to the pipeline for merge-requests, I have to apply only: [merge_requests] to all other jobs. The problem with that approach is that now these regular jobs do not get executed for normal git-pushes anymore. And I have no way to re-introduce these regular jobs to pipelines for normal pushes, because Gitlab has no support for only: [always] or anything like that.\nNow I also have noticed that the only syntax is candidate for deprecation and one should prefer the rules syntax instead, so I took a look at that. There are multiple problems with that approach: \n\nThe only way to detect with rules whether the pipeline is executed for a merge-request or not is to evaluate the variables related to merge-requests, like $CI_MERGE_REQUEST_ID. Unfortunately these variables only exist when only: [merge_requests] is used, which would re-introduce the above problems.\nRules only allow the conditional application of other attributes, so I still would have to use only, except or when attributes to actually remove or add jobs from or to the pipeline. Unfortunately Gitlab does not support anything like only: [never] or when: never, so i have no way to actually remove or add the jobs.\n\nI also tried to have the jobs depend on another using need or dependencies attributes, this seemed to have no effect on whether the job is included to the pipeline or not.\nThe last thing I desperately tried was including all jobs always and just mark them as when: manual to be triggered manually by pushing a button. This somewhat works, but is very tedious because the deployment to staging is a multi-job process with every job taking quite some time to finish. So I would see a merge-request, push the button for the first job, wait 5 minutes, press the next button, wait 5 minutes again, and only then am able to use the staging. For many small merge-requests, this would take up a lot of my time and would not be a efficient solution. I also cannot just mark the first of these jobs as manual because Gitlab will then just skip that job and execute that later ones out of order (And again, needs and dependencies seem to have no effect on this when dealing with manually triggered jobs).\nWhat i am a bit baffled about is that after searching the net, I have found nobody having the same problem. Either I am the only Gitlab User that wants to execute some jobs only for merge-requests without excluding all other jobs (which seems highly unlikely) or I am missing something obvious (which seems more likely). Am I missing something or does Gitlab really not support this use-case?"}, {"role": "assistant", "content": "From the previous answer:\n\nBut there is a problem. This example launches two pipelines for every push after MR is created. One for only: [branch], one for only: [merge_requests]\n\nCheck if the last GitLab 13.8 (January 2021) can help:\n\nUse both branch and MR pipelines without duplication\nPreviously it was not possible to run pipelines for branches first, then switch to merge requests pipelines when the MR is created.\nConsequently, with some configurations, a push to a branch could result in duplicate pipelines if a merge request was already open on the branch: one pipeline on the branch and another for the merge request.\nNow you can use the new $CI_OPEN_MERGE_REQUESTS predefined environment variable in your CI configurations to switch from branch pipelines to MR pipelines at the right time, and prevent redundant pipelines.\n\nSee Documentation and Issue.\n\nuser2993689 points out in the comments to the documentation for a similar example:\n\nAvoid duplicate pipeline"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab SSH keys stopped working\n\nOK, I've stumbled on this topic many times, but this is the first time that none of the regular solutions worked.\nI have a CentOS 6.4 server running GitLab. It's been working great with 20+ users and 60+ projects, but about 5 hours ago, my main staging server was unable to connect to the GitLab machine for the first time using key authentication and it prompted for password. I regenerated the RSA key and added it to my deploy keys, but that failed as well.\nNext, I tried to create a new user on the staging server, create a key for it, and add it to GitLab but it still fails.\nPermissions:\ndrwxr-x---  22 root root 4.0K Oct 28 13:20 root\n\nInside root:\ndrwx------   2 root root     4096 Oct 28 11:49 .ssh\n\nInside .ssh:\n-rw-------  1 root root  227 Oct 28 11:48 authorized_keys\n-rw-------  1 root root 1675 Oct 28 13:09 id_rsa\n-rw-------  1 root root  398 Oct 28 13:09 id_rsa.pub\n-rw-r--r--  1 root root  413 Oct 28 11:49 known_hosts\n\nWhen I try to connect to the git machine:\nOpenSSH_4.3p2, OpenSSL 0.9.8e-fips-rhel5 01 Jul 2008\ndebug1: Reading configuration data /etc/ssh/ssh_config\ndebug1: Applying options for *\ndebug1: Connecting to git.mygitlab.com [212.29.122.24] port 22.\ndebug1: Connection established.\ndebug1: permanently_set_uid: 0/0\ndebug1: identity file /root/.ssh/identity type -1\ndebug1: identity file /root/.ssh/id_rsa type 1\ndebug1: identity file /root/.ssh/id_dsa type -1\ndebug1: loaded 3 keys\ndebug1: Remote protocol version 2.0, remote software version OpenSSH_5.3\ndebug1: match: OpenSSH_5.3 pat OpenSSH*\ndebug1: Enabling compatibility mode for protocol 2.0\ndebug1: Local version string SSH-2.0-OpenSSH_4.3\ndebug1: SSH2_MSG_KEXINIT sent\ndebug1: SSH2_MSG_KEXINIT received\ndebug1: kex: server->client aes128-cbc hmac-md5 none\ndebug1: kex: client->server aes128-cbc hmac-md5 none\ndebug1: SSH2_MSG_KEX_DH_GEX_REQUEST(1024<1024<8192) sent\ndebug1: expecting SSH2_MSG_KEX_DH_GEX_GROUP\ndebug1: SSH2_MSG_KEX_DH_GEX_INIT sent\ndebug1: expecting SSH2_MSG_KEX_DH_GEX_REPLY\ndebug1: Host 'git.mygitlab.com' is known and matches the RSA host key.\ndebug1: Found key in /root/.ssh/known_hosts:1\ndebug1: ssh_rsa_verify: signature correct\ndebug1: SSH2_MSG_NEWKEYS sent\ndebug1: expecting SSH2_MSG_NEWKEYS\ndebug1: SSH2_MSG_NEWKEYS received\ndebug1: SSH2_MSG_SERVICE_REQUEST sent\ndebug1: SSH2_MSG_SERVICE_ACCEPT received\ndebug1: Authentications that can continue: publickey,gssapi-keyex,gssapi-with-    mic,password\ndebug1: Next authentication method: gssapi-with-mic\ndebug1: Unspecified GSS failure.  Minor code may provide more information\nNo credentials cache found\n\ndebug1: Unspecified GSS failure.  Minor code may provide more information\nNo credentials cache found\n\ndebug1: Unspecified GSS failure.  Minor code may provide more information\nNo credentials cache found\n\ndebug1: Next authentication method: publickey\ndebug1: Offering public key: /root/.ssh/id_rsa\ndebug1: Authentications that can continue: publickey,gssapi-keyex,gssapi-with-    mic,password\ndebug1: Trying private key: /root/.ssh/identity\ndebug1: Trying private key: /root/.ssh/id_dsa\ndebug1: Next authentication method: password\n[email\u00a0protected]'s password:\n\nWhen I add SSH keys through the web interface, they aren't added to .ssh/authorized_keys.\nI don't really know what to try next :("}, {"role": "assistant", "content": "If keys that you add to GitLab aren't making it into .ssh/authorized_keys:\n\nMake sure that sidekiq is running. Keys are added to gitlab-shell in a Sidekiq worker, so if Sidekiq is down or backlogged, they won't make it in. You can check this in the output of ps -fu git and by checking the \"background jobs\" tab on the admin page.\nEnsure that GitLab can execute gitlab-shell properly. The Sidekiq worker adds keys by exec'ing a gitlab-shell process. In particular, this won't work if the ssh_user setting is incorrect in gitlab.yml, or if gitlab-shell is installed to a location other than ~/gitlab-shell for that user.\nVerify that the server's /home partition isn't full. If the disk that the authorized_keys file is stored on fills up, key appends with fail! This one has gotten me a few times. Use df -h /home to see if you still have room.\n\nCheck your logs for error messages from gitlab-shell: depending on the problem, error messages could appear in unicorn's or sidekiq's logs."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to send an email from GitLab CI pipeline's job?\n\nI am trying to set up a GitLab CI configuration that sends an email after a pipeline's job completes with a link of the artifacts to the upload site. The pipeline builds based upon pom.xml, then tests with sonarqube and then uploads the artifacts using curl to a specific artifactory location. The folder structure and link of the artifact directory depends upon the CI_PIPELINE_ID. After all of these succeeds, I need to send this link for downloading the artifacts to a list of people via mail. My .gitlab-config.yml looks like the following:\n\n\nimage: maven:3.3.9-jdk-8\n\nvariables:\n  MAVEN_OPTS: \"-Dmaven.repo.local=.m2/repository -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=WARN -Dorg.slf4j.simpleLogger.showDateTime=true -Djava.awt.headless=true\"\n  MAVEN_CLI_OPTS: \"-U --batch-mode --errors --fail-at-end --show-version -DinstallAtEnd=true -DdeployAtEnd=true\"\n  REPO_NAME: \"<artifactory url>\"\n\ncache:\n  paths:\n    - .m2/repository\n    - ./target/\n\nstages:\n  - build\n\ncompile_commit:\n  stage: build\n  only:\n    - cr_integrate\n  before_script:\n    - git submodule sync --recursive\n    - git submodule update --init --recursive --remote\n  script:\n    - mvn -f pom.xml -s settings.xml $MAVEN_CLI_OPTS clean install $MAVEN_OPTS\n    - curl -i -u<username>:<token> -T \"target/<artifact-1>.zip\" \"${REPO_NAME}/${CI_PIPELINE_ID}/<artifact-1>.zip\"\n    - curl -i -u<username>:<token> -T \"target/<artifact-1>.zip\" \"${REPO_NAME}/${CI_PIPELINE_ID}/<artifact-2>.zip\"\n    - - curl -i -u<username>:<token> -T \"target/<artifact-1>.zip\" \"${REPO_NAME}/${CI_PIPELINE_ID}/<artifact-3>.zip\"\n  tags:\n    - <tagname>\n\n\n\nHow do I send a mail to some people after this with the link?"}, {"role": "assistant", "content": "I built a solution for this, sharing it here.\nThe following tools were used for this:\n\nGitLab release api\nPython-GitLab api\nDocker\nMicrosoft Teams\nSharepoint\n\nThe process flow can be outlined as follows:\n\nA new pipeline is triggered\nAfter successful build, codescan and publish, a release job is run\nThe release job uses a python script written with the help of\npython-gitlab api to create a release using gitlab release api. It\ninserts external artifactory links for downloading artifacts under\nrelease assets and adds links to release note and other documents.\nGitLab sends a release mail to the appropriate notification channel,\na group email id created by Microsoft Teams and Sharepoint, so that\nthe entire team receives the release mail.\n\nThe python script is given below:\nimport os\nimport gitlab\nfrom datetime import datetime\n\nif __name__ == '__main__':\n    access_token = os.environ['RELEASE_TOKEN']\n    gitlab_url = os.environ['GITLAB_URL']\n    project_id = int(os.environ['CI_PROJECT_ID'])\n    \n    tag_name = os.environ['CI_PIPELINE_ID']\n    ref = os.environ['CI_COMMIT_REF_NAME']\n    \n    # artifactory_links\n    artifactory_link = os.environ['ARTIFACTORY_PATH']\n    group_name = os.environ['GROUP_NAME']\n    project_name = os.environ['CI_PROJECT_NAME']\n    directory = f'{datetime.now():%Y%m%d}'\n    artifact_name = os.environ['ARTIFACT_NAME']\n    package_type = os.environ['PACKAGE_TYPE']\n        \n    # artifacts_links\n    artifacts_links = f'{artifactory_link}/{group_name}/{project_name}/{directory}/{artifact_name}-{tag_name}.{package_type}'\n        \n    # release note\n    release_note = os.environ['RELEASE_NOTE']\n    \n    # authenticate with gitlab\n    gl = gitlab.Gitlab(gitlab_url, private_token=access_token)\n    gl.auth()\n    \n    # obtain the project object by id\n    project = gl.projects.get(project_id)\n    \n    # creating the project tags\n    project.tags.create({'tag_name': tag_name, 'ref': ref})\n    \n    # creating the project releases\n    release = project.releases.create(\n        {\n            'name': f'Release for Pipeline ID {ref}',\n            'tag_name': tag_name,\n            'description': release_note,\n            'assets': {\n                'links': [{'name': artifact_name, 'url': artifacts_links}],\n            }\n        }\n    )\n\nThe script requires the following environment variables:\n\nRELEASE_TOKEN \u2013 GitLab access token\nGITLAB_URL \u2013 GitLab base URL.\nARTIFACTORY_PATH \u2013 Artifactory base URL.\nGROUP_NAME \u2013 In case the project is under a group.\nARTIFACT_NAME \u2013 The artifact name\nPACKAGE_TYPE \u2013 Artifact package type\nRELEASE_NOTE \u2013 Link to release note and any other document.\n\nThese variables can be provided as GitLab CI variables. If there are more than one artifacts, the python script can be modified accordingly.\nSince the python script needs to be called during the pipeline event and adding the script in the project would be modifying the project codebase, dockerizing the script is the best solution. That way, it can be pulled directly from docker hub. The dockerfile contents for this are as follows:\nFROM python:3.7-alpine\nCOPY release_api.py /bin\nRUN pip install python-gitlab\nENTRYPOINT [\"/bin/release_api.py\"]\nCMD [\"/bin/bash\"]\n\nIn order to send a release mail to every member of the team, irrespective of their individual GitLab notification and subscription preferences, a team needs to be set up using Microsoft Teams. When a team is created in Teams application, a corresponding sharepoint site is created, along with a team email id. This set up takes some time.\nOnce a team is created, under Files section, there\u2019s an option to open it in sharepoint (screenshot below).\n\nThe sharepoint site has a link in the left sidebar called Conversations. Once the sharepoint site is fully ready, clicking this link will open the inbox of the Teams email.\nUnder the settings for the group, the option Edit Group can be found and there the group email id can be found. This group email id will be used to send the release mail to everyone in the team.\nUnder user settings of GitLab, the group email needs to be added. Once the mail is added and verified, the notification channel can be set up under Notifications. Once this is done, all notifications for that group (or project) will go to the group mail, and everyone in the team will get them. The last activity left is to set up notification preference to send a notification when a new release is available."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Can Gitlab/Gitolite enforce correct username/email\n\nExperimenting with git, I've setup Gitlab for a self hosted repository and it looks great.\nThe one thing bugging me is that it appears anyone can make commits as anyone else (ie: spoof a commit). \nie: I have my users setup in Gitlab with public key access\n\nUser1 \nUser2\n\nNow only those users may push - using their private SSH keys - but it seems there is nothing stopping User2 tweaking their gitconfig to commit under the name of User1 and pushing that up?\nThe history in gitlab and git -show shows the committer as whatever the User1's gitconfig text was. I want Gitlab to stamp the username associated with the pushing ssh key into the history instead so I know whose ssh key was used to push.\nThe scenario is the repo would be used in a team environment and it just seems prudent to not allow spoofed commits. \nI've done some reading and understand that typically one might change the workflow to have a blessed repository and only have trusted committers that can push to that - but at this stage while learning git I want to stay in a more centralised/SVN type workflow. \nIs this possible using hooks?\nThere is a similar question answered for gitosis but even that appears to only enforce the committer is from a range of users which doesn't stop User1 spoofing as User2 - as far as I can tell.\nPS: Maybe I am asking the wrong question - is there a way in gitlab to discover which ssh key (and therefore real user) was used to push code into the repo? It doesn't appear so from what I can find."}, {"role": "assistant", "content": "Update 2015\nAs this thread mention, GitLab Enterprise has among its git hooks associated to a project a way to control emails:\n\nGo to project settings -> git hooks and check validation of author email. \n\nAny email that doesn't match a known user is rejected.\n\nOriginal answer (2012)\nA partial way to achieve user id control is to make gitolite (which gitlab relies on) reject the push if at least one of the pushed commits isn't committed by the one pushing it.\nWhen you push, you are authenticated (either based on the name of the public key registered by Gitolite, or by another way like an LDAP connection).\nYou can add a pre-receive hook which will check all the new commits, and look for at least one committed by the right name (ie the id of the user pushing said commits).\nSee this pre-receive hook as an example."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI/CD fails while \"Cleaning up project directory and file based variables\" with \"ERROR: Job failed: exit code 1\"\n\nMy gitlab pipeline which has been running for nearly six months is now failing unexpectedly.\nEvery line prior runs successfully and then this happens:\nSetting up curl (7.52.1-5+deb9u16) ...\n$ curl -s https://deb.nodesource.com/setup_12.x | bash\nCleaning up project directory and file based variables \nERROR: Job failed: exit code 1\n\nI cannot for the life of me figure out what has changed. I thought it might be related this issue but I'm not having any network issues, timeouts, etc.\nMildly obfuscated version of my .gitlab-ci.yml.\nObviously I'm using .gitlab-ci.yml to configure my pipelines and I'm also using the shared GitLab runners.\n\nimage: python:3.6-stretch\n\nvariables:\n    ACCESS_KEY_ID: **********\n    SECRET_ACCESS_KEY: **********\n\nbefore_script:\n  - apt-get update\n  - apt-get install -y curl\n  - curl -s https://deb.nodesource.com/setup_12.x | bash\n  - apt-get install -y nodejs\n  - apt-get install -y npm\n  - npm install -g serverless\n  - pip install  --upgrade awscli\n  - python --version\n  - nodejs --version\n\nstages:\n  - deploy\n\ndeploy:\n  stage: deploy\n\n  only:\n  - master   # We will run the CD only when something is going to change in master branch.\n\n  script:\n    - npm install   # Archive the code repository.\n    - pip install -r requirements.txt\n\n    - cd services/service1/\n    - sls deploy -v --stage production\n    - cd ../../\n\n    - cd services/service2/\n    - sls deploy -v --stage production\n    - cd ../../\n\n    - cd services/service3/\n    - sls deploy -v --stage production\n    - cd ../../\n\n\n  environment:\n    name: master"}, {"role": "assistant", "content": "That second to last line (Cleaning up project directory and file based variables ) is always present in a CI/CD job, pass or fail.\nWhat's likely happening is the last command, curl -s https://deb.nodesource.com/setup_12.x | bash is failing. Unfortunately, since you're downloading a remove file and piping it into bash, it's quite possible that your pipeline starts randomly failing, because that script isn't guaranteed to be the same every time.\nTo test it out, I created a clean ubuntu VM, and ran that curl command, and get the following error: \nYour best bet to fix this long-term is to create a container that has all the dependencies you need for you CI baked in, and store that in your container registry for your GitLab project, then to pull that container each time. Not only will that save you CI/CD minutes since you don't have to run installs each time, but it'll prevent this exact issue where your dependencies change underneath you and cause error. It's also worth noting you should be very careful about passing an externally downloaded script to bash, because that script could change to include anything and your CI would just unknowingly run it."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab: Is it possible to filter merge requests by multiple authors?\n\nWe have monorepo, my team responsible for 3 of 20 packages/folder of repository, but sometimes we need to touch others packages/folders.\nFor reviewing teammates changes every member should add \u201cteam_label\u201d for ability to filter by this label or to keep opened several tabs with merge requests for each author/team member.\nPreferable could be filtering MRs something like this by one of the author:\nauthor: username1 OR author:username2 OR author:username3\nWe are using GitLab Enterprise Edition 12.6.2-ee\nupd:\ndiscussed in gitlab docs comments and there is no ability to filter merge requests even with advanced search\n\nAdvanced Search does currently not have the facets available that you use in the dedicated issue or MR search\n\nhttps://docs.gitlab.com/ee/user/search/index.html#comment-4776091890\nFeature proposal:\n\nhttps://gitlab.com/gitlab-org/gitlab/issues/7826"}, {"role": "assistant", "content": "Unfortunately to date you can't search merge requests with an OR query - and although gitlab states that successive clauses should be ANDed together a quick test suggests that in fact an arbitrary single clause is applied.\nSee e.g. https://forum.gitlab.com/t/mr-filtering-by-multiple-authors/33864"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Storing SSH Private Key in GitLab repository variables\n\nUsing GitLab CI, I want to push production code to a remote webhost.\nTo connect with SSH, I am storing the key pair's private key in the variables of my GitLab repository. I've also copied the public key to the authorized keys of the server. This is (part of) my .gitlab-ci.yml.\nimage: ubuntu\n\nbefore_script:\n  # Setup SSH credentials and known host\n  - which ssh-agent || ( apt-get update -y && apt-get install openssh-client -y )\n  - mkdir -p ~/.ssh\n  - echo \"$SSH_PRIVATE\" | tr -d '\\r' > ~/.ssh/id_rsa\n  - chmod 700 ~/.ssh/id_rsa\n  - eval \"$(ssh-agent -s)\"\n  - ssh-add ~/.ssh/id_rsa\n  - echo \"$SSH_KNOWN_HOSTS\"\n  - echo \"$SSH_KNOWN_HOSTS\" > ~/.ssh/known_hosts\n  - chmod 644 ~/.ssh/known_hosts\n\nThis method works, but I'm questioning the security of it. Is my private key safe this way? How else can I achieve the result that I'm looking for?\nEDIT: I'm particularly questioning the security of this method in a production environment."}, {"role": "assistant", "content": "The official example is in gitlab-examples/ssh-private-key\nIts .gitlab-ci.yml uses a custom environment variable SSH_PRIVATE_KEY, as described in \"How to simplify your smart home configuration with GitLab CI/CD  / Preparing the server (and GitLab) for SSH access\".\nAs long as that variable is masked, this should be secure enough.\n\nsneaky suggests in the comments to create a pre-processing file:\n\ncat id_rsa | base64 -w0 insert into script-part of your job in .gitlab-ci.yml:\nmkdir -p ~/.ssh && echo \"$SSH_PRIVATE_KEY\" | \\\n  base64 -d > ${SSH_KEY_FILE} && chmod 0600 ${SSH_KEY_FILE}"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab-runner with syntax error\n\nI recently used the docker image gitlab/gitlab-runner:9.1.0 in conjunction with a gitlab container to have some CI.\nAn error occurs and similar support requests recommended using a different version, so I tried with :latest and some :1.11 too.\nUnfortunately it keeps telling me this error:\nRunning with gitlab-ci-multi-runner 1.11.4 (5e7ba4a)\n  on foo (02cdacdc)\nUsing Docker executor with image pretzlaw/php:7.1-apache ...\nStarting service mariadb:latest ...\nPulling docker image mariadb:latest ...\nWaiting for services to be up and running...\nPulling docker image pretzlaw/php:7.1-apache ...\nRunning on runner-02cdacdc-project-7-concurrent-0 via 9d1d33dc9212...\nFetching changes...\nHEAD is now at 7580815 QA: CI Lint\nFrom http://idgaf.example.org/foo/bar\n   7580815..affeede  develop    -> origin/develop\nChecking out affeede as develop...\nSkipping Git submodules setup\n[: 1: [: Syntax error: end of file unexpected\n[: 1: [: Syntax error: end of file unexpected\nERROR: Job failed: exit code 2\n\nNeither do I know how to debug this nor do I see any problem in my container or test script. This is the .gitlab-ci.yml:\nbefore_script:\n  - composer install\n\ntest_7_1:\n  image: pretzlaw/php:7.1-apache\n  script: ls\n\nIt could be a problem of the container somewhere but I don't get it. Doing this manually (with the recent failed docker container) everything works fine:\ndocker container exec 68c7b5448a56 ls\nbin\nbuilds\n...\n\nHow do I trace back the problem?\nWhat is it all about?\nIt's for GitLab 9.1.1-ce.0."}, {"role": "assistant", "content": "As pointed out by #1550, the problem seems to be coming from the shell detection done in the bash.go file between lines 16-31 which it is injected without newlines and thus creating the syntax error you are yourself experiencing.\nSince you have a custom entrypoint in your Dockerfile and it looks like you have not passed quotes to the arguments of the exec here, that's what I think is failing and should be modified.\nChange it to\nexec \"${*}\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Status from gitlab-ci not showing up anymore on gitlab merge request\n\nGitlab-CI works perfectly as far as I can tell. It runs and does everything as it should, but gitlab itself doesn't show the status.\nAll I keep seeing is \"Checking for CI status for x\" with the spinner standing still.\nThe only clue I get is from the gitlab production.log when I open the page:\nOpenSSL::SSL::SSLError (SSL_connect returned=1 errno=0 state=SSLv3 read server certificate B: certificate verify failed):\n  app/models/project_services/gitlab_ci_service.rb:39:in `commit_status'\n  app/controllers/projects/merge_requests_controller.rb:165:in `ci_status'\n  app/controllers/application_controller.rb:57:in `set_current_user_for_thread'\n\nThis is odd to say the least. Everything else works fine, so it doesn't seem systemic to gitlab as a whole.\nGitlab details:\nGitLab 6.6.4\nGitLab Shell 1.8.4\nGitLab API v3\nRuby 1.9.3p194\nRails 4.0.3\nGitLab CI 4.3.0 267edb0\n\nI searched around and did not find similar problems. It's puzzling since it stopped working after an upgrade from 6.something to 6.6.4 in gitlab. This is not a critical piece, but removes some of the easy use of the CI server."}, {"role": "assistant", "content": "Maybe you're using self-signed certificates? I had to patch my Gitlab CI like this and then set config.verify_ssl = false.\nEdit: maybe I should make a pull request out of it? :)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Jenkins fails to build when I use a parameterised branch: fatal: Couldn't find remote ref refs/heads/${BUILD_BRANCH}\n\nAs soon as I attempted to upgrade my Jenkins job to use a parameter for the branch rather than a hard coded value it no longer works.\n\nHave tried many other names than BUILD_BRANCH\n\nHere I've tried ${env.BUILD_BRANCH}, refs/heads${BUILD_BRANCH} and absolutely none of them work\n\nWhen I did this initially I did check lightweight checkout, I removed it after reading many online answers from those having the same problem. Still nothing!. I just added the 'wipe' command to see if that would help but it didn't\nerror:\n > git rev-list --no-walk 97428a402f3304a21ccc8df435a40468ebf406c1 # timeout=10\nRunning in Durability level: MAX_SURVIVABILITY\n[Pipeline] Start of Pipeline\n[Pipeline] readTrusted\n[Pipeline] End of Pipeline\nhudson.plugins.git.GitException: Command \"git fetch --tags --progress --prune -- origin +refs/heads/${BUILD_BRANCH}:refs/remotes/origin/${BUILD_BRANCH}\" returned status code 128:\nstdout: \nstderr: fatal: Couldn't find remote ref refs/heads/${BUILD_BRANCH}\nfatal: The remote end hung up unexpectedly\n\n    at org.jenkinsci.plugins.gitclient.CliGitAPIImpl.launchCommandIn(CliGitAPIImpl.java:2429)\n\nThank you for reading even if you couldn't help"}, {"role": "assistant", "content": "Do you have lightweight checkout selected in the Pipeline SCM section? Unchecking lightweight checkout fixed this issue for me."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is 'gitlab/gitlab-runner-helper' docker image used for?\n\nMy overall goal is to install a self-hosted gitlab-runner that is restricted to use prepared docker images from my own docker registry only.\nFor that I have a system.d configuration that looks like:\n/etc/systemd/system/docker.service.d/allow-private-registry-only.conf\nBLOCK_REGISTRY='--block-registry=all'\nADD_REGISTRY='--add-registry=my.private.registry:8080'\n\nBy this, docker pull is allowed to pull images from my.private.registry/ only.\nAfter I had managed to get this working, I wanted to clean up my local registry and remove old docker images. It was during that process when I stumbled over a docker image named gitlab/gitlab-runner-helper which presumably is some component used by the gitlab-runner itself and presumably has been pulled from docker.io.\nNow I'm wondering if it is even possible/advisable to block images from docker.io when using a gitlab-runner?\nAny hints are appreciated!"}, {"role": "assistant", "content": "I feel my sovereign duty to extend the accepted answer (it is great btw), because the word 'handle' basically tells us not so much, it is too abstract. Let me explain the whole flow in far more details:\n\nWhen the build is about to begin, gitlab-runner creates a docker volume (you can observe it with docker volume ls if you want). This volume will server as a storage for caches and artifacts that you are using during the build.\n\nThe second thing - You will have at least 2 containers involved in each stage: gitlab-runner-helper, container and the container created from the image you specified (in .gitlab-ci.yml or in config.toml). What gitlab-runner-helper container does it, essentially, just cloning the remote git repository (that you are building) in the aforementioned docker volume along with caches and artifacts.\n\n\nIt can do it becuase within gitlab-runner-helper image itself are 2 important utilities: git (obviously - to clone the repo) and gitlab-runner-helper binary (this utility can pull and push artifacts, caches)\n\nThe gitlab-runner-helper container starts before each stage for a couple of seconds, to pull artifacts and caches, and then terminates. After that the container, created from image that you specified will be launched, ant it will also have this volume (from step 1) attached - this is how it receives artifacts btw.\n\nThe rest of the details about the registry from where gitlab-runner-helper get pulled are described by @Nicolas pretty well. I append this comment just for someone, who, perhaps, want to know what exactly means this sneaky 'handle' word.\nHope it helps, have a nice day, my friend!"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab - push using https, specifying username & password\n\nI am trying to push a newly created repository to gitlab. Here's what I did:\n\nCreate a project in gitlab. Example URL: https://gitlab.example.com/group1/project1.git\nInitiated a local bare repo:\ncd ~/projects\ngit init --bare ./project1.git\ncd project1.git\n\n\nQuestion:\nNext step is to push all of my local repo into gitlab. \nBut I want to specify username and password using https. How do I change the following to do it? \ngit remote add origin https://gitlab.example.com:group1/project1.git\ngit push --all\ngit push --tags"}, {"role": "assistant", "content": "Like others mentioned here, ssh is preferred. But for those you want to use just http/https, you can specify credentials like this:\ngit remote add origin https://username:[email\u00a0protected]:group1/project1.git\n\nVerified for gitlab 9.0\nNote: Please replace '@' symbols in username with '%40' to work this."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to import an existing bare git repository into Gitlab?\n\nI import my bare git repository into Gitlab as described as here , because it was not recognized as an git repository, but creates a 94K big 'empty' repo (the original is 2,8GB big):\n$ bundle exec rake gitlab:import:repos RAILS_ENV=production\nfatal: Not a git repository (or any of the parent directories): .git\nProcessing test.git\nINFO: Sidekiq client using redis://localhost:6379 with options:namespace=>\"resque:gitlab\"}\n * Created test (test.git)\nDone!\n\nAs a workaround I replace the empty project folder (which was created by import trial) with my bare repo. Afterwards I tree to clone the repo from remote and get the following error:\n$ git clone [email\u00a0protected]:...test.git\nCloning into 'test'\nfatal: '...test.git' does not appear to be a git repository\nfatal: Could not read from remote repository.\n\nPlease make sure you have the correct access rights\nand the repository exists.\n\nBut the git user should have all rights which are needed. -Maybe I have something overlooked?\nMy System: RHEL6.3, Git 1.8.3.4, Gitlab5.3.\nDoes Gitlab need a normal repository (non-bare)? Or what could be my problem?"}, {"role": "assistant", "content": "Does Gitlab need a normal repository (non-bare)?\n\nNo, all repos managed by gitlab are bare repos.\nYou should see:\n/home/git/repositories/user1/repo1.git\n/home/git/repositories/user1/repo2.git\n/home/git/repositories/greoup1/repo3.git\n...\n\nMake sure the rights  of your test.git folder (and bare repo files within it) are the same than the existing bare repos under /home/git/repositories/.\nIf the import doesn't work, then \"replace the empty project folder (which was created by import trial) with my bare repo\" should.\nBut: you need to make sure any hook which was in the empty bare repo created by GitLab (in ~git/repositories/arepo.git/hooks) is copied over your full bare repo replacing the empty one (same path).\nCheck also what was in ~git/repositories/arepo.git/info and ~git/repositories/arepo.git/config \nTo debug, try first to clone the empty bare repo created by GitLab during the failed import.\nThen replace it with your own, double-check the hooks and try again.\n\nAs mentioned by the OP and documented in GitLab \"Trouble Shooting Guide\", the correct ssh url is:\n[email\u00a0protected]:repositories/mygroup/proj1.git\n\nwith :repositories mentioned.\n\nTo import bare repos (as mentioned by Sytse Sijbrandij below and in raketasks/import.md)\n\ncopy your bare repos under git repos_path (see config/gitlab.yml gitlab_shell -> repos_path)\nrun the command below\nbundle exec rake gitlab:import:repos RAILS_ENV=production"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Git does not use SSH key (Windows)\n\nI created a SSH key for my GitLab repository and when I test it with SSH it does work and asks for the passphrase:\n>ssh -T [email\u00a0protected]\nEnter passphrase for key 'C:\\Users\\[username]/.ssh/id_ed25519':\nWelcome to GitLab, @000[...]!\n\nI also used\n>git remote set-url origin [email\u00a0protected]:000[...]/project.git\n\nwithout errors. However, when I try to commit and push to the repository, then Git asks for the Password of [email\u00a0protected] and not for the passphrase of the SSH key.\nAccording to the Docs (https://docs.gitlab.com/ee/ssh/), you can set the ssh key in the config file ~/.ssh/config. So I created a text file in this directory with this content:\nHost gitlab.lrz.de\n HostName gitlab.lrz.de\n IdentityFile ~/.ssh/id_ed25519\n\nIt still does not work and I am not sure if it even uses this config file. I was able to get everything running on a Linux server but not on this Windows computer. I tried it via command line and via Pycharm.\n>git --version\ngit version 2.35.1.windows.1"}, {"role": "assistant", "content": "@kipy is nearly correct...\nThe issue is that git bundles its own SSH executable with it, and as in Windows (at least historically) the native OpenSSH client was optional, git won't acknowledge it by default. As a result of this, when you're doing things like:\nssh-add <my-key>\nIn Powershell (or whatever), that's not actually the SSH client that your git commands are using.\nThis complicates things further as, like me, you'll type:\nssh -T [email\u00a0protected]\nSee the \"Success!\" message, and then scratch your head, wondering why git clone [email\u00a0protected]:<username>/<repo>.git gives a (public key) error. I guess the clue is pretty clear, but not obvious... In one you run ssh directly, the other one you run git, which then calls 'ssh' by proxy.\nThe correct command to solve this, is to tell your git installation (via its config) which version of SSH you want it to use, so:\ngit config --global core.sshCommand C:/Windows/System32/OpenSSH/ssh.exe\nThis will then prompt all git commands to use the same SSH client that your ssh command does.\nThis also allows you to use different keys for different remotes, as well as working in all terminals/applications.\n\nNOTE: The above assumes that OpenSSH for Windows is installed via the Windows Optional Programs process, which is most likely the case, but just to be sure, you can open a PowerShell window, and run:\n(Get-Command ssh).Path\nWhich will output something like:\nC:\\Windows\\System32\\OpenSSH\\ssh.exe\nIf it doesn't output that, then replace the last part of the git config command above with this output instead."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab push error: LFS objects are missing\n\nI've used Git LFS for GitLab for a few months now without any problems, but it returned the following error while pushing files lately:\n$ git push origin master\nGit LFS: (14 of 14 files) 8.88 MB / 8.88 MB\nCounting objects: 54, done.\nDelta compression using up to 6 threads.\nCompressing objects: 100% (49/49), done.\nWriting objects: 100% (54/54), 5.42 KiB | 0 bytes/s, done.\nTotal 54 (delta 15), reused 0 (delta 0)\nremote: GitLab: LFS objects are missing. Ensure LFS is properly set up or try a manual \"git lfs push --all\".\nTo https://gitlab.com/<gitURL>.git\n! [remote rejected] master -> master (pre-receive hook declined)\nerror: failed to push some refs to 'https://gitlab.com/<gitURL>.git'\n\nwhere gitURL is my git-repository URL.\nAs the error suggests I tried to manually push my binary files, using git lfs push --all, which gives me the following output:\n$ git lfs push --all origin master\nGit LFS: (0 of 0 files, 1370 skipped) 0 B / 0 B, 1.77 GB skipped\n\nwhich means by my understanding that all my local files are already successfully stored on my server.\nTrying to fetch all lfs files does work fine as well:\n$ git lfs fetch --all\nScanning for all objects ever referenced...\n* 1446 objects found\nFetching objects...\n\nwhich finishes without any errors.\nMoreover checking all lfs files for consistency using git lfs fsck seems to work fine too:\n$ git lfs fsck\nGit LFS fsck OK\n\nI'm starting to run out of ideas about fixing this error now. \nAny help would be greatly appreciated."}, {"role": "assistant", "content": "I got this error even though (to my knowledge) I did not have any LFS objects in my gitlab repository.\nremote: GitLab: LFS objects are missing. Ensure LFS is properly set up or try a manual \"git lfs push --all\".\n\nThe solution was to disable Git Large File Storage (LFS) in the gitlab project settings.\nSettings > General > Visibility, project features, permissions > Expand > Git Large File Storage (LFS)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Unable to print string containing double quotes in GitLab CI YAML\n\nI'm using the CI Lint tester to try and figure out how to store an expected JSON result, which I later compare to a curl response. Neither of these work:\nAttempt 1\n---\n  image: ruby:2.1\n  script:\n  - EXPECT_SERVER_OUTPUT='{\"message\": \"Hello World\"}'\n\nFails with:\n\ndid not find expected key while parsing a block mapping at line 4 column 5\n\nAttempt 2\n---\n  image: ruby:2.1\n  script:\n  - EXPECT_SERVER_OUTPUT=\"{\\\"message\\\": \\\"Hello World\\\"}\"\n\nFails with:\n\njobs:script config should be a hash\n\nI've tried using various combinations of echo as well, without a working solution."}, {"role": "assistant", "content": "You could use literal block scalar1 style notation and put the variable definition and subsequent script lines on separate lines2 without worrying about quoting:\nmyjob:\n  script:\n    - |\n      EXPECT_SERVER_OUTPUT='{\"message\": \"Hello World\"}'\n\nor you can escape the nested double quotes:\nmyjob:\n  script:\n    - \"EXPECT_SERVER_OUTPUT='{\\\"message\\\": \\\"Hello World\\\"}'\"\n\nbut you may also want to just use variables like:\nmyjob:\n  variables:\n    EXPECT_SERVER_OUTPUT: '{\"message\": \"Hello World\"}'\n  script:\n    - dothething.sh\n\nNote: variables are by default expanded inside variable definitions so take care with any $ characters inside the variable value (they must be written as $$ to be literal). This feature can also be turned off.\n1See this answer for an explanation of this and related notation\n2See this section of the GitLab docs for more info on multi-line commands"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab: How can I programatically download the artifacts issued at end of CI pipeline?\n\nIn Gitlab, how can I programatically download the artifacts issued at end of a CI pipeline?\nIt is easy to download it via the UI but how can I get it through API? In other words, is it possible to access it via a token or something similar?"}, {"role": "assistant", "content": "It is possible through the API as in https://docs.gitlab.com/ee/api/jobs.html#get-job-artifacts\n\nGET /projects/:id/jobs/:job_id/artifacts\n\nExample requests:\n\nUsing the PRIVATE-TOKEN header:\n curl --location --header \"PRIVATE-TOKEN: 9koXpg98eAheJpvBs5tK\" \"https://gitlab.example.com/api/v4/projects/1/jobs/8/artifacts\"\n\n\nUsing the JOB-TOKEN header (only inside .gitlab-ci.yml):\n curl --location --header \"JOB-TOKEN: $CI_JOB_TOKEN\" \"https://gitlab.example.com/api/v4/projects/1/jobs/8/artifacts\"\n\n\nUsing the job_token parameter (only inside .gitlab-ci.yml):\n curl --location --form \"job-token=$CI_JOB_TOKEN\" \"https://gitlab.example.com/api/v4/projects/1/jobs/8/artifacts\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "VS 2022: \"Error encountered while pushing to the remote repository: Git failed with a fatal error...\"\n\nMy company uses GitLab, and when I try to push to my remote feature branch using the Git UI in Visual Studio 2022, I get the following error in the Output window:\nGit failed with a fatal error.\nunable to access '<my gitlab server url>': \n  schannel: CertGetCertificateChain trust error CERT_TRUST_IS_UNTRUSTED_ROOT\"\n\nI tried the following command that I saw in another solution git config --global http.\"<my gitlab server url>.sslCAInfo C:/path/to/cert.pem but it gives me the same error. The certificate used in the command I downloaded it from the GitLab server for the repo by clicking the padlock icon \ud83d\udd0f and View Certificate.\nThis happens each time I push or pull from the UI. The error doesn't occur when I use a separate terminal like Git Bash or PowerShell."}, {"role": "assistant", "content": "After much gnashing of teeth and searching (and placing a bounty on this question) I was able to determine a workaround myself: Switch the Cryptographic network provider from OpenSSL to Secure Channel.\n\nUnder Tools > Options > Source Control > Git Global Settings\nI don't know why OpenSSL gave me an error; perhaps there's a better solution that works with OpenSSL. But just using the Windows SSL implementation resolved it for me when connecting to my company's Azure DevOps repository."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab pipeline should stop on pipeline failure\n\nI have a sample pipeline in gitlab. i want the the pipe to stop if any of the jobs fail. below is the code am using to replicate the scenario. the pipe does show failure as the status but the jobs continue to run even after a failed stage. example in the picture attached.\n  stages:\n  - unittest\n  - coverage_test\n  - static_code_analysis\n\nvariables:\n  skip_integration:\n    value: 'false'\n    description: \"This variable for skipping integration tests\"\n  skip_migration:\n    value: 'false'\n\nunittest:\n  stage: unittest\n  script:\n    - echo \"testing the code\"\n  rules:\n    - if: '$CI_COMMIT_BRANCH == \"master\"' \n      when: always\n    - if: '$skip_integration == \"true\"'\n      when: never \n    - if: '$skip_integration == \"false\"'\n      when: always\n\n    \nlint_test:\n  stage: static_code_analysis\n  allow_failure: false\n  script:\n    - echo \"this is a test\"\n  rules:\n    - if: '$CI_COMMIT_BRANCH == \"master\"' \n      when: always\n    - if: '$skip_integration == \"true\"'\n      when: never \n    - if: '$skip_integration == \"false\"'\n      when: always\n    - when: on_success\n\ncoverage_test:\n  stage: coverage_test\n  script:\n    - echo00 \"this is test again\"\n  rules:\n    - if: '$CI_COMMIT_BRANCH == \"master\"' \n      when: always\n    - if: '$skip_integration == \"true\"'\n      when: never \n    - if: '$skip_integration == \"false\"'\n      when: always\n    - when: on_success\n\nbut the pipe does not stop on failure."}, {"role": "assistant", "content": "when: always\n\n\nAs the name implies, runs the job always. If you want to run the job when the previous stage succeeded, run it on_success. Change all always to on_success.\nwhen: on_success"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI with JS Linting\n\nI have 0 experience with GitLab Continuous Integration and I need to setup a job to run ESLint on .js files.\nI've already read the GitLab CI and Pipeline documentations, along with some Git Hooks, but I still have no idea how to setup this, so any detailed and starting from the very beginning answer is appreciated."}, {"role": "assistant", "content": "First you need to setup your CI and have some runners available so they can run your continuous integration jobs. The easiest way for this is to use gitlab-ci-multi-runner (project is here along with documentation) along with the docker executor that will run your CI jobs in docker containers. Once you have configured some runners, add them to your Gitlab project so they're available to run jobs.\nOnce that's taken care of, you need to add a .gitlab-ci.yml file to your project. This file is used to describe the jobs that need to run during continuous integration etc. Here is an example (assuming you install eslint using npm)\nimage: node:latest\n\nstages:\n  - lint\n\neslint:\n  stage: lint\n  script:\n    # Install ESLint in this docker container\n    - npm install -g eslint\n    # Configure ESLint (will read your .eslintrc file)\n    - eslint --init\n    # Run ESLint\n    - eslint <your_js_file>\n\nAdd your .gitlab-ci.yml file, commit and push the changes. The CI pipeline should start and run the above steps."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI - How to skip job if cache exists\n\nI have a setup job in my CI which installs all npm packages and stores them in cache:\nsetup:\n  stage: pre-build\n  cache:\n    untracked: true\n    when: on_success\n    key:\n      files:\n        - repo-hash\n      prefix: workspace\n  script:\n    - yarn install --frozen-lockfile\n\nCurrently, if the repo-hash does not change between two pipelines, the job successfully downloads the existing cache, but it still runs yarn install --frozen-lockfile.\nHow to change this behaviour, so that if the cache exists, this job is skipped?"}, {"role": "assistant", "content": "Right now on an NPM-based Preact project, I'm using gitlab-ci.yml's only feature to run an install job if there was any change to package-lock.json (and to skip install if not). Then my build job picks up the node_modules cache from the install job:\ninstall:\n  stage: setup # gitlab.com shared runners are slow; don't run unless there's a reason to install\n  cache:       # even a \"echo 'hello world'\" script would be about a 30s job, worse if queued\n    key:\n      files: [package-lock.json] # the key is a hash of package-lock; branches with it will use this cache :D\n    paths: [node_modules] # we're not caching npm (ie `npm ci --prefer-offline --cache`) because it's slow\n    policy: push # override the default behavior of wasting time downloading and unpacking node_modules\n  script: [npm ci] # I believe in package-lock/npm ci's mission\n  only:\n    changes: [package-lock.json] # our forementioned reason to install\n    refs:\n      - master\n      - develop\n      - merge_requests\n\nbuild: # uses the default behavior, which runs even if install is skipped; but not if install failed\n  stage: build\n  cache:\n    key:\n      files: [package-lock.json]\n    paths: [node_modules]\n    policy: pull # override the default behavior of wasting time packing and uploading node_modules\n  script:\n    - npm run build\n  artifacts:\n    paths: [build]\n  only:\n    changes:\n      - src/**/*\n      - tsconfig.json\n      - preact.config.js\n      - package-lock.json\n    refs:\n      - master\n      - develop\n      - merge_requests\n\nFor Yarn you would simply replace any package-lock.json you see here with yarn.lock, and replace npm ci with yarn install --frozen-lockfile.\nPreviously, I was doing it all in the build job like this (similar to one of the other answers here):\nbuild:\n  stage: build\n  cache:\n    key:\n      files: [package-lock.json]\n    paths: [node_modules]\n  script:\n    - test -d node_modules || npm ci\n    - npm run build\n  artifacts:\n    paths: [build]\n  only:\n    changes:\n      - src/**/*\n      - tsconfig.json\n      - preact.config.js\n      - package-lock.json\n    refs:\n      - master\n      - develop\n      - merge_requests\n\nI changed to the more complicated approach because I thought I was also going to implement caching for npm cache, but I couldn't seem to get that to improve any actual install times -- things actually got worse. I stuck with it though simply because it allowed me to squeeze another 20 seconds out of the lockfile-wasn't-changed scenario. I find both approaches to be valid and effective. In my specific case, caching node_modules has cut about a minute and a half off of deployments."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What would be the standard and better approach of the git repository structure for microservice architecture?\n\nThe better approach of repository structure for microservice architecture based applications?\nFor example, I was referring through Microsoft reference architecture i.e. eShopContainers in github repository [https://github.com/dotnet-architecture/eShopOnContainers/tree/dev/src].  But that comes up with some more complexity of dynamic work environment, where team work on various UI, microservices, hence everything under one repository is making it more time consuming process on merge/conflicts, etc.  Some team members would like to have each microservice in separate repository while development for better management and then to export to group repository after production i.e. while BAU.  Appreciate to have a discussion the pros and cons to make a better decision for our environment."}, {"role": "assistant", "content": "Having done both, here are some of the tradeoffs:\nFor a monorepo (all code and services in the same repo):\n\nMuch easier to keep related changes in sync (e.g., both a producer and a consumer change; the changes to both can be saved as a single commit).\nIt's easier to set up a consistent build environment. Properly set up, all of the services can be built using exactly the same toolchain and possibly the same Makefile.\nIf you choose to use a single GOPATH, all of the services need to be kept in lockstep. This can cause a lot of pain if one service needs to switch to a newer version of a library with a breaking change; every service using that library has to upgrade at once. Multiple GOPATHS make the process more complex to maintain.\nIf properly managed with CI and testing, it's possible to keep HEAD in a deployable state at all times, decreasing the chance you'll end up with a set of services that can't interoperate because they don't match up.\n\nMultiple repositories:\n\nMuch easier to get a service to a stable level and leave it alone. Because it lives in its own repository, there's no requirement to do upgrades even if another service needs a newer version of a library, or you decide to change libraries (e.g. from Gin to Echo).\nTempting to neglect upgrades on stable services (the Gin to Echo change, for example), possibly entailing a significant update for a breaking change under time pressure; definitely increasing maintenance load (do we do the long-postponed upgrade to Echo, or do we just leave it at Gin? If we have to make a significant change to our APIs, how many different frameworks will we need to work with when we do that?)\nProliferation of repositories makes it harder to find something when it's needed (which service did we define this in? I need to reuse that over here)\nProliferation of duplicate or (worse) near-duplicate code across multiple repositories. It's easy to get into the habit of copying a service as a base and then making changes on top of the old code, resulting in a fractal set of differences across the codebase, especially because \"working\" code doesn't tend to get updated to match the changes.\n\nThere are no doubt others, but these are some that I've actually experienced in both cases. A monorepo is probably better if you're going to be evolving a lot of services in parallel; multiple repos is better if you can architect your services pretty much independent of each other."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab runner unable to clone repository via http\n\nI have the latest docker image of GitLab running in a test environment and I'm running into an issue with the GitLab runner. It's unable to clone via the HTTP link, yielding the following message:\nRunning on runner-bd27e50b-project-1-concurrent-0 via machine...\nCloning repository...\nCloning into '/builds/my/awesome-project'...\nfatal: unable to access 'http://gitlab-ci-token:[email\u00a0protected]/my/awesome-project.git/': \n    Failed to connect to 127.0.0.1 port 80: Connection refused\n\nERROR: Build failed with: exit code 1\n\nI ran gitlab-runner with the --debug flag and used the exact address it was trying (with the token in-tact) and I could clone the repository just fine. I'm at a loss as to why the service is unable to clone the repository. The runner executor is configured as 'docker' as well. Maybe there is some port mapping issue into that container?"}, {"role": "assistant", "content": "I hypothesized the issue might have something to do with registering the runner as a docker container causing the localhost address not to resolve to the right machine (where I'm starting the runner); in this case it probably resolves to the container instead. Using the host's IP on the docker proxy interface (172.17.0.1 for me) or using the host's real address instead of \"localhost\" when registering the runner fixes the problem.\nEdit: Here is a bit more detail on the problem as I understand it and a solution. The docker instance that's loaded up is like a (very) lightweight virtual machine. Docker configures a virtual network interface which you'll see if you run ifconfig from your host machine:\nuser@pc:~> ifconfig\ndocker0   Link encap:Ethernet  HWaddr XXXX\n          inet addr:172.17.0.1  Bcast:0.0.0.0  Mask:255.255.0.0\n          ...\n\nThis is the IP address of the host machine on that interface. So, if you want the runner to be able to connect to the service that's running on that host machine, you can't point it to localhost/127.0.0.1 because, coming from inside the runner's instance, that will route to the runner's \"VM\", but GitLab is not running inside that runner \"VM\", it's on the host, so the runner is unable to communicate with GitLab.\nThe solution is to register the runner to point to the host's virtual address on the docker interface (http://172.17.0.1/ci for me), or to use the host's public IP or a domain name if you have one and it's accessible publicly. Just don't send it to localhost or 127.0.0.1 because, to the runner, that points to its \"VM\", not your GitLab instance."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab disable regular username password login and only allow OmniAuth login\n\nI have gitlab all set up and ready with omniauth and I was wondering if it is possible to disable default authentication with password and username entirely and to use only omniauth (in our case google login). What I'm hoping to achieve is enhanced security through enforced two factor authentication with google apps bundled together with omniauth."}, {"role": "assistant", "content": "After Gitlab version 7.7.0, you can now set up sign-up and sign-in behaviour in the Admin area, under the Settings page. Unchecking Signin enabled option will only let OAuth login available.\nNote that gitlab_rails['gitlab_signin_enabled'] and gitlab_rails['gitlab_signup_enabled'] settings in gitlab.rb now have no effect."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab: How to include the previous job's artifacts as release assets?\n\nThe task create:release creates a new release. How do we add the artifact core.zip in task create:release?\nprepare:release:\n  stage: prepare_release\n  before_script:\n    - echo \"Setting up packages for Build\"\n    - apk --no-cache add zip\n  script:\n    - echo \"Preparing release\"\n    - echo \"Build Core\"\n    - yarn --cwd ./core/ install && yarn --cwd ./core/ build\n    - echo \"Zip distribution folder for Core\"\n    - zip -r core.zip ./core/dist ./core/node_modules ./core/package.json\n  artifacts:\n     paths:\n       - core.zip\n     expire_in: never\n\ncreate:release:\n  stage: release\n  image: registry.gitlab.com/gitlab-org/release-cli:latest\n  needs:\n    - job: prepare:release\n      artifacts: true\n  variables:\n    TAG: '$CI_COMMIT_SHA'\n  script:\n    - echo \"Create Release $TAG\"\n  release:\n    name: 'Release $TAG'\n    tag_name: '$TAG'\n    ref: '$TAG'\n    description: 'Release $TAG'"}, {"role": "assistant", "content": "I have resolved this. In prepare:release job, save the job id in an environment file and this file should be in the artifacts.reports.env of this job. Later, in the create:release job, use the API \"https://gitlab.com/<namespace>/<project_name>/-/jobs/<job_id>/artifacts/download\" to refer to the artifact.\nUpdated pipeline:\nprepare:release:\n  stage: prepare_release\n  before_script:\n    - echo \"Setting up packages for Build\"\n    - apk --no-cache add zip\n  script:\n    - echo \"Preparing release\"\n    - echo \"Build Core\"\n    - yarn --cwd ./core/ install && yarn --cwd ./core/ build\n    - echo \"Zip distribution folder for Core\"\n    - zip -r core.zip ./core/dist ./core/node_modules ./core/package.json\n  after_script:\n    - echo \"JOB_ID=$CI_JOB_ID\" >> job.env\n  artifacts:\n     paths:\n       - core.zip\n     expire_in: never\n     reports:\n       dotenv: job.env\n\ncreate:release:\n  stage: release\n  image: registry.gitlab.com/gitlab-org/release-cli:latest\n  needs:\n    - job: prepare:release\n      artifacts: true\n  variables:\n    TAG: '$CI_COMMIT_SHA'\n  script:\n    - echo \"Create Release $TAG\"\n    - echo $JOB_ID  \n  release:\n    name: 'Release $TAG'\n    tag_name: '$TAG'\n    ref: '$TAG'\n    description: 'Release $TAG'\n    assets:\n      links:\n        - name: \"core.zip\"\n          url: \"https://gitlab.com/<namespace>/<project_name>/-/jobs/$JOB_ID/artifacts/download\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Hotfix on GitLab\n\nI'm trying to understand GitLab's suggested flow on http://docs.gitlab.com/ee/workflow/gitlab_flow.html. But, I'm not really sure about this statement:\n\nIf you need to cherry-pick a commit with a hotfix it is common to\n  develop it on a feature branch and merge it into master with a merge\n  request, do not delete the feature branch. If master is good to go (it\n  should be if you a practicing continuous delivery) you then merge it\n  to the other branches.\n\nDoes it mean, there will be more than 1 commit in the master? For example, the first commit (actually merge request) is to test whether the fix is working, the second commit is when the first commit fails.\nThe other thing is, (given that we have a production branch) if we merge the hotfix into master, I think we have to deploy the other features on the master, isn't it? Otherwise, we do cherry pick the hotfix commits in the master into the production branch.\nActually the suggested flow is not as detail as another flow in http://nvie.com/posts/a-successful-git-branching-model/. So, it's a bit confusing."}, {"role": "assistant", "content": "I experimented with the hotfix process in a test-hotfix repo available at https://github.com/oldsj/test-hotfix/commits/master\nBasically as long as the hotfix branch is created from the prod branch it the process seems fairly straightforward, even if master is ahead of imp/prod.\nNote: imp is what we refer to as \"pre-production\"\nmaster (dev branch)\ngit init\necho \"Hello wolrd\" > hello.txt\ngit add -A .\ngit commit -m \"add hello.txt\"\ngit log\ncommit 66b1a08080f0db548da85471b4673c5a9f6d703f (HEAD -> master)\n\ncat hello.txt\nHello wolrd\n\ngit checkout -b imp\ngit checkout -b prod\n\nProd shows typo\ncat hello.txt\nHello wolrd\n\ngit log\ncommit 66b1a08080f0db548da85471b4673c5a9f6d703f (HEAD -> prod, master, imp)\n\nLet's add some commits to master, ahead of prod\ngit checkout master\ngit log\ncommit 66b1a08080f0db548da85471b4673c5a9f6d703f (HEAD -> master, prod, imp)\n\necho \"new stuff\" >> newstuff.txt\ngit add -A .\ngit commit -m \"add newstuff.txt\"\ngit log\ncommit df1ca012262c26ab3a29d81b5cb6d46f6c1fc3cc (HEAD -> master)\ncommit 66b1a08080f0db548da85471b4673c5a9f6d703f (prod, imp)\n\nA user reported the typo in prod, let's hotfix by creating a new branch off of the prod branch:\ngit checkout prod\ngit log\ncommit 66b1a08080f0db548da85471b4673c5a9f6d703f (HEAD -> prod, imp)\n\ngit checkout -b hotfix\nSwitched to a new branch 'hotfix'\ngit log\ncommit 66b1a08080f0db548da85471b4673c5a9f6d703f (HEAD -> hotfix, prod, imp)\n\necho \"Hello world\" > hello.txt\ngit add -A .\ngit commit -m \"fix typo\"\ngit log\ncommit 1243123edc75e0abf349e1bb154d39c9f25dab2d (HEAD -> hotfix)\n\ncat hello.txt\nHello world\n\nCool our typo is fixed in the hotfix branch, lets merge to master and test in dev\ngit checkout master\ngit merge hotfix\ngit log\ncommit 2672d5059a55472132f02178c7f51d8b1af0f8ea (HEAD -> master)\n\n> cat hello.txt\nHello world\n\nLooks good in dev! Lets merge to imp and prod\ngit checkout imp\ngit merge hotfix\ngit log\ncommit 1243123edc75e0abf349e1bb154d39c9f25dab2d (HEAD -> imp, hotfix)\ncat hello.txt\nHello world\n\ngit checkout prod\ngit merge hotfix\ngit log\ncommit 1243123edc75e0abf349e1bb154d39c9f25dab2d (HEAD -> imp, hotfix)\ncat hello.txt\nHello world\n\ngit branch -D hotfix\n\nTypo's fixed in prod after testing in lower environments by merging the \"PR\" to those environment branches\nNow let's promote dev changes up (commit df1ca012262c26ab3a29d81b5cb6d46f6c1fc3cc)\ngit checkout master\ngit log\ncommit 2672d5059a55472132f02178c7f51d8b1af0f8ea (HEAD -> master, imp)\ncommit 1243123edc75e0abf349e1bb154d39c9f25dab2d (prod)\ncommit df1ca012262c26ab3a29d81b5cb6d46f6c1fc3cc\ncommit 66b1a08080f0db548da85471b4673c5a9f6d703f\n\ngit checkout imp\ngit merge master\ngit log\ncommit 2672d5059a55472132f02178c7f51d8b1af0f8ea (HEAD -> imp, master)\ncommit 1243123edc75e0abf349e1bb154d39c9f25dab2d (prod)\ncommit df1ca012262c26ab3a29d81b5cb6d46f6c1fc3cc\ncommit 66b1a08080f0db548da85471b4673c5a9f6d703f\n\ncat newstuff.txt\nnew stuff\ncat hello.txt\nHello world\n\ngit checkout prod\ngit merge imp\ngit log\ncommit 2672d5059a55472132f02178c7f51d8b1af0f8ea (HEAD -> prod, master, imp)\ncommit 1243123edc75e0abf349e1bb154d39c9f25dab2d\ncommit df1ca012262c26ab3a29d81b5cb6d46f6c1fc3cc\ncommit 66b1a08080f0db548da85471b4673c5a9f6d703f\n\ndev changes are now in imp and prod, along with the hotfix\ncat hello.txt\nHello world\ncat newstuff.txt\nnew stuff"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Is there a way to skip a pipeline when there are markdown changes only?\n\nGoal\nThe release pipeline should start a deployment for specific branches.\nThis should not happen (skip the job), if there are only documentation changes. (*.md files)\nThe problem\n\nIf you change multiple files, but only one file ends in .md, the build job is still skipped. The job does not run for any of the files.\n\nhttps://docs.gitlab.com/ee/ci/jobs/job_control.html#onlychanges--exceptchanges-examples\nSo, is it even possible to specifcy a rule as mentioned above?\nWhat I tried so far (an excerpt)\nSo, if \"*.md\" doesn't work, is it possible to revert it?\n\"**/!(*.md)\" # Every file except *.md\nThis does not execute anything\n  rules:\n    - if: $CI_COMMIT_BRANCH == \"main\"\n      changes:\n      - \"**/!(*.md)\" # Every file except *.md\n\nThis executes always\n  rules:\n    - if: $CI_COMMIT_BRANCH == \"main\"\n    - changes:\n      - \"**/!(*.md)\"\n\nQuestion\nDo I have to use custom variables to solve this problem or is there a simpler way?"}, {"role": "assistant", "content": "After contacting the GitLab Support, I can document here, that there is no way of doing that currently.\nA new issue has been created for this specific use case:\nhttps://gitlab.com/gitlab-org/gitlab/-/issues/348141"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Best way to deploy react app with gitlab-ci?\n\nI'm just getting started figuring out gitlab CI/CD.  I have my own gitlab instance, and a couple runners, 1 shared, 1 project specific, both using docker engine.\nCurrently my staging server is its own VM that it hosts with docker-compose.  I usually deploy to this server with a bare git repo, and just keep the build files in git.\nBut I wanted to switch to a CI/CD model, so I tried this as my .gitlab-ci.yml:\nimage: node\n\nstages:\n- build\n- stage\n\nbuild_frontend:\n  stage: build\n  script:\n  - cd ./src/frontend\n  - npm install && npm audit fix\n  # CI=false set to ignore warnings as errors\n  - CI=false npm run build\n  artifacts:\n    paths:\n    - ./src/frontend/build\n  tags:\n  - projectname\n\nBut I'm sort of lost on how to actually deploy the build.  What would the best way be to get the files onto the staging server, which is just a VM."}, {"role": "assistant", "content": "You can take some clues from how GitLab itself uses its own CI, as described in \"How to use GitLab CI for Vue.js\":\nThey have a dedicated deploy step:\nbuild site:\n  image: node:6\n  stage: build\n  script:\n    - npm install --progress=false\n    - npm run build\n  artifacts:\n    expire_in: 1 week\n    paths:\n      - dist\n\nunit test:\n  image: node:6\n  stage: test\n  script:\n    - npm install --progress=false\n    - npm run unit\n\ndeploy:\n  image: alpine\n  stage: deploy\n  script:\n    - apk add --no-cache rsync openssh\n    - mkdir -p ~/.ssh\n    - echo \"$SSH_PRIVATE_KEY\" >> ~/.ssh/id_dsa\n    - chmod 600 ~/.ssh/id_dsa\n    - echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" > ~/.ssh/config\n    - rsync -rav --delete dist/ [email\u00a0protected]:/your/project/path/\n\nSo if you can package and scp your app, you can deploy it to your VM."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab Shell Script Permission Denied\n\nI am running a simple shell script with Gitlab CICD and I am getting Permission denied. Kindly suggest\nWhen I do chmod +x test.sh it says operation not permitted.\nstages:\n  - build \n\nbuild: \n  stage: build \n  script: \n    - ls\n    - ./test.sh\n\nShell test.sh\necho Hi\n\nError:"}, {"role": "assistant", "content": "Instead of simply running chmod on your local system, it's better to run git update-index --chmod=+x path/to/file. This adds an executable flag to a file in Git and should ensure that a script can be executed inside a GitLab pipeline.\nSee also this question."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Modify PATH for gitlab-runner\n\nI want to install a gitlab-runner (executor shaell) on my Windows 10 box. I start the job on the gitlab server and it always ends up with the message the command \"git\" cannot be found (roughly translated into english).\nAs a matter of fact git is not part of my path.\nHow can I modify my PATH variable for the shell the gitlab-runner starts?\nTo use git on the command line in windows I usually set it with the statement: PATH %PATH%C:\\Program Files\\Git\\bin.\nIs it documented somewhere, git has to be available to the runner?\nHow can I see the command line the runner invokes (i.e. the call to git)?"}, {"role": "assistant", "content": "This GitLab Runner issue answers your question.\nThe environment setting doesn't work since it gets evaluated before the variables are set, but you can use pre_build_script in the runner config to update the path.\n[[runners]]\n  name = \"My Runner\"\n  url = \"https://gitlab.com/\"\n  token = \"Abcd1234\"\n  executor = \"shell\"\n  pre_build_script = \"set Path=%GIT_HOME%\\\\usr\\\\bin;%Path%\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab merge request. Who is the assignee?\n\nThere is one particular point I don't understand for GitLab's merge requests.\nI cloned a repository and made a feature branch. I worked something on it, committed it, and pushed the new branch to my GitLab repo.\nWith that I can make a merge request. When I do it says:\nAssignee (and Assign to me)\nWho should I assign it to? I mean, if I assign it to me, it is going to be me who \"reviews\" the change and approves it, so what is the point?\nOr should I assign it to the repository administrator? Or to other member reviewers, so that they can check that and approve the merge?\nWhat is the \"Assign to me\" option, and how does that makes sense?"}, {"role": "assistant", "content": "There is documentation for that. It states:\n\nThis person owns the merge request, but isn\u2019t responsible for reviewing it.\n\nAdditionally, the documentation explains an exemplary merge request workflow:\n\nYou would typically create the MR before working on your feature branch.\nThen you can use the Assign to me feature to indicate that you are the one currently working on implementing the features of the MR.\nAfter your work is done you can request a review following these guidelines.\nAfter finishing the review you can fall back to step 8 in the MR workflow."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do you create a project in a specific group via GitLab API?\n\nI tried to use GitLab API to create a new project. This worked, but this is in my user space:\n        curl \\\n            --header \"Authorization: Bearer ${GITLAB_API_TOKEN}\" \\\n            --request POST \\\n            \"https://gitlab.com/api/v4/projects/?name=$test-proj\"\n\nBut I wanted to do it under a specific group with group_id <group_id> (I blanked it here). The most sensible approach that occured to me was:\n        curl \\\n            --header \"Authorization: Bearer ${GITLAB_API_TOKEN}\" \\\n            --request POST \\\n            \"https://gitlab.com/api/v4/groups/<group_id>/projects/?name=test-proj\n\nBut this did not work. Are there any suggestions on how I could achieve this?\nI consulted the following references\n\nhttps://forum.gitlab.com/t/create-a-new-project-in-a-group-using-api/1552\nhttps://docs.gitlab.com/ee/api/projects.html#create-project\n\nThe GitLab documentation mentions the path or namespace_id attribute (although I would actually be in search of a group_id attribute). I am not sure about path and how to specify that. I tried - without success - to retrieve the namespace_id via\ncurl --header \"PRIVATE-TOKEN: ${GITLAB_API_TOKEN}\" \"https://gitlab.example.com/api/v4/namespaces\"\n\nIt is well possible that I might not have the rights to do the required operation. Therefore a reference to an official (GitLab) documentation together with a test curl command that works would be very helpful to me - thank you!"}, {"role": "assistant", "content": "For anyone looking for the direct command:\nSTEP 1:\nNavigate as below and identify the group ID from GUI:\nAdmin Area -> Groups -> GroupName\n\nSTEP 2:\nConstruct the command with two parameters viz., name, namespace_id\ncurl --header \"PRIVATE-TOKEN: <myprivatetoken>\" -X POST \"https://gitlab.com/api/v4/projects?name=myexpectedrepo&namespace_id=38\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I extract test coverage from the istanbul text-summary reporter with a regex?\n\nGitlab CI requires you to specify a regex to extract the statements code coverage (so that they can display it). Given the build output below (with jest and istanbul), I've managed to come as far as: /Statements.*(\\d+\\%)/\n... (other build output)\n=============================== Coverage summary ===============================\nStatements   : 53.07% ( 95/179 )\nBranches     : 66.67% ( 28/42 )\nFunctions    : 30.99% ( 22/71 )\nLines        : 50.96% ( 80/157 )\n================================================================================\n... (other build output)\n\nThis highlights the part Statements   : 53.07% (see here: http://regexr.com/3e9sl). However, I need to match only the 53.07 part, how do I do that?"}, {"role": "assistant", "content": "I need to match only the 53.07 part,\n\nUse lazy .*?, add (?:\\.\\d+)? to also match floats,  and access the capture group:\n\n\nvar re = /Statements.*?(\\d+(?:\\.\\d+)?)%/; \r\nvar str = '... (other build output)\\n=============================== Coverage summary ===============================\\nStatements   : 53.07% ( 95/179 )\\nBranches     : 66.67% ( 28/42 )\\nFunctions    : 30.99% ( 22/71 )\\nLines        : 50.96% ( 80/157 )\\n================================================================================\\n... (other build output)';\r\nvar res = (m = re.exec(str)) ? m[1] : \"\";\r\nconsole.log(res);\n\n\n\nNote that Statements.*?(\\d+(?:\\.\\d+)?)% also allows integer values, not only floats.\nPattern description:\n\nStatements - a literal string \n.*? - zero or more chars other than whitespace, but as few as possible\n(\\d+(?:\\.\\d+)?) - Group 1 (the value you need will be captured into this group) capturing 1+ digits and an optional sequence of . and 1+ digits after it\n% - a percentage sign (if you need to print it, move it inside parentheses above)\n\nSee the regex demo."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab docker registry with external nginx and omnibus\n\nI already run a gitlab server inside a docker container with an external nginx server inside an other docker container, so the gitlab nginx server is deactivated. Now I want to use the docker registry included in the gitlab server. \nI try to get the information from the administration manual: https://docs.gitlab.com/ee/administration/container_registry.html\nand use a fitted nginx config from linked file:\nhttps://gitlab.com/gitlab-org/gitlab-ce/blob/master/lib/support/nginx/registry-ssl\nto the gitlab.rb I added:\n... \nregistry_external_url 'url'\nregistry_nginx['enable'] = false\nregistry['enable'] = true\n...\n\nBut if I try to login (docker login url), I only get an 502 Bad Gateway error. I also tried some other configuration with ombinations, but gotting always the same error. Do anybody get it work? Need I to add more settings to the omnibus file or is it still not possible to use the gitlab internal docker registry with omnibus and external nginx?"}, {"role": "assistant", "content": "ok i got it work. \n## Lines starting with two hashes (##) are comments with information.\n## Lines starting with one hash (#) are configuration parameters that can be uncommented.\n##\n###################################\n##         configuration         ##\n###################################\n\nupstream docker-registry {\n server <ip_of_gitlab_docker_container>:<port_of_gitlab_container>;\n}\n\n## Redirects all HTTP traffic to the HTTPS host\nserver {\n  listen *:80;\n  server_name  sub.domain.tld;\n  server_tokens off; ## Don't show the nginx version number, a security best practice\n  return 301 https://$http_host:$request_uri;\n  access_log  /var/log/nginx/gitlab_registry_access.log;\n  error_log   /var/log/nginx/gitlab_registry_error.log;\n}\n\n\nserver {\n  # If a different port is specified in https://gitlab.com/gitlab-org/gitlab-ce/blob/8-8-stable/config/gitlab.yml.example#L182,\n  # it should be declared here as well\n  listen *:443 ssl http2;\n  server_name  sub.domain.tld;\n  server_tokens off; ## Don't show the nginx version number, a security best practice\n\n  client_max_body_size 0;\n  chunked_transfer_encoding on;\n\n  ## Strong SSL Security\n  ## https://raymii.org/s/tutorials/Strong_SSL_Security_On_nginx.html & https://cipherli.st/\n   ssl on;\n   ssl_certificate /etc/letsencrypt/live/sub.domain.tld/fullchain.pem;\n   ssl_certificate_key /etc/letsencrypt/live/sub.domain.tld/privkey.pem;\n\n  ssl_ciphers 'EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH';\n  ssl_protocols  TLSv1 TLSv1.1 TLSv1.2;\n  ssl_prefer_server_ciphers on;\n  ssl_session_cache  builtin:1000  shared:SSL:10m;\n  ssl_session_timeout  5m;\n\n  access_log  /var/log/nginx/gitlab_registry_access.log;\n  error_log   /var/log/nginx/gitlab_registry_error.log;\n\n\n    location /\n{\n     # let Nginx know about our auth file\n     proxy_pass http://docker-registry;\n     proxy_set_header Host $host; # required for docker client's sake\n     proxy_set_header X-Real-IP $remote_addr; # pass on real client's IP\n     proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n     proxy_set_header X-Forwarded-Proto $scheme;\n }\n\n location /v2/ {\n     # To add basic authentication to v2 use auth_basic setting plus\n     # add_header\n     add_header 'Docker-Distribution-Api-Version' 'registry/2.0' always;\n     proxy_pass http://docker-registry;\n     proxy_set_header Host $http_host; # required for docker client's sake\n     proxy_set_header X-Real-IP $remote_addr; # pass on real client's IP\n     proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n     proxy_set_header X-Forwarded-Proto $scheme;\n     proxy_read_timeout 900;\n }\n\n}\n\nMaybe the nginx configuration of Andrioshe also work, but I did some change and mix up with other configurations while trying. I think a configuration file for normal docker-regsitry will also work... will try it in future.\nBut the more important thing is the gitlab omnibus configuration.\nregistry_external_url 'https://sub.domain.tld'\nregistry['registry_http_addr'] = \"<ip_of_gitlab_docker_container>:<port_of_gitlab_container>\"\nregistry_nginx['enable'] = false\nregistry['enable'] = true\n\n\nIt is important to set the 'regsitry_http_addr' to the gitlab docker registry ip and port instead of localhost."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to create a milestones in GitLab\n\nI'm kind of new to Git and I'm using a GitLab repository to track my issue list. I wanted to create milestones but I can not find where. Are milestones and issue tracking part of the git itself and not of Gitlab?\nEDIT: This is my milestones page screenshot:\nThere is no new Milestone button on it"}, {"role": "assistant", "content": "Are milestones and issue tracking part of the git itself and not of Gitlab?\n\nNo, they are part of GitLab only, not git.\nIf that hasn't change from issue 339, you have a \"new milestone\" button in the Issues section, tab 'Milestones':\n\n\nAs the OP Hoffmann reports: the presence of this button depends on your role (or abilities).\nAs you can see in ability.rb, only the ability 'master' allows to create / manage milestones:\ndef project_master_rules\n  project_dev_rules + [\n    :push_code_to_protected_branches,\n    :modify_issue,\n    :modify_project_snippet,\n    :modify_merge_request,\n    :admin_issue,\n    :admin_milestone,                   <=============\n    :admin_project_snippet,\n    :admin_team_member,\n    :admin_merge_request,\n    :admin_note,\n    :admin_wiki,\n    :admin_project\n  ]\nend"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Checking if variable is null in Gitlab pipeline\n\nHow to check a null variable in Gitlab pipeline when it's declared with a content of another null variable? Like the variable VAR_NULL below when NO_VAR is null:\nvariables:\n  VAR_EMPTY: \"\"\n  VAR_NULL: \"${NO_VAR}\"\n\nCheck the pipeline result out where only VAR_EMPTY == \"\" and NO_VAR == null evaluate to true all others are false.\nPipeline result (a screenshot for convenience, the full result: https://gitlab.com/labaz/test-gitlab-pipeline-null-var/-/pipelines/493036820):\n\nFull pipeline script (https://gitlab.com/labaz/test-gitlab-pipeline-null-var/-/blob/main/.gitlab-ci.yml):\nvariables:\n  VAR_EMPTY: \"\"\n  VAR_NULL: \"${NO_VAR}\"\n\njobTest-Var_Empty-IsNull:       # This job runs in the build stage, which runs first.\n  rules:\n    - if: '$VAR_EMPTY == null'\n  script:\n    - 'echo \"VAR_EMPTY IS null\"'\n\njobTest-Var_Empty-IsEmpty:       # This job runs in the build stage, which runs first.\n  rules:\n    - if: '$VAR_EMPTY == \"\"'\n  script:\n    - 'echo \"VAR_EMPTY IS \\\"\\\"\"'\n\njobTest-Var_Null-IsNull:       # This job runs in the build stage, which runs first.\n  rules:\n    - if: '$VAR_NULL == null'\n  script:\n    - 'echo \"VAR_NULL IS null\"'\n\njobTest-Var_Null-IsEmpty:       # This job runs in the build stage, which runs first.\n  rules:\n    - if: '$VAR_NULL == \"\"'\n  script:\n    - 'echo \"VAR_NULL IS Empty\"'\n\njobTest-No_Var-IsNull:       # This job runs in the build stage, which runs first.\n  rules:\n    - if: '$NO_VAR == null'\n  script:\n    - 'echo \"NO_VAR IS null\"'\n\njobTest_No_Var-IsEmpty:       # This job runs in the build stage, which runs first.\n  rules:\n    - if: '$NO_VAR == \"\"'\n  script:\n    - 'echo \"NO_VAR IS Empty\"'"}, {"role": "assistant", "content": "The problem you're encountering is that VAR_NULL: \"${NO_VAR}\" is not a null variable. It's actually the same thing as VAR_EMPTY: \"\" -- you are declaring the variable (therefore it is not null) with an empty value.\nThe only way to test if the variable was created with another empty variable is to test the original variable itself. That is, test NO_VAR, not VAR_NULL.\nAn alternative strategy would be to use rules:variables: in order to conditionally declare VAR_NULL\nworkflow:\n  rules:\n    - if: '$NO_VAR' # or '$NO_VAR != null' depending on what you want\n      variables:\n        VAR_NULL: \"$NO_VAR\"\n    - when: always\n\njobTest-Var_Null-IsNull:\n  rules:\n    - if: '$VAR_NULL == null'\n  script:\n    - echo \"VAR_NULL is null\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to trigger a GitLab CI/CD Pipeline when cutting a new Release?\n\nI'm in the process of migrating my projects from GitHub.com to a self-hosted GitLab CE instance. I had previously set up a GitHub Actions pipeline to publish the application when a new release was cut from a tag. That is, when I went to github.com/<organization>/<project>/tags and edited a tag to publish a release, the following *-workflow.yml script snippet would trigger my desired action:\non:\n  release:\n    types: [created]\n\nWhat is the equivalent of that on GitLab CI/CD (.gitlab-ci.yml)? I searched all over the GitLab docs and auxiliary websites like gitlab.reddit.com and Stack Overflow, but couldn't find any way to do that. To be clear, the steps for converting a tag into a bona-fide release in GitLab are as follows:\n\nGo to <GitLab CE>/<group>/<project>/-/releases/new\n\"Create from\" any tag in the list\nFill out the details\nClick on the \"Create release\" button\n\nI'd like GitLab to execute my script immediately upon step 4 above."}, {"role": "assistant", "content": "I'm not sure if Gitlab has a similar feature, or at least I couldn't find anything in the documentation.\nA workaround could be creating a release automatically in the CI pipeline after creating a tag. So whenever a tag is created from a specific branch, the CI pipeline will create a release. You can also control the creation of the Release using the $CI_COMMIT_TAG value.\nrelease:\n  stage: release\n  script:\n    - echo \"Create release when a tag is created\"\n  rules:\n    - if: '$CI_COMMIT_TAG' # Any tag is created\n    - if: '$CI_COMMIT_TAG =~ /^v\\d+\\.\\d+\\.\\d+\\-release/' # A specific tag with 'vX.Y.Z-release' pattern is created\n  release:\n    name: 'My awesome release'\n    tag_name: '$CI_COMMIT_TAG'\n\nFor more information about creating a new Release using the CI pipeline you can read this page from the documentation:\nCreate release from GitLab CI"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to fix : failed to push some refs to gitlab?\n\nI tried to push the project to the repository of GitLab but there was an error occurred.\nTo https://gitlab.com/codersclan-interviews-frontend/codersclan-david-rose.git\n ! [remote rejected] test -> test (pre-receive hook declined)\nerror: failed to push some refs to 'https://gitlab.com/codersclan-interviews-frontend/codersclan-david-rose.git' \n\nHow can I fix this?\nGit repository wasn't created by me, it was created by the client.\nAnd he asked me to push the code to the branch which I made by myself and let him know when I finish.\nTo do this task, I did like following\ngit clone https://gitlab.com/codersclan-interviews-frontend/codersclan-david-rose.git\ngit checkout -b 'test'\ngit branch test\nadd project\ngit add .\ngit commit -m \"...\"\ngit push origin test\n\nI expected the successful push result but the above error occurred."}, {"role": "assistant", "content": "This could also happen as a result of a protected branch name. Try changing your branch name to something that isn't a protected name on the remote repository. hotfix, development and the likes may be protected names."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab - reference file line/lines range with snippet in issue\n\nGitHub can do that, but I'm not able to find the same on GitLab.\nDoes GitLab currently support this functionality?"}, {"role": "assistant", "content": "From the GitLab documentation at https://docs.gitlab.com/ee/user/markdown.html#gitlab-specific-references:\n\n[README](doc/README#L13) repository file line references\n\nFrom trying out myself:\n[README](doc/README#L13-22) \n\nwill reference a line range. GitLab EE 11.5"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I get a Docker Gitlab CI runner to access Git on its parent host?\n\nGitlab is setup on our internal network at http://gitlab\nDocker containers on the same machine can't connect to it.\nHow do I configure docker so that it knows gitlab is its parent?\n\nThe problem exhibits itself when Gitlab CI attempts to run a build (inside a Docker container):\n\nCloning into '/builds/ns/project'... fatal: unable to access\n  'http://gitlab-ci-token:xxxxxx@gitlab/ns/project.git/': Couldn't\n  resolve host 'gitlab'\n\nI've tried adding the network's DNS servers to DOCKER_OPTS in /etc/default/docker to no avail."}, {"role": "assistant", "content": "According to the GitLab CI Runner Advanced configuration, you can try to play with the extra_hosts param in your GitLab CI runner. \nIn /etc/gitlab-runner/config.toml : \n[[runners]]\n  url = \"http://gitlab/ci\"\n  token = \"TOKEN\"\n  name = \"my_runner\"\n  executor = \"docker\"\n  [runners.docker]\n    host = \"tcp://<DOCKER_DAEMON_IP>:2375\"\n    image = \"...\"\n    ...\n    extra_hosts = [\"gitlab:192.168.0.39\"]\n\nWith this example, when inside the container running the test git will try to clone from gitlab, it will use the 192.168.0.39 as IP for this hostname."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "I am unable to add hyperlinks to a mermaid flowchart within the wiki functionality of gitlab\n\nI want to use my flowchart as a table of contents that also represents the progression of parallel events vaguely in chronological order and their relation to one another.\nI know to create these charts using markdown. By adding the \"click\" line for the \"B\" node i can see my cursor change when hovering over the node as if it were a link but any attempt to select it doesn't work.\ngraph LR;\n    A-->B;\n    click B \"http://www.github.com\"\n\nIs this a limitation of Gitlab itself?"}, {"role": "assistant", "content": "Update:\nThis is now supported since GitLab 12.1.\nThe given example works in GitLab Wiki pages.\ngraph LR;\n    A-->B;\n    click B \"http://www.github.com\"\n\nThanks, KargWare for pointing this out in the comments.\n\nYes, this is a limitation of GitLab. There is an open issue requesting the feature:\nhttps://gitlab.com/gitlab-org/gitlab-ce/issues/50459\nHopefully, it will be implemented eventually."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to solve conflicts on GitLab?\n\nI recently worked with git and there was such a question. I made a merge request from the current branch into master. And received such a message: \n\nWhat are the options to allow this, so that the button appeared on the site to accept the merge? If I do local merge then it closes automatically, but I don\u2019t need to. Are there any options?"}, {"role": "assistant", "content": "Normally to resolve issues like this I would do the following locally:\ngit pull origin master\n\nThis should pull the current master from the remote and merge it with your local branch, then you can resolve the conflicts on your local copy, commit that and you should be good to proceed with your merge\nI have since been told that the better way to do this is to rebase, by taking all the changes on your local branch since the most recent common commit on the master, you can apply those changes to the current master, when you're on your local branch you can run:\ngit rebase master\n\nThis will delete your commit and create a new commit with all the changes and you don't need a second commit. This means the git history will be cleaner.\nTo try to avoid this when going forward, try to make sure you pull master before making a new branch so you're up to date when you start. Obviously if you take a while to ready your commit before trying to merge again you might need to pull the master in again to make sure you don't have a conflict first."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Integrate Gitlab and TravisCi\n\nIs there a way where I can integrate TravisCi with Giltab? or at least logging in TravisCi using username and password and not Github credentials?"}, {"role": "assistant", "content": "No, as of right now, Travis-CI is strictly bound to GitHub. While there are certainly talks about lessening this requirement, it's still there for still some time to come.\nAs a workaround, you could push your stuff to GitHub and from there to Travis, using GitHub only as an intermediary."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Installed gitlab, but only nginx welcome page shows\n\nI installed gitlab using its installation guide. Everything was OK, but when I open localhost:80 in the browser all I see it the message Welcome to nginx!. I can't find any log file with any errors in it.\nI am running Ubuntu in VirtualBox. My /etc/nginx/sites-enabled/gitlab config file reads:\n# GITLAB\n# Maintainer: @randx\n# App Version: 3.0\n\nupstream gitlab {\n  server unix:/home/gitlab/gitlab/tmp/sockets/gitlab.socket;\n}\n\nserver {\n  listen 192.168.1.1:80;         # e.g., listen 192.168.1.1:80;\n  server_name aridev-VirtualBox;     # e.g., server_name source.example.com;\n  root /home/gitlab/gitlab/public;\n\n  # individual nginx logs for this gitlab vhost\n  access_log  /var/log/nginx/gitlab_access.log;\n  error_log   /var/log/nginx/gitlab_error.log;\n\n  location / {\n    # serve static files from defined root folder;.\n    # @gitlab is a named location for the upstream fallback, see below\n    try_files $uri $uri/index.html $uri.html @gitlab;\n  }\n\n  # if a file, which is not found in the root folder is requested,\n  # then the proxy pass the request to the upsteam (gitlab unicorn)\n  location @gitlab {\n    proxy_read_timeout 300; # https://github.com/gitlabhq/gitlabhq/issues/694\n    proxy_connect_timeout 300; # https://github.com/gitlabhq/gitlabhq/issues/694\n    proxy_redirect     off;\n\n    proxy_set_header   X-Forwarded-Proto $scheme;\n    proxy_set_header   Host              $http_host;\n    proxy_set_header   X-Real-IP         $remote_addr;\n\n    proxy_pass http://gitlab;\n  }\n}"}, {"role": "assistant", "content": "The nginx documentation says:\nServer names are defined using the server_name directive and determine which server block is used for a given request. \n\nThat means in your case that that you have to enter aridev-VirtualBox within your browser instead of localhost.\nTo get this working you have to enter aridev-VirtualBox within your local Hosts file and point it to the IP of your VirtualBox PC.\nThis would look something like follows:\n192.168.1.1 aridev-VirtualBox"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to replace a variable in yml file with a gitlab ci pipeline variable using sed\n\nI want to replace a variable in my .yml file with a variable from the gitlab ci pipeline.\ngitlab-ci.yml\ndeploy_test:\n  stage: deploy\n  script:\n    - sed -i 's/$TAG/$CI_COMMIT_REF_NAME/g' deploy/test.yml\n    - kubectl apply -f deploy/test.yml\n  when: manual\n  only:\n    - master\n    - tags\n\nThis says within the deploy/test.yml file it should replace $TAG with the value of $CI_COMMIT_REF_NAME?\ndeploy/test.yml\nimage: git.<removed>.com:5005/eng/my-group/my-image:$TAG"}, {"role": "assistant", "content": "Use double quotes(\") instead of single quotes (') in sed and also take note that forward slashes (/) need to be escaped too (like \\/).\nso given the following (assuming you are using docker hub)\n$CI_COMMIT_REF_NAME=docker_user/repo:v1\n\nYou will firstly need to escape the '/' character first, like so\n$CI_COMMIT_REF_NAME=docker_user\\/repo:v1\n\nThen finally use double quotes in the sed command\nsed -i \"s/$TAG/$CI_COMMIT_REF_NAME/g\" deploy/test.yml\n\nNote: In addition to this you can also prefer using | instead of / if there's too many escapes.\nLike:\nsed -i \"s|$TAG|$CI_COMMIT_REF_NAME|g\" deploy/test.yml"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to check remote GIT repository permission without commit/add any files or modify any files\n\nI'm trying to find remote GIT repository permission without any file changes.\nI have tried below command,\n\"git push --dry-run\"\n\nits shows, everything-up-to-date.\nThe problem is I have cloned my remote repository after that I removed all my permission in remote git repository I want to know the remote repository permission before any local changes I made."}, {"role": "assistant", "content": "You can at least check if the remote repo is still remotely readable with git ls-remote\nFrom any folder in your local machine, type git ls-remote /url/remote/repo.\nBut for any more advance permission check, you would need to go to the remote server hosting that repo.\nOr at list query that server, listing the members for a given project.\nSee GitLab API \"List all members of a group or project\".\nEach member has access_level which will give a fined-grained permission.\n10 => Guest access\n20 => Reporter access\n30 => Developer access\n40 => Maintainer access\n50 => Owner access # Only valid for groups\n\n\nNote that GitLab 15.1 (June 2022) adds:\n\nAPI includes additional detail about who added members\nThe members API now returns more information about who added a user to a project or group in the new created_by field.\nThank you R\u00e9my Jacquin for your contribution!\nSee Documentation and Issue."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Integrating GitLab with TeamCity\n\nSince GitLab 7.6, or thereabouts, there is a new option to use TeamCity directly from GitLab projects. In the setup there is this message: \n\nThe build configuration in Teamcity must use the build format number\n  %build.vcs.number% you will also want to configure monitoring of all\n  branches so merge requests build, that setting is in the vsc root\n  advanced settings.\n\nI'm not sure how this works. Lets say I have a repository Foo. \nI have setup a build on TeamCity to listen to Foo with branch specification: +:refs/pull/*/merge\nI then fork Foo in gitlab as FooFork, make a change, then request a merge FooFork -> Foo. \nBut nothing happens to test this merge, which is what I was expecting GitLab to do. If I accept the merge than the build server jumps into action (immediately) and builds twice (master and /ref/master).\nI've also set the build configuration to use exactly: %build.vcs.number% as the build number as prescribed, but gitlab doesn't seem to give me any information about the build result. \nSo I'm a bit confused really as to what exactly this GitLab -> TeamCity integration is supposed to do and whether I'm doing wrong. \nI'm currently running GitLab 7.9 and TeamCity 8.1.4\nUpdate: \nSeems this use case was not supported prior to version 8 - https://github.com/gitlabhq/gitlabhq/issues/7240"}, {"role": "assistant", "content": "I'm running GitLab 8.0.2 and TeamCity 9.1.1 and am able to run CI builds on branches and merge requests.\nI trigger CI builds for specific branches by setting a VCS trigger together with the branch specification +:refs/heads/(xyz*) where xyz is the string for our ticket system prefix since all active branches need to be named after an entry in our issue tracker.\nI trigger builds for merge requests via the branch specification +:refs/(merge-requests/*)\nEverything works as as expected and lets us know the status of all feature / bug branches and merge requests automatically.\nThanks to Rob's comment linking to the GitLab 8 release notes entry on the merge request spec."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to login docker account in Gitlab-ci\n\nI have subscribed for a Pro plan of docker account to increase rate limit in my self hosted Gitlab CI jobs. Then successfully logged-in using this command on the server:\n$ sudo docker login -u user -p *******\n\nThis is my .gitlab-ci.yml file:\nimage: edbizarro/gitlab-ci-pipeline-php:7.3-alpine\n\nunittest:\n  stage: testing\n  services:\n    - mysql:latest\n  script:\n    - ./vendor/bin/phpunit --colors --stop-on-failure\n\nBut when jobs get started, I'm still getting this error:\nRunning with gitlab-runner 13.6.0 (8fa89735)\n  on fafa-group-runner n7oiBzAk\nPreparing the \"docker\" executor\n30:53\nUsing Docker executor with image edbizarro/gitlab-ci-pipeline-php:7.3-alpine ...\nStarting service mysql:latest ...\nPulling docker image mysql:latest ...\nERROR: Preparation failed: Error response from daemon: toomanyrequests: You have reached your pull rate limit. You may increase the limit by authenticating and upgrading: https://www.docker.com/increase-rate-limit (docker.go:142:4s)\n\nAm I missing something?"}, {"role": "assistant", "content": "You performed the docker login as the root user on the host. However the images are being pulled by the GitLab runner, which will be another user, possibly containerized.\nThe instructions for configuring runner registry credentials has several options, including setting DOCKER_AUTH_CONFIG in either the project's .gitlab-ci.yml or runner's config.toml. That variable contains the content of the ~/.docker/config.json with the registry credentials inside."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI - ERROR: Job failed: executor requires OSType=linux, but Docker Engine supports only OSType=windows\n\nGetting this error while running Gitlab CI pipeline. As I understand the error says that I'm trying to run a Linux type docker image on a windows docker-engine? But the thing is I'm using a windows docker image. What could be the problem?\n\nERROR: Job failed: executor requires OSType=linux, but Docker Engine supports only OSType=windows\n\nMy CI:\nimage: hello-world:nanoserver\n\nstages:\n  - build\n\nbuild1:\n  stage: build\n  script:\n    - echo \"Hello world\""}, {"role": "assistant", "content": "What's the difference between \"Shared\" and \"Simple\" tags?\n\nSome images have separated \"Simple Tags\" and \"Shared Tags\" sections\n  under \"Supported tags and respective Dockerfile links\" (see the mongo\n  image for an example).\n\"Simple Tags\" are instances of a \"single\" Linux or Windows image. It\n  is often a manifest list that can include the same image built for\n  other architectures; for example, mongo:4.0-xenial currently has\n  images for amd64 and arm64v8. The Docker daemon is responsible for\n  picking the appropriate image for the host architecture.\n\"Shared Tags\" are tags that always point to a manifest list which\n  includes some combination of potentially multiple versions of Windows\n  and Linux images across all their respective images' architectures --\n  in the mongo example, the 4.0 tag is a shared tag consisting of (at\n  the time of this writing) all of 4.0-xenial,\n  4.0-windowsservercore-ltsc2016, 4.0-windowsservercore-1709, and 4.0-windowsservercore-1803.\nThe \"Simple Tags\" enable docker run mongo:4.0-xenial to \"do the right\n  thing\" across architectures on a single platform (Linux in the case of\n  mongo:4.0-xenial). The \"Shared Tags\" enable docker run mongo:4.0 to\n  roughly work on both Linux and as many of the various versions of\n  Windows that are supported (such as Windows Server Core LTSC 2016,\n  where the Docker daemon is again responsible for determining the\n  appropriate image based on the host platform and version).\n\nI suggest you to try shared tags:\nimage: hello-world\n\nthe latest  tag has:\nlinux/386\n\nwindows v10.0.17134.1069/amd64\n\nwindows v10.0.17763.802/amd64\n\nand Docker will pick up the right one for you\nFrom here you need the executer docker-windows to run Windows Container\nso you may add executor = \"docker-windows\" to your runners config"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to ask for CLA signature in merge requests on GitLab?\n\nI would like to publish a project under GPL license, but would like to request CLA (Contributor License Agreements) signing before accepting merge requests. \nGitHub has a few solutions which automate this (ClaHub, cla-assistant), however I can't find anything similar for GitLab. There is a long standing issue to add support for it natively, but it's been opened 2 years ago.\nI know Git sign-off can be used for DCO, but I am wondering if it could somehow be (ab)used for signing CLA agreements?\nIn short, how do I make the process of signing CLAs as painless as possible for both contributors and myself, while still making the agreements (somewhat) legally binding?\nEDIT: To the person who cast a vote for closing: I checked the guidelines again and it seems to me that the question falls squarely in software tools commonly used by programmers; and is a practical, answerable problem that is unique to software development. It also doesn't fall into exceptions listed, at least the way I understand them. That said, I would appreciate a comment about the reasons for the vote, so that I can formulate the question better or find a more suitable StackExchange site if needed."}, {"role": "assistant", "content": "There is no official native support for CLA in GitLab for now.\nThe issue you are referencing is linked to issue 48118 (\"Stakeholder approval for merge requests\"), but itself is linked to two GitLab Enterprise issues -issues 1979 \"Multiple blocking merge request approval rules\" and issue 965 \"Upgrading approvals with approval chain\")\nSo for now, relying on a third-party service site remains the \"less painful\" solution.\nThat means, using the services highlighted in the original issue: CLAClub or cla-assistant.io.\nThe last one (cla-assistant) will, for a public registered repo (registered to cla-assistant) will:\n\nComments on each opened pull request to ask the contributor to sign the CLA\nAllows contributors to sign a CLA from within a pull request\nAuthenticates the signee with his or her GitHub account\nUpdates the status of a pull request when the contributor agrees to the CLA\nAutomatically asks users to re-sign the CLA for each new pull request in the event the associated Gist & CLA has changed\n\nNote: you can install and run your own instance of cla-assistant in order to store in your own private dedicated database the CLAs for your project.\nBut: since those services are tied to GitHub accounts, and there is no equivalent for GitLab, DCO should not be dismissed, especially in light of the Nov. 2017 GitLab blog post \"GitLab Transitions Contributor Licensing to Developer Certificate of Origin to Better Support Open Source Projects; Empower Contributors \"\n\nGitLab\u2019s move away from a CLA is meant to modernize its code hosting and collaborative development infrastructure for all open source projects.\nAdditionally, requiring a CLA became problematic for developers who didn\u2019t want to enter into legal terms; they weren\u2019t reviewing the CLA contract and they effectively gave up their rights to own and contribute to open source code.\n\nAnd \"We're switching to a DCO for source code contributions\". When it comes to GitLab projects, a DCO like this one remains the chosen solution.\nSee the analysis comparing CLA and DCO.\n\nGitLab 15.5 (October 2022) prpose for non-free editions of GitLab:\n\nEnforce Developer Certificate of Origin on all contributions\nThe Developer Certificate of Origin (DCO) is a per-commit sign-off made by a contributor stating that they have the right to submit the code to the project. By signing off on a commit, the contributor agrees to the terms published at developercertificate.org.\nNow, you can easily enforce this Developer Certificate via a per-project setting to prevent contributors from contributing code that violates your license. When enabled, all new commits must include such a certificate of origin in the form of a line in the commit message Signed-off-by:.\n\nSee Documentation and Issue."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Migrating Repo from Gitlab to Azure DevOps\n\nI am migrating repositories (.Net, Angular) from GitLab to Azure DevOps. Can't find much documentation on the implications of this migration. \nMy questions are:\n\nDo all remote branches gets migrated? With all commits and comments?\nDoes Azure DevOps support sub-folder type repository structure?\n\nAny precautions/best practices I may have to consider."}, {"role": "assistant", "content": "Yes, when you import a Git repository from GitLab (or any Git server) to Azure DevOps, all the branches and folders will be imported with all the history (commits)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab login error: invalid email or password [closed]\n\nIt's difficult to tell what is being asked here. This question is ambiguous, vague, incomplete, overly broad, or rhetorical and cannot be reasonably answered in its current form. For help clarifying this question so that it can be reopened, visit the help center.\n                                \n                            \n\n\n\nClosed 11 years ago.\n\n\n\nI installed gitlab on my homeserver, the server is running. I can access the login page but I can't login. \n[email\u00a0protected].\n5iveL!fe\nError: invalid email or password. \nWhat could be the problem?"}, {"role": "assistant", "content": "/home/gitlab/github/app/observers/user_observer.rb\n\nNotify.delay.new_user_email(user.id, user.password) \n\nto change:\nNotify.new_user_email(user.id, user.password)\n\nRun: \n[email\u00a0protected] ~/gitlab/github $ bundle exec rake db:seed_fu RAILS_ENV=production"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Accept merge request without running manual stages\n\nI have a pipeline with 3 stages: build, deploy-test and deploy-prod. I want stages to have following behavior: \n\nalways run build \nrun deploy-test automatically when on master or manually when on other branches\nrun deploy-prod manually, only available on master branch \n\nMy pipeline configuration seems to achieve that but I have a problem when trying to merge branches into master. I don't want to execute deploy-test stage on every branch before doing merge. Right now I am required to do that as the merge button is disabled with a message Pipeline blocked. The pipeline for this merge request requires a manual action to proceed. The setting Pipelines must succeed in project is disabled.\nI tried adding additional rule to prevent deploy-test stage from running in merge requests but it didn't change anything:\nrules:\n   - if: '$CI_MERGE_REQUEST_ID'\n     when: never\n   - if: '$CI_COMMIT_BRANCH == \"master\"'\n     when: on_success\n   - when: manual\n\nFull pipeline configuration:\nstages:\n  - build\n  - deploy-test\n  - deploy-prod\n\nbuild:\n  stage: build\n  script:\n    - echo \"build\"\n\ndeploy-test:\n  stage: deploy-test\n  script:\n    - echo \"deploy-test\"\n  rules:\n    - if: '$CI_COMMIT_BRANCH == \"master\"'\n      when: on_success\n    - when: manual\n\ndeploy-prod:\n  stage: deploy-prod\n  script:\n    - echo \"deploy-prod\"\n  only:\n    - master"}, {"role": "assistant", "content": "The only way I got it to work was to set \u2611\ufe0f Skipped pipelines are considered successful in Setttings > General > Merge requests > Merge Checks\n\nand marking the manual step as \"allow_failure\"\nupload:\n  stage: 'upload'\n  rules:\n    # Only allow uploads for a pipeline source whitelisted here.\n    # See: https://docs.gitlab.com/ee/ci/jobs/job_control.html#common-if-clauses-for-rules\n    - if: $CI_COMMIT_BRANCH\n      when: 'manual'\n      allow_failure: true\n\nAfter this clicking the Merge when Pipeline succeeds button \u2026\n\n\u2026 will merge the MR without any manual interaction:"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Use dependencies from a private GitLab with NPM\n\nI'm trying to install NPM dependencies from a private GitLab instence.\nSo, I have my repo with basic files\n\nAnd I added this dependencie in the package.json on my project\n\"node-demo-package\": \"https://oauth2:<ACCESS TOKEN>@gitlab.fullurl.git\"\n\nBut, when I run npm install, I receive this error message:\nnpm ERR! code ENOPACKAGEJSON\nnpm ERR! package.json Non-registry package missing package.json: node-demo-package@https://oauth2:<ACCESS TOKEN>@gitlab.fullurl.git.\nnpm ERR! package.json npm can't find a package.json file in your current directory.\n\nnpm ERR! A complete log of this run can be found in:\nnpm ERR!     /Users/arnaud.delante/.npm/_logs/2018-01-24T15_05_49_456Z-debug.log\n\nWhich I don't understand as there is a package.json as showed in the screenshot.\nHere it is\n{\n  \"name\": \"demo-package\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Test pasckage\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\"\n  },\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"[email\u00a0protected]\"\n  },\n  \"author\": \"Arnaud Delante\",\n  \"license\": \"MIT\"\n}\n\nI already tried switching https by git+https but I get another error\nnpm ERR! Error while executing:\nnpm ERR! /usr/local/bin/git ls-remote -h -t https://oauth2:<ACCES TOKEN>@gitlab.fullrul.git\nnpm ERR!\nnpm ERR! remote: You are not allowed to download code from this project.\nnpm ERR! fatal: unable to access 'https://oauth2:<ACCES TOKEN>@gitlab.fullrul.git': The requested URL returned error: 403\nnpm ERR!\nnpm ERR! exited with error code: 128\n\nnpm ERR! A complete log of this run can be found in:\nnpm ERR!     /Users/arnaud.delante/.npm/_logs/2018-01-24T17_19_16_677Z-debug.log\n\nWhich is weird because the token is correct.\nWould you have any idea?"}, {"role": "assistant", "content": "In package.json try to replace https:// by git+https://\ndoc : https://docs.npmjs.com/files/package.json#git-urls-as-dependencies"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is the best way to do CI/CD with AWS CDK (python) using GitLab CI?\n\nI am using AWS CDK (with Python) for a containerized application that runs on Fargate. I would like to run cdk deploy in a GitLab CI process and pass the git tag as an environment variable that replaces the container running in Fargate. I am currently doing something similar with CloudFormation (aws cloudformation update-stack ...). Is anyone else doing CI/CD with AWS CDK in this way? Is there a better way to do it? \nAlso, what should I use for my base image for this job? I was thinking that I can either start with a python container and install node or vice versa. Or maybe there is prebuilt container somewhere that I haven't been able to find yet. \nHere is start that seems to be working well:\nCDK:\n  image: python:3.8\n  stage: deploy\n  before_script:\n    - apt-get -qq update && apt-get -y install nodejs npm\n    - node -v\n    - npm i -g aws-cdk\n    - cd awscdk\n    - pip3 install -r requirements.txt\n  script:\n    - cdk diff\n    - cdk deploy --require-approval never\n\nEdit 2020-05-04:\nCDK can build docker images during cdk deploy, but it needs access to docker. If you don't need docker, the above CI job definition should be fine. Here's the current CI job I'm using: \ncdk deploy:\n  image: docker:19.03.1\n  services:\n    - docker:19.03.5-dind\n  stage: deploy\n  only:\n    - master\n  before_script:\n    - apk add --no-cache python3\n    - python3 -V\n    - pip3 -V\n    - apk add nodejs-current npm\n    - node -v\n    - npm i -g aws-cdk\n    - cd awscdk\n    - pip3 install -r requirements.txt\n  script:\n    - cdk bootstrap aws://$AWS_ACCOUNT_ID/$AWS_DEFAULT_REGION\n    - cdk deploy --require-approval never\n\nThe cdk bootstrap is needed because I am using assets in my cdk code:\n        self.backend_task.add_container(\n            \"DjangoBackend\",\n            image=ecs.AssetImage(\n                \"../backend\",\n                file=\"scripts/prod/Dockerfile\",\n                target=\"production\",\n            ),\n            logging=ecs.LogDrivers.aws_logs(stream_prefix=\"Backend\"),\n            environment=environment_variables,\n            command=[\"/start_prod.sh\"],\n        )\n\nHere's more information on cdk bootstrap: https://github.com/aws/aws-cdk/blob/master/design/cdk-bootstrap.md"}, {"role": "assistant", "content": "you definitely have to use CDK deploy inside the CI/CD pipeline if you have lambda or ECS assets, otherwise, you could run CDK synth and pass the resulting Cloudformation to AWS Code Deploy. That means a lot of your CI/CD will be spent deploying which might drain your free tier build minutes or just means you pay more (AWS Code Deploy is free)\nI do something similar with Golang in CircleCi. I use the Go base image and install nodejs and cdk. I use this base image to build all my go binaries, the vuejs frontend and compile cdk typescript and deploy it.\nFROM golang:1.13\n\nRUN go get -u -d github.com/magefile/mage\nWORKDIR $GOPATH/src/github.com/magefile/mage\nRUN go run bootstrap.go\n\nRUN curl -sL https://deb.nodesource.com/setup_12.x | bash -\nRUN apt-get install -y nodejs\nRUN npm i -g [email\u00a0protected]\nRUN npm i -g typescript\nRUN curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | apt-key add -\nRUN echo \"deb https://dl.yarnpkg.com/debian/ stable main\" | tee /etc/apt/sources.list.d/yarn.list\nRUN apt update && apt install yarn\n\nI hope that helps."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Continuous Deployment of a Node.js app to Heroku using GitLab\n\nThere are tutorials covering the deployment of Ruby and Python apps but I can't find good documentation or examples for NodeJS. \nhttp://docs.gitlab.com/ce/ci/examples/test-and-deploy-python-application-to-heroku.html\nhttp://docs.gitlab.com/ce/ci/examples/test-and-deploy-ruby-application-to-heroku.html\nDoes anyone have a .gitlab-ci.yml to share?"}, {"role": "assistant", "content": "create a project \n\n npm init -y\n npm i  #install dependencies \n\n\nadd the following lines in package.json\n\n    \"engines\": {\n        \"node\": \"8.12.0\",  //node version\n        \"npm\": \"6.4.1\"     //npm version\n    },\n    \"scripts\": {\n        \"start\": \"node app.js\", //heroku will using the following script to run node app\n    }\n\n\ncreate a heroku project\n\nselect NEW -> Create new app\nset the App name & choose a region\nclick on Create app\n\nGitlab setup create new repo or add to exist project given on gitlab website\ncreate a .gitlab-ci.yml file\nimage: node:latest\nstages:\n- production\nproduction:\ntype: deploy\nstage: production\nimage: ruby:latest\nscript:\n    - apt-get update -qy\n    - apt-get install -y ruby-dev\n    - gem install dpl\n    - dpl --provider=heroku --app=APPNAME_OF_Heroku App --api-key=$HEROKU_API_KEY # security add the heroku api to CI/CD setting\nonly:\n    - master  #branch name to deploy on heroku\n\n\nSetting HEROKU_API_KEY\n\nSetting -> CI/CD -> Variable -> Expand\nInput Variable key -> variable name in .gitlab-ci.yml\nInput Variable value -> Heroku Api Key\n\nGet the Heroku Api Key \n\nHeroki Dashborad -> Account Settings \n\nset the Runner on Gitlab\n\nSetting -> CI/CD -> Variable -> Expand\n\n\nSpecific Runners\n\n\nInstall the gitlab-runner \nWindows\nLinux\nMacOS\nFor setup steps here\n\nShared Runners\n\n\njust click Disable shared Runners to enable the shared runner \n\n\n\npush the files to gitlab it will automatically deploy on heroku \ngit add .                 #to add all the files)\ngit commit -m \"message\"   #to commit files\ngit push origin master"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Does GitLab permit wiki merge requests?\n\nI know GitLab stores wiki pages in a separate Git repository. How can we create a merge request for the wiki project of my project? Is it possible?\nI found a similar question about GitHub:\nHow can I make a pull request for a wiki page on GitHub?, but nothing about GitLab."}, {"role": "assistant", "content": "2016: Creating a MR (Merge Request) requires the name of a project, not of its wiki.\nThe workaround would then be similar to the one described in your linked answer\n\nhaving a dedicated repo \"project\" being a fork/clone of the wiki\nmaking your MR to this wiki project/fork\npushing from this fork back to the original wiki repo\n\n\n2022: this is followed by Epic 7107, which refers to this workaround:\n\nAccepting merge requests on wikis\nIt's possible to work around the limitation of Wiki permissions\nby creating a mirror of the git wiki backing the wikis.\nThis way more users can suggest changes to the wiki by submitting merge requests.\nIt's not as easy as editing the wiki, but at least provides\na way for outside contributors to participate.\nTo do this, you'll need to create project access tokens in the\nWiki and use the repository mirror feature to replicate the wiki\ninto a separate project.\n\nIn the Wiki project, head for the Settings: Access Tokens page\nand create a new token with write_repository access\n\noptionally, create a new project for the wiki, for example called\nwiki-replica.\nYou can also use the same project as the wiki\nif you do not plan to host other source code specific to that\nproject there.\nWe'll call this the \"wiki replica\" in either case\n\nIn the wiki replica, head for the Settings: Mirroring repositories section and fill in the details for the wiki HTTPS clone URL:\n\nGit repository URL: the HTTPS URL of the Git repository (which\nyou can find in the Clone repository page on the top-right\nof the wiki)\nImportant: Make sure you add a username to\nthe HTTPS URL, otherwise mirroring will fail.\nFor example, this wiki URL:\nhttps://gitlab.torproject.org/tpo/tpa/team.wiki.git\n\nshould actually be:\nhttps://[email\u00a0protected]/tpo/tpa/team.wiki.git\n\n\nMirror direction: push (only \"free\" option, pull is non-free)\n\nAuthentication method: Password (default)\n\nPassword: the Access token you created in the first\nstep\n\nKeep divergent refs: checked (optional, should make sure\nsync works in some edge cases)\n\nMirror only protected branches: checked (to keep merge\nrequests from being needlessly mirrored to the wiki)\n\n\n\n\nWhen you click the Mirror repository button, a sync will be\ntriggered.\nRefresh the page to see status, you should see the Last successful update column updated.\nWhen you push to the replica, the wiki should be updated.\nNaturally, because of limitations of GitLab, you cannot pull changes\nfrom the wiki to the replica.\nBut considering only a limited set of\nusers have access to the wiki in the first place, this shouldn't be a\nproblem as long as everyone pushes to the replica."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab-ci is not using the node version I have specified\n\nI'm very new to GitLab and am trying to set up the CI/CD system for my project.\nMy .gitlab-ci.yml file is as follows:\nimage: node:10.15.3\n\ncache:\n  paths:\n  - node_modules/\n\nbefore_script:\n  - node -v\n  - npm install\n\nstages:\n  - test\n\nall-tests:\n  stage: test\n  script:\n    - npm run lint\n    - npm run test:unit:cov\n    - npm run test:server\n\n\nHowever the node -v line outputs 6.12.0 not 10.15.3 and my tests are failing because the node version is wrong.\nHow do I tell GitLab CI to use Node 10.15.3?"}, {"role": "assistant", "content": "You are not tagging your job so perhaps it is running on a shell-executor and not a docker-executor. Check for .dockerenv in your job spec to ensure you're running in a container;\nGiven this simple pipeline (based on yours):\nimage: node:10.15.3\n\nbefore_script:\n  - node -v\n\nstages:\n  - test\n\nall-tests:\n  tags:\n    - docker\n  stage: test\n  script:\n    # are we in a docker-executor\n    - if [ -f /.dockerenv ]; then echo \"docker-executor\"; fi\n\nI get the following output, which suggests we are pulling the correct node image version:\nRunning with gitlab-runner 11.3.1 (0aa5179e)\n  on gitlab-docker-runner fdcd6979\nUsing Docker executor with image node:10.15.3 ...\nPulling docker image node:10.15.3 ...\nUsing docker image sha256:64c810caf95adbe21b5f41be687aa77aaebc197aa92f2b2283da5d57269d2b92 for node:10.15.3 ...\nRunning on runner-fdcd6979-project-862-concurrent-0 via af166b7f5bef...\nFetching changes...\nHEAD is now at b46bb77 output container id\nFrom https://gitlab/siloko/node-test\n   b46bb77..adab1e3  master     -> origin/master\nChecking out adab1e31 as master...\nSkipping Git submodules setup\n$ node -v\nv10.15.3\n$ if [ -f /.dockerenv ]; then echo \"docker-executor\"; fi\ndocker-executor\nJob succeeded"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How can I force GitLab to carry out a garbage collection (and permanently remove a file)\n\nOne of our developers checked in (and pushed) a secure file.\nI removed the file from their history, and did a push --force, in order to get the new history out there, which now doesn't include the file.\nHowever, the orphaned check-in from before is still referenced in the project \"Activity\", and if I click on the hash then I can still see it that checkin, and the file.\nBecause it's no longer referenced by the master/head, I assume this orphan checkin will vanish the next time that GitLab carries out a garbage collection.  But I'd like that to happen now, so that the secure file is no longer accessible.\nHow can I force this to happen?"}, {"role": "assistant", "content": "Running housekeeping should solve your problem. When running housekeeping Gitlab will run a git repack or git gc (depending on the admin settings).\nSee https://docs.gitlab.com/ee/administration/housekeeping.html for more info."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab API - How to get private_token using GET with session parameter?\n\nI am using GitLab API v3 to do some operations on my private installation. Using private_token in GET URL is working fine. e.g.\nGET http://git.example.com/api/v3/projects?=private_token=xyz123\n\nBut in order to make this possible, you need a private_token. There is one sure way to get it - from your account settings. But I want my users to use their email id/ login id and password to retrieve the private key and use it from there for rest of the operations.\nI used following GET url and it is doing nothing for me:\nGET http://git.example.com/api/v3/session?login=xyzuser&password=xyzpassword\n\nIdeally as per GitLab documentation, I should get a JSON as follows -\n{\n  \"id\": 1,\n  \"username\": \"john_smith\",\n  \"email\": \"[email\u00a0protected]\",\n  \"name\": \"John Smith\",\n  \"private_token\": \"dd34asd13as\",\n  \"blocked\": false,\n  \"created_at\": \"2012-05-23T08:00:58Z\",\n  \"bio\": null,\n  \"skype\": \"\",\n  \"linkedin\": \"\",\n  \"twitter\": \"\",\n  \"dark_scheme\": false,\n  \"theme_id\": 1,\n  \"is_admin\": false,\n  \"can_create_group\" : true,\n  \"can_create_team\" : true,\n  \"can_create_project\" : true\n}\n\nIf I get this, I can get private_token and work from there.\nWhat am I doing wrong?"}, {"role": "assistant", "content": "You need to POST the data as stated in the api (http://api.gitlab.org/session.html).\nBe aware that if you do this action on a http port (instead of using https) that the password is send in plain text to the server."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Create Helm chart extending an existing chart\n\nI am using https://gitlab.com/charts/gitlab to deploy certain components included in the chart on an Openshift cluster. For now I just want to deploy the included Prometheus chart. I accomplished this, having an specific values.yaml configuration.\nI want to extend the Gitlab helm chart, to do so I am adding it as a requirement of my own chart. The problem comes whenever I add the previous values.yaml as subpart of my values.\nDeploying upstream Gitlab chart works with:\nglobal:\n  registry:\n    enabled: false\n  # Disabling minio still requires to disable gitlab.minio or it will complain about \"A valid backups.objectStorage.config.secret is needed\"\n  minio:\n    enabled: false\n  ingress:\n    enabled: false\n    configureCertmanager: false\n\nnginx-ingress:\n  enabled: false\nregistry:\n  enabled: false\ncertmanager:\n  install: false\n  rbac:\n    create: false\n...\n\nDeploying my chart including configuration as a subchart does not work:\nglobal:\n  registry:\n    enabled: false\n  # Disabling minio still requires to disable gitlab.minio or it will complain about \"A valid backups.objectStorage.config.secret is needed\"\n  minio:\n    enabled: false\n  ingress:\n    enabled: false\n    configureCertmanager: false\n\n\ntest:\n  nginx-ingress:\n    enabled: false\n\n  registry:\n    enabled: false\n  certmanager:\n    install: false\n    rbac:\n      create: false\n  ...\n\nI added the Gitlab upstream chart as a requirement:\ndependencies:\n- name: gitlab\n  # Upgrade manually. Check https://gitlab.com/charts/gitlab/blob/master/requirements.yaml for the new Prometheus chart version.\n  version: 1.7.1\n  repository: https://charts.gitlab.io/\n  alias: test\n\nIt seems that it is not fully checking my configuration, so this creates objects that the serviceAccount does not have permissions to, failing in the process. It still tries to create objects related to certmanager even if it is disabled and was correctly disabled when deploying Gitlab chart directly."}, {"role": "assistant", "content": "Found it. Requirements conditions for a subchart have to be specified on the first level of values.yaml.\nIf A has B as a subchart requirement, in order to specify the B requirement conditions, you have to set them at A level:\nglobal:\n  registry:\n    enabled: false\n  # Disabling minio still requires to disable gitlab.minio or it will complain about \"A valid backups.objectStorage.config.secret is needed\"\n  minio:\n    enabled: false\n  ingress:\n    enabled: false\n    configureCertmanager: false\n\n\ntest:\n  nginx-ingress:\n    enabled: false\n\n  registry:\n    enabled: false\n  ...\n\ncertmanager:\n  install: false\n  rbac:\n    create: false\n  ..."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Running gitlab-ci pipeline jobs as non-root user\n\nI have a mvn project  which must be build as an non-root user\nbut by default gitlab-ci allows runners to run as root user.\nI'm using gitlab.com runners by setting up gitlab-ci.yml file.\nI tried creating a user and switching to it like this:\n$ useradd ***\n$ su -***\n$ whoami\nroot\n\nIt still says I'm root.\nHow can I solve this?"}, {"role": "assistant", "content": "You can easily achieve this with sudo, e.g.,\nexcerpt from my .gitlab-ci.yml:\nscript:\n    - useradd -d /builds/{GITLAB_USER} -g users -M -N builder\n    - chown -R builder:users ..\n    - |     \n      sudo -H -i -u builder sh -e -x << EOS                                                                                                                                                                                                                       \n      umask 0077                                                                                                                                                                                                                                               \n      export CONTINUOUS_INTEGRATION_SYSTEM=\"gitlab\" TIMESTAMP=`date +%Y%m%d%H%M%S` DEFAULT_TARGET=\"debug\"                                                                                                                                                      \n      export PREFIX=\"\\${HOME}/usr\" SYSCONFDIR=\"\\${HOME}/etc/conf\" LOCALSTATEDIR=\"\\${HOME}/var\"                                                                                                                                                                 \n      cd my-project                                                                                                                                                                                                                                                  \n      make install                                                                                                                                                                                                                                             \n      make -C _deploy/debian clean package bundle BUILD_ID=\"-0{other}\\${TIMESTAMP}\"                                                                                                                                                                        \n      EOS\n\nWhere {GITLAB_USER} is your actual gitlab user.\nRemember to escape $ in your script"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to specify project language in GitLab?\n\nOne can manually select project language at Bitbucket or use .gitattributes at GitHub.\nIs there a way to make GitLab assign a specific language to a project?"}, {"role": "assistant", "content": "GitLab will adhere to the overrides specified in your .gitattributes file.  Currently, GitLab uses the Linguist Gem. Without these overrides Linguist will deduce the main language used for a project by analysing the code within files in the project.\nYou can find out how the magic happens by referring to the Repository#main_language method within the gitlab-ce project."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Can't publish private npm package on Gitlab - E404 Not found PUT\n\nI've tried many different docs and tutorials to publish a scoped npm package on a private gitlab instance.\nSo far I've:\nCreated a deploy token with package write & read permissions:\n\nSetup a .npmrc file with the following contents:\n@<scope>:registry=https://<domain>/api/v4/packages/npm/\n\n//<domain>/api/v4/projects/<id>/packages/npm/:_authToken=<token>\n\n//<domain>/api/v4/packages/npm/:_authToken=<token>\n\nAdded \"publishConfig\" to \"package.json\":\n{\n  \"name\": \"@<scope>/<name>\",\n  \"version\": \"1.0.0\",\n  \"main\": \"dist/index.js\",\n  \"license\": \"MIT\",\n  \"publishConfig\": {\n    \"@<scope>:registry\": \"https://<domain>/api/v4/projects/<id>/packages/npm\"\n  },\n  \"scripts\": {\n    \"build\": \"tsc\",\n    \"prepublish\": \"tsc\"\n  },\n  \"devDependencies\": {\n    \"ts-node\": \"^9.1.1\"\n  }\n}\n\nVerified that the repo allows packages to be stored:\n\nBut everytime I try and run either npm publish or yarn publish, it builds, packages but fails to publish:\n\nThe log file verbosily repeats the error log above.\nI'm trying to release a private SDK for an internal service and would need a way to publish it so only those with the correct credentials can install it on their projects.\nThe link provided (Not Found - PUT https:// <link...> ) redirects to npmjs.com, which I believe wasn't supposed to happen, since I'm trying to store it on Gitlab instead of purchasing an organization on npmjs.\nI've tried this process both on the private domain (running gitlab 13.9.1) and on https://gitlab.com, both with the same result on the same repository configuration disclosed above.\nAm I missing some step? Thanks in advance!"}, {"role": "assistant", "content": "Your .npmrc file has both instance and project level endpoints, but if you're using a project deploy token, the authentication of the token you're providing is scoped to the project, so you should only have the project endpoint.\n@<scope>:registry=https://<domain>/api/v4/projects/<ID>/packages/npm/\n\n//<domain>/api/v4/projects/<ID>/packages/npm/:_authToken=<TOKEN>"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Is it possible to deploy GItLab Pages without CI/CD?\n\nWe have a locally deployed instance of Gitlab, where at the time we cannot afford to have a GitLab Runner to run CI/CD pipelines.\nIs it possible to use GitLab Pages without CI/CD? E.g. is it possible to manually prepare the HTML-content, put it in the public folder in the root and make it accessible?"}, {"role": "assistant", "content": "I assume you don't want to use GitLab shared runner which costs you and CI minutes limits.\nPublic folder\nRefer to this gitlab-ci.yaml for making HTML content available https://gitlab.com/pages/plain-html/-/blob/master/.gitlab-ci.yml\nRunning locally without registration\nHere is the known limitations: https://docs.gitlab.com/runner/commands/#limitations-of-gitlab-runner-exec\nPages are directly managed by Gitlab so running locally won't affect the page's state.\nUse your own runner and register with gitlab (Possible)\nInstall GitLab runner on your machine and register as a runner, instructions can be found at Settings->CI/CD->Runners->Specific runner Enable it for your project or group.\nI use my personal machine gitlab-runner to execute CI jobs that aren't counted towards CI minutes."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Sonarqube quality badges on gitlab\n\nI have a project on gitlab for which I'm trying to display quality badges from sonarqube on. For that I used the \"Get project badges\" button on the bottom right corner of your sonarqube project overview. They give you for each badge a Markdown which you can easily copy & paste to your README.md file on gitlab/github.\n\nMarkdown looks like this: [![Bugs](https://yourprojectonsonarqube/api/project_badges/measure?project=your_project_key&metric=bugs)](https://yourprojectonsonarqube/dashboard?id=your_project_key)\nFor me it looks like this on the README.md file(logged in as maintainer):\n\nFor other users on the project which also have maintainer or developer permissions it looks like this:\n\nIf you click on the missing images, it will redirect you to sonarqube and ask for you to log in. Afterwards the images are visible. How can I change that? I want them to always be visible to every user of my project."}, {"role": "assistant", "content": "If this is for a private project on SonarQube, this is most likely a permissions issue.\nThere is currently an open issue for SonarQube to allow this to work: https://jira.sonarsource.com/browse/MMF-1942\nAs an FYI, this feature has already been implemented for SonarCloud: https://jira.sonarsource.com/browse/MMF-1178."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab not sending notifications to merge request approvers\n\nI have written an entire software development course, and until recently we've been using Bitbucket. I recently rewrote the course to use GitLab instead, mostly because GitLab the username isn't tied to a particular email like Bitbucket. I had heard good things. But I'm running into problems already.\nThe first is that merge requests (what the other hosting services call \"pull requests\") are not sending out notifications to approvers. We just had the lesson where I taught my students to create merge requests. I had them add me as \"Reporter\" to their projects. Then I had them create a merge request, and add me as an \"Approver\".\nYet I received no email notifying me that two student had created merge requests with me as an approver on each. I double-checked, and my global notifications are set to \"Participate\".\nI reported this issue in a comment to a GitLab ticket, but received no response. I even filed a new official GitLab bug report; someone finally looked at it, and created another ticket for GitLab EE. So far no one has actually found the problem.\nSo as a workaround I went into my GitLab nofication settings and set the notification level for each student repository to \"Watch\" so that I (in theory) should be notified of any activity at all. Sure enough, I was notified when my students created merge requests.\nUnfortunately even with a notification level of \"watch\", I was not notified when a student updated a merge request by making a new commitment to the branch and pushing it to GitLab.\nAm I doing something wrong? Why am I not getting notifications of merge requests on which I am approver\u2014not even when I'm watching the project? If I can't get this simple, core functionality to work I guess we'll move to Github, now that they introduced private repositories.\nUpdate: I finally abandoned GitLab, primarily because of basic issues like this one. I rewrote the software development course again, this time using GitHub."}, {"role": "assistant", "content": "Role \"Reporter\" cannot accept/manager Merge Requests in the repository. See the whole list of permissions but basically they are:\n\nGuest: Read only access\nReporter: Issues and comments\nDeveloper: Push, actions to the repository\nMaintainer: Admin\n\nI did not test myself but maybe GitLab notifications check this internally. My recommendation is to protect the master branch or develop depending on your Git Workflow. Ideally only Maintainers can push or merge to protected branches after code review, so you should be assigned this role in the repos to approved things and hopefully receive the notifications. The global notification should be \"Participate\" and this is propagated to all your repos to avoid be overwhelmed by notifications (\"Watch\" notify all the activities in the repos). Developers should create feature or bugfix branches from master/develop and push always to this branch.\nSuggestion\nI would research some Git Workflow: Github, GitLab or GitFlow are very good examples to analyse. You can adapt the workflow to your own needs. Another MUST should be to configure GitLab CI/CD before merging into the protected branches to assure the robustness and quality of the code and teach the students good practices from the beginning.\nUPDATE 2\nThis is happening in the CE and EE. No emails are sent when pushing new commits to Merge Requests. I tested with \"Watch\", \"Custom\", \"Participate\", \"Developer\", \"Maintainer\" and no emails have been sent. Actually \"Custom\" has an specific option for \"Push to Merge Requests\". However even not ideal, there is a workaround if you want to use it. Actually it also sends the diff between commits inside the email. In Settings/Integration there is an option Emails on push. You can configure there a list of emails to send the notifications. See the image below. If you want to be informed when someone push new commits to the MR another workaround is to configure the CI pipeline. You will receive an email if the pipeline fails or succeeds (this is the way we are doing). Let's wait until GitLab people answers to your GitLab ticket. If this is a NO GO issue for you and none of the workarounds work for you, I would move to GitHub Private Repositories."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab runner + autoscaling + scaled runner options\n\nI'm using gitlab runner with docker+machine executor to fire up autoscaled runners on AWS. I would like to use docker-in-docker setup inside the runners to build containers, but I can't find out how to define the needed [runners.docker] properties for the spawned runners to enable docker usage.\nIs it possible to somehow pass some config info to autoscaled runners?"}, {"role": "assistant", "content": "you just need this in your config.toml of your autoscale runner:  \n[runners.docker]\n  privileged = true\n\nI use docker-in-docker to build my own php containers for testing and store them in gitlabs registry. see https://gitlab.cwd.at/docker/php/builds/21582 for a build example and https://gitlab.cwd.at/docker/php/blob/master/.gitlab-ci.yml for the build definition\nsee here my current config - its using S3 for caching and digitalocean for the runners:\nconcurrent = 10\n\n[[runners]]\n  name = \"ec2-autoscale-runner\"\n  url = \"https://gitlab.mydomain.at/ci\"\n  token = \"12345\"\n  executor = \"docker+machine\"\n  limit = 10\n  environment = [\"COMPOSER_CACHE_DIR=/cache\"]\n  [runners.machine]\n    OffPeakPeriods = [               # Set the Off Peak time mode on for:\n      \"* * 0-9,18-23 * * mon-fri *\", # - Monday to Friday for 12am to 9am and 6pm to 11pm\n      \"* * * * * sat,sun *\"          # - whole Saturday and Sunday\n    ]\n    OffPeakIdleCount = 0             # There must be 1 machine in Idle state - when Off Peak time mode is on\n    OffPeakIdleTime = 3550           # Each machine can be in Idle state up to 1200 seconds (after this it will be removed) - when Off Peak time mode is on\n    IdleCount = 0                    # There must be 5 machines in Idle state - when Off Peak time mode is off\n    IdleTime = 3550                  # Each machine can be in Idle state up to 600 seconds (after this it will be removed) - when Off Peak time mode is off\n    MaxBuilds = 100                    # Each machine can handle up to 100 builds in a row (after this it will be removed)\n    MachineName = \"auto-scale-%s\"    # Each machine will have a unique name ('%s' is required)\n    MachineDriver = \"digitalocean\"   # Docker Machine is using the 'digitalocean' driver\n    MachineOptions = [\n        \"digitalocean-image=21937863\",\n        #\"digitalocean-image=20969606\",\n        \"digitalocean-access-token=12345\",\n        \"digitalocean-region=fra1\",\n        \"digitalocean-size=4gb\",\n        \"digitalocean-private-networking\",\n        \"digitalocean-ipv6=true\"\n    ]\n  [runners.ssh]\n    user = \"root\"\n    identity_file = \"/etc/gitlab-runner/id_rsa\"\n  [runners.docker]\n    privileged = true\n  [runners.cache]\n    Type = \"s3\"\n    ServerAddress = \"s3.amazonaws.com\"\n    AccessKey = \"1234\"\n    SecretKey = \"1234\"\n    BucketName = \"cwd-gitlab-cache\"\n    BucketLocation = \"eu-central-1\"\n    Insecure = false"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to view shared runner queue\n\nI'm using Gitlab's shared runner. Build has been in 'pending' state for over 20 minutes.\nHow to debug this? is it something to do with the runner availability or script execution issue.. Is it possible to gain more insight by any means?"}, {"role": "assistant", "content": "I don't think the UI supports viewing a shared runner's queue. However, this 'pending' state can be caused by things other than a queue.\nCheck the tags for that pipeline stage against the tags supported by the runners available to the runners activated for your project:\n\nRemember, tags can vary from stage to stage, so it's possible for the first few stages to work before your pipeline is blocked.\nGitlab-ci will indicate 'pending' when a runner cannot be found with tags matching a given stage."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab-reconfigure blocked on redis after reinstalling gitlab on ubuntu 18.04.4LTS\n\nThis is the third time I install gitlab on server and never had issues before. \nI decide to reinstall gitlab-ce ( 12.10.0 ) after dealing with issues on 12.9.0. \nBefore installing the new version, I had ensured that all gitlab files where removed and reboot the server.\nStep1: Uninstall gitlab 12.9.0\n# gitlab-ctl stop\n# gitlab-ctl uninstall\n# apt-get remove --purge gitlab-ce\n# find / -iname \"gitlab\" then try to remove all outputed files\n# init 6\n\nStep 2: Fresh install gitlab 12.10.0\n# apt-get update\n# apt-get install gitlab-ce=12.10.0-ce.0\n\nThen I updated my /etc/gitlab/gitlab.rb file according to my server config.\nFinally, I executed:\ngitlab-ctl reconfigure\n\nThe processes was blocked on : \nruby_block[wait for redis service socket] action run\nAny solutions ?"}, {"role": "assistant", "content": "The link provided by Manuel Richarz indicated there might be different lines upon which the installation may hang, one of them being the ruby_block[wait for redis service socket] action run line your question is about.\nTheir proposed solution is to open a new terminal and run:\nsystemctl restart gitlab-runsvdir.service\n\nThis worked for me for the ruby_block[wait for logrotate service socket] action run line."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "git: 'credential-wincred' is not a git command. See 'git --help'. on mac\n\nHow to solve this error on \"MacBook pro\".\n\ngit: 'credential-wincred' is not a git command. See 'git --help'.\ngit: 'credential-wincred' is not a git command. See 'git --help'.\nremote: HTTP Basic: Access denied\n  fatal: Authentication failed for 'https://gitlab01.xxxxx.com.tw/xxxxx/xxxxxxx.git/'\n\nI use \"git config --system --unset credential.helper\" & \"git config --global credential.helper wincred\n\", and nothing work for me.\nThanks."}, {"role": "assistant", "content": "The problem is that you're trying to use the wincred credential helper, which is only available on Windows, on macOS. You mentioned that you've run git config --global credential.helper wincred, which sets the credential helper to wincred. When Git tries to invoke it, it fails because it's unavailable.\nInstead, you should run git config --unset-all credential.helper and run git config --global credential.helper osxkeychain. That will result in you using the macOS Keychain for storing credentials, which will work on macOS."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Install gitlab-ce on ubuntu server 17.04\n\nI'm trying to install the gitlab-ce package on a system running Ubuntu server 17.04. I followed the official installation instructions here.\nFirst I ran:\nsudo apt-get install curl openssh-server ca-certificates postfix\n\nI already had all of those installed. Then I ran:\ncurl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.deb.sh | sudo bash\n\nWhich also worked fine. But when I try to run\nsudo apt-get install gitlab-ce\n\nI get the following error message:\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nE: Unable to locate package gitlab-ce\n\nI know it's possible to install gitlab on Ubuntu server 17.04, since I had already done It on a previous installation. Unfortunately I installed the OS again from scratch and I can't remember how I had installed gitlab.\nThanks for any help in advance!"}, {"role": "assistant", "content": "I gave up with the \"full\" automated script, as it doesn't appear to be working with 17.04... Anyway. I grabbed the latest package from https://packages.gitlab.com/gitlab/gitlab-ce/packages/ubuntu/xenial/gitlab-ce_9.3.0-ce.0_amd64.deb\ncurl -LJO https://packages.gitlab.com/gitlab/gitlab-ce/packages/ubuntu/xenial/gitlab-ce_9.3.0-ce.0_amd64.deb/download\n\nInstalled it with the package manager\nsudo dpkg -i gitlab-ce_9.3.0-ce.0_amd64.deb\n\nThen configured it with\nsudo gitlab-ctl reconfigure\n\nThen, point your web browser at your new gitlab install and you should be good to go...\nUbuntu 20.04.1\nIncase anyone bumps back into this, while trying to gitlab on version 20.0.4 of ubuntu, life is much easier... and the instructions and automated script actually work. GitLab-CE installation instructions\non a fresh install of ubuntu: -\nsudo apt install curl\ncurl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab- ce/script.deb.sh | sudo bash\nsudo apt install gitlab-ce\n\ndone!"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I generate a new ssh-key for my new gitlab account?\n\nI have two Gitlab accounts. On my old account I added an ssh-key that is located in ~/.ssh/id_rsa.pub on my computer.  \nNow I want to add another ssh-key for my new Gitlab account. How do I do this without having the ssh-keys conflict?"}, {"role": "assistant", "content": "I would recommend a second key, for now without passphrase:\nssh-keygen -t rsa -C \"[email\u00a0protected]\" -P \"\" -q -f ~/.ssh/gitlab_rsa\n\nThat will create (without any prompt) ~/.ssh/gitlab_rsa (private key) and ~/.ssh/gitlab_rsa.pub (public key)\nYou need to register that second gitlab_rsa.pub public key to your second GitLab account.\n\nNavigate to the 'SSH Keys' tab in your 'Profile Settings'. Paste your key in the 'Key' section and give it a relevant 'Title'. \n\nThen add a ~/.ssh/config file with:\nHost gitlab_rsa\n    HostName gitlab.com\n    User git\n    PreferredAuthentications publickey\n    IdentityFile /home/<you>/.ssh/gitlab_rsa\n\nFinally, you can clone any GitLab repo as your second identity with:\ngit clone gitlab_rsa:<yourSecondAccount>/<yourRepo.git>\n\nThat will be replaced automatically with [email\u00a0protected]:<yourSecondACcount>/<yourRepo.git> and will use your second key."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to disable the Two-factor authentication in GitLab?\n\ni changed the gitlab server. On the old i had created a backup and now i had imported the backup into the new system. Everyting works!\nNow i have the issue, that i can't login because of the Two-factor authentication. I think, that the secret salt changend.\nThis is the log:\nParameters: {\"utf8\"=>\"\u2713\", \"authenticity_token\"=>\"[FILTERED]\", \"user\"=>{\"otp_attempt\"=>\"[FILTERED]\"}}\n\nCompleted 500 Internal Server Error in 10ms (ActiveRecord: 0.9ms)\n\nOpenSSL::Cipher::CipherError (bad decrypt):\napp/controllers/sessions_controller.rb:95:in valid_otp_attempt?'\napp/controllers/sessions_controller.rb:63:in authenticate_with_two_factor'\n\nHow can i disable the Two-factor authentication for one user?\ngreetings"}, {"role": "assistant", "content": "Gitlab has updated the command to disable two-factor authentication for all users to this:\nsudo gitlab-rails runner 'User.find_each(&:disable_two_factor!)'\n@poldixd's answer should still work. If it doesn't try setting encrypted_opt_secret to nil instead of \"\".\nFound this here:\nhttps://gitlab.com/gitlab-org/gitlab-ce/issues/1960"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Errno::EACCES: Permission denied when installing gems via gitlab\n\nI'm trying to setup gitlab and thus install some gems from another user account using sudo,\nbut I'm constantly getting Permission denied error.\nsudo -u gitlab -H bundle install --deployment --without development test postgres\n\n> Using ... ( a lot of successful gems there )\n> Using pygments.rb (0.3.2) from https://github.com/gitlabhq/pygments.rb.git (at master) \n> Errno::EACCES: Permission denied - pygments.rb-0.3.2.gem\n> An error occurred while installing pygments.rb (0.3.2), and Bundler cannot continue.\n> Make sure that `gem install pygments.rb -v '0.3.2'` succeeds before bundling.\\\n\n\n\nsudo -u gitlab -H gem install pygments.rb -v '0.3.2'\n\n> Successfully installed pygments.rb-0.3.2\n> 1 gem installed\n> Installing ri documentation for pygments.rb-0.3.2...\n> Installing RDoc documentation for pygments.rb-0.3.2...\n# no matter how many times I run this command, I always get the same output\n# as if the gem installation doesn't stick \n\n\n# I've tried to chmod\nchmod 777 -R /usr/local/lib/ruby\n\n\n\n# then Again\nsudo -u gitlab -H bundle install --deployment --without development test postgres\n# same result, Errno::EACCES: Permission denied - pygments.rb-0.3.2.gem"}, {"role": "assistant", "content": "Lain suggested to try to install the bundles into another sub directory. When that worked out, it became clear the problem was about permissions in the current directory.\nExecuting chown -R gitlab:gitlab . has solved the problem.    \nIn the gitlab installation guide there is a gem install command preceding our story that was ran as root and probably the gemfile or some other file had permissions change during that."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab-CI how to use artifacts in different pipeline\n\nCurrently, I have two main project.\n1-) Vue Project which contains (webviews for IOS and Android, websites, and renderer for our Electron ) they are sharing components & API's. \n2-) Electron Project which builds desktop app for (windows, darwin, linux) \ni would like to automate our building, releasing process. my current setup..\n            before_script: \n                - apt-get update\n                - apt-get install zip unzip \n                - rm -rf vue-project\n                - git clone vue-project\n                - cd vue-project\n                - git checkout dev\n                - git pull\n                - sed -i \"/\\b\\(areaCode\\|inline-svg-loader\\)\\b/d\" ./packages/devtool/package.json\n                - yarn install\n                - ln -s vue-project/packages/desktop/ web\n                - npm install\n\n            build_darwin:\n                stage: build\n                script:\n                    - npm run package -- darwin --deploy\n                cache:\n                    paths:\n                        - vue-project/node_modules\n                        - node_modules\n\nwhich basically before bundling electron project it's cloning vue-project install dependencies and bundling electron-renderer then when it's finish. i'm running package.\nI would like to separate this two different job from each other. is there anyway i could use artifacts from different project gitlab-CI pipelines ?\nany help would be an appreciated."}, {"role": "assistant", "content": "Gitlab has a API for do a lot of tricks.\ncurl --header \"PRIVATE-TOKEN:YOURPRIVATETOKEN\" \"https://gitlab.example.com/api/v4/projects/1/jobs/artifacts/master/download?job=test\"\n\nfor download it as a file.\ncurl --header \"PRIVATE-TOKEN:YOURPRIVATETOKEN\" -o artifacts.zip \"http://gitlab.example.net/api/v4/projects/<projectnumber>/jobs/artifacts/master/download?job=build_desktop"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "regular expression for [STRING] in gitlab-ci.yml file\n\nI am tyring to set rule for deployment stage in gitlab-ci.yml file where if the git commit message is having a particular [STRING] in this format then it should deploy to that particular environment where this rule is written.\n# Deploy to QAT environment\ndeploy-qat:\n  stage: deploy\n  extends: .helm_deploy\n  environment:\n    name: qat\n  tags:\n    - exe-prd\n  rules:\n    - if: $CI_COMMIT_MESSAGE =~ \"/[QAT]$/|/[qat]$/\"  #&&  $CI_COMMIT_REF_NAME == \"example/qat\"\n      when: always\n\nI have wrote above rule however it is not working. I have tried below combinations of regular expressions however none of them are working.\n\"/\\[QAT\\]/|/\\[qat\\]/\"\n\"/[QAT]/|/[qat]/\"\n\"*\\[QAT\\]*|*\\[qat\\]*\"\n\"\\[\\(QAT\\|qat\\)\\]\"\n\"\\[\\(QAT\\|qat\\)]\"\n\"/\\[(qat|QAT)\\]/\"\n\nI tried following website for regular expression here which validates my requirement but it is not working inside gitlab-ci.yml file."}, {"role": "assistant", "content": "You can use\n# Deploy to QAT environment\ndeploy-qat:\n  stage: deploy\n  extends: .helm_deploy\n  environment:\n    name: qat\n  tags:\n    - exe-prd\n  rules:\n    - if: $CI_COMMIT_MESSAGE =~ /\\[(QAT|qat)]/\n      when: always\n\nSee more about how to format regex matching conditions at the rules:variables reference page.\nNOTES:\n\n/\\[(QAT|qat)]/ should not be put inside quotes\nYou need to use /.../ regex literal syntax (the backslashes are regex delimiters)\n\\[(QAT|qat)] is a regex that matches [, then either QAT or qat, and then a ] char\n=~ is a regex matching operator."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Append the script on one stage .gitlab-ci.yml\n\nHow to append the script section in one stage in the .gitlab-ci.yml file?\ne.g in this example\nstages:\n  - stage1_name\n\n.a:\n  script:\n    - echo \"String 1\"\n\n.b:\n  script:\n    - echo \"String 2\"\n\n\nstage1_name:\n  stage: stage1_name\n  extends: .a\n  extends: .b\n  script:\n    - echo \"String 3\"\n\nhow to get as output:\nString 1\nString 2\nString 3\n\ninstead of: \nString 3"}, {"role": "assistant", "content": "Gitlab 13.9 introduced a !reference-tag which makes this possible;\n.setup:\n  script:\n    - echo creating environment\n\ntest:\n  script:\n    - !reference [.setup, script]\n    - echo running my own command"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How exactly does git pull --allow-unrelated-histories work?\n\nRight, so I've searched through some other SO threads, and also checked out this: https://git-scm.com/docs/git-merge\nI understand that --allow-unrelated-histories allows two projects to join together, however, what I don't understand is how exactly it works.\nDoes it just work like this? https://i.sstatic.net/ikscx.jpg \nThe git site above shows this diagram:\n      A---B---C topic\n     /         \\\nD---E---F---G---H master\n\nHowever, to me that makes it look like they don't have unrelated histories, because the topic branch split off from 'E'. Even if the topic branch split off from master at 'D', they would still share the 'D' branch.\nWould anyone be able to explain (preferably with visuals) how exactly allow-unrelated-histories works? I am trying to git pull, but one of my team members edited the branch I am pulling from and now I have to use --allow-unrelated-histories.\nThanks!"}, {"role": "assistant", "content": "You're right that your diagram (from git-scm.com/docs/git-merge) shows a merge that has a common ancestor commit.  It's worth noting that this is a shared commit; the term branch is kind of tricky, in Git.  (See What exactly do we mean by \"branch\"?)\nAnyway, I think it helps if you forget that git pull even exists.  All git pull does is run two different Git commands for you.  You're better off, until you are well-experienced with Git, using separate git fetch and git merge commands.  (Note that git pull --rebase switches the second command to git rebase, but we won't get into details here.)  There are several issues with using git pull to run the other two commands.  One of them is that git pull uses a weird pull-only syntax, different from all other Git commands, including the git merge that git pull runs.  That is, instead of git pull origin xyz, you'll run git merge origin/xyz.  To see what that is, you'd run git log origin/xyz, or git show origin/xyz, etc.  These are always spelled origin/xyz, with the slash, except when using git pull\u2014so don't use git pull. :-)  Let's break it into the two separate commands.\n\nThe first command git pull runs is git fetch, which you can run any time you like: git fetch calls up some other Git, asks it what commits it has for you, under what names (typically branch and tag names).  It collects those commits (and their files of course), and for each of their branch names, creates or updates your remote-tracking names.  So that's where origin/master comes from, for instance: git fetch sees that they have a master, that their master is commit badf00d or whatever, and creates or updates your origin/master to remember: origin's master was badf00d the last time I checked.\nThe second command that git pull runs for you is where all the interesting action is.  This second command should not be run at any old time, on any old branch, because whichever second command you have Git run, this one has to be on the right branch: the one you want to merge into, or the one you want to rebase.  I find using the separate commands helps here, because it's clearer that git merge is going to  affect the current branch, even though you'll name something like origin/master.\n\nNow that we know --allow-unrelated-histories is really an option to git merge, let's dive into git merge, and see what it does.  First we'll look at what it does with a common starting point, then again at what it does without one.\nMerge is about combining changes since a common starting point\nConsider the diagram you quoted above, which I'll redraw just a little bit:\n     A--B--C   <-- topic\n    /\nD--E--F--G   <-- master (HEAD)\n\nThis indicates that whoever has been working on topic, they started by checking out commit E.  Probably, at that time, commit E was the last commit on master:\nD--E   <-- master, topic\n\nSince then, someone added two commits on master, which are F and G, and someone\u2014probably someone else\u2014added three commits on topic, which are now the A-B-C chain (with A's parent commit being E).\nEach commit represents a complete snapshot of all source files.  So commit E has all the files in it\u2014well, all the files it had when you, or whoever, made commit E\u2014saved in that form, forever.  Any changes you, or whoever, made to any files from that saved state and saved in, say, commit A, cause those files to be in their new state in A.  Any unchanged files in A simply exactly-match the files in E.\nFor simplicity, we'll assume there are two people acting here, \"you\" and \"they\", and you made the changes on master, eventually resulting in commit G.  They then made A through C.  So you and they both started with whatever is saved forever in commit E.  You ended up with what you have saved forever in G.  So Git can find out what you changed by a simple git diff, to compare commit E to commit G.  Likewise, they ended up at C, so Git can find out what they changed by a similar simple git diff, comparing E vs C:\n\ngit diff --find-renames hash-of-E hash-of-G: what you changed\ngit diff --find-renames hash-of-E hash-of-C: what they changed\n\nGit then checks out the files from commit E, i.e., what you both started with, combines your changes to those files, and builds a new commit with the combined changes in them.  That determines what files/contents go into commit H:\n     A--B--C   <-- topic\n    /       \\\nD--E--F--G---H   <-- master (HEAD)\n\nNew commit H's first parent is G, which was the tip of master and is the branch you have checked out.  Its second parent is C, the one you told git merge to merge.\nNote that when Git does all this change-combining, it has an easy job on all the files that are exactly the same in both branch-tips, because no matter what was the case in the merge base, the two tips match, so both files are the same and either one works fine.  It also has an easy job if you changed file X and they didn't, and where they changed file Y and you didn't, because again, it can just take your or their version of those files.  It's only where you both touched the same file, in different ways, that Git has to work hard.\nUnrelated histories\nUnrelated histories occur when there's no common connection between the two sets of commits:\nA--B--C   <-- master (HEAD)\n\nJ--K--L   <-- theirs\n\nYour commits start at C and work backwards, ending at A.  No commits come before A: A has no parents.\nTheir commits start, in this case, at L (I skipped a lot of letters to leave room to insert our merge).  L's parent is K, and K's parent is J, but J has no parents either.  So there's no common starting point at all.\nIf you tell Git to merge these, Git just pretends there is one.  The pretend starting point has no files.  Git runs:\n\ngit diff empty-tree hash-of-C: what you changed\ngit diff empty-tree hash-of-L: what they changed\n\nOf course, what you changed, from this diff, is that you added every file (that's in your commit C).  What they changed is that they added every file (that's in their commit L).\nIf the files have different names, they are different files and there is no problem: Git takes yours, or theirs.  If they have the same names, but the exact same contents, there's no conflict here either: Git can just take yours (or theirs).  The problems occur for all files where yours and theirs have the same name, but different contents.  As far as Git is concerned, you whipped yours up from scratch, and so did they, so everything conflicts.  You must pick the winning contents or construct a new file from the \"everything conflicts\" inputs.\nOnce you have resolved any of these conflicts and run git merge --continue to make Git finish, Git makes a merge commit as usual:\nA--B--C--D   <-- master (HEAD)\n        /\nJ--K---L   <-- theirs\n\nThe new commit has two parents, C and L, and saves, forever, the snapshot that you built by fixing the conflicts that Git reported, and otherwise whatever files were exactly the same in C and L or that were only in C, or only in L.\n(\"Forever\" is a bit too strong: the saved files last only as long as the commit itself.  However, the default is for each commit to live forever.  If you make the commit go away, the files do too.)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Deploy docker container from external registry to Heroku\n\nI got project repository hosted on gitlab. I am using gitlab-ci to build docker container from my project. What I would like to achieve is deploying that container to heroku.\nI was trying to follow solution from this question: How to build, test and deploy using Jhipster, Docker, Gitlab and Heroku\nHere is how my .gitlab-ci.yaml looks like:\nstages:\n - build\n - package\n - deploy\n\nbuild_npm:\n  image: node:latest\n  stage: build\n  script:\n  - npm install\n  - npm run build:prod\n  artifacts:\n    paths:\n      - dist/\n\nbuild_image:\n  image: docker:latest\n  services:\n  - docker:dind\n  stage: package\n  script:\n    - docker login -u gitlab-ci-token -p $CI_BUILD_TOKEN registry.gitlab.com\n    - docker build -t registry.gitlab.com/maciejsobala/myApp .\n    - docker push registry.gitlab.com/maciejsobala/myApp:latest\n\n\ndeploy_to_heroku:\n  stage: deploy\n  services:\n  - docker:dind\n  script:\n    - gem install dpl\n    - docker run registry.gitlab.com/maciejsobala/myApp:latest\n    - dpl --provider=heroku --app= myApp --api-key=$HEROKU_API_KEY\n\nWhat I am trying to achieve is, have 3 stages:\n\nbuild: at this moment, compile only npm project (in the future, I\nwant to add some jar here) \npackage: create and push to registry docker image. \ndeploy: install docker image on heroku.\n\nI am running into issues with the last stage (deploy). To be honest I am not really sure, what should be done here.\nI tried to use dpl, regarding to this tutorial: https://docs.gitlab.com/ce/ci/examples/test-and-deploy-ruby-application-to-heroku.html \nUnfornatelly I am running into issues when trying to run docker image\n$ docker run registry.gitlab.com/maciejsobala/myApp:latest\n/bin/bash: line 49: docker: command not found\n\nI am completely blind here. I would really appreciate any solutions, links to articles/tutorials etc."}, {"role": "assistant", "content": "You are starting the app for some reason (using docker run) you might don't need. The dpl tool is intended to be used inside a codebase, rather than for image deployment. As you said\nbuild_image:\n  image: docker:latest\n  services:\n  - docker:dind\n  stage: package\n  script:\n    - docker login -u gitlab-ci-token -p $CI_BUILD_TOKEN registry.gitlab.com\n    - docker build -t registry.gitlab.com/maciejsobala/myApp .\n    - docker push registry.gitlab.com/maciejsobala/myApp:latest\n\nis working, what means your runner is able to run docker in docker and successfully pushing images. For heroku deployment, you must only push that image to the heroku docker registry, according to the official heroku documentation. In short you do a\ndeploy_to_heroku:\n  stage: deploy\n  services:\n  - docker:dind\n  script:\n    - docker login --email=_ --username=_ --password=<YOUR-HEROKU-AUTH-TOKEN> registry.heroku.com\n    - docker tag registry.gitlab.com/maciejsobala/myApp:latest registry.heroku.com/maciejsobala/myApp:latest\n    - docker push registry.heroku.com/maciejsobala/myApp:latest\n\nwith your heroku auth token, which you can get by heroku auth:token\nAs said in the documentation, pushing to herokus registry triggers a release process of the app."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI - Trying to use docker buildx to build for ARM64\n\nTrying to use docker buildx with GitLabs shared runners to build a Docker image that can be run on my Raspberry Pi. Job fails saying git is not in PATH but git is installed in image: docker:stable-git. Any known fixes or a better way to build an ARM64-compatible image without having to build on the Raspberry Pi itself? (RPi becomes unusable while building on it due to CPU usage)\ndeploy:\n  image: docker:stable-git\n  stage: deploy\n  services:\n    - docker:dind\n  before_script:\n    - export DOCKER_BUILDKIT=1\n    - export DOCKER_CLI_EXPERIMENTAL=enabled\n    - docker build --platform=local -o . git://github.com/docker/buildx\n    - mv buildx ~/.docker/cli-plugins/docker-buildx\n  script:\n    - docker buildx build --platform linux/amd64,linux/arm64 -t $CI_REGISTRY_IMAGE .\n    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY\n    - docker push $CI_REGISTRY_IMAGE\n\n$ export DOCKER_BUILDKIT=1\n$ export DOCKER_CLI_EXPERIMENTAL=enabled\n$ docker build --platform=local -o . git://github.com/docker/buildx\n#1 [internal] load git source git://github.com/docker/buildx\n#1 ERROR: failed to init repo at /var/lib/docker/overlay2/xxx/diff: exec: \"git\": executable file not found in $PATH\n------\n > [internal] load git source git://github.com/docker/buildx:\n------\nfailed to solve with frontend dockerfile.v0: failed to resolve dockerfile: failed to build LLB: failed to load cache key: failed to init repo at /var/lib/docker/overlay2/xxx/diff: exec: \"git\": executable file not found in $PATH\nERROR: Job failed: exit code 1"}, {"role": "assistant", "content": "It looks like the issue was that the build was failing due to git not being installed in docker:dind\nWas able to work around the issue by cloning Docker/BuildX in a separate stage, running docker build on it, then exporting it to the deploy stage using artifacts.\nbuildx:\n  image: docker:19.03-git\n  stage: buildx\n  variables:\n    GIT_STRATEGY: none\n  artifacts:\n    paths:\n      - buildx\n    expire_in: 1 hour\n  services:\n    - docker:19.03-dind\n  script:\n    - export DOCKER_BUILDKIT=1\n    - git clone git://github.com/docker/buildx ./docker-buildx\n    - docker build --platform=local -o . ./docker-buildx\n\ndeploy:\n  image: docker:19.03\n  stage: deploy\n  services:\n    - name: docker:19.03-dind\n      command: [\"--experimental\"]\n  before_script:\n    - mkdir -p ~/.docker/cli-plugins\n    - mv buildx ~/.docker/cli-plugins/docker-buildx\n    - docker run --rm --privileged multiarch/qemu-user-static --reset -p yes\n  script:\n    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY\n    - docker buildx create --use --name mybuilder\n    - docker buildx build --platform linux/amd64,linux/arm64,linux/arm/v7 --push -t $CI_REGISTRY_IMAGE .\n\nI've decided to update my answer with info about using BuildX in CircleCI due to changes made by GitLab to free accounts as well as comments posted by j0nl1 and Yajo\nYou can download the BuildX binary and use it in your CircleCI job by doing the following\njobs:\n  build-and-push:\n    executor: docker/machine\n    steps:\n      - checkout\n      - run:\n          name: Remove old installation\n          command: |\n            sudo systemctl stop docker.service\n            sudo apt remove docker-ce docker-ce-cli containerd.io\n      - docker/install-docker:\n          install-dir: /usr/bin\n      - run:\n          name: Restart docker daemon with experimental features\n          command: |\n            sudo bash -c 'echo \"{\\\"experimental\\\":true}\" > /etc/docker/daemon.json'\n            if [[ $EUID == 0 ]]; then export SUDO=\"\"; else export SUDO=\"sudo\"; fi\n            $SUDO systemctl unmask docker.service\n            $SUDO systemctl unmask docker.socket\n            $SUDO systemctl start docker.service\n      - run:\n          name: Install buildx\n          command: |\n            BUILDX_VERSION=\"v0.4.1\"\n\n            curl -sSLo docker-buildx \"https://github.com/docker/buildx/releases/download/$BUILDX_VERSION/buildx-$BUILDX_VERSION.linux-amd64\"\n            chmod a+x docker-buildx\n            mkdir -p ~/.docker/cli-plugins\n            mv docker-buildx ~/.docker/cli-plugins/docker-buildx\n\n            docker version\n            docker buildx install\n      - docker/check:\n          registry: $DOCKER_REGISTRY\n      - run:\n          name: Create buildx profile\n          command: |\n            docker run --rm --privileged multiarch/qemu-user-static --reset -p yes\n            docker buildx create --use --name mybuilder\n      - docker/build:\n          registry: $DOCKER_REGISTRY\n          image: username/repo\n          tag: latest\n          extra_build_args: --platform linux/amd64,linux/arm64,linux/arm/v7 --push"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI SAST access to gl-sast-report.json artifact in subsequent stage\n\nI am wanting to use the gl-sast-report.json file created during the SAST process in a subsequent stage of my CI but it is not found.\nci.yml\ninclude:\n  - template: Security/SAST.gitlab-ci.yml\n\nstages:\n  - test\n  - .post\nsast:\n  rules:\n    - if: $CI_COMMIT_TAG\n\nsend-reports:\n  stage: .post\n  dependencies: \n    - sast\n  script: \n    - ls\n    - echo \"in post stage\"\n    - cat gl-sast-report.json\n\noutput:\nRunning with gitlab-runner 13.2.1 (efa30e33)\non blah blah blah\nPreparing the \"docker\" executor\n00:01\n.\n.\n.\n\nPreparing environment\n00:01\nRunning on runner-zqk9bcef-project-4296-concurrent-0 via ff93ba7b6ee2...\nGetting source from Git repository\n00:01\nFetching changes with git depth set to 50...\nReinitialized existing Git repository in blah blah\nChecking out 9c2edf67 as 39-test-dso...\nRemoving gl-sast-report.json\nSkipping Git submodules setup\nExecuting \"step_script\" stage of the job script\n00:03\n$ ls\n<stuff in the repo>\n$ echo \"in .post stage\"\nin post stage\n$ cat gl-sast-report.json\ncat: can't open 'gl-sast-report.json': No such file or directory\nERROR: Job failed: exit code 1\n\nYou can see the line Removing gl-sast-report.json which I assume is the issue.\nI don't see that anywhere in the SAST.gitlab-ci.yml at https://gitlab.com/gitlab-org/gitlab/-/blob/v11.11.0-rc2-ee/lib/gitlab/ci/templates/Security/SAST.gitlab-ci.yml#L33-45\nAny ideas on how to use this artifact in the next stage of my CI pipeline?\nUPDATE:\nSo I tried out k33g_org's suggestion below but to no avail. Seems that this is due to limitations in the sast template specifically. Did the following test.\ninclude:\n  - template: Security/SAST.gitlab-ci.yml\n\nstages:\n  - test\n  - upload\n\nsomething:\n  stage: test\n  script:\n      - echo \"in something\"\n      - echo \"this is something\" > something.txt\n  artifacts:\n      paths: [something.txt]\n\nsast:\n  before_script:\n      - echo \"hello from before sast\"\n      - echo \"this is in the file\" > test.txt\n  artifacts:\n    reports:\n      sast: gl-sast-report.json\n    paths: [gl-sast-report.json, test.txt]\n\nsend-reports:\n  stage: upload\n  dependencies:\n    - sast\n    - something\n  before_script:\n      - echo \"This is the send-reports before_script\"\n  script:\n    - echo \"in send-reports job\"\n    - ls\n  artifacts:\n      reports:\n          sast: gl-sast-report.json\n\nThree changes:\n\nUpdated code with k33g_org's suggestion\nCreated another artifact in the sast job (to see if it would pass through to send-reports job)\nCreated a new job (something) where I created a new something.txt artifact (to see if it would pass through to send-reports job)\n\nOutput:\nPreparing environment\n00:01\nRunning on runner-zqx7qoq-project-4296-concurrent-0 via e3fe672984b4...\nGetting source from Git repository\nFetching changes with git depth set to 50...\nReinitialized existing Git repository in /<repo>\nChecking out 26501c44 as <branch_name>...\nRemoving something.txt\nSkipping Git submodules setup\nDownloading artifacts\n00:00\nDownloading artifacts for something (64950)...\nDownloading artifacts from coordinator... ok        id=64950 \nresponseStatus=200 OK token=zoJwysdq\nExecuting \"step_script\" stage of the job script\n00:01\n$ echo \"This is the send-reports before_script\"\nThis is the send-reports before_script\n$ echo \"in send-reports job\"\nin send-reports job\n$ ls\n...<other stuff in repo>\nsomething.txt\nUploading artifacts for successful job\n00:01\nUploading artifacts...\nWARNING: gl-sast-report.json: no matching files    \nERROR: No files to upload                          \nCleaning up file based variables\n00:01\nJob succeeded\n\nNotes:\n\nsomething.txt made it to this job\nall artifacts from the sast job to not make it to subsequent jobs\n\nI can only conclude that there is something internal to the sast template that is not allowing artifacts to propagate to subsequent jobs."}, {"role": "assistant", "content": "I spent a full day banging my head against this, trying to access the gl-sast-report.json file generated by the built-in IaC scanner. Here's what ultimately worked for me:\nFirst and foremost, DO NOT use this code suggested by GitLab's documentation:\ninclude:\n  - template: Security/SAST-IaC.latest.gitlab-ci.yml\n\nThe above code works fine if all you want to do is scan for IaC vulnerabilities and download the report from the GitLab UI later. But who wants to do that?! I want to access the report in my next job and fail the pipeline if there are medium+ vulnerabilities in the report!\nIf that's what you want to do, you'll need to add all of the code from the official GitLab IaC scanner template to your pipeline, and then make some modifications. You can find the latest template code here, or use my example below.\nModified template:\n# Read more about this feature here: https://docs.gitlab.com/ee/user/application_security/iac_scanning/\n#\n# Configure SAST with CI/CD variables (https://docs.gitlab.com/ee/ci/variables/index.html).\n# List of available variables: https://docs.gitlab.com/ee/user/application_security/iac_scanning/index.html\n\nvariables:\n  # Setting this variable will affect all Security templates\n  # (SAST, Dependency Scanning, ...)\n  TEMPLATE_REGISTRY_HOST: 'registry.gitlab.com'\n  SECURE_ANALYZERS_PREFIX: \"$TEMPLATE_REGISTRY_HOST/security-products\"\n  SAST_IMAGE_SUFFIX: \"\"\n\n  SAST_EXCLUDED_PATHS: \"spec, test, tests, tmp\"\n\niac-sast:\n  stage: test\n  artifacts:\n    name: sast\n    paths:\n      - gl-sast-report.json\n    #reports:\n    #  sast: gl-sast-report.json\n    when: always\n  rules:\n    - when: never\n  # `rules` must be overridden explicitly by each child job\n  # see https://gitlab.com/gitlab-org/gitlab/-/issues/218444\n  variables:\n    SEARCH_MAX_DEPTH: 4\n  allow_failure: true\n  script:\n    - /analyzer run\n\nkics-iac-sast:\n  extends: iac-sast\n  image:\n    name: \"$SAST_ANALYZER_IMAGE\"\n  variables:\n    SAST_ANALYZER_IMAGE_TAG: 3\n    SAST_ANALYZER_IMAGE: \"$SECURE_ANALYZERS_PREFIX/kics:$SAST_ANALYZER_IMAGE_TAG$SAST_IMAGE_SUFFIX\"\n  rules:\n    - if: $SAST_DISABLED\n      when: never\n    - if: $SAST_EXCLUDED_ANALYZERS =~ /kics/\n      when: never\n    - if: $CI_COMMIT_BRANCH\n  \n\nEnforce Compliance:\n  stage: Compliance\n  before_script:\n    - apk add jq\n  script:\n    - jq -r '.vulnerabilities[] | select(.severity == \"Critical\") | (.severity, .message, .location, .identifiers[].url)' gl-sast-report.json > results.txt\n    - jq -r '.vulnerabilities[] | select(.severity == \"High\") | (.severity, .message, .location, .identifiers[].url)' gl-sast-report.json >> results.txt\n    - jq -r '.vulnerabilities[] | select(.severity == \"Medium\") | (.severity, .message, .location, .identifiers[].url)' gl-sast-report.json >> results.txt\n    - chmod u+x check-sast-results.sh\n    - ./check-sast-results.sh\n\nYou'll also need to make sure to add two stages to your pipeline (if you don't have them already):\nstages:\n  # add these to whatever other stages you already have\n  - test\n  - Compliance\n\nNote: it's extremely important that your job which is trying to access gl-sast-report.json (\"Compliance\" in this case) is not in the same stage as the sast scans themselves (\"test\" in this case). If they are, then your job will try to access the report before it exists and fail.\nI'll include my shell script referenced in the pipeline in case you want to use that too:\n#!/bin/sh\n\nif [ -s results.txt ]; then\n        echo \"\"\n        echo \"\"\n        cat results.txt\n        echo \"\"\n        echo \"ERROR: SAST SCAN FOUND VULNERABILITIES - FIX ALL VULNERABILITIES TO CONTINUE\"\n        echo \"\"\n        exit 1\nfi\n\nThis is a basic script that checks to see if the \"results.txt\" file has any contents. If it does, it exits with code 1 to break the pipeline and print the vulnerabilities. If there are no contents in the file, the script exits with code 0 and the pipeline continues (allowing you to deploy your infra). Save the file above as \"check-sast-results.sh\" in the root directory of your GitLab repository (the same level where \".gitlab-ci.yml\" resides).\nHope this helps someone out there."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to increase maximum artifacts size for Gitlab on-premises\n\nWe've installed Gitlab on-premises, however someone else did the installation so I don't know as much about configuring the runners, etc.  A pipeline failed due to the following error:\nUploading artifacts...\napp/build/outputs/apk/debug/app-debug.apk: found 1 matching files\napp/build/outputs/apk/androidTest/debug/app-debug-androidTest.apk: found 1 matching files\nERROR: Uploading artifacts to coordinator... too large archive id=13832 responseStatus=413 Request Entity Too Large status=413 Request Entity Too Large token=fCysmH9H\nFATAL: Too large\nERROR: Job failed: exit code 1\n\nWhere/how do I configure the allowable artifact size?"}, {"role": "assistant", "content": "I was able to solve my problem after finding https://gitlab.com/gitlab-org/gitlab-runner/issues/2584.  It suggests increasing maximum artifacts size on the on-prem instance of Gitlab.  Here are the steps that worked for me:\n\nClick Admin Area (top of Gitlab on-prem screen)\nClick Settings\n\nThe direct link, assuming the on-prem instance is hosted at gitlab.MYCOMPANY.com is: https://gitlab.MYCOMPANY.com/admin/application_settings/ci_cd\n\nExpand \"Continuous Integration and Deployment\"\nSet the \"Maximum artifacts size (MB)\"\n\nThis assumes your login credentials allow you to see the Admin Area."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI multiple branches\n\nI have two branches: master and test. When I push to the master branch, my code is deployed to the first server by gitlab-ci. I want to deploy to a different server whenever I push to the test branch. Is this possible using Gitlab CI?\n\nmaster - 10.10.10.1\ntest - 10.10.10.2\n\nMy gitlab-ci.yml:\nmaven_build:\nscript: \n    - mvn install\n    - /opt/payara41/bin/./asadmin --passwordfile /home/asadminpass --user admin undeploy myApplication-ear-1.0-SNAPSHOT\n    - sudo /etc/init.d/glassfish restart\n    - /opt/payara41/bin/./asadmin --passwordfile /home/asadminpass --host localhost --user admin deploy --force /home/gitlab-runner/builds/10b25461/0/myapp/myAppPrototype/myApp-ear/target/myApplication-SNAPSHOT.ear\n\nonly:\n    - master"}, {"role": "assistant", "content": "You're on the right track with only:.\nSimply create two different steps, one with only: master and one with only: test.\nChange the script: to deploy to a different server.\ndeploy_master:\n  script: \n    - <script to deploy to master server>\n  only:\n    - master\n\ndeploy_test:\n  script: \n    - <script to deploy to test server>\n  only:\n    - test"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Changing GitLab CI Multirunner executor after initial configuration\n\nI am reading through GitLab CI Multirunner documentation where it walks one through how to set up a GitLab CI Multirunner executor, but I can't seem to find anything about changing the executor once initially set, either in the docs or searching online. Is this supported?"}, {"role": "assistant", "content": "The configuration is written to /etc/gitlab-runner/config.toml which you can edit with your favourite editor, after which you need to reload or restart the runner service.\nHere's documentation for the GitLab Runner config.toml file."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI enable SCP\n\nI'm using one of the shared runners on GitLab.com currently. Is it possible to set up the .gitlab-ci.yaml file such that a build can SCP files from a remote server onto the runner? My goal is to SCP files that are necessary dependencies for my build, but they are not tracked in any Git repositories.\nI've marked the line where I would like to be able to perform the transfer, but I don't know how to express it properly. \nNote: CodeA has dependencies in CodeB and CodeC, which must be built before CodeA can compile, so I need to have access to CodeB and CodeC to build them first on the ubuntu image.\nimage: ubuntu:12.04\n\nbefore_script:\n\nbuild_CodeC:\n  stage: build\n  allow_failure: true\n  script:\n-->- scp user@remoteServer:/home/user/file.tar . <---\n   - sh ./continuous_integration/build_CodeC_dependency.sh\n\nbuild_CodeB:\n  stage: build\n  script:\n    - sh ./continuous_integration/build_CodeB_dependency.sh\n\nbuild_CodeA:\n  stage: build\n  script:\n    - sh ./continuous_integration/build_CodeA.sh"}, {"role": "assistant", "content": "From your question here, I think that getting your dependencies through http is not possible, so here's what you need to do in order to use scp:\n\nGenerate a key pair\nCopy the private key to a gitlab CI variable (let's call it SSH_PRIVATE_KEY)\nCopy the public key to the server gitlab will connect to and add it to your ~/.ssh/authorized_keys file\nTell your CI pipeline to use the private key that is stored in the Gitlab CI variable\n\nIn order to do that last step, just add the following to your .gitlab-ci.yml in the script or before_script section of the job of interest: \n- 'which ssh-agent || ( apt-get update -y && apt-get install openssh-client -y )'\n# Run ssh-agent (inside the build environment)\n- eval $(ssh-agent -s)\n# Add the SSH key stored in SSH_PRIVATE_KEY variable to the agent store\n- ssh-add <(echo \"$SSH_PRIVATE_KEY\")\n- mkdir -p ~/.ssh\n- '[[ -f /.dockerenv ]] && echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" > ~/.ssh/config'\n\nYou may also want to specify that CodeA is dependent on B and C. In order for that to work, build_CodeB and build_CodeC need to be in a different stage than build_CodeA.\nBesides that, you need a way to carry the built files from build_CodeB and build_CodeC jobs to the build_CodeA job. One way to do that is to use artifacts.\nIn the end, your .gitlab-ci.yml file should look something like this:\nimage: ubuntu:12.04\n\nstages:\n  - deps\n  - build\n\nbuild_CodeC:\n  stage: deps\n  allow_failure: true\n  script:\n    - 'which ssh-agent || ( apt-get update -y && apt-get install openssh-client -y )'\n    # Run ssh-agent (inside the build environment)\n    - eval $(ssh-agent -s)\n    # Add the SSH key stored in SSH_PRIVATE_KEY variable to the agent store\n    - ssh-add <(echo \"$SSH_PRIVATE_KEY\")\n    - mkdir -p ~/.ssh\n    - '[[ -f /.dockerenv ]] && echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" > ~/.ssh/config'\n    - scp user@remoteServer:/home/user/file.tar .\n    - sh ./continuous_integration/build_CodeC_dependency.sh\n  artifacts:\n    paths:\n      - path_to_built_codeC\n\nbuild_CodeB:\n  stage: deps\n  script:\n    - sh ./continuous_integration/build_CodeB_dependency.sh\n  artifacts:\n    paths:\n      - path_to_built_codeB\n\nbuild_CodeA:\n  stage: build\n  dependencies:\n    - build_CodeB\n    - build_CodeC\n  script:\n    - sh ./continuous_integration/build_CodeA.sh\n\nI only put the SSH key setup part in build_CodeC because that's where you are using scp. You would need to copy this over to any job that would require to use scp. I'm thinking you may need to do this in build_codeB since your tar file will not be carried to the build_CodeB job."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Running Gitlab Docker\n\nI'm following these instructions:\nhttp://doc.gitlab.com/omnibus/docker\nHowever http://localhost is says Webpage is not available.  \nHere are the commands that I'm running (Ubuntu 14.04 LTS):\n    ole@MKI:~$ docker version\n    Client:\n     Version:      1.9.1\n     API version:  1.21\n     Go version:   go1.4.3\n     Git commit:   a34a1d5\n     Built:        Fri Nov 20 17:56:04 UTC 2015\n     OS/Arch:      linux/amd64\n\n    Server:\n     Version:      1.9.1\n     API version:  1.21\n     Go version:   go1.4.3\n     Git commit:   a34a1d5\n     Built:        Fri Nov 20 17:56:04 UTC 2015\n     OS/Arch:      linux/amd64\n\n    ole@MKI:~$ sudo docker run --detach \\\n    >     --hostname gitlab.example.com \\\n    >     --publish 443:443 --publish 80:80 --publish 22:22 \\\n    >     --name gitlab \\\n    >     --restart always \\\n    >     --volume /srv/gitlab/config:/etc/gitlab \\\n    >     --volume /srv/gitlab/logs:/var/log/gitlab \\\n    >     --volume /srv/gitlab/data:/var/opt/gitlab \\\n    >     gitlab/gitlab-ce:latest\n    613d4d2d612f977d3d25746a169d9209acb864e57c5184083dccd02b1e4a157c\n\n    ole@MKI:~$ docker ps\n    CONTAINER ID        IMAGE                     COMMAND             CREATED             STATUS              PORTS                                                          NAMES\n    613d4d2d612f        gitlab/gitlab-ce:latest   \"/assets/wrapper\"   4 seconds ago       Up 2 seconds        0.0.0.0:22->22/tcp, 0.0.0.0:80->80/tcp, 0.0.0.0:443->443/tcp   gitlab\n\nIf I rerun docker ps I get this:\n    CONTAINER ID        IMAGE                     COMMAND             CREATED             STATUS                              PORTS                                                          NAMES\n    613d4d2d612f        gitlab/gitlab-ce:latest   \"/assets/wrapper\"   9 minutes ago       Restarting (1) About a minute ago   0.0.0.0:22->22/tcp, 0.0.0.0:80->80/tcp, 0.0.0.0:443->443/tcp   gitlab\n\nIt says Restarting about a minute ago... ... does that mean there is something wrong internally?\n[EDIT - ADDING LOGS]\n  ole@MKI:~$ sudo mkdir -p /var/log/gitlab/reconfigure\n\n  ole@MKI:~$ sudo docker run --detach \\\n  >     --hostname gitlab.example.com \\\n  >     --publish 443:443 --publish 80:80 --publish 22:22 \\\n  >     --name gitlab \\\n  >     --restart always \\\n  >     --volume /srv/gitlab/config:/etc/gitlab \\\n  >     --volume /srv/gitlab/logs:/var/log/gitlab \\\n  >     --volume /srv/gitlab/data:/var/opt/gitlab \\\n  >     gitlab/gitlab-ce:latest\n  f4dee0a603bdc95594e8a77d51762f2d78d44ec077f2d57645e651ed628a4d6b\n\n  ole@MKI:~$ docker logs\n  docker: \"logs\" requires 1 argument.\n  See 'docker logs --help'.\n\n  Usage:    docker logs [OPTIONS] CONTAINER\n\n  Fetch the logs of a container\n\n  ole@MKI:~$ docker logs gitlab\n  Thank you for using GitLab Docker Image!\n  Current version: gitlab-ce=8.5.0-ce.1\n\n  Configure GitLab for your system by editing /etc/gitlab/gitlab.rb file\n  And restart this container to reload settings.\n  To do it use docker exec:\n\n    docker exec -it gitlab vim /etc/gitlab/gitlab.rb\n    docker restart gitlab\n\n  For a comprehensive list of configuration options please see the Omnibus GitLab readme\n  https://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/README.md\n\n  If this container fails to start due to permission problems try to fix it by executing:\n\n    docker exec -it gitlab update-permissions\n    docker restart gitlab\n\n  Preparing services...\n  Starting services...\n  Configuring GitLab...\n  /opt/gitlab/embedded/bin/runsvdir-start: line 34: ulimit: max user processes: cannot modify limit: Operation not permitted\n  /opt/gitlab/embedded/bin/runsvdir-start: line 37: /proc/sys/fs/file-max: Read-only file system\n  [2016-02-23T01:16:47+00:00] FATAL: Failed to open or create log file at /var/log/gitlab/reconfigure/1456190207.log: Errno::ENOENT (No such file or directory @ rb_sysopen - /var/log/gitlab/reconfigure/1456190207.log)\n  [2016-02-23T01:16:47+00:00] FATAL: Aborting due to invalid 'log_location' configuration\n  Thank you for using GitLab Docker Image!\n  Current version: gitlab-ce=8.5.0-ce.1\n\n  Configure GitLab for your system by editing /etc/gitlab/gitlab.rb file\n  And restart this container to reload settings.\n  To do it use docker exec:\n\n    docker exec -it gitlab vim /etc/gitlab/gitlab.rb\n    docker restart gitlab\n\n  For a comprehensive list of configuration options please see the Omnibus GitLab readme\n  https://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/README.md\n\n  If this container fails to start due to permission problems try to fix it by executing:\n\n    docker exec -it gitlab update-permissions\n    docker restart gitlab\n\n  Preparing services...\n  Starting services...\n  Configuring GitLab...\n  /opt/gitlab/embedded/bin/runsvdir-start: line 34: ulimit: max user processes: cannot modify limit: Operation not permitted\n  /opt/gitlab/embedded/bin/runsvdir-start: line 37: /proc/sys/fs/file-max: Read-only file system\n  [2016-02-23T01:16:51+00:00] FATAL: Failed to open or create log file at /var/log/gitlab/reconfigure/1456190211.log: Errno::ENOENT (No such file or directory @ rb_sysopen - /var/log/gitlab/reconfigure/1456190211.log)\n  [2016-02-23T01:16:51+00:00] FATAL: Aborting due to invalid 'log_location' configuration\n  Thank you for using GitLab Docker Image!\n  Current version: gitlab-ce=8.5.0-ce.1\n\n  Configure GitLab for your system by editing /etc/gitlab/gitlab.rb file\n  And restart this container to reload settings.\n  To do it use docker exec:\n\n    docker exec -it gitlab vim /etc/gitlab/gitlab.rb\n    docker restart gitlab\n\n  For a comprehensive list of configuration options please see the Omnibus GitLab readme\n  https://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/README.md\n\n  If this container fails to start due to permission problems try to fix it by executing:\n\n    docker exec -it gitlab update-permissions\n    docker restart gitlab\n\n  Preparing services...\n  Starting services...\n  Configuring GitLab...\n  /opt/gitlab/embedded/bin/runsvdir-start: line 34: ulimit: max user processes: cannot modify limit: Operation not permitted\n  /opt/gitlab/embedded/bin/runsvdir-start: line 37: /proc/sys/fs/file-max: Read-only file system\n  [2016-02-23T01:16:56+00:00] FATAL: Failed to open or create log file at /var/log/gitlab/reconfigure/1456190216.log: Errno::ENOENT (No such file or directory @ rb_sysopen - /var/log/gitlab/reconfigure/1456190216.log)\n  [2016-02-23T01:16:56+00:00] FATAL: Aborting due to invalid 'log_location' configuration\n  Thank you for using GitLab Docker Image!\n  Current version: gitlab-ce=8.5.0-ce.1\n\n  Configure GitLab for your system by editing /etc/gitlab/gitlab.rb file\n  And restart this container to reload settings.\n  To do it use docker exec:\n\n    docker exec -it gitlab vim /etc/gitlab/gitlab.rb\n    docker restart gitlab\n\n  For a comprehensive list of configuration options please see the Omnibus GitLab readme\n  https://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/README.md\n\n  If this container fails to start due to permission problems try to fix it by executing:\n\n    docker exec -it gitlab update-permissions\n    docker restart gitlab\n\n  Preparing services...\n  Starting services...\n  Configuring GitLab...\n  /opt/gitlab/embedded/bin/runsvdir-start: line 34: ulimit: max user processes: cannot modify limit: Operation not permitted\n  /opt/gitlab/embedded/bin/runsvdir-start: line 37: /proc/sys/fs/file-max: Read-only file system\n  [2016-02-23T01:17:02+00:00] FATAL: Failed to open or create log file at /var/log/gitlab/reconfigure/1456190222.log: Errno::ENOENT (No such file or directory @ rb_sysopen - /var/log/gitlab/reconfigure/1456190222.log)\n  [2016-02-23T01:17:02+00:00] FATAL: Aborting due to invalid 'log_location' configuration\n  Thank you for using GitLab Docker Image!\n  Current version: gitlab-ce=8.5.0-ce.1\n\n  Configure GitLab for your system by editing /etc/gitlab/gitlab.rb file\n  And restart this container to reload settings.\n  To do it use docker exec:\n\n    docker exec -it gitlab vim /etc/gitlab/gitlab.rb\n    docker restart gitlab\n\n  For a comprehensive list of configuration options please see the Omnibus GitLab readme\n  https://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/README.md\n\n  If this container fails to start due to permission problems try to fix it by executing:\n\n    docker exec -it gitlab update-permissions\n    docker restart gitlab\n\n\n  ole@MKI:~$ docker ps\n  CONTAINER ID        IMAGE                     COMMAND             CREATED             STATUS                         PORTS                                                          NAMES\n  f4dee0a603bd        gitlab/gitlab-ce:latest   \"/assets/wrapper\"   39 seconds ago      Restarting (1) 4 seconds ago   0.0.0.0:22->22/tcp, 0.0.0.0:80->80/tcp, 0.0.0.0:443->443/tcp   gitlab\n\nIt still does not boot, even after creating /var/log/gitlab/reconfigure manually."}, {"role": "assistant", "content": "Modifying the docker command to the following resolved the issue for me:\nsudo docker run -i \\\n    --hostname ubuntu \\\n    --publish 443:443 --publish 80:80 --publish 2222:22 \\\n    --name gitlab \\\n    --restart always \\\n    --volume /srv/gitlab/config:/etc/gitlab \\\n    --volume /srv/gitlab/logs:/var/log/gitlab \\\n    --volume /srv/gitlab/data:/var/opt/gitlab \\\n    --volume /srv/gitlab/logs/reconfigure:/var/log/gitlab/reconfigure \\\n    gitlab/gitlab-ce:latest\n\nNote I used -i so I could watch it start up, but you can set it back to --detach."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to mirror a GitLab repository to GitHub using SSH keys?\n\nGitLab has a mirror feature:\nhttps://docs.gitlab.com/ee/user/project/repository/mirror/\nand GitHub does not support simple password authentication. I tried to follow\nhttps://meesvandongen.nl/posts/mirror-gitlab-github\nUsing the target url\nssh://[email\u00a0protected]:stefaneidelloth/mirror_demo.git\n\nand SSH public key as authentication method.\nHowever, I get an error\nRemote mirrors url is blocked: URI is invalid \n\nfrom GitLab.\nIf I specify the target url\nhttps://github.com/stefaneidelloth/mirror_demo.git\n\nI am not able to select SSH public key as authentication method.\n=> What are the right settings to mirror a GitLab project to a GitHub project (without PREMIUM edition of GitLab)?\nEdit\nThe second : needs to be replaced with a /.\nSuggested by GitHub:\n\nAdding ssh:// prefix is not enough.\nWrong: ssh://[email\u00a0protected]:stefaneidelloth/mirror_demo.git\nStill need to replace : after github.com:\nRight: ssh://[email\u00a0protected]/stefaneidelloth/mirror_demo.git\nThen GitLab generates the SSH key for the connection and one needs to copy it to the GitHub project settings (not the user settings), see https://meesvandongen.nl/posts/mirror-gitlab-github\nNow I get the next error:\n13:get remote references: create git ls-remote: exit status 128, stderr: \"ssh connect to host github.com port 22: Connection timed out\\r\\nfatal: Could not read from remote repository.\\n\\nPlease make sure you have the correct access rights\\nand the repository exists.\\n\".\n\na) Do I need to specify a different port than 22? How? I tried\nssh://[email\u00a0protected]:443/stefaneidelloth/mirror_demo.git\n\nbut that did not help.\nb) Do I need to use \"Input host keys manually\"? What should be specified? I tried to use\nSHA256:uNiVztksCsDhcc0u9e8BujQXVUpKZIDTMczCvj3tD2s\nfrom\nhttps://docs.github.com/en/authentication/keeping-your-account-and-data-secure/githubs-ssh-key-fingerprints\nbut that did not help.\nc) I also tried to generate a GitHub AccessToken in the user settings and apply it for the password option of the GitLab Mirror settings. I tried both, https:// and git:// urls. No success."}, {"role": "assistant", "content": "I got this to work after all.\n\nYes, you need to manually edit the git SSH URL, as you have shown:\nssh://[email\u00a0protected]/stefaneidelloth/mirror_demo.git\nSelect SSH public key as authentication method.\nThen click mirror repository button\nCopy the SSH key generated as shown here: https://meesvandongen.nl/posts/mirror-gitlab-github and https://docs.gitlab.com/ee/user/project/repository/mirror/push.html#set-up-a-push-mirror-from-gitlab-to-github\nThe key then needs to be added as a Deploy Key to the GitHub Repo, which is done from Settings > Deploy Keys (see figure below)\nClick refresh on the mirror. Note that when I first did this, nothing happened, no errors, but also no update. I did it four times and still nothing happened. Then about 27 minutes later, the update happened."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Difference between different GitLab CI Merge Request rules\n\nAs several other users, I'm facing issues with duplicate pipelines in GitLab CI/CD. While there is some documentation on how to prevent this scattered around in the GitLab docs,\nmy impression is that the indivdual docs pages and sections are rather inconsistent.\nMy question is, what are the differences between the following rules? Or, more specifically, are there cases in which these rules are evaluated differently?\n\nSwitch between branch pipelines and merge request pipelines suggest this to identify merge request pipelines:\nif: '$CI_PIPELINE_SOURCE == \"merge_request_event\"'\n\n\nAdditionally, Switch between branch pipelines and merge request pipelines also uses this rule in combination with $CI_COMMIT_BRANCH &&:\nif: '$CI_OPEN_MERGE_REQUESTS'\n\n\nMoreover, the MergeRequest-Pipelines.gitlab-ci.yml uses a third rule:\nif: $CI_MERGE_REQUEST_IID\n\n\n\nAny explanation or hints to docs pages I might have overlooked is highly appreciated."}, {"role": "assistant", "content": "In order to avoid duplicate pipeline creation and the requirement that you want to switch between Branch-Pipelines and Merge-Request-Pipelines I recommend using these workflow rules\nworkflow:\n  rules:\n    - if: '$CI_PIPELINE_SOURCE == \"merge_request_event\"'\n    - if: '$CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS'\n      when: never\n    - if: '$CI_COMMIT_BRANCH' || '$CI_COMMIT_TAG'\n\nThere is another SO-question that asks how to prevent duplicate pipelines here\nThe Explanation(s):\nIn the following section I will try to explain your different rules and how GitLab CI will evaluate them during pipeline creation.\nThe merge_request_event-rule\nUsing this rule:\nif: '$CI_PIPELINE_SOURCE == \"merge_request_event\"'\n\nwill create a pipeline each time a Merge-Request is created/updated, but there will also be a pipeline created for the branch if you do not have another prevention mechanism (rule).\nAs the variable naming also points out, this is about the source of the pipeline trigger, other sources could be schedule, push, trigger etc.\nThe CI_OPEN_MERGE_REQUESTS variable:\nUsing a rule like:\nif: '$CI_OPEN_MERGE_REQUESTS'\n\nGitLab will create new pipelines if there is an open Merge-Request for this branch. Pipelines because there will be a Merge-Request pipeline (denoted with the detached flag) and a branch pipeline for the branch you pushed changes.\nif: '$CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS'\n\nThis rule above will create a pipeline for your branch when, and only when there is an open MR on that branch.\nif: '$CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS'\nwhen: never\n\nWhen using the above combination no pipeline will be created if there are open Merge-Requests on that branch, which might also be undesirable since the CI should run tests for branches and/or Merge-Requests.\nBut how to be able to have pipelines for MRs and Branches, but prevent duplications in pipeline creation?\n- if: '$CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS'\n  when: never\n- if: '$CI_COMMIT_BRANCH' || '$CI_COMMIT_TAG'\n\nWith this rule set above GitLab will create pipelines for branches and Merge-Requests (the detached ones), as well as pipelines for git-tags, but it will prevent GitLab from duplicating pipelines.\nThe last rule evaluates to true either when there is a commit to a branch or there is a git-tag.\nFurther links\n\nOfficial docs on switching between MR- and Branch-Pipelines\nDocs on how to avoid duplicate pipelines with rules examples"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to download single raw file from private gitlab repo using username and password\n\nI can clone a private repo with username & password using command below\ngit clone https://some-git-lab-token:[email\u00a0protected]/foo/bar.git\n\nI'm wondering if it's possible to curl or wget a single raw file from the same repo using the same credential some-git-lab-token:someHash\nA sample gitlab raw file url as below\nhttps://gitlab.com/athos.oc/lodash-has-plugin/-/raw/master/.eslintrc.json\n\nI've tried to curl a single file as below but failed\ncurl https://some-git-lab-token:[email\u00a0protected]/foo/bar/-/raw/master/testing.js\n\nThe result that I got is as below\n<html><body>You are being <a href=\"https://git.xxx.com/users/sign_in\">redirected</a>.</body></html>"}, {"role": "assistant", "content": "To download a repository file through curl, you need to use the repository files API endpoint.\nUsing your example https://gitlab.com/athos.oc/lodash-has-plugin/-/raw/master/.eslintrc.json, would turn into:\nhttps://gitlab.com/api/v4/projects/30349314/repository/files/%2Eeslintrc%2Ejson/raw?ref=master\nHowever, API authentication does not include username and password as an available authentication method, so you would need to use a token (or a session cookie)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Variable inside variable gitlab ci\n\nIs there a way to use predefined variable inside custom variable in gitlab ci like this:\nbefore_script:\n  - cat \"${$CI_COMMIT_REF_NAME}\" >> .env\n\nto extract the name of branch from $CI_COMMIT_REF_NAME and use it as a name of custom variable\nUpdate:"}, {"role": "assistant", "content": "Check out GitLab 14.3 (September 2021)\n\nUse variables in other variables\nCI/CD pipeline execution scenarios can depend on expanding variables declared in a pipeline or using GitLab predefined variables within another variable declaration.\nIn 14.3, we are enabling the \u201cvariables inside other variables\u201d feature on GitLab SaaS.\nNow you can define a variable and use it in another variable definition within the same pipeline.\nYou can also use GitLab predefined variables inside of another variable declaration.\nThis feature simplifies your pipeline definition and eliminates pipeline management issues caused by the duplicating of variable data.\nNote - for GitLab self-managed users the feature is disabled by default.\nTo use this feature, your GitLab administrator will need to enable the feature flag.\n(demo -- video)\n\nSee [Documentation]https://gitlab.com/gitlab-org/gitlab/-/blob/ee8cb300efb6f917eab6d865c9d430eb62077b44/doc/ci/variables/index.md#use-variables-in-other-variables) and Issue.\n\nQ4 2023: the documentation now refers to Use CI/CD variables in other variables\n\nUse CI/CD variables in other variables\nYou can use variables inside other variables:\njob:\n variables:\n   FLAGS: '-al'\n   LS_CMD: 'ls \"$FLAGS\"'\n script:\n   - 'eval \"$LS_CMD\"'  # Executes 'ls -al'\n\nUse the $ character in CI/CD variables.\nIf you do not want the $ character interpreted as the start of another variable, use $$ instead:\njob:\n variables:\n   FLAGS: '-al'\n   LS_CMD: 'ls \"$FLAGS\" $$TMP_DIR'\n script:\n   - 'eval \"$LS_CMD\"'  # Executes 'ls -al $TMP_DIR'\n\nPrevent CI/CD variable expansion\nIntroduced in GitLab 15.7.\nExpanded variables treat values with the $ character as a reference to another variable.\nCI/CD variables are expanded by default. To treat variables with a $ character as raw strings, disable variable expansion for the variable\n\n\ndba asks in the comments:\n\nDoes this include or exclude using globally defined variables?\n\ndba's own answer:\n\nGlobal variables can be reused, but they need the local_var: ${global_var} syntax with recursive expansion (independent of the shell)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Unable to push nuGet packages to GitLab with dotnet CLI due to Unauthorized error\n\nGitLab now supports nuget public and private feed repository.\nI've got a public project (e.g: https://gitlab.com/sunnyatticsoftware/sasw-test-support)\nI create an access token for my user with api and write_repository (e.g: AAABBBCCCDDD)\nI create a group variable in my CI/CD: SASW_API_ACCESS_TOKEN: AAABBBCCCDDD. All normal.\nThen I create the multi stage CI/CD script to build, pack and publish.\nWhen attempting to publish the nuGet package with the following:\ndotnet nuget push **/*.nupkg --source https://gitlab.com/api/v4/projects/17141695/packages/nuget/index.json --api-key AAABBBCCCDDD --skip-duplicate\nI get the error:\ninfo : Pushing Sasw.TestSupport.2.0.2.nupkg to 'https://gitlab.com/api/v4/projects/17141695/packages/nuget'...\ninfo :   PUT https://gitlab.com/api/v4/projects/17141695/packages/nuget/\ninfo :   Unauthorized https://gitlab.com/api/v4/projects/17141695/packages/nuget/ 397ms\nerror: Response status code does not indicate success: 401 (Unauthorized).\nERROR: Job failed: exit code 1\n\nThe documentation doesn't mention anything special, but I notice that when using the (legacy?) nuget CLI it passes a username. Dotnet CLI, however, doesn't support username, just API KEY.\nAny idea why this is not working?\nThis is my CI/CD script:\nvariables:\n  GITLAB_RUNNER_DOTNET_CORE: mcr.microsoft.com/dotnet/core/sdk:3.1\n  NUGET_REPOSITORY: https://gitlab.com/api/v4/projects/${CI_PROJECT_ID}/packages/nuget/index.json\n  NUGET_API_KEY: $SASW_API_ACCESS_TOKEN\n  NUGET_FOLDER_NAME: nupkgs\n  NUGET_VERSION_SUFFIX: $SASW_PRERELEASE_SUFFIX\n\nstages:\n  - build\n  - pack\n  - release\n  \n#Docker image\nimage: $GITLAB_RUNNER_DOTNET_CORE\n\n#Jobs\nci:\n  stage: build\n  script:\n    - dotnet restore --no-cache --force\n    - dotnet build --configuration Release --no-restore\n    #- dotnet vstest test/*UnitTests/bin/Release/**/*UnitTests.dll\n    #- dotnet vstest test/*IntegrationTests/bin/Release/**/*IntegrationTests.dll\n    \npack-prerelease:\n  stage: pack\n  script:\n    - dotnet pack *.sln --configuration Release --output $NUGET_FOLDER_NAME --version-suffix $NUGET_VERSION_SUFFIX --include-symbols -p:SymbolPackageFormat=snupkg\n  artifacts:\n    paths:\n    - $NUGET_FOLDER_NAME\n    expire_in: 1 week\n  except:\n    - master\n\npack-release:\n  stage: pack\n  script:\n    - dotnet pack *.sln --configuration Release --output $NUGET_FOLDER_NAME\n  artifacts:\n    paths:\n    - $NUGET_FOLDER_NAME\n    expire_in: 1 week\n  only:\n    - master\n\npublish-nuget:\n  stage: release\n  script:\n    - dotnet nuget push **/*.nupkg --source $NUGET_REPOSITORY --api-key $NUGET_API_KEY --skip-duplicate\n\nPS: The project is public, so in case it's needed have a look at: https://gitlab.com/sunnyatticsoftware/sasw-test-support/-/jobs/451080235\n\nUPDATE 1: Further verbosity from my local linux console\n$ dotnet nuget -v Debug push **/*.nupkg --source https://gitlab.com/api/v4/projects/17141695/packages/nuget/index.json --api-key cBwt5_hidden_ --skip-duplicate\ntrace: NuGet Command Line Version: 5.4.0.2\ninfo : Pushing Sasw.TestSupport.2.0.2.nupkg to 'https://gitlab.com/api/v4/projects/17141695/packages/nuget'...\ninfo :   PUT https://gitlab.com/api/v4/projects/17141695/packages/nuget/\ninfo :   Unauthorized https://gitlab.com/api/v4/projects/17141695/packages/nuget/ 1159ms\nerror: Response status code does not indicate success: 401 (Unauthorized).\ntrace: System.AggregateException: One or more errors occurred. (Response status code does not indicate success: 401 (Unauthorized).)\ntrace:  ---> System.Net.Http.HttpRequestException: Response status code does not indicate success: 401 (Unauthorized).\ntrace:    at System.Net.Http.HttpResponseMessage.EnsureSuccessStatusCode()\ntrace:    at NuGet.Protocol.Core.Types.PackageUpdateResource.EnsureSuccessStatusCode(HttpResponseMessage response, Nullable`1 codeNotToThrow, ILogger logger)\ntrace:    at NuGet.Protocol.Core.Types.PackageUpdateResource.<>c__DisplayClass23_0.<PushPackageToServer>b__0(HttpResponseMessage response)\ntrace:    at NuGet.Protocol.HttpSource.ProcessResponseAsync[T](HttpSourceRequest request, Func`2 processAsync, SourceCacheContext cacheContext, ILogger log, CancellationToken token)\ntrace:    at NuGet.Protocol.Core.Types.PackageUpdateResource.PushPackageToServer(String source, String apiKey, String pathToPackage, Int64 packageSize, Boolean noServiceEndpoint, Boolean skipDuplicate, TimeSpan requestTimeout, ILogger logger, CancellationToken token)\ntrace:    at NuGet.Protocol.Core.Types.PackageUpdateResource.PushPackageCore(String source, String apiKey, String packageToPush, Boolean noServiceEndpoint, Boolean skipDuplicate, TimeSpan requestTimeout, ILogger log, CancellationToken token)\ntrace:    at NuGet.Protocol.Core.Types.PackageUpdateResource.PushPackage(String packagePath, String source, String apiKey, Boolean noServiceEndpoint, Boolean skipDuplicate, TimeSpan requestTimeout, ILogger log, CancellationToken token, Boolean isSnupkgPush)\ntrace:    at NuGet.Protocol.Core.Types.PackageUpdateResource.Push(String packagePath, String symbolSource, Int32 timeoutInSecond, Boolean disableBuffering, Func`2 getApiKey, Func`2 getSymbolApiKey, Boolean noServiceEndpoint, Boolean skipDuplicate, SymbolPackageUpdateResourceV3 symbolPackageUpdateResource, ILogger log)\ntrace:    at NuGet.Commands.PushRunner.Run(ISettings settings, IPackageSourceProvider sourceProvider, String packagePath, String source, String apiKey, String symbolSource, String symbolApiKey, Int32 timeoutSeconds, Boolean disableBuffering, Boolean noSymbols, Boolean noServiceEndpoint, Boolean skipDuplicate, ILogger logger)\ntrace:    at NuGet.CommandLine.XPlat.PushCommand.<>c__DisplayClass0_1.<<Register>b__1>d.MoveNext()\ntrace:    --- End of inner exception stack trace ---\ntrace:    at System.Threading.Tasks.Task.ThrowIfExceptional(Boolean includeTaskCanceledExceptions)\ntrace:    at System.Threading.Tasks.Task`1.GetResultCore(Boolean waitCompletionNotification)\ntrace:    at System.Threading.Tasks.Task`1.get_Result()\ntrace:    at Microsoft.Extensions.CommandLineUtils.CommandLineApplication.<>c__DisplayClass56_0.<OnExecute>b__0()\ntrace:    at Microsoft.Extensions.CommandLineUtils.CommandLineApplication.Execute(String[] args)\ntrace:    at NuGet.CommandLine.XPlat.Program.MainInternal(String[] args, CommandOutputLogger log)\n\n\nUPDATE 2: Alexey's answer is the proper one and up to date as per April 2021. GitLab has improved Nuget support in the last year and now it's possible to easily push packages to the repo package registry and have readacces on Nuget feed at project level or group level using deploy tokens."}, {"role": "assistant", "content": "Pushing NuGet packages built from the current repository is quite easy, following the documentation. You do not need a NuGet.config file to push packages, as the credentials can be specified for the dotnet push command. You also don't need to keep the credentials in the CI file, as the CI variables contain all the necessary temporary credentials to push packages to the project package registry.\nThis is a fragment from my working .gitlab-ci.yml file, which I literally copy-pasted from the docs. All the necessary information comes from CI variables, so this snippet is totally reusable.\nnuget:\n  stage: deploy\n  image: mcr.microsoft.com/dotnet/sdk:5.0-buster-slim\n  script:\n    - dotnet pack -c Release -o $PWD/nuget\n    - dotnet nuget add source \"$CI_SERVER_URL/api/v4/projects/$CI_PROJECT_ID/packages/nuget/index.json\" --name gitlab --username gitlab-ci-token --password $CI_JOB_TOKEN --store-password-in-clear-text\n    - dotnet nuget push \"$PWD/nuget/*.nupkg\" --source gitlab\n  only:\n    - master\n    - tags\n\nConcerning the question about installing the package, you would, indeed, need a token. But it is not your personal access token. All you need really to let people install and restore from your feed is the repository deploy token. It doesn't have to be defined on the project level if you have multiple projects in a group, which contains several projects that have NuGet packages published. You can also create a deploy token for the whole group. The deploy token you create for this purpose only needs to have the read_package_registry permissions and it doesn't give any other rights to the users who get this token.\nAfter creating a deploy token, the token name is used as the username, and the token itself is the password. You put both of those to the NuGet.config file, where you have your project or group feed listed.\nFor example:\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<configuration>\n    <packageSources>\n        <clear />\n        <add key=\"nuget.org\" value=\"https://api.nuget.org/v3/index.json\" protocolVersion=\"3\" />\n        <add key=\"myfeed\" value=\"https://gitlab.mydomain.dev/api/v4/groups/19/-/packages/nuget/index.json\" />\n    </packageSources>\n    <packageSourceCredentials>\n        <myfeed>\n            <add key=\"Username\" value=\"gitlab+deploy-token-14\" />\n            <add key=\"ClearTextPassword\" value=\"thetokenvalue\" />\n        </myfeed>\n    </packageSourceCredentials>\n</configuration>"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Does gitlab API have a rate limit\n\ngithub has a rate limit of 5000/hour for OAuth client, but I can't find the same information from gitlab (apart from 6/minute for creating new users and resetting password), does it mean there's no limit?"}, {"role": "assistant", "content": "The answer is no longer \"no\", at least on gitlab.com:\n\nWe enabled capacity limiting on GitLab.com to reduce impact of GitLab Runners on stability of GitLab.\n\nNow each API response has the following headers:\nRateLimit-Limit: 600\nRateLimit-Observed: 12\nRateLimit-Remaining: 588\n\nFrom this issue, it looks like the limit is 10 requests per second per IP address."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Change SSH host for cloning\n\nIs there any way to change default ssh host for gitlab (displayed at top of repository view in web interface)? I mean only for SSH in clone urls.\nFor example I have my gitlab installation on git.example.com, but example.com also points to the same machine (different site). Can I change ssh clone urls from:\ngit clone [email\u00a0protected]:user/repository\n\nto:\ngit clone [email\u00a0protected]:user/repositiory\n\nbut for http and https leave it with git.example.com?"}, {"role": "assistant", "content": "Yes,\nIf you are using the omnibus package you can edit /etc/gitlab/gitlab.rb and add gitlab_rails['gitlab_ssh_host'] = 'example.host.com'\nThere is the equivalent option somewhere in gitlab.yml : ssh_host: example.host.com"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Pushing tags with Jenkins Git Publisher - multiple Git repositories (forks)\n\nOur team is transitioning from CVS to Git.  We intend to use the similar workflow as most open source projects on GitHub - each developer takes a fork of the main repo and then submits a pull request which will allow the project master to do a code review before merging the changes into the main repo.\nJenkins allows us to add multiple Git repositories (the standard Git plugin, not the Multiple SCM one).  Presumably I can enter the URL for each forked repo and then Jenkins will check all branches each fork for changes.  I give each repository a name eg \"master\", \"developer1\", \"developer2\"...\nWe want to have Jenkins tagging each build on the appropriate remote/fork.  The Git Publisher plugin requires that you provide the \"target remote name\", but we need Jenkins to be able to figure this out for itself."}, {"role": "assistant", "content": "I've managed to solve this one myself.  \n\nAt the top of the Jenkins project config page check \"This build is parameterized\" and add a string parameter \"remote\" with default \"master\".\nAdd \"Git Publisher\" as a Post-build action, and a Tag \"$BUILD_TAG\" and Target remote name = \"$remote\"\nIn Build Triggers, check \"Trigger builds remotely\"\nWe're using GitLab and under the project Settings menu I add a \"Web Hook\":\nhttp://my-jenkins-server.com/job/my-project/buildWithParameters?token=secret&remote=master\n\nAdd a web hook for each fork, and make sure that the \"remote\" parameter matches the repository name configured in Jenkins."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Push existing folder to GitLab\n\nIn Gitlab project from the instructions, they tell how to add an existing_folder to Git repository.\nBut after I press git commit the console open a vim.\nThen how can I go to the last one git push -u origin master and push my repository to gitlab.\ncd existing_folder\ngit init\ngit remote add origin [remote url]\ngit add .\ngit commit\ngit push -u origin master"}, {"role": "assistant", "content": "The command git commit launches your default command line text editor because a commit needs a message describing what is happening in it. There are two ways to add this message:\n\nWhen the editor (vim) is launched, write a commit message in the editor, then save and close the file. This message will now be stored with the commit. Exiting without saving the file will cancel the commit.\nUse the command git commmit -m \"Commit message here\", which allows you add a short commit message in the quotes without launching the editor.\n\nA commit message can be anything, but here is an article if you want to go in depth on what should be in a message and how to format it. Sometimes I use the full text editor to write a complex message, sometimes I just need a quick note and use the inline command with the -m flag.\nWant to change the default editor git uses for commit messages? You're in luck! Simply add it to your git config like this: git config --global core.editor \"nano\". Now commit messages will be opened in nano, or whatever editor command you put in this config command."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to setup connection to MySql database with gitlab CI/CD\n\nI'm trying to set up automatic testing of django project using CI/CD gitlab. The problem is, I can't connect to the Mysql database in any way.\ngitlab-ci.yml\nservices:\n  - mysql:5.7\n\nvariables:\n      MYSQL_DATABASE: \"db_name\"\n      MYSQL_ROOT_PASSWORD: \"dbpass\"\n      MYSQL_USER: \"username\"\n      MYSQL_PASSWORD: \"dbpass\"\n      \n\nstages:\n  - test\n\ntest:\n  stage: test\n  before_script:\n  - apt update -qy && apt-get install -qqy --no-install-recommends default-mysql-client\n  - mysql --user=$MYSQL_USER --password=$MYSQL_PASSWORD --database=$MYSQL_DATABASE --host=$MYSQL_HOST --execute=\"SHOW DATABASES; ALTER USER '$MYSQL_USER'@'%' IDENTIFIED WITH mysql_native_password BY '$MYSQL_PASSWORD'\"\n  script:\n  - apt update -qy\n  - apt install python3 python3-pip virtualenvwrapper -qy\n  - virtualenv --python=python3 venv/\n  - source venv/bin/activate\n  - pwd\n  - pip install -r requirement.txt\n  - python manage.py test apps\n\nWith this file configuration, I get  error\n ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)\n\nWhat have I tried to do\nadd to  mysql script tcp connection unstead socket\nmysql --protocol=TCP --user=$MYSQL_USER --password=$MYSQL_PASSWORD --database=$MYSQL_DATABASE --host=$MYSQL_HOST --execute=\"SHOW DATABASES; ALTER USER '$MYSQL_USER'@'%' IDENTIFIED WITH mysql_native_password BY '$MYSQL_PASSWORD'\"\n\nAnd in this case I got\nERROR 2002 (HY000): Can't connect to MySQL server on 'localhost' (99)\n\nHow do I set up properly?"}, {"role": "assistant", "content": "There can be multiple reasons for your issue:\n\nIncorrect MySQL version.\n\nSolution: Use mysql:5.7 instead of mysql:latest\n\n\nMySQL host is missing.\n\nSolution: add MYSQL_HOST in the variables with the hostname of the MySQL server. (Should be mysql when using mysql:5.7 in services key)\n\n\nDjango uses different credentials of DB.\n\nSolution: check that the credentials in the variables section of your .gitlab-ci.yml and compare against Django's settings.py. They should be the same.\n\n\nMySQL client not installed.\n\nSolution: install the mysql-client in the script section and check if it is able to connect.\n\n\n\nHere is a sample script that installs MySQL client and connects to the database in a debian based image (or a python:latest image):\nscript:\n  - apt-get update && apt-get install -y git curl libmcrypt-dev default-mysql-\n  - mysql --version\n  - sleep 20\n  - echo \"SHOW tables;\"| mysql -u root -p\"$MYSQL_ROOT_PASSWORD\" -h \"${MYSQL_HOST}\" \"${MYSQL_DATABASE}\"\n\nHere is a complete and valid example of using MySQL 5.7 as a service and a python image with mysql-client installed successfully connecting to the MySQL database:\nstages:\n  - test\n\nvariables:\n  MYSQL_DATABASE: \"db_name\"\n  MYSQL_ROOT_PASSWORD: \"dbpass\"\n  MYSQL_USER: \"username\"\n  MYSQL_PASSWORD: \"dbpass\"\n  MYSQL_HOST: mysql\n\ntest:\n  image: python:latest\n  stage: test\n  services:\n    - mysql:5.7\n  script:\n    - apt-get update && apt-get install -y git curl libmcrypt-dev default-mysql-client\n    - mysql --version\n    - sleep 20\n    - echo \"SHOW tables;\" | mysql -u root -p\"$MYSQL_ROOT_PASSWORD\" -h \"${MYSQL_HOST}\" \"${MYSQL_DATABASE}\"\n    - echo \"Database host is '${MYSQL_HOST}'\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "SSH key per project in Gitlab\n\ni have a problem that i don't know how to handle.\nI have 2 Repos in Gitlab , RepoA and RepoB. In my gitlab user i have 3 ssh keys, one from my laptop and 2 from the 2 VM (VMA and VMB) that work with the 2 repos. In this way i can pull and push easy from the VMs and from my laptop. \nOn RepoA i have a colaborator that also works. He has RepoA shared to his Gitlab account and he has access to VMA to push and pull code. He sould never have access to RepoB, so from here comes my problem. If he can guess the RepoB url , he can pull and see it on the VMA where he has access already just becouse Gitlab does not have a granular way o adding ssh keys per project. I probably am missing something very logical here but i just can't see what.\nHow can i give access to to my colaborator on VMA to only see RepoA.\nA hack-ish way of doing this is to generate a 3rd user in gitlab that handles just VMA an the ssh key from VMA  will be introduced in this user account on Gitlab. But i bet there's got to be a better, cleaner way."}, {"role": "assistant", "content": "GitLab has the feature of project-specific SSH keys:\nThey are called Deploy keys. You can use them to provide read-only or read/write access for one or multiple repositories.\n\nUse deploy keys to access repositories that are hosted in GitLab.\nDeploy keys can\u2019t be used for Git operations if external authorization is enabled."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab-ci.yml, before_script and artifact\n\nIn gitlab-ci.yml documentation, it says that\n\nbefore_script is used to define the command that should be run before all\n  jobs, including deploy jobs, but after the restoration of artifacts.\n\nThis tells me that artifact is produced before a job start running\nBut the artifact documentation says that\n\nArtifacts is a list of files and directories which are attached to a\n  job after it completes successfully\n\nThis tells me that artifact is produced after a job finish running.\nThis is a contradiction. Can someone please explain how this is not a contradiction?\nI imagine they are talking about the artifact in previous job? But I don't know how artifact and job work and can be wrong."}, {"role": "assistant", "content": "Artifacts can be produced by build jobs from one stage and consumed by build jobs from the next stage. So before_script is run after the artifacts produced by the previous stage are restored for the current stage.\nSo the follwing .gitlab-ci.yml\nstages:\n  - build\n  - test\n\nbefore_script:\n  - echo \"before_script\"\n  - ls\n\nbuild_artifacts:\n  stage: build\n  tags:\n    - docker\n  script:\n    - echo \"build_artifacts\"\n    - touch build_output\n  artifacts:\n    paths:\n      - build_output\n\ntest_artifacts:\n  stage: test\n  tags:\n    - docker\n  script:\n    - echo \"test_artifacts\"\n\nWill give the following outputs:\n# build_artifacts job\n$ echo \"before_script\"\nbefore_script\n$ ls\nREADME.md\n$ echo \"build_artifacts\"\nbuild_artifacts\n$ touch build_output\nUploading artifacts...\nbuild_output: found 1 matching files               \nUploading artifacts to coordinator... ok            id=56026 responseStatus=201 Created token=xxxxzzzz\nJob succeeded\n\n\n\n# test_artifacts job\nDownloading artifacts for build_artifacts (56026)...\nDownloading artifacts from coordinator... ok        id=56026 responseStatus=200 OK token=xxxxzzzz\n$ echo \"before_script\"\nbefore_script\n$ ls\nREADME.md\nbuild_output\n$ echo \"test_artifacts\"\ntest_artifacts\nJob succeeded\n\nAs you can see the test_artifacts job downloads the artifacts before the before_script runs."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Can we include git commands in docker image?\n\nI am new to docker. I would like to create an image which will run as part of my project build to check commited files.\nMy requirement is, Docker file should have these statements\n\nGet commited files from current git repo\nCOPY myapp/ /app\nCMD /app/entry.pl <git files> (as command line arg)\n\nI would like to create an image for this process.\nI should get the git commited files list from current local repo and pass those files to my application to scan those files.\nWhile building my image I just need to copy my application but while running the container I need to run git diff to find changed files and pass that to my application as arguments.\nIs it possible to run git diff by docker container?\nUPDATE:\nI tried to execute git diff on current repo from docker but it is saying not a git repository.\nI am running my docker images as part of continuous integration in gitlab yml file. \nPlease help me to achieve this requirement?"}, {"role": "assistant", "content": "Yes, you can. \nLet me recommend some things about that.\n\nDefine a git token in github associated to a generic user. I like to give only read permissions to that user.\nDeclare some ARGs related to git in your Dockerfile, so you can customize your build.\nAdd Git installation to your Dockerfile.\nDo git clone cloning only needed folders, not the whole repo.\n\nSo, your Dockerfile could be, for example for debian/ubuntu:\nFROM <your linux distribution>\nARG GIT_USER\nARG GIT_TOKEN\nARG GIT_COMMIT\nARG SW_VERSION\nRUN apt-get update\nRUN apt-get -y install git\nRUN git clone -n https://${GIT_USER}:${GIT_TOKEN}@github.com/<your git>/your_git.git --depth 1 && cd <your_git> && git checkout ${GIT_COMMIT} <dir_you_want_to_checkout>\nCOPY myapp/ /app\nCMD /app/entry.pl /<your_git>/<dir_you_want_to_checkout>/...\n\nThen, you can build as you know with: \ndocker build -t --build-arg GIT_USER=<your_user> --build-arg GIT_TOKEN=d0e4467c63... --build-arg GIT_COMMIT=a14dc9f454... <your_image_name> .\n\nGood luck."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to mark a git branch as merged?\n\nI know this sounds a little weird, but sometimes manually editing is more convenient than merging and resolving conflicts. I would like GitHub/GitLab to show a merged label on the branches I manually \"merged\". Can I do that?"}, {"role": "assistant", "content": "One way you can do this is to actually do a git merge, but use the -s ours merge strategy to ignore any actual contribution from the branch. From the git merge documentation:\n\nours\nThis resolves any number of heads, but the resulting tree of the merge is always that of the current branch head, effectively ignoring all changes from all other branches. It is meant to be used to supersede old development history of side branches. Note that this is different from the -Xours option to the recursive merge strategy.\n\nThis would be suitable to use after you have manually edited a branch to \"merge\" it, but then want to inform Git that the branch has in fact been logically merged."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to setup two PyPI indices\n\nI have a local GitLab installation that comes with a local PyPI server to store company internal Python packages.\nHow can I configure my PyPI to search packages in both index servers?\nI read about .pypirc / pip/pip.ini and found various settings but no solution so far.\n\nMost solutions permanently switch all searches to the other index server. But I want to be able to install and update packages from pypi.org as normal while some packages come from the local index.\nsetting multiple index servers with credentials seams to be limited to distutils (used e.g. by twine) only, but is not used by pip\nThere is confusion if to configure index servers in [global] or [install]. I assume the latter one is a rule subset for pip install. (The documentation is here unclear.)\nWhile twine can reference a repository entry in the config file like -r gitlab refers to a [gitlab] section, such a named reference can't be used by pip...\n\nSo what I want to achieve:\n\npip should be able to install and update regular packages from pypi.org like colorama\npip should be able to install and update packages from gitlab.company.com\n\nauthentication with username (__token__) and password (7a3b62342c784d87) must work\n\n\n\nExperiment so far:\n[global]\n\n\n[install]\nfind-links =\n    https://pypi.org\n    https://gitlab.company.de/api/v4/projects/2142423/packages/pypi\ntrusted-host =\n    https://pypi.org\n    https://gitlab.company.de/api/v4/projects/2142423/packages/pypi\n\n[distutils]\nindex-servers =\n    gitlab\n\n[gitlab]\nrepository = https://gitlab.company.de/api/v4/projects/2142423/packages/pypi\nusername = __token__\npassword = geheim"}, {"role": "assistant", "content": "Goal\n\npip install should install/update packages from GitLab as well as PyPi repo. If same package is present in both, PyPi is preferred.\npip install should support authentication. Preferred, if somehow we can make it read from a config file so that we don't need to specify it repeatatively.\n\nTheory\n\npip install supports --extra-index-url to specify additional PyPi indexes. The same can also be provided via pip.conf file.\npip uses requests which supports ~/.netrc as config file (docs).\n\nSteps\n\nCreate a pip.conf (pip.ini if on Windows) in any of the locations suggested by pip config -v list.\nAdd your GitLab PyPi index URL to pip.conf.\n\n[install]\nextra-index-url = https://gitlab.com/api/v4/projects/12345678/packages/pypi/simple\n\n\nCreate or update your ~/.netrc file and add your auth details for GitLab.\n\nmachine gitlab.com\n    login <token-name>\n    password <token-pass>\n\n\nWe can now install packages as simply as pip install <package-name>. pip will now look at both indexes to find your packages, with preference provided to the one pointed by index-url.\n\nAdditional info\n\nThe same could have been possible for pip search too, had there been support for multiple indexes. Till then, one needs to manually specify which PyPi index URL should be used. GitLab does not seem to support pip search since it throws 415 Client Error: Unsupported Media Type when specified as the PyPi index.\nAs for your doubts, each section in pip.conf points to that particular command, [install] provides configuration for pip install, [search] for pip search and so on. [global] probably refers to parameters that can be specified for all the commands be it pip install or pip search.\n.pypirc file is made specially for configuring package indexes related to upload (used by twine/flint), where as pip.conf is associated with configuring pip which manages python packages on your local system."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to transfer a project from user to a group in Gitlab?\n\nI want to move a project under my username/ownership to a group whose owner is a different user. Something like https://gitlab/user/project to https://gitlab/group/project\nHow can I achieve this?"}, {"role": "assistant", "content": "You can do this in the left-hand sidebar, under Settings -> General -> Transfer project.  You will need manage rights to that group that you are transferring to though.\n\n\nBe careful. Changing the project's namespace can have unintended side    effects. \nYou can only transfer the project to namespaces you manage.\nYou will need to update your local repositories to point to the new    location.\nProject visibility level will be changed to match namespace rules    when transferring to a group."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Fork between GitHub and GitLab projects\n\nIs it possible to fork a GitHub project into a GitLab project and the other way around?"}, {"role": "assistant", "content": "When creating a new repository, you can choose to import another repository, and one of the options is to import it via its https://... url from another repository site, such as github. This starts a git clone --bare <url> to import the repository. In the GitLab documentation the process is described in detail. Whenever I tried that, the process kept refreshing to the same \"in progress\" state indefinetly. \n\nUpdate: This seems to work only for repositories you own. So to import a public repository, a workaround would be to fork it and import the fork.\n\nSo another way would be to clone the repository on the commandline before populating your new repository:\nWhen you create a new, empty repository at your gitlab site, you get a page full of suggestions how to proceed to populate this repository.\nSetting up a tracker for a github site is basically a variant of the \nExisting Git repository recipe with the minor difference of cloning the repository to track first, and instead of renaming the previous origin to  old-origin as suggested in the recipe, you want to rename it to upstream instead to maintain conventions. So you'll end up with proceedings as outlined:\n\nClone the original repository you want to track:\n\ngit clone https://github.com/<author>/<repository.git> <repository>-tracker\n\nChange into the directory the repository was cloned into\n\ncd <repository>-tracker\n\nrename the source (origin) to something else (upstream), so you can still address it. \n\ngit remote rename origin upstream\n\ncreate your own repository located at your gitlab server, giving it a suitable name and description (don't miss to reference/link the original source there)\nadd the url of your own gitlab repository as origin. The exact line to use including the path to your own repository can be found in the Existing Git repository recipe you probably received as a result of the previous step.\n\ngit remote add origin git@<gitlab-server>/<path-to-your-repo>.git\n\npush the repository to your gitlab server:\n\ngit push -u origin --all\ngit push -u origin --tags\n\nafterwards:\n\ngit remote -v\norigin   git@<gitlab-server>/<path-to-your-repo>.git (fetch)\norigin   git@<gitlab-server>/<path-to-your-repo>.git (push)\nupstream     https://github.com/<author>/<repository.git> (fetch)\nupstream     https://github.com/<author>/<repository.git> (push)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Git LFS files not found on server\n\nWe have been using Git with git-lfs hosted by our own instance of Gitlab.\nSometimes when one particular user pushes files, some of them (seems to be .png files) don't make it to the LFS storage, but are added to git. I haven't been able to see the log / messages when this happens yet on their machine.\nBut what ends up happening is when other users try to download that file from LFS, it throws an error:\n\n[28bbec36fe441b7de97d566872c71cd4542384d871b369168285408c1f062cfd] Object does not exist on the server or you don't have permissions to access it\n\nI have tried manually uploading a file in its place on the Gitlab server in the git-lfs data directory with the correct SHA ID for the file name, but it doesn't seem to get picked up. So far my only solution is to touch the file so it generates a different SHA ID, and re-upload it.\nIs there any way to manually add an individual file to Gitlab's git-lfs storage?"}, {"role": "assistant", "content": "i guess that the git-lfs was not installed correctly on the clientside of the client pushing. However, if you have git-lfs 0.5.4 you should be able to fix it with following:\n# git lfs push --object-id origin [oid] [oid] [oid]\n$ git lfs push --object-id origin 28bbec36fe441b7de97d566872c71cd4542384d871b369168285408c1f062cfd"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "\"Missing CI config file\" message on run pipeline, but .gitlab-ci.yml exists\n\n3 screenshots to explain the issue\nWhen I run the pipeline I've an error...\n\nBut the file exists\n\nAnd it's good"}, {"role": "assistant", "content": "GitLab shows this error message when trying to execute an empty .gitlab-ci.yml file\nCheck your configured .gitlab-ci.yml file location (Settings > CI/CD > General Pipelines), make sure that it points to the correct place in the repository"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "find (and remove) member from all GitLab projects (that I own)\n\nIs there a way to search all GitLab groups and associated projects (that I own or administer) for a specific user (with the intent of removing that user)?  I know how if they are a member of the group itself, but if the group has many projects and some projects have users added individually, then it's tedious to search each project one-by-one."}, {"role": "assistant", "content": "I have not found such functionality in GitLab UI, so I developed python script using GitLab API.\nHere is the link to repo with source code of my script and docs: https://gitlab.com/CVisionLab/gitlab-tools/\nJust download the gitlab-delete-members.py script and run in bash command line. Usage example:\n$ gitlab-delete-members.py --query johndoe123 --token Abcdefg123\n\ud83d\udcac Auth at https://gitlab.com\nProject \"MyGroupSpam / my-project-foo\" (id=11111111) : no users to delete\nProject \"MyGroupSpam / my-project-bar\" (id=11111112) : delete johndoe123 (id=3333333) : \ud83d\udfe2 ok\nProject \"NotMyGroupEggs / not-my-project-baz\" (id=11111113) : delete johndoe123 (id=3333333) : \ud83d\udd34 fail\n\ud83d\udcac 1 members deleted in 2 repositories\n\nJust in case I provide full source of the script here:\n#!/usr/bin/env python3\n\n# -*- coding: utf-8 -*-\n\n\"\"\"Handy script for searching and deleting members from Gitlab projects.\nBuilt on top of GitLab Python API: https://python-gitlab.readthedocs.io/\n\"\"\"\n\nimport argparse\nimport gitlab\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser(\n        description='Delete member from all accessible gitlab projects.')\n    parser.add_argument('--query', required=True,\n                        help='Gitlab query string that defines users '\n                        'to be deleted (username is recommended)')\n    parser.add_argument('--token', required=True,\n                        help='Gitlab token of your user')\n    parser.add_argument('--url', default='https://gitlab.com',\n                        help='Gitlab URL')\n    parser.add_argument('--visibility', default='private',\n                        help='Gitlab projects visibility')\n    parser.add_argument('--dry', action='store_true',\n                        help='dry run')\n    return parser.parse_args()\n\n\ndef print_ok():\n    print('\ud83d\udfe2 ok')\n\n\ndef print_fail():\n    print('\ud83d\udd34 fail')\n\n\ndef print_skip():\n    print('\ud83d\udfe1 skip')\n\n\ndef main():\n    # Greeting and args parsing.\n    args = parse_args()\n\n    # Initialize Gitlab API.\n    print(f'\ud83d\udcac Auth to {args.url} : ', end='')\n    gl = gitlab.Gitlab(args.url, private_token=args.token)\n    try:\n        gl.auth()\n        print_ok()\n    except:  # noqa\n        print_fail()\n        return\n\n    # Iterate over projects.\n    projects = gl.projects.list(all=True, visibility=args.visibility)\n    del_members_count = 0\n    del_projects_count = 0\n    for p in projects:\n        print(f'Project \"{p.name_with_namespace}\" (id={p.id}) :',\n              end='')\n\n        # Query members.\n        members = p.members.list(query=args.query)\n\n        # Delete members.\n        if len(members) == 0:\n            print(' no users to delete')\n        else:\n            del_projects_count += 1\n            for m in members:\n                print(f' delete {m.username} (id={m.id}) : ', end='')\n                if not args.dry:\n                    try:\n                        m.delete()\n                        print_ok()\n                        del_members_count += 1\n                    except:  # noqa\n                        print_fail()\n                else:\n                    print_skip()\n\n    # Statistics.\n    print(f'\ud83d\udcac {del_members_count} members deleted '\n          f'in {del_projects_count} repositories')\n\n\nif __name__ == '__main__':\n    main()\n\n\nIf you want to know which GitLab API functions are used, here is the short list:\n\ngl = gitlab.Gitlab(...) \u2013 create API object\ngl.auth() - authenticate\nprojects = gl.projects.list(...) - get list of projects\nmembers = p.members.list(...) - list members of the certain project that matches query\nm.delete() - delete member from project"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI Python black formatter says: would reformat, whereas running black does not reformat\n\nWhen I run GitLab CI on this commit\nwith this gitlab-ci.yml:\nstages:\n    - format\n    - test\n\nblack_formatting:\n  image: python:3.6\n  stage: format\n  \n  before_script:\n    # Perform an update to make sure the system is up to date.\n    - sudo apt-get update --fix-missing\n    # Download miniconda.\n    - wget -q https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh; bash miniconda.sh -b -f -p $HOME/miniconda;\n    # Ensure the (mini) conda environment can be activated.\n    - export PATH=\"$HOME/miniconda/bin:$PATH\"\n    # (Re)create the environment.yml file for the repository.\n    - conda env create -q -f environment.yml -n checkstyle-for-bash --force\n    # Activate the environment of the repository.\n    - source activate checkstyle-for-bash\n\n  script:\n    # Verify the Python code is black formatting compliant.\n    - black . --check --exclude '\\.venv/|\\.local/|\\.cache/|\\.git/'\n    # Verify the Python code is flake8 formatting compliant.\n    - flake8 .\n  allow_failure: false\n\n\ntest:pytest:36:\n  stage: test\n  image: python:3.6\n  script:\n    # Ensure the (mini) conda environment can be activated.\n    - export PATH=\"$HOME/miniconda/bin:$PATH\"\n    # Activate the environment of the repository.\n    - source activate checkstyle-for-bash\n    # Run the python tests.\n    - python -m pytest\n\nit outputs:\nRunning with gitlab-runner 14.8.0 (565b6c0b)\n  on trucolrunner DS42qHSq\nPreparing the \"shell\" executor\n00:00\nUsing Shell executor...\nPreparing environment\n00:00\nRunning on pcname...\nGetting source from Git repository\n00:02\nFetching changes with git depth set to 20...\nReinitialized existing Git repository in /home/gitlab-runner/builds/DS42qHSq/0/root/checkstyle-for-bash/.git/\nChecking out 001577c3 as main...\nRemoving miniconda.sh\nSkipping Git submodules setup\nExecuting \"step_script\" stage of the job script\n02:55\n$ sudo apt-get update --fix-missing\nHit:1 http://nl.archive.ubuntu.com/ubuntu impish InRelease\nGet:2 http://security.ubuntu.com/ubuntu impish-security InRelease [110 kB]\nGet:3 http://nl.archive.ubuntu.com/ubuntu impish-updates InRelease [115 kB]\nHit:4 https://repo.nordvpn.com/deb/nordvpn/debian stable InRelease\nGet:5 http://nl.archive.ubuntu.com/ubuntu impish-backports InRelease [101 kB]\nHit:6 https://brave-browser-apt-release.s3.brave.com stable InRelease\nGet:7 http://security.ubuntu.com/ubuntu impish-security/main amd64 DEP-11 Metadata [20,3 kB]\nGet:8 http://security.ubuntu.com/ubuntu impish-security/universe amd64 DEP-11 Metadata [3.624 B]\nGet:9 http://nl.archive.ubuntu.com/ubuntu impish-updates/main amd64 DEP-11 Metadata [25,8 kB]\nGet:10 http://nl.archive.ubuntu.com/ubuntu impish-updates/universe amd64 DEP-11 Metadata [35,4 kB]\nGet:11 http://nl.archive.ubuntu.com/ubuntu impish-updates/multiverse amd64 DEP-11 Metadata [940 B]\nGet:12 http://nl.archive.ubuntu.com/ubuntu impish-backports/universe amd64 DEP-11 Metadata [16,4 kB]\nFetched 428 kB in 2s (235 kB/s)\nReading package lists...\n$ wget -q https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh; bash miniconda.sh -b -f -p $HOME/miniconda;\nPREFIX=/home/gitlab-runner/miniconda\nUnpacking payload ...\nCollecting package metadata (current_repodata.json): ...working... done\nSolving environment: ...working... done\n# All requested packages already installed.\ninstallation finished.\n$ export PATH=\"$HOME/miniconda/bin:$PATH\"\n$ conda env create -q -f environment.yml -n checkstyle-for-bash --force\nCollecting package metadata (repodata.json): ...working... done\nSolving environment: ...working... done\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\nInstalling pip dependencies: ...working... done\n$ source activate checkstyle-for-bash\n$ black . --check --exclude '\\.venv/|\\.local/|\\.cache/|\\.git/'\nwould reformat src/arg_parser.py\nwould reformat src/helper_text_parsing.py\nOh no! \ud83d\udca5 \ud83d\udc94 \ud83d\udca5\n2 files would be reformatted, 10 files would be left unchanged.\nERROR: Job failed: exit status 1\n\nHowever, if I run black src/** on the GitHub repository, black returns:\n~/git/checkstyle-for-bash$ git pull\nAlready up to date.\n(base) some@name:~/git/checkstyle-for-bash$ black src/**\nAll done! \u2728 \ud83c\udf70 \u2728\n8 files left unchanged.\n\nJust in case I did not clone the right repository, I also manually copy-pasted the content of the src/arg_parser.py file from GitLab into ~/git/checkstyle-for-bash/src/arg_parser.py and ran black again. However, the output is the same, it does not change anything.\nFor completeness, this is the content of the src/arg_parser.py file:\n# This is the main code of this project nr, and it manages running the code and\n# outputting the results to LaTex.\nimport argparse\n\n\ndef parse_cli_args():\n    # Instantiate the parser\n    parser = argparse.ArgumentParser(description=\"Optional app description\")\n\n    # Include argument parsing for default code.\n    # Allow user to load a graph from file.\n    parser.add_argument(\n        \"--ggl\",\n        dest=\"google_style_guide\",\n        action=\"store_true\",\n        help=(\n            \"boolean flag, determines whether the Google Style Guide for \"\n            \"Bash rules are followed.\"\n        ),\n    )\n\n    # Allow user to specify an infile.\n    parser.add_argument(\"infile\", nargs=\"?\", type=argparse.FileType(\"r\"))\n\n    # Specify default argument values for the parser.\n    parser.set_defaults(google_style_guide=True,)\n\n    # Load the arguments that are given.\n    args = parser.parse_args()\n    return args\n\n\nQuestion\nWhat could be causing the GitLab CI to say the files would be reformatted by black (even though the files are not reformatted when running black on them (on the same device (in a different conda environment)))?\nSetup\nI run my own GitLab CI on the same device on which I test the conda black commands. The GitLab CI copies the GitHub commits of a repository, one at a time, runs its CI on it, and then reports the results back to GitHub.\nI am currently not able to expose my GitLab server on clearnet as I am behind a gateway that I currently do not control.\nDoubts\nI am fairly certain it is a \"silly\" mistake from my side, however I have not yet been able to figure out what it is. Especially since I manually copy pasted the GitLab file content of the src/arg_parser.py file twice, and ran black twice to verify black indeed does not change \"that\" file. Also, to be sure it was not a trailing newline or anything, I used the copy button with the mouse, instead of manual selection:\n\nAdditionally, the file is flake8 compliant. My current guess is that somehow the CI is not ran on the most recent commit of that repository. However, to verify that I clicked on the GitLab of the failed commit, which indeed redirects to the \"05e85fd54f93ccfc427023b21f9cdb0c0cd6db2e\" commit (copy) in GitLab:\n It is from this commit that I copy-pasted the src/arg_parser.py file twice.\nAnother guess would be that the gitlab-ci.yml loads a miniconda environment whereas my local version of black uses a full conda environment. Perhaps they have a different newline character that would lead to a formatting difference. (Even  though I doubt that would be the case).\nIssue\nI ran the CI again whilst include the black . --diff command in the gitlab-ci.yml script, and the difference is between a:\n''' Return\n\nand:\n'''Return\n\nas is displayed in the accompanying output:\n$ black . --diff --exclude '\\.venv/|\\.local/|\\.cache/|\\.git/'\n--- src/arg_parser.py   2022-04-03 10:13:10.751289 +0000\n+++ src/arg_parser.py   2022-04-03 11:11:26.297995 +0000\n@@ -24,10 +24,12 @@\n \n     # Allow user to specify an infile.\n     parser.add_argument(\"infile\", nargs=\"?\", type=argparse.FileType(\"r\"))\n \n     # Specify default argument values for the parser.\n-    parser.set_defaults(google_style_guide=True,)\n+    parser.set_defaults(\n+        google_style_guide=True,\n+    )\n \n     # Load the arguments that are given.\n     args = parser.parse_args()\n     return args\nwould reformat src/arg_parser.py\n--- src/helper_text_parsing.py  2022-04-02 19:35:45.142619 +0000\n+++ src/helper_text_parsing.py  2022-04-03 11:11:26.342908 +0000\n@@ -5,11 +5,11 @@\n def add_two(x):\n     return x + 2\n \n \n def get_function_line_nrs(filecontent, rules):\n-    \"\"\" Returns two lists containing the starting and ending line numbers of\n+    \"\"\"Returns two lists containing the starting and ending line numbers of\n     the functions respectively.\n \n     :param filecontent: The content of the bash file that is being analysed.\n     :param rules: The Bash formatting rules that are chosen by the user.\n     \"\"\"\nwould reformat src/helper_text_parsing.py\nAll done! \u2728 \ud83c\udf70 \u2728\n2 files would be reformatted, 10 files would be left unchanged.\n\nI am not quite sure exactly why this happens, as I thought python black would always converge to the exact same formatting for a given valid python file. I assume it is because two different black versions are used between the miniconda environment and the anaconda environment on the same device.\nTo test this hypothesis I am including a black --version command in the gitlab-ci.yml."}, {"role": "assistant", "content": "The miniconda environment in the GitLab CI used python black version:\nblack, 22.3.0 (compiled: yes)\n\nWhereas the local environment used python black version:\nblack, version 19.10b0\n\nUpdating the local black version, pushing the formatted code according to the latest python black version, and running the GitLab CI on that GitHub commit resulted in a successful GitLab CI run."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I remove a tracked file from merge request\n\nI have committed and pushed some files to remote feature branch and created a merge request. I used\ngit commit -a -m \"blah blah\"\ngit push\n\nSo it pushed all the modified files. One of the files (which is an existing file in in the master) was not supposed to be pushed (like for e.g. executables). How do I remove this file from the merge request, so that when the MR is merged into master, the unwanted file is not merged (as if it was never there in the MR). I found this page mentioning the following commands\ngit rm {filename} --cached\ngit commit -m \"[...]\"\ngit push\n\nI tried the commands, but do not see the file removed in the merge request in Gitlab. Is this the right way to do it?\nUpdate1:\nWith the above commands, I could see the file mentioned as deleted in the above commit. But then when I merge the updated MR into master, the file is deleted from master too.\nUpdate2:\nRemoved sentences causing confusion and updated the title"}, {"role": "assistant", "content": "What version of Gitlab are you using?\nJust tested with latest version (14.5.2):\ngit checkout -b feature-123\ngit add package.json package-lock.json\ngit commit -m 'Commit with extra file.'\ngit push --set-upstream origin feature-123\n\nCreated MR, it shows two files changed\nNow, from the same branch:\ngit rm --cached package-lock.json\ngit commit -m 'Removing extra file.'\ngit push\n\nMR now shows only one modified file.\nBut if this MR is accepted without squash, the git history will contain adding and removing an extra file.\nIf you have committed a very large file, it may be better to ask the maintainer to squash your changes before merging. Or delete MR and create a new one with a single commit."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Exception in integrating gitlab with jenkins\n\nI have a project created and configured on private Gitlab v9.0 instance. I have imported this project on Jenkins v2.46.1, the connection with gitlab is successful. Afterwards, I tried to configure build trigger on push event from repo in gitlab. I have generated secret token for it on jenkins and added a webhook with Gitlab CI URL and secret token when I tried to test the webhook it returned me below exception\n\n\nHook executed successfully but returned HTTP 403 <html> <head> <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"/> <title>Error 403 anonymous is missing the Job/Build permission</title> </head> <body><h2>HTTP ERROR 403</h2> <p>Problem accessing /project/tapp-builder-service. Reason: <pre> anonymous is missing the Job/Build permission</pre></p><hr><i><small>Powered by Jetty://</small></i><hr/> </body> </html>\n\n\n\nCan anyone please help me solving this?"}, {"role": "assistant", "content": "You can either add a special user in Jenkins for this and configure the Webhook in GitLab accordingly or you can uncheck the checkbox \"Enable authentication for '/project' end-point\" in the GitLab section of the global Jenkins configuration. But this should be unchecked by default."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitlabCi deploy on multiple servers\n\nI use Gitlab runner and works fine for a single server. The gitlab-ci.yml is simple:\nstages:\n  - test\n  - deploy\n\ntest:\n  stage: test\n  image: php\n  tags:\n      - docker\n  script:\n      - echo \"Run tests...\"\ndeploy:\n    stage: deploy\n    tags:\n      - shell\n    script:\n      - sh deploy.sh\n\nAs i said this is fine for a single server but to deploy same app on another server? I tried with same gitlab-runner config (same conf.toml) but then it was only updating one of them randomly.\nIs there somehow gitlab Ci to be triggered by more than 1 runner and deploy all of them according gitlab-ci.yml?"}, {"role": "assistant", "content": "You can register several runners (e.g. tagged serverA and serverB) from different servers and have multiple deployment jobs, each of them performed by a different runner. This is because you can set more than one tag in a job and only a runner having all the tags will be used.\nstages:\n  - test\n  - deploy\n\ntest:\n  stage: test\n  image: php\n  tags:\n      - docker\n  script:\n      - echo \"Run tests...\"\n\ndeployA:\n    stage: deploy\n    tags:\n      - shell\n      - serverA\n    script:\n      - sh deploy.sh\n\ndeployB:\n    stage: deploy\n    tags:\n      - shell\n      - serverB\n    script:\n      - sh deploy.sh\n\nHowever, take into account a situation when one of the deployment jobs fails - this would end up in you having two different versions of the code on the servers. Depending on your situation this might or might not be a problem."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Sending Emails With GitLab not working correctly\n\nI'm trying to troubleshoot why GitLab Omnibus is not sending automated emails using Postfix, which is already installed and configured correctly (it's being used by other applications installed on the server as well). \nWhen I make a change to an issue, while tailing the Gitlab logs, this is what I'm noticing: \n\n==> /var/log/gitlab/sidekiq/current <==\n  2015-04-03_20:06:30.79386 2015-04-03T20:06:30.793Z 8126 TID-aq3vk Sidekiq::Extensions::DelayedMailer JID-460531f571f6756908805d66 INFO: start\n  2015-04-03_20:06:31.53363 sendmail: recipients with -t option not supported\n==> /var/log/gitlab/gitlab-rails/production.log <==\nSent mail to [email\u00a0protected] (48.3ms)\n==> /var/log/gitlab/sidekiq/current <==\n  2015-04-03_20:06:31.57039 2015-04-03T20:06:31.570Z 8126 TID-aq3vk Sidekiq::Extensions::DelayedMailer JID-460531f571f6756908805d66 INFO: done: 0.776 sec\n\nI sanitized the email address, but it is sending to a correct address. \nI'm guessing the issue is related to the \" sendmail: recipients with -t option not supported\"\nHowever, I cannot find anybody else out there who has had this issue. \nThanks."}, {"role": "assistant", "content": "I fixed this issue by switching GitLab to SMTP by following the guide here: https://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/doc/settings/smtp.md\nIt seems like SMTP is documented in greater detail."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Jenkins does not show configured git credentials\n\nI have Jenkins 2.204.2 and want to configure a project with my git credentials for our gitlab server.\nI created under Jenkins > Credentials > System > Global credentials an entry with a secret key.\nNevertheless, if I create a freestyle project and set git as source code management, the opttions for Credentials remain empty.\nAlso if I use the Add button next to the credentials options and add the same secret key again, this does not show up in the options (though the new entry is shown in the Global credentials menu).\nHow can I configure the credentials to be used for Jenkins ? What do I miss, that I cannot select my created credentials ?"}, {"role": "assistant", "content": "To use the git protocol (and not the https protocol) your Jenkins credentials must be of type \"SSH Username with private key\". \nEven so, those credentials won't appear in the dropdown list due to this known issue: likely you have installed the \"Authorize Project\" Plugin and in the \"Configure Global Security\" > \"Project Default Build Authorization\" section, \"Strategy\" field configured to \"Run as specified user\" (and a user) or \"Run as anonymous\". As a workaround for the issue, you can select \"Run as SYSTEM\" and the SSH credentials will appear in the list.\nSee:\nWhy credentials are not listed in the GIT SCM section?\nhttps://support.cloudbees.com/hc/en-us/articles/360017499672-Why-credentials-are-not-listed-in-the-GIT-SCM-section-"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "cannot validate certificate for <ip-address> because it doesn't contain any IP SANs\n\nI'm working on a GitLab CI pipeline that will deploy my docker stack. I'm trying to set the $DOCKER_HOST to be tcp://DROPLET_IP:2377, but I'm getting an error saying that my certificate does doesn't contain any IP SANs. I'm testing with a Digital Ocean Droplet, so I haven't set a domain name for my droplet yet. \ndeploy:\n  stage: deploy\n  image: docker:stable\n  services:\n    - docker:dind\n  variables:\n    DOCKER_HOST: \"tcp://$DROPLET_IP:2377\"\n    DOCKER_TLS_VERIFY: 1\n  before_script:\n    - mkdir -p ~/.docker\n    - echo \"$TLS_CA_CERT\" > ~/.docker/ca.pem\n    - echo \"$TLS_CERT\" > ~/.docker/cert.pem\n    - echo \"$TLS_KEY\" > ~/.docker/key.pem\n  script:\n    - docker login -u gitlab-ci-token -p \"$CI_JOB_TOKEN\" \"$CI_REGISTRY\"\n    - docker info\n    - docker stack deploy --with-registry-auth --compose-file=docker-stack.yml mystack\n\nHere's the error I'm getting in the output of my GitLab CI job:\n$ docker login -u gitlab-ci-token -p \"$CI_JOB_TOKEN\" \"$CI_REGISTRY\"\nWARNING! Using --password via the CLI is insecure. Use --password-stdin.\nerror during connect: Post https://<ip-address>:2377/v1.39/auth: x509: cannot validate certificate for <ip-address> because it doesn't contain any IP SANs\n\nI'm using the following set of commands to generate my certs (ca.pem, server-cert.pem and server-key.pem) that I'm trying to use in my deploy stage described above. I have saved TLS_CA_CERT, TLS_CERT and TLS_KEY to variables that are being used in GitLab CI. \nopenssl genrsa -aes256 -out ca-key.pem 4096\n\nopenssl req -new -x509 -days 365 -key ca-key.pem -sha256 -out ca.pem\n\nopenssl genrsa -out server-key.pem 4096\n\nopenssl req -subj \"/CN=<ip-address>\" -sha256 -new -key server-key.pem -out server.csr\n\necho subjectAltName = IP:<ip-address> >> extfile.cnf\n\necho extendedKeyUsage = serverAuth >> extfile.cnf\n\nopenssl x509 -req -days 365 -sha256 -in server.csr -CA ca.pem -CAkey ca-key.pem \\\n  -CAcreateserial -out server-cert.pem -extfile extfile.cnf"}, {"role": "assistant", "content": "I see you have included the IP address in the subjectAltName\necho subjectAltName = IP:<ip-address> >> extfile.cnf\n\nCheck, as in here, if this is a configuration issue:\n\nI put subjectAltName in the wrong section. Working method: Basically I edited openssl.cnf, in section [v3_ca] I added 'subjectAltName = IP:192.168.2.107'.\n  Produced new certificate and added to server + client.\n\nYou need to make sure your extension is declared in the v3_ca part, as shown here."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How can I get the commit diff in Gitlab CI?\n\nI use Gitlab CI for checking a code quality of my project. Sometime I want to check only new code ( new commit ).\nHow can I get diff from Gitlab CI ?"}, {"role": "assistant", "content": "I found out solution, it was obvious, but not for me\n diff:\n   script:\n     - git diff ${CI_COMMIT_SHA} master\n   except:\n     - master"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Publish Jenkins Job build status to Gitlab commit with Jenkins Pipeline job\n\nI have integrated my Gitlab CE version 9.3.5 with jenkins version 2.60.1 . \nI am able to trigger builds with Gitlab webhook and publish the result back to the commit with a jenkins freestyle job. \nI was wondering how can i achieve the same with jenkins pipeline job as every article on the above integration works with jenkins freestyle job."}, {"role": "assistant", "content": "If I follow the documentation about the Gitlab Jenkins plugin, you should be able to use the  gitlabCommitStatus method which will publish the status of the build steps declared after (here is an example from the doc) : \nnode() {\n    stage 'Checkout'\n    checkout <your-scm-config>\n\n    gitlabCommitStatus {\n       <script that builds, tests, etc. your project>\n    }\n}\n\nIf this is not enough, you also have the possibility to use updateGitlabCommitStatus name: 'build', state: 'pending' to control more precisely which state you're sending to the gitlab instance."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Git - Push subfolder to different repository\n\nI have a big repository with many files and projects. One of the sub-folders in this repo has to be a new, separated repository.\nI don't need to preserve history in the new one, but I have to be able, at any time, to update new repo with changes from the original repo.\nThe idea is that the old repo is a private, internal gitlab and the new repo is a public repo for deployed project.\nHow can I do this?"}, {"role": "assistant", "content": "You can treat the new repo as subtree for the old repo, and update new repo with old repo by git subtree push. Detail steps as below:\nAssume the old repo has folders project1, project2, project3 etc for different projects. And the project1 has managed in the new repo.\nFrist, replace the project1 folder in old repo by the new repo.\n# Copy project1 folder out of old repo\n# Delete the project1 folder in old repo, then use the commands in old repo\ngit add .\ngit commit -m 'delete project1 folder in old repo'\ngit subtree add --prefix=project1 <URL for new repo> master\n\nNow project1 folder in old repo is the subtree from new repo. You can make change and commit (git commit) in old repo.\nWhen you need to update the new repo by the old repo, you can use:\ngit subtree push --prefix=project1 <URL for new repo> master\n\nNow the new repo will be updated."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI setup error - Could not find a JavaScript runtime\n\nI am trying to setup Gitlab CI for my Ruby on Rails project, but ran into an error that I don't know how to fix.\nThe application is running on Ruby 2.3.1, Rails 5.0 and is using a postgreSQL database.\nMy current .gitlab.ci.yml file looks like this:\n# https://hub.docker.com/r/library/ruby/tags/\nimage: \"ruby:2.3.0\"\n\n# Pick zero or more services to be used on all builds.\n# Only needed when using a docker container to run your tests in.\n# Check out: http://docs.gitlab.com/ce/ci/docker/using_docker_images.html#what-is-service\nservices:\n  - redis:latest\n  - postgres:latest\n  - node:latest\n\n# This is a basic example for a gem or script which doesn't use\n# services such as redis or postgres\nbefore_script:\n  - gem install bundler         # Bundler is not installed with the image\n  - bundle install -j $(nproc)  # Install dependencies\n\nrubocop:\n  script:\n  - rubocop\n\nrspec:\n  script:\n  - rspec spec\n\nrails:\n  script:\n  - rails db:migrate\n  - rspec spec\n\nSo it's supposed to be using NodeJS as runtime. However, I get the following error:\n$ rails db:migrate\nrails aborted!\nBundler::GemRequireError: There was an error while trying to load the gem 'uglifier'.\nGem Load Error is: Could not find a JavaScript runtime. See https://github.com/rails/execjs for a list of available runtimes.\nBacktrace for gem load error is:\n/usr/local/bundle/gems/execjs-2.7.0/lib/execjs/runtimes.rb:58:in `autodetect'\n/usr/local/bundle/gems/execjs-2.7.0/lib/execjs.rb:5:in `<module:ExecJS>'\n/usr/local/bundle/gems/execjs-2.7.0/lib/execjs.rb:4:in `<top (required)>'\n/usr/local/bundle/gems/activesupport-5.0.0.rc2/lib/active_support/dependencies.rb:293:in `require'\n/usr/local/bundle/gems/activesupport-5.0.0.rc2/lib/active_support/dependencies.rb:293:in `block in require'\n/usr/local/bundle/gems/activesupport-5.0.0.rc2/lib/active_support/dependencies.rb:259:in `load_dependency'\n/usr/local/bundle/gems/activesupport-5.0.0.rc2/lib/active_support/dependencies.rb:293:in `require'\n/usr/local/bundle/gems/uglifier-3.0.0/lib/uglifier.rb:5:in `<top (required)>'"}, {"role": "assistant", "content": "You need to have a javascript runtime (e.g. nodejs). You can install it by using the following command:\nFor Ubuntu Users\nsudo apt-get install nodejs\n\nFor CentOS / RedHat Users\nsudo yum install nodejs\n\nIn case you can't install nodejs you can install and then use therubyracer gem. \nDescription from repository:\n\nEmbed the V8 JavaScript interpreter into Ruby.\n\nAdd this line to your Gemfile\ngem 'therubyracer', platforms: :ruby"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How can I completely delete a file that was uploaded to Gitlab in an issue comment?\n\nSomeone uploaded (attached) a file in a Gitlab issue comment. They did not mean to share that file publicly. I can delete the comment, but the file is still available via the original direct url. The file is at:\nhttps://gitlab.com/<username>/<repo>/uploads/<hash>/<filename>\n\nIs there any way to completely remove files from this uploads directory?"}, {"role": "assistant", "content": "I raised a case with GitLab support and they were able to provide a solution for this. Using GraphQL, you can delete any uploaded files you have access to.\nNavigate to GitLab's GraphQL explorer: https://gitlab.com/-/graphql-explorer\nUse this query to delete your file:\nmutation{\n  uploadDelete(input: { projectPath: \"YOUR_PROJECT_PATH\", secret: \"YOUR_SECRET_HASH_KEY\" , filename: \"FILE_NAME\" }) { \n    upload {\n      id\n      size\n      path \n    }\n    errors\n  }\n}\n\nExample:\nIf your uploaded file path is https://gitlab.com/s_shaik/ci256986/uploads/abefe4f256e91ffc212c40605ae91ab3/ci.yml\nThen\nprojectPath: \"s_shaik/ci256986\"\nsecret: \"abefe4f256e91ffc212c40605ae91ab3\"\nfilename: \"ci.yml\"\nOn success you will receive a response like this:\n{\n  \"data\": {\n    \"uploadDelete\": {\n      \"upload\": {\n        \"id\": \"gid://gitlab/Upload/<id>\",\n        \"size\": <file_size>,\n        \"path\": \"@hashed/some/path/to/file\"\n      },\n      \"errors\": []\n    }\n  }\n}"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Why does GitLab say there are conflicts when there have not been commits to the target branch since the last merge?\n\nWe use GitLab.com for our project. We are merging code into our release branch (master) from our QA branch (qa). There have been no commits to the master branch since the last release about a month ago.\nFor a couple of the projects, the automatic merge fails in GitLab's UI, and I have to do it manually via the command line resolve the conflicts via GitLab's UI. I do not understand how this can occur since there are no changes on master to conflict with.\nqa      --\u25cf--\u25cf--\u25cf--\u25cf--\u25cf--\n           \\           \\\nmaster  ----\u25cf-----------\u25cf--\n\nWhen I merge the conflicts I end up just taking all changes from the qa branch anyway (git merge -X theirs). It's also not all files (thankfully!), just 5-10 changes of 5 files out of say, 300 changes in 50 files.\nBut I just don't understand what's triggering these conflicts.\nNOTE: I do squash all commits from qa when merging into master. Now I'm thinking that could be part of the problem. Not sure how, still."}, {"role": "assistant", "content": "I think I found the issue. In one simple dependancy project it occurred, so serves well as an example.\nThe merges that fail to work in the UI at all (the ones that have to be resolved locally with the CLI) were merged without the issue I am describing. I have updated the question to reflect that.\nThe issue is that GitLab is making an automatic merge commit from the target branch to the source branch seconds before the merge in the desired direction. I verified that the projects that had 'conflicts' all had these bad merges occur. They were also the projects that were not merged manually.\n$ git log --abbrev-commit --graph qa master\n\n*   commit 92xxx (tag: v1.3.1, tag: v1.3.0, origin/master, origin/HEAD, master)\n|\\  Merge: 83xxx 7fxxx\n| | Author: Nick\n| | Date:   Fri Sep 7 00:52:37 2018 +0000\n| |\n| |     Merge branch 'qa' into 'master'\n| |\n| |     v1.3\n| |\n| |     See merge request translations!17\n| |\n| * commit 7fxxx\n|/  Author: Nick\n|   Date:   Fri Sep 7 00:52:37 2018 +0000\n|\n|       v1.3\n|\n| *   commit c14xxx (HEAD -> qa, origin/qa)\n| |\\  Merge: 76xxx 83xxx\n| |/  Author: Nick\n|/|   Date:   Fri Sep 7 00:52:29 2018 +0000\n| |\n| |       Merge branch 'master' into 'qa'\n| |\n| |       # Conflicts:\n| |       #   langs/en-US.json\n| |\n* |   commit 83xxx (tag: v1.2.1, tag: v1.2.0)\n|\\ \\  Merge: 08xxx 73xxx\n| | | Author: Nick\n| | | Date:   Fri Aug 3 14:09:04 2018 +0000\n| | |\n| | |     Merge branch 'qa' into 'master'\n| | |\n| | |     Merge for v1.1.2\n| | |\n| | |     See merge request translations!13\n| | |\nm   qa\n\nmaster is the left line. 83xxx the merge from last release. master has no commits since the last release, except this inexplicable bad merge.\nSo this explains the conflicts. These conflicts appear immediately after opening a merge request in GitLab's UI, so I'm guessing the creation of the merge request is what's causing the bad merge commit. Perhaps using the 'squash commits' checkbox comes into play (it is available to select on creation of merge request, and also with the merge action of an already open merge request).\nStill at a loss as to why GitLab is doing this, perhaps a bug. Next time I create merge requests that have these weird conflicts I'll leave them open to see if it did indeed create bad merge request as part of the creation process.\nUpdate Dec 2018\nRelease time again. I paid attention. Still not 100% sure what's going on. Starting a merge request for the translations project, which has zero commits to master since last merge from qa.\nConflicts. Looked over them. Did not make any sense. Did not notice any commits when refreshing the repo in another tab. Clicked on 'resolve conflicts' in the UI, after completing the conflict resolution a commit from master->qa was created. It's just the Gitlab implementation's way of merging. You resolve conflicts by pulling master into QA, then merge back up. It literally says this in the UI's conflict resolution page \ud83d\ude44\nOr something. Drives me nuts but don't have time to dilly-dally on release day."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gerrit - Gitlab Integration\n\nIn order to improve the development process, our organization have decided to introduce Gerrit in the development workflow. I am the person responsible for implementing Gerrit server.\nThe user guides available in internet were very helpful in implementing Gerrit to our existing workflow. We are using Jenkins and Sonar as Non-interactive users for verifying the builds.\nBut while dealing with repositories one question rises. Most of the open sources are using gerrit-replication plugin to replicate the latest code to their public code repository. These public repositories are exposed using GitLab so that the users can clone the code.\nHere we doesn't need a public repository as the code is maintained in house.\nIs it a good choice to point both GitLab and Gerrit to a common git repository location?\nAny help appreciated."}, {"role": "assistant", "content": "You can use gerrit in front of gitlab via the replication feature. The replication feature does not do a git clone/fetch, it only pushs (approved) changes to a remote repository.\n\nyou have to import repositories via e.g. 'git push origin master' which requires extra permissions (or you need to be the admin). That is not a big deal unless you forget to remove these\npermissions. If you forget to remove these permissions or are\nadministrator (who has these permissions): a default \"git push\" will\nmake it through without being reviewed.\nyou have to make sure that no one can commit to the gitlab instance.\nElse you have a high chance to run into merge conflicts (gerrit is\nnot aware of these new commits). You can protect the branches in\ngitlab -- but the admins (and if I remember correct also the\nrepository creator/owner) will always have this right, too.\nYou have to grant a gerrit user master permissions to allow it push to the gitlab repository.\nAll projects have to be first created in gitlab, else they will not be synchronized (unless you find a way that the repo will be automatically created in gitlab on the first git push)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab api to get commits in a merge request\n\nFrom the GITLAB API documentation, I can get the merge request details,\nfrom which I can get the source project and the branch.\nThe api to get the list of commits in the branch, list all the commits in that branch.\nIs there a way to get the list of commits specific to a merge request through API.?\nThe objective is to know only the new commits in the merge request.\nThank You."}, {"role": "assistant", "content": "I think you are looking for this:\ncurl --header \"PRIVATE-TOKEN: ****\" \"http://gitlab/api/v3/projects/:project_id:/merge_requests/:mr_id:/commits\"\n\nhttps://docs.gitlab.com/ce/api/merge_requests.html#get-single-mr-commits"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to force GitLab to run a complete pipeline before starting a new one?\n\nI have one runner associated with my project to avoid concurrent build. GitLab to process the complete pipeline before start a new one?\nconcurrent is set to = 1 (config file of the runner)\nbefore_script:\n  - echo %CI_COMMIT_SHA%\n  - echo %CI_PROJECT_DIR%\n\nstages:\n  - createPBLs\n  - build\n  - package\n\n\ncreate PBLs:\n  stage: createPBLs\n  script: \n    - md \"C:\\HierBauen\\%CI_COMMIT_SHA%\\\"\n    - xcopy /y /s \"C:/Bauen\" \"C:/HierBauen/%CI_COMMIT_SHA%\"\n    - xcopy /y /s \"%CI_PROJECT_DIR%\" \"C:\\HierBauen\\%CI_COMMIT_SHA%\"\n    - cd \"C:\\HierBauen\\%CI_COMMIT_SHA%\"\n    - ./run_orcascript.cmd\n  only:\n  - tags\n  - master\n\nbuild:\n  stage: build\n  script:\n  - cd \"C:\\HierBauen\\%CI_COMMIT_SHA%\"\n  - ./run_pbc.cmd\n  only:\n  - tags\n  except:\n  - master\n\nbuild_master:\n  stage: build\n  script:\n  - cd \"C:\\HierBauen\\%CI_COMMIT_SHA%\"\n  - ./run_pbcm.cmd\n  only:\n  - master\n\npackage:\n  stage: package\n  script:\n  - cd \"C:\\HierBauen\\%CI_COMMIT_SHA%\"\n  - ./cpfiles.cmd\n  artifacts:\n    expire_in: 1 week\n    paths:\n      - GitLab-Build\n    name: \"%CI_COMMIT_REF_NAME%\"\n  only:\n  - tags\n  - master\n\nUnfortunately, the earlier started pipeline is disturbed by a new started pipeline. As a result, the build is flawed at the end ...\nEDIT new config file:\nbefore_script:\n  - echo %CI_BUILD_REF%\n  - echo %CI_PROJECT_DIR%\n  - xcopy /y /s \"C:/Bauen\" \"%CI_PROJECT_DIR%\"\n\nstages:\n  - createPBLs\n  - build\n  - package\n\n\ncreate PBLs:\n  stage: createPBLs\n  script: \n    - ./run_orcascript.cmd\n  only:\n  - tags\n  - master\n\n\nbuild:\n  stage: build\n  script:\n  - ./run_pbc.cmd\n  only:\n  - tags\n  except:\n  - master\n\n\nbuild_master:\n  stage: build\n  script:\n  - ./run_pbcm.cmd\n\n\n\n  only:\n  - master\n\npackage:\n  stage: package\n  script:\n  - ./cpfiles.cmd\n  artifacts:\n    expire_in: 1 week\n    name: \"%CI_COMMIT_REF_NAME%\"\n    paths:\n      - GitLab-Build\n  only:\n  - tags\n  - master"}, {"role": "assistant", "content": "Currently there is no way for this, and there is an open issue at the moment on GitLab.\nWhat you can do instead is to add limit = 1 in your gitlab-runner config.toml file, which would enforce the gitlab-runner to only accept one job at a time.\nI see that you are not passing artifacts between your stages, but if your build stage, depended on anything in the createPBLs stage, you can use\na combination ofartifacts and dependencies to pass data between stages.\n\nFor example:\nbefore_script:\n  - echo %CI_COMMIT_SHA%\n  - echo %CI_PROJECT_DIR%\n\nstages:\n  - createPBLs\n  - build\n  - package\n\n\ncreate PBLs:\n  stage: createPBLs\n  script: \n    - md \"C:\\HierBauen\\%CI_COMMIT_SHA%\\\"\n    - xcopy /y /s \"C:/Bauen\" \"C:/HierBauen/%CI_COMMIT_SHA%\"\n    - xcopy /y /s \"%CI_PROJECT_DIR%\" \"C:\\HierBauen\\%CI_COMMIT_SHA%\"\n    - cd \"C:\\HierBauen\\%CI_COMMIT_SHA%\"\n    - ./run_orcascript.cmd\n  artifacts:\n    name: createPBLS_%CI_COMMIT_SHA%\n    untracked: true\n    expire_in: 1 day\n  only:\n  - tags\n  - master\n\nbuild:\n  stage: build\n  script:\n  - cd \"C:\\HierBauen\\%CI_COMMIT_SHA%\"\n  - ./run_pbc.cmd\n  dependencies:\n  - createPBLs\n  artifacts:\n    name: build_%CI_COMMIT_SHA%\n    untracked: true\n    expire_in: 1 day\n  only:\n  - tags\n  except:\n  - master\n\nbuild_master:\n  stage: build\n  script:\n  - cd \"C:\\HierBauen\\%CI_COMMIT_SHA%\"\n  - ./run_pbcm.cmd\n  dependencies:\n  - createPBLs\n  artifacts:\n    name: build_%CI_COMMIT_SHA%\n    untracked: true\n    expire_in: 1 day\n  only:\n  - master\n\npackage:\n  stage: package\n  script:\n  - cd \"C:\\HierBauen\\%CI_COMMIT_SHA%\"\n  - ./cpfiles.cmd\n  dependencies:\n  - build_master\n  artifacts:\n    expire_in: 1 week\n    paths:\n      - GitLab-Build\n    name: \"%CI_COMMIT_REF_NAME%\"\n  only:\n  - tags\n  - master"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab - How to add badge based on jobs pipeline\n\nMy goal is to show badges (ex : ) based on pipeline results.\nI have a private gitlab ce omnibus instance with the following .gitlab-ci.yml : \nimage: python:3.6\n\nstages:\n  - lint\n  - test\n\nbefore_script:\n  - python -V\n  - pip install pipenv\n  - pipenv install --dev\n\nlint:\n  stage: lint\n  script:\n  - pipenv run pylint --output-format=text --load-plugins pylint_django project/ | tee pylint.txt\n  - score=$(sed -n 's/^Your code has been rated at \\([-0-9.]*\\)\\/.*/\\1/p' pylint.txt)\n  - echo \"Pylint score was $score\"\n  - ls\n  - pwd\n  - pipenv run anybadge --value=$score --file=pylint.svg pylint\n  artifacts:\n    paths:\n      - pylint.svg\n\ntest:\n  stage: test\n  script:\n  - pipenv run python manage.py test\n\nSo I thought that I would store the image in the artifacts of the lint job and display it via the badge feature.\nBut I encounter the following issue : when I browse https://example.com/[group]/[project]/-/jobs/[ID]/artifacts/file/pylint.svg, instead of seeing the badge I have the following message : \nThe image could not be displayed because it is stored as a job artifact. You can download it instead.\n\nAnd anyways, I feel like this is the wrong way, because even if I could get the image, there don't seems to be a way to get the image from the last job since gitlab URL for badges images only supports %{project_path}, %{project_id}, %{default_branch}, %{commit_sha}\nSo how one would add badge to a gitlab project based on a svg generated from results in a gitlab pipeline ?\nMy guess is that I could push to a .badge folder but that doesn't sound like a clean solution."}, {"role": "assistant", "content": "You can indeed get the artifact(s) for the latest job (see documentation here), but the trick is that you need to use a slightly different URL:\nhttps://example.com/[group]/[project]/-/jobs/artifacts/[ref]/raw/pylint.svg?job=lint\nwhere [ref] is the reference to your branch/commit/tag.\nSpeaking of badge placeholders available in Gitlab, you can potentially put %{default_branch} or %{commit_sha} into [ref]. This won't allow you to get the correct badge for every branch, but at least your default branch will get one.\nPlease also note that ?job=lint query parameter is required, without it the URL won't work."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "different push/pull urls for git submodule\n\nI'm using the git superproject pattern in a large project which is deployed by a Teamcity build agent which does not have a repository account, however the repository is set up to allow anonymous cloning. For this reason I have set up the submodules with their http:// url rather than their git url. The issue with this is that the repository rejects http pushes:\nTotal 0 (delta 0), reused 0 (delta 0)\nerror: RPC failed; result=22, HTTP code = 401\nfatal: The remote end hung up unexpectedly\nfatal: The remote end hung up unexpectedly\n\nSo every time I update the submodules when switching branches, I have to do a git remote add-url --push to add the git:// url.\nIs there any way to set up the submodules in the superproject such that they already use the http:// url for pulling and the git:// url for pushing?"}, {"role": "assistant", "content": "The LibreOffice project also uses submodules and includes:\n\nBy default you submodules repository is in a state called 'detached HEAD' that means that the commit checked-out -- which is the one that the super-project (core) need -- is not associated with a local branch name.\nDon't forget to add a correct pushurl for the submodule you are working on or you will not be able to commit.\n\n$ editor .git/modules/submodule/config\n\n\nAnd in the section [remote \"origin\"] add:\n\npushurl = ssh://logerrit/submodule\n\n(similar to soulseekah's comment) (in your case, use a git:// address)\nYou can also do it through (within a submodule)\ngit config remote.origin.pushurl git://...\n\nIf you don't, as illulstrated in this project, you would get a:\nfatal: The remote end hung up unexpectedly"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab, in markdown, how can I use anchors other than headers?\n\nI would like to use links in markdown that points to an element in a list or a table (or text) and not specially a header.\nThe only solution I found for markdown is to use HTML anchors :\nThis is a list of actions:\n- <a id=\"action-one\">action one</a>`: blablanla\n- <a id=\"action-two\">action two</a>`: patata\n\nLater, in text, [action one](#action-one) is mandatory...\n\nThis works well in VScode (for example) but not in Gitlab.\nFYI:\n\nUsing name instead of id as explained here would not work for vscode.\nIn the official documentation, there's only mention of header anchors.\n\nAny idea or solution is welcome. Thanks."}, {"role": "assistant", "content": "I found a workaround for the limitations of bmaupin's solution, which is to add an empty link to the <a> tag with the id and name:\n<a id=\"link-ref\" name=\"link-ref\"></a>\n<a href=\"#link-ref\"></a>\n\nIn particular, I used this for headings like this:\n## 2.3 \u25b8 some section <a id=\"2.3\" name=\"2.3\"></a><a href=\"#2.3\"></a>\n\nwhich renders the heading's text to \"2.3 \u25b8 some section\"\nThe link is needed because gitlab's markdown engine is too smart for our own good and \"guesses\" that the <a> tag is not needed if there's no link pointing to it."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to unlock a runner?\n\nContext\nI am the (beginner) admin of my company GitLab server and I have a shared runner that is locked for an unknown reason. I couldn't find any information about what it means to be locked (and the difference with \"paused\") or how a runner can get locked. I also tried to find a way to unlock it, but all I could find was \"how to register an unlocked runner in the first place\".\nWhat I did\n\nRemove the runner from https://gitlab.my-company.com/admin/runners.\nUnregister the runner with gitlab-runner unregister the-runner-name.\nRegister a new one with gitlab-runner register --locked=false.\nClean everything with gitlab-runner verify --delete.\n\nWhat I wanted to do\nEdit the current runner with something like gitlab-runner edit the-runner-name --locked=false.\nWhat I wanted to do even more\nGo to https://gitlab.my-company.com/admin/runners and click on Unlock runner.\nQuestion\nIs there a way to unlock a runner or do I have to unregister it each time it's locked and register a new one?"}, {"role": "assistant", "content": "Just go to runners page and click you runner (or Edit icon next to its name). It should lead you to a screen where you can remove Locked status. \nYou may be using some old version of gitlab or have no sufficient permissions if you can't access this screen."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI runner configuration with cache on docker\n\nI can't seem to get the cache or the artifacts to carry over between jobs in gitlab CI.  I suspect it's something to do with my configuration, but I'm not sure what.  I'm running gitlab and gitlab-ci-multirunner, both in docker, using the following docker-compose config. I've left out the database config and some environment variables for brevity:\nversion: '2'\n\nservices:\n  gitlab:\n    image: sameersbn/gitlab:8.5.1\n    links:\n      - redis:redisio\n      - postgresql:postgresql\n    ports:\n      - \"10080:80\"\n      - \"10022:22\"\n    environment:\n      ...\n    volumes:\n      - gitlab_data:/home/git/data\n\n  gitlab-ci-runner:\n    restart: always\n    image: gitlab/gitlab-runner\n    volumes:\n      - gitlab_runner_config_data:/etc/gitlab-runner\n      - /var/run/docker.sock:/var/run/docker.sock\n      - /etc/nginx/ssl/gitlab.crt:/etc/gitlab-runner/certs/ca.crt\n      - /etc/ssh:/ssh\n    links:\n      - gitlab:gitlab\n\n  redis:\n    ...\n  postgresql:\n    ...\n\n\nvolumes:\n  postgresql_data:\n  redis_data:\n  gitlab_data:\n  gitlab_runner_config_data:\n\nThe runner configuration (config.toml) is:\nconcurrent = 1\n\n[[runners]]\n  name = \"docker\"\n  url = <public gitlab url>/ci \n  token = <gitlab token>\n  tls-ca-file = \"/etc/gitlab-runner/certs/ca.crt\"\n  executor = \"docker\"\n  [runners.docker]\n    image = \"docker-bash\"\n    volumes = [\"/var/run/docker.sock:/var/run/docker.sock\", \"/cache\"]\n\nThe docker-bash image referred to is just the official docker:1.10 image with bash installed.\nMy build process consists of 3 steps:\n\nRun npm install and the tests in the official node:5 image.  For now, I've left this step out in order to test the deploy.\nBuild a docker image containing the code\nUse ansible, via a custome built ansible docker image to deploy the built image to the production server.\n\nThe .gitlab-ci.yml file looks like this:\nvariables:\n  FULL_IMAGE_TAG: deploy-$CI_BUILD_REF_NAME:$CI_BUILD_ID-$CI_BUILD_REF\n  IMAGE_FILE: deploy-$CI_BUILD_REF_NAME.tar.gz\n\ncache:\n  paths:\n    - $IMAGE_FILE\n\nbuild:\n  stage: build\n  script:\n    - docker build -t $FULL_IMAGE_TAG .\n    - docker save $FULL_IMAGE_TAG | gzip -cf - > $IMAGE_FILE\n  artifacts:\n    paths:\n      - $IMAGE_FILE\n\ndeploy:\n  stage: deploy\n  image: ansible-ssh\n  script:\n    - ls\n    - ansible-playbook -e image_file=$IMAGE_FILE -e branch=$CI_BUILD_REF_NAME -e full_image_name=$FULL_IMAGE_TAG deploy-playbook.yml\n  only:\n    - develop\n    - master\n\nAs you can see, the compressed docker image is referred to here both in the cache and artifacts sections, but is not actually available in the deploy step, where ansible is supposed to copy it to the remote machine.  I have tried including an ls command so check the folder contents and the file is clearly not there, but it is definitely built and I can download it from the gitlab UI.  Here is the log from the deploy job:\ngitlab-ci-multi-runner 1.0.4 (014aa8c)\nUsing Docker executor with image ansible-ssh ...\nPulling docker image ansible-ssh ...\nWARNING: Cannot pull the latest version of image ansible-ssh : Error: image library/ansible-ssh not found\nWARNING: Locally found image will be used instead.\n\nRunning on runner-59d43cf3-project-8-concurrent-0 via 381c2ea97744...\nFetching changes...\nRemoving artifacts.zip\nRemoving deploy-develop.tar.gz\nHEAD is now at 6009bd0 test\nChecking out 6009bd0f as develop...\nHEAD is now at 6009bd0... test\n\n$ ls\nDockerfile\ndeploy-playbook.yml\nserver\n$ ansible-playbook -e image_file=$IMAGE_FILE -e branch=$CI_BUILD_REF_NAME -e full_image_name=$FULL_IMAGE_TAG deploy-playbook.yml\nUsing /etc/ansible/ansible.cfg as config file\n1 plays in deploy-playbook.yml\n\nPLAY ***************************************************************************\n\nTASK [setup] *******************************************************************\nok: [deploy-host]\n\nTASK [copy docker image] *******************************************************\ntask path: /builds/test/test/deploy-playbook.yml:44\nfatal: [deploy-host]: FAILED! => {\"changed\": false, \"failed\": true, \"msg\": \"could not find src=/builds/test/test/deploy-develop.tar.gz\"}\n\nNO MORE HOSTS LEFT *************************************************************\n    to retry, use: --limit @deploy-playbook.retry\n\nPLAY RECAP *********************************************************************\ndeploy-host            : ok=1    changed=0    unreachable=0    failed=1   \n\n\nERROR: Build failed with: exit code 1\n\nI suspect that I am not setting up or using the runner correctly, but I can't find much in the documentation for anything beyond really simple cases and I don't know the tool well enough to know how it all fits together under the hood."}, {"role": "assistant", "content": "Caching is not designed to pass files between stages of a build.\nFrom the doc\n\ncache : Define list of files that should be cached between subsequent\n  runs\n\nI think what you need is in fact in progress : WIP: Download build artifacts from previous stages and restore them in context of the build (Technology Preview)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Mercurial clients and GitLab?\n\nIs there a good way to let both git and hg clients use one repo system, like GitLab? \nPretty much like bitbucket. Should we just use https://hg-git.github.io/?"}, {"role": "assistant", "content": "One (commercial) solution (developed by the same company behind Stack Exchange) is Kiln, which can managed a repo with Git or mercurial.\nSee kiln Harmony.\nIf you use a git hosting service, then you need to manage a conversion system like hg-git yourself."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab runner can not resolve host when running pipeline\n\nI have a dockerized GitLab and GitLab Runner installation, with following docker-compose.yml:\nversion: \"3\"\n\nservices:\n  gitlab:\n    image: gitlab/gitlab-ee:latest\n    container_name: gitlab\n    restart: always\n    hostname: gitlab\n    ports:\n      - \"45022:22\"\n      - \"45080:80\"\n      - \"45443:443\"\n    volumes:\n      - /srv/gitlab/config:/etc/gitlab\n      - /srv/gitlab/logs:/var/log/gitlab\n      - /srv/gitlab/data:/var/opt/gitlab\n\n  python-runner:\n    image: gitlab/gitlab-runner:latest\n    container_name: python-runner\n    hostname: python-runner\n    volumes:\n      - /srv/python-runner/config:/etc/gitlab-runner\n      - /var/run/docker.sock:/var/run/docker.sock\n    environment:\n      - CI_SERVER_URL=http://gitlab/ci\n      - RUNNER_TOKEN=myTokenCode\n      - RUNNER_DESCRIPTION=Python 2.7.14\n      - RUNNER_EXECUTOR=docker\n      - DOCKER_IMAGE=python:2.7.14\n    restart: always\n\nI have registered the runner:\ndocker exec -it python-runner gitlab-runner register \\\n    --non-interactive \\\n    --url \"http://gitlab/\" \\\n    --registration-token \"${GITLAB_REGISTRATION_TOKEN}\" \\\n    --description \"Python 2.7.14\" \\\n    --executor \"docker\" \\\n    --docker-image python:2.7.14\n\nThe runner is listed in the Runners list:\n\nI can ping the gitlab host from the python-runner:\n\u00bb docker exec -it python-runner bash\nroot@python-runner:/# ping gitlab\nPING gitlab (172.20.0.2) 56(84) bytes of data.\n64 bytes from gitlab.gitlab_default (172.20.0.2): icmp_seq=1 ttl=64 time=0.112 ms\n64 bytes from gitlab.gitlab_default (172.20.0.2): icmp_seq=2 ttl=64 time=0.055 ms\n^C\n--- gitlab ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 999ms\nrtt min/avg/max/mdev = 0.055/0.083/0.112/0.029 ms\n\nBut when running the pipeline, it fails:\n`fatal: unable to access 'http://gitlab-ci-token:xxxxxxxxxxxxxxxxxxxx@gitlab/group/project.git/': Could not resolve host: gitlab\n\nHow is this possible? How can this be solved?\nEDIT\nIt seems the architecture that I am creating is the following:\n\ngitlab running in gitlab docker container\ngitlab runner running in python-runner docker container\ndocker-compose creates a private network gitlab_default (gitlab is the name of the project), and both the gitlab and python-runner containers can reach it other, by IP and by name.\nthe python-runner uses the docker executor to spawn containers during CI (in the host?), based on python:2.7.14 as defined. I do not know how gitlab names these containers, let's call it ci-job\nthe project is cloned in this ci-job container, by issuing a git clone. This fails because the ci-job container can not reach the gitlab container, since it is probably in a different network (default network?)\n\nI have tried to force the python-runner to spawn containers in the same gitlab_default network, by using --docker-network-mode gitlab_default flag as follows:\ndocker exec -it python-runner gitlab-runner register \\\n    --non-interactive \\\n    --tag-list python-2.7.14 \\\n    --url \"http://gitlab\" \\\n    --registration-token \"$(GITLAB_REGISTRATION_TOKEN)\" \\\n    --name \"Python 2.7.14\" \\\n    --executor \"docker\" \\\n    --docker-image python:2.7.14 \\\n    --docker-network-mode gitlab_default\n\nBut it still does not work. I am not sure if that's the right flag, since it is poorly documented.\nTwo questions:\n\nHow can I see the containers that the executor is creating when running CI? Can I enter them and do some debugging there?\nWhat is the relevant parameter to ensure that the containers spawned by the docker executor are in the same network as the gitlab container?\n\nEDIT2\nAfter some idle time, my jobs started working. It seems configuring --docker-network-mode did indeed work as expected."}, {"role": "assistant", "content": "I had the same problem with gitlab-runner not able to resolve host names. But we use Gitlab running on Debian server (not docker installation) and runners in Google Cloud connected with VPN.\nWhat worked for me was to add dns addresses to the runners config.toml, like this:\n  [runners.docker]\n    dns = [\"dns-1-ip\", \"dns-2-ip\"]"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to migrate gitlab backups to new server which has latest gitlab version\n\nI am trying to migrate my gitlab backups for my old server to new server. my old server has gitlab (gitlab-6.5.1-0) and my new server has gitlab version (gitlab 6.6.5-omnibus). i taken backup from my old server using the following command \nbundle exec rake gitlab:backup:create RAILS_ENV=production\n\nand when i try to restore this backup in new server using this command\ngitlab-rake gitlab:backup:restore BACKUP=1395394855\n\nI am getting the following output\nUnpacking backup ... done\nGitLab version mismatch:\n  Your current GitLab version (6.6.5) differs from the GitLab version in the backup!\n  Please switch to the following version and try again:\n  version: 6f6f1588ba5123f156ee3b0635a061745b71fcde\n\nI tried searching for solution . but in all documents its says The backup is already migrated to the previous version. but none of them describes how to migrate backups . Any solution regarding this is Appreciated !"}, {"role": "assistant", "content": "This error message is produced by lib/backup/manager.rb#L87-L92:\n  settings = YAML.load_file(\"backup_information.yml\")\n  ENV[\"VERSION\"] = \"#{settings[:db_version]}\" if settings[:db_version].to_i > 0\n\n  # restoring mismatching backups can lead to unexpected problems\n  if settings[:gitlab_version] != Gitlab::VERSION\n    puts \"GitLab version mismatch:\".red\n\nIt seems to force an incremental backup, as described in this comment:\n\nI have faced the same issue when restoring the backup to a new server.\nbackup.rake checks GITLAB commit number at time of backup is taken and when you are restoring to the same branch name from latest check out.\nI have to:\n\ndelete 5-2-stable and \ncheck out again 5-2-stable with the same commit hash ( git checkout -b 5-2-stable COMMIT-HASH), \nran all tasks as installing a fresh 5-2-stable release with same config/gitlab.yml, config/database.yml. \nThen I have copied backup.tar file into default /home/git/gitlab/tmp/backups and ran restore rake task.\n\nIt worked without any problem. Then I have followed 5-2-stable to 5-3-stable upgrade and it went all well."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to add symlink file to a gitlab repo\n\nHow can I add symlink to file to gitlab repository?\nEvery time I run a pipeline from gitlab, the local symlink gets destroyed.\nAny suggestions on how to create a symlink for a folder which resides inside of gitlab repo would be great."}, {"role": "assistant", "content": "You can store in  a Git repo a symlink (special entry 12000), but, as seen in this test, that would make the GitLab pipeline fail.\nSee gitlab-ce issue 27542 (though it is for the particular case of  .gitlab-ci.yml being a symlink).\nIt is best if the pipeline first recreate the symlink, then process in its subsequent steps, with the normal build: regenerating it seems better than storing it."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab: Get merge request from a commit id\n\nI'm using the API of gitlab and I'm building a changelog. I use merge request in my project. In my changelog I get all commits ordered by id and now I want to get the merge request of gitlab to get his message. How can I get a merge request from a commit id?\nThanks,"}, {"role": "assistant", "content": "It is an open issue in gitlab:\nhttps://gitlab.com/gitlab-org/gitlab-ce/issues/28037"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Configuring GitLab to use SAML OmniAuth with an Active Directory IdP\n\nI am in the process of altering an existing GitLab installation to use SAML rather than LDAP for authentication. \nAt this point, users can successfully sign into the Web application using the 'Sign in with Saml' button. I am unclear, however, about what seems to be a difference between the LDAP and SAML approaches: users with accounts created via an LDAP sign-in can then access Git repositories (e.g. using clone, push, ...) using their LDAP usernames and passwords, but users with accounts created via a SAML sign-in cannot. \nThrough experimentation, I\u2019ve found that users can access the Git repositories if they use the GitLab UI to set a separate GitLab account password on the account that is created during the initial SAML interaction. I was pointed in this direction by a GitLab message that appeared after creating a project under one of the new user accounts: 'You won't be able to pull or push project code via HTTPS until you set a password on your account'. \nIt seems possible that this separate password configuration is only necessary because I\u2019ve misconfigured the SAML integration somehow. So, my question is whether I am wrong to expect that authenticating access to the GitLab-hosted Git repositories would work the same regardless of whether SAML or LDAP is used? If not, does anyone know of relevant SAML configuration settings that I should review?\nIn case it\u2019s of interest: I have posted a similar question to the GitLab Google group, but I have not received any responses there yet."}, {"role": "assistant", "content": "This is an old question, but I'm responding anyway in hopes it helps someone else who stumbles upon this question. \nAn important distinction between LDAP and SAML is that SAML is a web-based single sign on technology. Part of the SAML sign in process happens between the user's client (browser) and the SAML server directly and then GitLab verifies that information on the backend. In contrast, when given a user's LDAP password GitLab can connect directly to the LDAP server and verify the identity. \nMany GitLab users utilize a combination of LDAP and SAML. SAML provides seamless single sign-on for the web side while LDAP allows Git over HTTPS to accept passwords and also opens the door to advanced features like LDAP Group Sync in Enterprise Edition."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI/CD pipeline, deploy to Windows Server\n\nUsing GitLab Runner I have on Linux, I am trying to connect to a Windows Server and run some basic commands there such as git pull.\nDoes GitLab runner provide any capabilities for accessing windows server?\nWhat other options are there to get such requirement done?"}, {"role": "assistant", "content": "I think you have a few options\n\ninstall openssh and configure server on your windows machine/vm and connect from your gitlab runner with ssh ( https://learn.microsoft.com/en-us/windows-server/administration/openssh/openssh_install_firstuse )\n( as Wojciech Wirzbicki commented) install a gitlab runner instance on windows. https://docs.gitlab.com/runner/install/windows.html . I think this option more secure and easy win\nconnect to windows server with winrm"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to manage multiple maven projects in gitlab\n\nWe have multiple (about 75) maven projects, which we have pushed to Gitlab individually in following manner:\nGROUP1 - 4 projects\nGROUP2 - 2 projects\nGROUP3 - 10 Projects\n.\n.\nGROUP10 - 6 Projects\n\nWe now want to implement CI tool like Jenkins. But creating and managing all 75 projects in jenkins individuality is very time consuming. So that we have 2 methods in mind.  \n\ngit submodules: In this case we might get many complications, as individual developer is forking the multiple project and works in his forked repo.\nSingle git Project: In this case if every developer will fork the main repo, then disk space required is much and the performance will also get degrade. But it will be better than git submodules to manage, as build can be simplified with maven multiple module way.   \n\nSo according to you, is there any other approach we can think about, or can we go with Single git project?"}, {"role": "assistant", "content": "I also manage over 50 Gitlab Maven Projects and use Gitlab CI to build each project and deploy the artifact to our central artifact repository. Gitlab CI does not support re-building consumers of Maven artifacts when a downstream artifact changes. They have a concept of \"Triggering\" but this simply does not work well when you have so many projects.\nI usually push changes in one at a time and wait for the previous commit to fully build and publish to the central repository before pushing in the next commit.\nThis was very time consuming so as an alternative we did build an internal tool to solve this. I made the tool public a few days ago and it's in the Alpha stage, but you are free to try it if you'd like.\nIt's called Gitlab Pipes. The documentation has a quick start to get you started quickly."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Creation of Merge Request in GitLab fails\n\nI migrated my existing sources from Microsoft SourceSafe to GitLab.\nNow I have two branches master and release.\nI created a third branch feature off master and committed and pushed this branch.\nAfterwards, I created a new merge request, which got accepted and merged feature into master without conflicts. Now I want to cherry-pick this merge request into release which is 15 commits behind and 12 commits ahead to master.\nWhen creating this merge request, I get an error saying \"Sorry, we cannot cherry-pick this merge request automatically.\nThis merge request may already have been cherry-picked, or a more recent commit may have updated some of its content.\" and no merge request is created. This merge request isn't already cherry-picked as it is the first cherry pick ever in this repository and there also isn't a more recent commit that updated this file.\nAdditionally, GitLab won't show any entries related to my error in the internal log.\n\nI want GitLab to create a merge request and let me resolve possible conflicts in the web interface. Is this possible?"}, {"role": "assistant", "content": "Usually in this case, create a new branch for your release, cherry pick to that branch, and then push that up as a separate merge request.\nThat's how we handle our release process when our release and main diverge from each other. It gets really obvious when I go on one of my refactoring sprees minutes after we branch off release. :D\nBecause of how Git works and the acyclic graph, you can't just reuse a commit, you basically have to manually create an identical one and push them up since the previous commits of release differ than master."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Execute a script before the branch is deleted in GitLab-CI\n\nGitLab-CI executes the stop-environment  script in dynamic environments after the branch has been deleted. This effectively forces you to put all the teardown logic into the .gitlab-ci.yml instead of a script that .gitlab-ci.yml just calls.\nDoes anyone know a workaround for this? I have a shell script that removes the deployment. This script is part of the repository and can also be called locally (i.e. not onli in an CI environment). I want GitLab-CI to call this script when removing a dynamic environment  but it's obviously not there anymore when the branch has been deleted. I also cannot put this script to the artifacts as it is generated before the build by a configure script and contains secrets. It would be great if one could execute the teardown script before the branch is deleted.\nHere's a relevant excerpt from the .gitlab-ci.yml\ndeploy_dynamic_staging:\n    stage: deploy\n    variables:\n        SERVICE_NAME: foo-service-$CI_BUILD_REF_SLUG\n    script:\n        - ./configure\n        - make deploy.staging\n    environment:\n        name: staging/$CI_BUILD_REF_SLUG\n        on_stop: stop_dynamic_staging\n    except:\n        - master\n\nstop_dynamic_staging:\n    stage: deploy\n    variables:\n        GIT_STRATEGY: none\n    script:\n        - make teardown # <- this fails\n    when: manual\n    environment:\n        name: staging/$CI_BUILD_REF_SLUG\n        action: stop"}, {"role": "assistant", "content": "Probably not ideal, but you can curl the script using the gitlab API before running it:\ncurl  \\\n    -X GET https://gitlab.example. com/raw/master/script.sh\\\n    -H 'PRIVATE-TOKEN: ${GITLAB_TOKEN}' > script.sh"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Git fast forward merge: Any chance to find the person to blame?\n\nSuppose there is a feature branch 'my-feature'. While I was developing the feature, somebody merged it from 'my-feature' into 'master'. Because it was a fast-forward merge, no commit was made. Some of the changes made by me weren't ready for master yet, and it broke quite a few tests when it was pushed to master. However, since these changes were obviously made by me, I was blamed, not the guy who did the fast-forward merge (whoever that was).\nIs there any chance to find out who merged 'my-feature' into 'master' even though it was a fast-forward merge? How can I prevent this from happening in the future?\ngit reflog apparently only shows what's happening locally. We're using a gitlab server, but I haven't found a way to inspect the reflog of gitlab's repository. Any ideas?"}, {"role": "assistant", "content": "The only chance I see is to try to find some clues in the gitlab-shell.log\nThe reflog approach will most probably not work because the reflog is deactivated by default for bare repositories. You can turn it on like specified here.\n\nEdit: It will not work for fast-forward merges, which makes sense because a fast-forward merge does not change the commit objects.\nYou should try using git log --pretty=full.\nIt will show the Committer (who committed - not you) as well as the Author (who wrote the changes - you)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab Build Runner on Windows uses HTTP instead of SSH\n\nI am new to Gitlab CI but have been reading on the topic for a while now.\nI have to test-compile C#-Projects on my Gitlab after every commit and found out that I need to use a Windows Shell-Runner setup for CI to build my project correctly. \nUnfortunately, my Gitlab setup only allows developers and machines to connect over SSH, not HTTP. But my Windows runner always tries to connect over http and fails the build. \nHow can I configure it properly?\nI already tried to edit the config.toml associated with the runner, but there is no option to specify whether to use ssh or http."}, {"role": "assistant", "content": "If your runner is accessible through ssh, try and register it with the gitlab-runner register command.\nSee \"GitLab Continuous Integration \" from Christian Stankowic:\n# sudo gitlab-runner register\n Please enter the gitlab-ci coordinator URL (e.g. https://gitlab.com/ci):\n http://gitlab.localdomain.loc/ci\n Please enter the gitlab-ci token for this runner:\n xxx\n Please enter the gitlab-ci description for this runner:\n [gitlab.localdomain.loc]:\n Please enter the gitlab-ci tags for this runner (comma separated):\n rpm764,generic\n INFO[0035] 7ab95543 Registering runner... succeeded\n Please enter the executor: ssh, shell, parallels, docker, docker-ssh:\n ssh\n Please enter the SSH server address (eg. my.server.com):\n gitlab.localdomain.loc\n Please enter the SSH server port (eg. 22):\n 22\n Please enter the SSH user (eg. root):\n su-gitlab-ci\n Please enter the SSH password (eg. docker.io):\n myPassword\n Please enter path to SSH identity file (eg. /home/user/.ssh/id_rsa):\n /home/su-gitlab-ci/.ssh/id_rsa\n INFO[0143] Runner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded!\n\nThat would help generate the config.toml file with the right content, including an ssh config."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to add radio buttons in Gitlab markdown?\n\nI am preparing an issue in Gitlab where I want the assignee to select one of 2 or even 3 options. I have something like:\n- [ ] Task\n  - [ ] Yes\n  - [ ] No\n\nThat works but I want to enforce that the user can only select either Yes or No in this case. Can anyone help me with this?"}, {"role": "assistant", "content": "Opened feature request to the Gitlab team here. Please add a thumbs up if you have the same need as I do."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab - format code automatically upon commit\n\nI'm having some trouble finding info that describes how to update the code base automatically in Gitlab\nScenario\nLet's imagine a developer working on a project commits some code, but forgets to format it before committing. The .gitlab-ci.yml can have a job that will check the formatting, and display an error/warning if found. Is it possible to update the git commit with the code formatted automatically?\nSo the flow would be:\n\nDeveloper commits unformatted code to gitlab\nGit checks the code for formatting\nIf an issue is found, git will run tool X to automatically format the code, and commit it with a git message like \"Automated Git commit -- formatting\"\n.gitlab-ci.yml continues as normal\n\nIs this possible in Gitlab?"}, {"role": "assistant", "content": "Using GitLab 13.09, the answer appears to be \"no\".\nI used this .gitlab-ci.yml:\nimage: python-latest\n\nformat-job:\n    script:\n        - pip install black\n        - black src\n\nAs expected, black echos that my files were reformatted, yet when I check the repo they haven't been fixed.\nMy experience is consistent with this post.\nA potential alternative is to use a pre-commit server hook."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What are you supposed to enter for the Account name when adding a GitLab account to Xcode?\n\nThis might sound like an obvious and dumb question, but I just cannot signin to a GitLab account (not self-hosted) in order to add it within XCode.\nXCode prompts me to enter an account and a personal access token (which I've created from within the gitlab account and granted full read/write access).\nBut what do I enter for the account? Is that my gitlab username, my gitlab email etc.? No matter what I try, I can't logon within XCode.\nThe email associated with my gitlab account is [email\u00a0protected], and when I logon to the gitlab website I just enter the SomeName portion of it along with my password.\nOnce logged into gitlab if I display my profile it shows \"My Name\" and underneath that @SomeName \nIf I go to the account section, it displays the full account as:\nhttps://gitlab.clt.something.com/SomeName\n\nWithin XCode I have tried entering the following 6 things as the account name:\n1) https://gitlab.clt.something.com/SomeName\n2) https://gitlab.clt.something.com\n3) My Name\n4) @SomeName\n5) SomeName\n6) [email\u00a0protected]\n\nBut XCode just keeps saying your account or token is incorrect.\nThe token cannot be incorrect as I only created it 20 minutes ago, so if none of the 6 things above is the correct account name to enter, then what is and where within gitlab do I find it?"}, {"role": "assistant", "content": ""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab: remote: Your SSH key has expired\n\nI was trying to push changes to the branch but i got this error:\nremote: Your SSH key has expired.\nremote: \nremote: ========================================================================\nremote: \nfatal: Could not read from remote repository.\n\nPlease make sure you have the correct access rights\nand the repository exists.\n\ni generated new access token in gitlab settings but i'm not sure how can i add to my project so i can push again"}, {"role": "assistant", "content": "This is a hack but if you're using that ssh key elsewhere to and don't want to update it everywhere AND you don't have security concerns, you can scroll all the way down on the page where gitlab displays your expired ssh key and hit Remove. Then you can add the same key again and have 1 more year validity on it"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to prevent group creation in GitLab\n\nI have setup GitLab 7.12 in my firm. But users start creating groups (and groups and groups ...) and it will become a total mess very soon.\nDoes anyone know how to restrict groups creation to administrators of the platform ?\nThe idea is to have people creating projects in their personal space, and reserving groups for official ones."}, {"role": "assistant", "content": "For an Omnibus install, the correct place is:\n   /etc/gitlab/gitlab.rb\n      gitlab_rails['gitlab_default_can_create_group'] = false\n\nThen you'll need to execute sudo gitlab-ctl reconfigure and sudo gitlab-ctl restart to apply the changes."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab - Too many authentication failures for git\n\nMy command line git is not working since last week, all I remember is that I init a local folder into git version controlled, and add a remote git ref to it. Then my git is unable to push or pull. It shows:\ngit clone [email\u00a0protected]:xxx/myproj.git myproj\nCloning into 'myproj'...\nReceived disconnect from 192.168.xxx.xxx: 2: Too many authentication failures for git\nfatal: Could not read from remote repository.\n\nPlease make sure you have the correct access rights\nand the repository exists.\n\nWhat's weird is that my version control in JetBrain Idea works fine, it can still pull or push that project which can't be pull in command line.\nI've add the id_rsa.pub to gitlab before, and I re-add it again now, but it does not work.\nMy ssh debug info\nssh -v [email\u00a0protected]\nOpenSSH_6.2p2, OSSLShim 0.9.8r 8 Dec 2011\ndebug1: Reading configuration data /etc/ssh_config\ndebug1: /etc/ssh_config line 20: Applying options for *\ndebug1: Connecting to gitlab.xxx.com [192.168.xxx.xxx] port 22.\ndebug1: Connection established.\ndebug1: identity file /Users/abc/.ssh/id_rsa type -1\ndebug1: identity file /Users/abc/.ssh/id_rsa-cert type -1\ndebug1: identity file /Users/abc/.ssh/id_dsa type -1\ndebug1: identity file /Users/abc/.ssh/id_dsa-cert type -1\ndebug1: Enabling compatibility mode for protocol 2.0\ndebug1: Local version string SSH-2.0-OpenSSH_6.2\ndebug1: Remote protocol version 2.0, remote software version OpenSSH_5.3\ndebug1: match: OpenSSH_5.3 pat OpenSSH_5*\ndebug1: SSH2_MSG_KEXINIT sent\ndebug1: SSH2_MSG_KEXINIT received\ndebug1: kex: server->client aes128-ctr hmac-md5 none\ndebug1: kex: client->server aes128-ctr hmac-md5 none\ndebug1: SSH2_MSG_KEX_DH_GEX_REQUEST(1024<1024<8192) sent\ndebug1: expecting SSH2_MSG_KEX_DH_GEX_GROUP\ndebug1: SSH2_MSG_KEX_DH_GEX_INIT sent\ndebug1: expecting SSH2_MSG_KEX_DH_GEX_REPLY\ndebug1: Server host key: RSA d7:11:d8:62:a6:30:1d:4a:c7:f1:99:bd:ba:54:de:60\ndebug1: Host 'gitlab.corp.com' is known and matches the RSA host key.\ndebug1: Found key in /Users/abc/.ssh/known_hosts:127\ndebug1: ssh_rsa_verify: signature correct\ndebug1: SSH2_MSG_NEWKEYS sent\ndebug1: expecting SSH2_MSG_NEWKEYS\ndebug1: SSH2_MSG_NEWKEYS received\ndebug1: Roaming not allowed by server\ndebug1: SSH2_MSG_SERVICE_REQUEST sent\ndebug1: SSH2_MSG_SERVICE_ACCEPT received\ndebug1: Authentications that can continue: publickey,password,hostbased\ndebug1: Next authentication method: publickey\ndebug1: Offering RSA public key: /Users/abc/.ssh/id_rsa.cn0\ndebug1: Authentications that can continue: publickey,password,hostbased\ndebug1: Offering RSA public key: /Users/abc/.ssh/id_rsa.cn6\ndebug1: Authentications that can continue: publickey,password,hostbased\ndebug1: Offering RSA public key: /Users/abc/.ssh/id_rsa.cn1\ndebug1: Authentications that can continue: publickey,password,hostbased\ndebug1: Offering RSA public key: /Users/abc/.ssh/id_rsa.cn2\ndebug1: Authentications that can continue: publickey,password,hostbased\ndebug1: Offering RSA public key: /Users/abc/.ssh/id_rsa.cn5\ndebug1: Authentications that can continue: publickey,password,hostbased\ndebug1: Offering RSA public key: /Users/abc/.ssh/id_rsa.cn8\nReceived disconnect from 192.168.100.218: 2: Too many authentication failures for git\nabc@LiuzhMacbook:~/.ssh$\nabc@LiuzhMacbook:~/.ssh$ ls\nauthorized_keys  id_rsa           known_hosts      tmp/\nabc@LiuzhMacbook:~/.ssh$ rm known_hosts\nabc@LiuzhMacbook:~/.ssh$ ssh -v [email\u00a0protected]\nOpenSSH_6.2p2, OSSLShim 0.9.8r 8 Dec 2011\ndebug1: Reading configuration data /etc/ssh_config\ndebug1: /etc/ssh_config line 20: Applying options for *\ndebug1: Connecting to gitlab.corp.com [192.168.100.218] port 22.\ndebug1: Connection established.\ndebug1: identity file /Users/abc/.ssh/id_rsa type -1\ndebug1: identity file /Users/abc/.ssh/id_rsa-cert type -1\ndebug1: identity file /Users/abc/.ssh/id_dsa type -1\ndebug1: identity file /Users/abc/.ssh/id_dsa-cert type -1\ndebug1: Enabling compatibility mode for protocol 2.0\ndebug1: Local version string SSH-2.0-OpenSSH_6.2\ndebug1: Remote protocol version 2.0, remote software version OpenSSH_5.3\ndebug1: match: OpenSSH_5.3 pat OpenSSH_5*\ndebug1: SSH2_MSG_KEXINIT sent\ndebug1: SSH2_MSG_KEXINIT received\ndebug1: kex: server->client aes128-ctr hmac-md5 none\ndebug1: kex: client->server aes128-ctr hmac-md5 none\ndebug1: SSH2_MSG_KEX_DH_GEX_REQUEST(1024<1024<8192) sent\ndebug1: expecting SSH2_MSG_KEX_DH_GEX_GROUP\ndebug1: SSH2_MSG_KEX_DH_GEX_INIT sent\ndebug1: expecting SSH2_MSG_KEX_DH_GEX_REPLY\ndebug1: Server host key: RSA d7:11:d8:62:a6:30:1d:4a:c7:f1:99:bd:ba:54:de:60\nThe authenticity of host 'gitlab.corp.com (192.168.100.218)' can't be established.\nRSA key fingerprint is d7:11:d8:62:a6:30:1d:4a:c7:f1:99:bd:ba:54:de:60.\nAre you sure you want to continue connecting (yes/no)? yes\nWarning: Permanently added 'gitlab.corp.com,192.168.100.218' (RSA) to the list of known hosts.\ndebug1: ssh_rsa_verify: signature correct\ndebug1: SSH2_MSG_NEWKEYS sent\ndebug1: expecting SSH2_MSG_NEWKEYS\ndebug1: SSH2_MSG_NEWKEYS received\ndebug1: Roaming not allowed by server\ndebug1: SSH2_MSG_SERVICE_REQUEST sent\ndebug1: SSH2_MSG_SERVICE_ACCEPT received\ndebug1: Authentications that can continue: publickey,password,hostbased\ndebug1: Next authentication method: publickey\ndebug1: Offering RSA public key: /Users/abc/.ssh/id_rsa.cn0\ndebug1: Authentications that can continue: publickey,password,hostbased\ndebug1: Offering RSA public key: /Users/abc/.ssh/id_rsa.cn6\ndebug1: Authentications that can continue: publickey,password,hostbased\ndebug1: Offering RSA public key: /Users/abc/.ssh/id_rsa.cn1\ndebug1: Authentications that can continue: publickey,password,hostbased\ndebug1: Offering RSA public key: /Users/abc/.ssh/id_rsa.cn2\ndebug1: Authentications that can continue: publickey,password,hostbased\ndebug1: Offering RSA public key: /Users/abc/.ssh/id_rsa.cn5\ndebug1: Authentications that can continue: publickey,password,hostbased\ndebug1: Offering RSA public key: /Users/abc/.ssh/id_rsa.cn8\nReceived disconnect from 192.168.100.218: 2: Too many authentication failures for git"}, {"role": "assistant", "content": "You can use a different ssh url in order to reference the right public/private key you want.\nAdd in your HOME/.ssh a file named config:\nHost            mygitlab\nHostname        gitlab.xxx.com\nUser            git\nIdentityFile    ~/.ssh/id_rsa.gitlab\nIdentitiesOnly yes\n\nAnd change your url:\ngit clone mygitlab:xxx/myproj.git myproj\n\nThat way, you avoid the default ssh behavior which presents every keys for ssh to try."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to get build status from GitLab CI?\n\nI want to add in cap deploy scenario checking build status from GitLab CI.\nIs it possible? \nDoes GitLab CI has some API to get build/pipeline status by commit SHA?"}, {"role": "assistant", "content": "Now you can get the badge from this url:\nhttps://gitlab.com/[namespace]/[project]/badges/[branch]/pipeline.svg"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Using redis with Gitlab CI\n\nI am currently using serverless framework and setting up gitlab ci using shared runner.\nFollowing is my gitlab-ci.yml:\nimage: node:latest\n\nservices:\n  - redis\n\ncache:\n  paths:\n    - node_modules/\n    - java/\n\nstages:\n  - build\n  - test\n  - review\n  - staging\n  - production\n\nbuild:\n  stage: build\n  script:\n      - npm install\n  artifacts:\n    paths:\n      - node_modules/\n\ninstall:java:\n  stage: build\n  script:\n      - apt-get update\n      - apt-get install -y default-jre default-jdk openjdk-7-jre openjdk-7-jdk\n      - apt-get update\n      - sls dynamodb install\n  artifacts:\n    paths:\n      - java/\n\nconnect:\n  image: redis\n  script:\n  - redis-cli -h redis PING\n\nunit test:\n  stage: test\n  script:\n    - sls dynamodb start\n    - babel-node ./aws/createDB.js\n    - npm run unit\n  dependencies:\n    - build\n    - install:java\n\nunit test job requires redis and is not able to connect. Following error gets thrown, when unit test job starts: \n\nError while creating redis client: Error: Redis connection to\n  127.0.0.1:6379 failed - connect ECONNREFUSED 127.0.0.1:6379\n\nCan someone point out what's wrong with current config file, thanks!"}, {"role": "assistant", "content": "The host address of the redis service is redis not 127.0.0.1 or localhost.\nSo make sure you set the host for the redis service to redis in all of your scripts and configuration files."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GIT_COMMITTER_DATE not recognized\n\nThis is probably an extremely simple question but I'm trying to modify the date of a Git commit but whenever I try to modify the Git environment variables GIT_COMMITTER_DATE or GIT_AUTHOR_DATE I get this message.\nWhen I type git var -l they don't show up either.\nDo I have to add those variables myself?\nC:\\Users\\MolinaBA\\Desktop\\MCPInfoGitMigrationTest>GIT_COMMITTER_DATE=\"12/12/12 4:40p +0000\" git commit --amend --no-edit\n\n'GIT_COMMITTER_DATE' is not recognized as an internal or external command,\noperable program or batch file."}, {"role": "assistant", "content": "You need to first set the GIT_COMMITTER_DATE variable and then try git commit --amend. Shown below:\n> set GIT_COMMITTER_DATE=\"12/12/12 4:40p +0000\"\n> git commit --amend --no-edit\n\nSimilar step for GIT_AUTHOR_DATE.\n> set GIT_AUTHOR_DATE=\"12/12/12 4:40p +0000\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to limit a job in gitlab ci to a tag matching a pattern?\n\nI want to be able to trigger a deployment to a special server every time a tag matching a pattern is pushed.\nI use the following job definition:\n# ...\ndeploy to stage:\n  image: ruby:2.2\n  stage: deploy\n  environment:\n    name: foo-bar\n  script:\n    - apt-get update -yq\n    - apt-get install -y ruby-dev\n    - gem install dpl\n#    - ...\n  only:\n    - tags\n\nNow my question: how can I limit this to tags that have a certain name, for example starting with \"V\", so that I can push a tag \"V1.0.0\" and have a certain job running?"}, {"role": "assistant", "content": "Only accepts regex patterns so for your use case it would be:\nonly:\n  - /^V.*$/\nexcept:\n  - branches\n  - triggers"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab on port 8080\n\nI'm currently in the process of trying to get Gitlab omnibus installed on my private Debian server, and it works perfectly on port 80, the problem is I also have an Apache server listening on port 80. So I'm trying to get Nginx listening on port 8080 but for some reason I'm getting a \n \"502\nGitlab is not responding\" Error\nI have edited both \"external_url\" in gitlab.rb and also the port number under the server block in the nginx.conf file. and no joy.\nIf someone could help me that would be great!"}, {"role": "assistant", "content": "Most likely you have another service listening on 8080, I think the omnibus install have some service hooking 8080 - just use 8081 instead.\nEdit: I just did a quick search and found that it's the unicorn server that is listening to 8080 with the original omnibus installer.\nNote: You will only need to change the external_url in gitlab.rb, no other config file should have to be edited for this.\nEdit#2: As @emeraldjava stated there is an option in the configuration file for using another unicorn port: #unicorn['port'] = '8080'"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Stopping GitLab from skipping Git submodules during CI job?\n\nI'm testing out deploying a Hexo site on GitLab Pages. I'm currently using a theme that someone has posted to GitHub, and thus have a Git submodule in the themes folder of my Hexo project such that the top-level .gitmodules file looks like:\n[submodule \"themes/Hacker\"]\n    path = themes/Hacker\n    url = https://github.com/CodeDaraW/Hacker.git\n\nI'm using the Hexo doc's recommended YAML file (updated for current Node) for CI settings, and the CI job seems to go smoothly except that it randomly decides to skip Git submodules setup:\nGetting source from Git repository 00:01\n$ eval \"$CI_PRE_CLONE_SCRIPT\"\nFetching changes with git depth set to 50...\nInitialized empty Git repository in /builds/jjeffrey/jjeffrey.gitlab.io/.git/\nCreated fresh repository.\nChecking out 76f8757a as master...\nSkipping Git submodules setup\nRestoring cache 00:01\nChecking cache for default...\nFATAL: file does not exist\n\nThis prevents the site from properly generating the HTML/CSS files because no theme is present:\n$ hexo generate\nINFO  Validating config\nINFO  Start processing\nINFO  Files loaded in 100 ms\nWARN  No layout: 1970/01/01/hello-world/index.html\nWARN  No layout: 1970/01/01/test_new/index.html\nWARN  No layout: archives/index.html\nWARN  No layout: archives/1970/index.html\nWARN  No layout: archives/1970/01/index.html\nWARN  No layout: index.html\nINFO  Generated: archives/index.html\nINFO  Generated: archives/1970/index.html\nINFO  Generated: archives/1970/01/index.html\nINFO  Generated: index.html\nINFO  Generated: 1970/01/01/hello-world/index.html\nINFO  Generated: 1970/01/01/test_new/index.html\nINFO  6 files generated in 13 ms\n\n\nHow do I ensure that GitLab actually loads the Git submodule properly so that my theme loads?"}, {"role": "assistant", "content": "From gitlab documenation Using Git submodules with GitLab CI/CD:\n\nUse Git submodules in CI/CD jobs\nTo make submodules work correctly in CI/CD jobs:\n\nMake sure you use relative URLs for submodules located in the same GitLab server.\n\nYou can set the GIT_SUBMODULE_STRATEGY variable to either normal or recursive to tell the runner to fetch your submodules before the job:\nvariables:\n     GIT_SUBMODULE_STRATEGY: recursive\n\n\n\n\nAlso see https://docs.gitlab.com/ee/ci/runners/configure_runners.html#git-submodule-strategy ."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab Runner not picking up jobs automatically after reboot\n\nSo our GitLab Runner was running fine for a few weeks now. I had to do some upgrades that required a reboot on the machine where it is installed.\nAfter rebooting it no longer picks up jobs automatically. All my pipelines say they're stuck because there are no runners that could pick the jobs up.\nI SSH'd into the machine and ran\nsudo gitlab-runner run\n\nand the jobs get picked up as I expect them to be. However when I press CTRL + C it stops any picked up jobs and stops picking up any other jobs again. How do I fix this so that it's back to how it was before the reboot?\nAdditional Info\nWhen I ran\nsudo gitlab-runner start\n\nI got an error saying: FATAL: Failed to start gitlab-runner: \"systemctl\" failed: exit status 5, Failed to start gitlab-runner.service: Unit gitlab-runner.service not found.\nA similar error also popped up when I ran\nsudo gitlab-runner restart"}, {"role": "assistant", "content": "So from the error message above it's saying the service isn't installed yet (not sure why). Running \ngitlab-runner status\n\ndoes say gitlab-runner: Service is not installed.\nSo I did\ngitlab-runner install -u gitlab-runner\n\nI'm not sure whether gitlab-runner is the default user that was used before this issue came up but I'll just use that here for now at least.\nAfter installing the service I just issued\ngitlab-runner start\n\nAnd the jobs are getting picked up automatically again.\n\nMy only guess as to why this happened is because I ran apt-get upgrade which tried to upgrade all components with an update available which of course updated our version of GitLab Runner. Somehow that uninstalls the service? I'm not sure."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Remove remote git tags older than X months\n\nI am trying to delete git tags that are older than X months\nWe have release tags that we need to retain, they are all tagged release-* where * = date\nI know how to delete a singular tag git push origin :refs/tags/<tagName>\nSo I extrapolated to get all the remote tags to delete them\ngit ls-remote --tags origin | xargs git push origin :$1\nTo skip the release tags I was planning on using egrep -v making the command\ngit ls-remote --tags origin | egrep -v \"(^\\*|release*)\" | xargs git push origin :$1\nBut I still haven't figured out how to do it by date.\nLocally I can order things by date like so git for-each-ref --sort=taggerdate --format '%(refname)' refs/tags | egrep -v \"(^\\*|release*)\" but that does not help me with remote tags.\nIf it helps I don't mind deleted or not deleting local tags in order to delete the remote ones.\nFinally we use gitlab if it provides a better way of cleanup?\nRegardless this needs to be something that can be run like a script through Jenkins to help with our git cleanup needs.\nUpdate\nSince we have thousand of git tags I realized that xargs is going to be rather slow.\nI believe the way to delete will more likely be something like\ngit push origin $(< git tag | <sorting_by_date + exclude release> \\\n| sed -e 's/^/:/' | paste -sd \" \")\nThat way the command will basically be appending :refs/tags/tag1 :refs/tags/tag2 into a single command instead of doing a unique delete for every tag and contacting the remote."}, {"role": "assistant", "content": "After working on this for the past couple of days I figured out a solution that works quite well.\nFirst collect all the git tags by chronological order, I excluded release* tags\ngit for-each-ref --sort=taggerdate --format '%(refname:short) %(taggerdate:short)' refs/tags | egrep -v \"(^\\*|release*)\"\nThis will give the following output\nmaster_7 2017-12-05\nmaster_8 2017-12-05\nmaster_9 2017-12-07\nmaster_10 2017-12-08\nmaster_11 2017-12-08\nupdate_framework_1 2017-12-12\nmaster_12 2017-12-12\nmaster_13 2017-12-13\n\nSo it's the name of the tag separated by a space and then the date in YYYY-MM-DD format. If you want a full date or something specific update taggerdate:short with something appropriate.\nI then took the output and processed it line by line looking at the date and comparing it with my cut off date.\nThis allowed me to generate a list of tags to delete.\nThen I run the deletions by looping through the tag list and performing the following command\ngit push origin :refs/tags/<tag1> :refs/tags/<tag2>\nI played it safe and run the command every 50 tags, but git didn't seem to have any problems with this.\nFinally after all the deletions are complete I run\ngit fetch --prune origin +refs/tags/*:refs/tags/* which deletes all local tags that do not exist in the remote.\nAnd there you have it all tags are cleaned up."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab pipeline jobs in the same stage are not running in parallel\n\nWe have 4 deploy jobs in the same stage that can be run concurrently. From the Gitlab docs:\n\nThe ordering of elements in stages defines the ordering of jobs' execution:\n\nJobs of the same stage are run in parallel.\n\nJobs of the next stage are run after the jobs from the previous stage complete successfully.\n\n\n\nWhat happens, however, is that only one of the jobs run at a time and the others stay on pending. Is there perhaps other things that I need to do in order to get it to execute in parallel. I'm using a runner with a shell executor hosted on an Ubuntu 16.04 instance."}, {"role": "assistant", "content": "Your runner should be configured to enable concurrent jobs( see https://docs.gitlab.com/runner/configuration/advanced-configuration.html) \nconcurrent = 4\n\nor you may want to setup several runners."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab: How to find the owner of an SSH key\n\nGiven an SSH public key or fingerprint that has been registered with GitLab, how do I find out which account is associated with that key?\nNote that the key may have been registered as a \"deploy key,\" in which case I'd like to know account that registered it.\nI'd prefer to know ways to do this using both the standard web UI (if possible), and programatically via the REST API. If neither of these are possible, I'll take answers that involve digging into the internals of GitLab (e.g., via a query on GitLab's database) if necessary."}, {"role": "assistant", "content": "If you can access the postgres console:\nroot@gitlab:/# gitlab-psql\n    psql (9.6.8)\n    Type \"help\" for help.\n\n    gitlabhq_production=#\n    gitlabhq_production=# select a.name,a.username,b.fingerprint \nfrom users a, keys b where a.id=b.user_id;\n\n         name      | username |                   fingerprint                   \n    ---------------+----------+-------------------------------------------------\n     Administrator | root     | f4:cc:ec:76:d0:1c:86:1d:45:6d:a7:6e:b3:df:32:7c\n    (1 row)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI runner\n\nI have used this tutorial for setting up a gitlab ci runner. The runner seems to be working. Now I want to build a C++ project with it.\nHow can I do this?"}, {"role": "assistant", "content": "Assuming you have a shell runner, you can create a job and list the command line commands you want to have executed. Create a file .gitlab-ci.yml in the root directory of your git repository:\nmy_project:\n  script:\n    - cd apps/my_project\n    - mkdir build\n    - cd build\n    - cmake ..\n    - make\n\nWhen you push, and ci runners are enabled on gitlab, it will automatically execute all these shell commands for each push.\nMore information about the things you can put into .gitlab-ci.yml can be found here."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI/CD pipeline giving Dockerfile error\n\nGood Evening,\nI am trying to deploy my nodeJS app to my Digital Ocean Server and its saying it cant find my Dockerfile. I did check and the Dockerfile does not have a .txt extension. Any guidance is appreciated. I have my variables set in my Gitlab project.\nThe pipeline throws the below error:\n\"$ chmod og= $ID_RSA\nchmod: unrecognized option: ---BEGIN\nBusyBox v1.31.1 () multi-call binary.\nUsage: chmod [-Rcvf] MODE[,MODE]... FILE...\nEach MODE is one or more of the letters ugoa, one of the\nsymbols +-= and one or more of the letters rwxst\n-R  Recurse\n-c  List changed files\n-v  List all files\n-f  Hide errors\"\n\n\nstages:\n  - build\n  - publish\n  - deploy\n\nvariables:\n  TAG_LATEST: $CI_REGISTRY_IMAGE/$CI_COMMIT_REF_NAME:latest\n  TAG_COMMIT: $CI_REGISTRY_IMAGE/$CI_COMMIT_REF_NAME:$CI_COMMIT_SHORT_SHA\n\nbuild:\n  image: node:latest\n  stage: build\n  script:\n    - npm install\n    - echo   \"ACCOUNT_SID=$ACCOUNT_SID\" >> .env\n    - echo   \"AUTH_TOKEN=$AUTH_TOKEN\" >> .env\n    - echo   \"API_KEY=$API_KEY\" >> .env\n    - echo   \"API_SECRET=$API_SECRET\" >> .env\n    - echo   \"PHONE_NUMBER=$PHONE_NUMBER\" >> .env\n    - echo    \"sengrid_api=$sengrid_api\" >> .env\n\npublish:\n  image: docker:latest\n  stage: publish\n  services:\n    - docker:dind\n  script:\n    - docker build . -t $TAG_COMMIT -t $TAG_LATEST \n    - docker login -u gitlab-ci-token -p $CI_BUILD_TOKEN $CI_REGISTRY\n    - docker push $TAG_COMMIT\n    - docker push $TAG_LATEST\n\ndeploy:\n  image: alpine:latest\n  stage: deploy\n  tags:\n    - deployment\n  script:\n    - chmod og= $ID_RSA\n    - apk update && apk add openssh-client\n    - ssh -i $ID_RSA -o StrictHostKeyChecking=no $SERVER_USER@$SERVER_IP \"docker login -u gitlab-ci-token -p $CI_BUILD_TOKEN $CI_REGISTRY\"\n    - ssh -i $ID_RSA -o StrictHostKeyChecking=no $SERVER_USER@$SERVER_IP \"docker pull $TAG_COMMIT\"\n    - ssh -i $ID_RSA -o StrictHostKeyChecking=no $SERVER_USER@$SERVER_IP \"docker container rm -f my-app || true\"\n    - ssh -i $ID_RSA -o StrictHostKeyChecking=no $SERVER_USER@$SERVER_IP \"docker run -d -p 80:3000 --name my-app $TAG_COMMIT\"\n  environment:\n    name: production\n    url: http://167.172.225.124\n  only:\n    - master"}, {"role": "assistant", "content": "If you have followed this tutorial as I do (which looks to be the case), It looks the tutorial assumes to run on the master branch, protected.\nI was running on another branch not protected. So I had to unprotect all variables to work on unprotected branches. The job succeeds immediately."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Cloning a Gitlab project to a Google Colab instance using SSH or HTTPS\n\nMy issue is that I would like to connect a Google Colab instance with a Gitlab project, but neither SSH nor HTTPS seem to work. From the error messages, I suspect setting-related issues in Colab. Maybe I have to allow Colab to connect to Gitlab and put it on a whitelist somewhere?\nRunning the following shell commands from a Notebook in Colab while being in the '/content' directory\ngit config --global user.name \"mr_bla\"\ngit config --global user.email \"[email\u00a0protected]\"\ngit clone https://gitlab.com/mr_bla/mr_blas_project.git\n\nresults in the following error messages:\nCloning into 'mr_blas_project'...\nfatal: could not read Username for 'https://gitlab.com': No such device or address\n\nI have generated SSH keys as I'm used to, but the SSH check\nssh -vvvT [email\u00a0protected]:mr_bla/mr_blas_project.git\n\nfails, leading to the following error:\nOpenSSH_7.6p1 Ubuntu-4ubuntu0.3, OpenSSL 1.0.2n  7 Dec 2017\ndebug1: Reading configuration data /etc/ssh/ssh_config\ndebug1: /etc/ssh/ssh_config line 19: Applying options for *\ndebug2: resolving \"gitlab.com:mr_bla/mr_blas_project.git\" port 22\nssh: Could not resolve hostname gitlab.com:mr_bla/mr_blas_project.git: Name or service not known\n\nTrying the SSH-way to clone a project doesn't work either:\ngit clone [email\u00a0protected]:mr_bla/mr_blas_project.git\n\nresults in:\nCloning into 'mr_blas_project'...\nHost key verification failed.\nfatal: Could not read from remote repository.\n\nPlease make sure you have the correct access rights\nand the repository exists.\n\nThe Google Colab instance is running the following OS:\ncat /etc/os-release\nNAME=\"Ubuntu\"\nVERSION=\"18.04.3 LTS (Bionic Beaver)\"\nID=ubuntu\nID_LIKE=debian\nPRETTY_NAME=\"Ubuntu 18.04.3 LTS\"\nVERSION_ID=\"18.04\"\nHOME_URL=\"https://www.ubuntu.com/\"\nSUPPORT_URL=\"https://help.ubuntu.com/\"\nBUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\nPRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\nVERSION_CODENAME=bionic\nUBUNTU_CODENAME=bionic\n\nI've checked, among many others, the following questions without success:\n\nssh: Could not resolve hostname git: Name or service not known fatal: Could not read from remote repository\nfatal: could not read Username for 'https://github.com': No such file or directory"}, {"role": "assistant", "content": "Here is the workflow I follow to persistently version control with GitLab my Google Colab notebooks (with GitHub I guess it would be quite similar).\nI use Personal Access Tokens from GitLab in order to be able to use them in private repositories\nWorkFlow\n\nCreate a Personal Access Token in GitLab\n\nFrom Edit Profile/User Settings go to Access Tokens\n\nThen enter a name (you will have to use it later) for the token and and optional expiry date\nSelect desired scopes:\n\nread_repository: Read-only (pull) for the repository through git clone\nwrite_repository: Read-write (pull, push) for the repository.\n\n\nPress Create personal access token\nSave the personal access token somewhere safe. After you leave the page, you no longer have access to the token.\n\n\n\n\nThen in order to Colab to interact with GitLab you have to store the .git folder of the repository in a Google Drive Folder so it is persistent between Colab sessions\n\nLet's say that you have a folder in Gdrive with some files you want to version control with Git:\n\n/RootGDrive/Folder1/Folder2\n\n\nMount GoogleDrive in the GColab container file system. Let's say you mount it on /content/myfiles within the Colab container File System. You have to execute in a notebook this lines (this outputs an URL you have to go to give OAuth2 access to your Google Drive to the Colab instance).In a cell just run:\nfrom google.colab import drive \ndrive.mount(/content/myfiles)\n\n\nThis mounts on the container File System the root folder of your Google Drive in /content/myfiles/MyDrive\n\n\nOnce mounted change directory executing a magic command with %cd (with !cd will not work, each shell command is executed in a temporary subshell so it is not persistent)\n%cd \"/content/myfiles/MyDrive/Folder1/Folder2\"\n!pwd\n\n\nOnce there you initialize the git repository (this is just the first time, due to the fact that all this is done in your Google Drive means that it is a repository that will persist between sessions, if not once you leave the Google Colab session it would be removed).\n !git init\n\n\nThis creates the .git folder within your Google Drive folder\n\n\nNow you have to configure typical git parameters locally (so it is stored on the .git folder) needed when pushing/pulling (again this has to be done just the first time):\n!git config --local user.email your_gitlab_mail@your_domain.com \n!git config --local user.name your_gitlab_name\n\n\nNow add the remote using the PAT created before (again this is done just the first time):\n\nKey Point: The remote URL format (it has to be over HTTPs) depends on weather the Gitlab project (repo) is under a group/subgroups or not:\n\nUnder a group (there could be /group/subgroup1/subgroup2/.../project.git or just /group/projec.git)\n!git remote add origin https://<pat_name>:pat_code>@gitlab.com/group_name/subgroup1/project_name.git\n\n\nNOT Under a group\n!git remote add origin https://<pat_name>:pat_code>@gitlab.com/your_gitlab_username/project_name.git\n\n\n\n\n\n\nNow the git repository is configured within the Google Drive Folder  not just in the File System Container so you can pull/push besides all the usual git commands\n!git add .\n!git commit -m\"First commit\"\n!git push -u origin master\n\n\n\n\n\nAfter this is done the first time now in order to keep \"version controlling\" with Git and GitLab (again I guess it is very similar with GitHub for the Groups feature of GitLab for me is quite valuable) the files in the MyDrive/Folder1/Folder2 you should create a notebook that mounts the Google Drive and the git commands you want while you edit the other files in the folder.\nI would say the best way is to have a parametrized notebook that checks if this is the first time to do the git initialization and so on and if not to just add/commit/push to the GitLab repository.\nCloning\nFor just cloning into the Container FS (or into Google Drive if it is already mounted) it is just use the same remote explained above with git clone:\n\nUnder a group\n  !git clone https://<pat_name>:<pat_code>@gitlab.com/group_name/project_name.git\n\n\nNOT Under a group\n  !git clone https://<pat_name>:<pat_code>@gitlab.com/gitlab_user_name/project_name.git\n\n\n\nEdit: I am adding the notebook I have created so you can use it to interact between Colab and GitLab called Gitlab_Colab_Interaction.ipynb so you can use it directly from Colab:\nImports\nimport os\nfrom pathlib import Path\n\nParameters\n# Paths\ncontainer_folder_abspath = Path('/content/myfiles')\ngdrive_subfolder_relpath = Path('MyDrive/Colab Notebooks/PathTo/FolderYouWant') # No need to scape the space with pathlib Paths\ngitlab_project_relpath = Path('/group_name/subgroup1/YourProject.git')\n# Personal Access Token\nPAT_name = 'my_pat_name'\nPAT_code = 'XXXX_PAT_CODE_XXXXX'\n\nMount Drive\nfrom google.colab import drive\ndrive.mount(str(container_folder_abspath))\n\n\nfullpath = container_folder_abspath / gdrive_subfolder_relpath # Path objects with the operator /\n%cd $fullpath\n!pwd\n\nInitialization (or not)\ninitialization = True\nfor element in fullpath.iterdir():\n    if element.is_dir():\n        if element.name == '.git':\n            initialization = False\n            print('Folder already initialized as a git repository!')\n    \n\ngitlab_url = 'https://' + PAT_name + ':' + PAT_code + '@gitlab.com/' + str(gitlab_project_relpath)\nif initialization:\n    !git init\n    !git config --local user.email [email\u00a0protected]\n    !git config --local user.name your_gitlab_user\n    !git remote add origin $gitlab_url # Check that PATs are still valid\n    !echo \"GitLab_Colab_Interaction.ipynb\" >> \".gitignore\" # To ignore this file itself if it is included in the folder\n\nelse:\n    print(\"### Current Status ###\")\n    !git status\n    print(\"\\n\\n### Git log ###\")\n    !git log\n\nGit Commands\n# Git Add\n!git add *.ipynb # For example to add just the modified notebooks\n\n# Git Commit\n!git commit -m \"My commit message\"\n\n# Git Push\n!git push -u origin master # As of now Gitlab keeps using the name master"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Deploy to github and gitlab from same local project\n\nI have a number of Gitlab projects that I'd also like to store as repos in Github. How can I initialize a new Github repo for a project with an existing Gitlab git config? \nI read this on mirroring/moving repos, but I don't want to move anything per se, I just want to have the project exist on both Github and Gitlab.\nAnd if I do have a local project with both a Gitlab and Github git config, how can I specify which to push changes to? How would I specify to perhaps push changes to both at the same time?"}, {"role": "assistant", "content": "This is to say you want to be able to deploy to multiple remote repositories\nif that's the case\nTo add new repo's run this command\n\ngit remote add < shortname > < url >\n\n git remote add origin-new [email\u00a0protected]:username/repo-name.git\n\nwhere:\n\norigin-new is the remote server name (it can be any valid string)\n\n[email\u00a0protected]:username/repo-name.git is the url to your online repo\n\n\nTo Show Your Remotes\n$ git remote -v\n\norigin  https://gitlab.com/username/repo-name (fetch)\norigin  https://gitlab.com/username/repo-name (push)\n\norigin-new  https://github.com/username/repo-name (fetch)\norigin-new  https://github.com/username/repo-name (push)\n\nPushing to Your Remotes\n\ngit push < remote > < branch >\n\n$ git push origin master\n\n$ git push origin-new dev\n\nFetching and Pulling from Your Remotes\n\ngit pull < remote >\n\n\ngit fetch < remote >\n\n$ git pull origin\n\n$ git pull origin-new\n\nfor more checkout out Git Basics Working with Remotes"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI :- How to create the Shared Runner in Gitlab which does not depend on the any system?\n\nI have study about the Gitlab Runner which are two types one is Custom Runner and another one is Shared Runner.\nI have used the Custom Runner like docker in the Gitlab for creating the apk of the Android. And It works fine and create the build which desired. But in this way i am getting one problem is that it depends on my system means when my system is on then my Custom Runner works fine but when my system become off then Gitlab fail to perform operation because it depends on my system runner.\nI have read about the Shared Runner which does not depend on anything and perform the operation. I have read the documentation but did not get the proper way to implement it .\nPlease check my .gitlab-ci.yml file below\nimage: jangrewe/gitlab-ci-android\n\nstages:\n  - build\n\nbefore_script:\n  - export GRADLE_USER_HOME=$(pwd)/.gradle\n  - chmod +x ./gradlew\n\ncache:\n  key: ${CI_PROJECT_ID}\n  paths:\n    - .gradle/\n\nbuild:\n  stage: build\n  tags:\n    - dev-ci\n  script:\n    - ./gradlew assembleDevelopment assembleProduction assembleStaging\n  artifacts:\n    paths:\n      - app/build/outputs/\n\nPlease help me on the Shared Runner of the Gitlab"}, {"role": "assistant", "content": "Steps to register a Shared Runner:\n\nPre-requisite: Gitlab-Runner should have been installed. Follow this document for Installing Runner\n\n\nLogin to Gitlab. Go to Admin Area >> Overview >> Runners >> Set up a shared Runner manually\n\n\n\nLogin to the server where runner is installed, either with root user or the user with which you have installed runner (say gitlab-runner). Here, we are registering the runner using root user. Run the below command:\ngitlab-runner register\n\nFill the following details according to your setup:\n\nPlease enter the gitlab-ci coordinator URL: https://example.com/gitlab/\n(Look for the url in the gitlab under Set up a shared Runner manually)\n\nPlease enter the gitlab-ci token for this runner: jiRS-3KxGaEdkLo6tToZ\n(Look for the token in the gitlab under Set up a shared Runner manually )\n\nPlease enter the gitlab-ci description for this runner: my-first-shred-runner\n(Enter any name for the runner)\n\nPlease enter the gitlab-ci tags for this runner (comma separated): ci-shared,ci-task\n(Enter any tags you want to associate with the runner)\n\nPlease enter the executor: docker-ssh, parallels, virtualbox, docker+machine, kubernetes, custom, docker, docker-ssh+machine, shell, ssh: shell\n(Enter the executor you need the runner to use, depending on choice of executor you will get other options to fill. Please go through documents of executors )\n\n\n\n\nNow, you can see the message runner has been registered.\n\nYou can verify the same in the Gitlab. Go to Gitlab, Admin Area >> Overview >> Runners >> Set up a shared Runner manually and you can see the runner has been registered with name my-first-shred-runner\n\nSteps to enable Shared Runner for a project in Gitlab:\n\nGo to a Project in Gitlab.\nThen, in the project page, Settings >> CI/CD >> Runners >> Shared Runners\nThen, click on Enable shared runners. Now, you can use the shared runner for Gitlab CI/CD.\nUse the tags associated with shared runner in .gitlab-ci.yml, so that the jobs will run using shared runner.\n\n\nChange the tags in .gitlab-ci.yml\nimage: jangrewe/gitlab-ci-android\n\nstages:\n  - build\n\nbefore_script:\n  - export GRADLE_USER_HOME=$(pwd)/.gradle\n  - chmod +x ./gradlew\n\ncache:\n  key: ${CI_PROJECT_ID}\n  paths:\n    - .gradle/\n\nbuild:\n  stage: build\n  tags:\n    - ci-shared\n  script:\n    - ./gradlew assembleDevelopment assembleProduction assembleStaging\n  artifacts:\n    paths:\n      - app/build/outputs/\n\n\nSteps to register Specific Runner:\n\nLogin to Gitlab. Go to the Project and then Settings >> CI/CD >> Runners >> Set up a specific Runner manually\nNext, follow the same steps from step 2 as given above for Registering Shared Runner"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI: Export variable in before_script build job\n\nI try to implement a conditional versioning depending on if the CI script runs for a tagged branch or not.\nHowever the version var is not resolved. Instead it is printed as a string.\nThe relevant jobs of the GitLab CI script:\n# build template\n.build_base_template: &build_base_template\n  image: registry.gitlab.com/xxxxxxx/npm:latest\n  tags:\n    - docker\n  stage: LintBuildTest\n  script:\n    - export CUR_VERSION='$(cat ./version.txt)$BUILD_VERSION_SUFFIX'\n    - npm ci\n    - npm run build\n  artifacts:\n    expire_in: 1 week\n    paths:\n      - dist/\n\n# default build job\nbuild:\n  before_script:\n    - export BUILD_VERSION_SUFFIX='-$CI_COMMIT_REF_SLUG-SNAPSHOT-$CI_COMMIT_SHORT_SHA'\n  <<: *build_base_template\n  except:\n    refs:\n      - tags\n  only:\n    variables:\n      - $FEATURE_NAME == null\n\n# specific build job for tagged versions\nbuild_tag:\n  before_script:\n    - export BUILD_VERSION_SUFFIX=''\n  <<: *build_base_template\n  only:\n    refs:\n      - tags"}, {"role": "assistant", "content": "Variables which are exported within before_script are visible within script.\nbefore:\n  before_script:\n    - export HELLOWELT=\"hi martin\"\n  script:\n    - echo $HELLOWELT  # prints \"hi martin\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to Merge two different Git repositories?\n\nI have two Github repositories. One repository is on the remote server and another on the local server. Both of them have different commit histories of different files and folders. Now I wanted to merge both of them so that I can have both of them on the remote server as one single repository. Please help!\nI have looked for various solutions suggesting as: reset the head of the local repository and then pull the remote repository on the same directory but it doesn't seem to be working: \ngit reset --soft head ~CommitSHA (First commit of the local repo)\ngit pull ~giturlofremoterepo (Pulling remote repo in the same directory)"}, {"role": "assistant", "content": "In a nutshell you can checkout one repository, add a remote to the second, rebase the second on top of the first and push the result to your new single remote repository:\nClone the first repository and add a remote to the second\ngit clone https://first.repo\ngit remote add second https://second.repo\n\nFetch the second and check its master branch out to a local branch second\ngit fetch second\ngit checkout second/master\ngit checkout -b second\n\nRebase the master branch of the second repository on top of the master branch of the first. Resolve any potential conflict along the way.\ngit rebase master second\n\nPush to a new upstream repository\ngit push -u ...\n\nThis results in the two commit histories being concatenated one after each other."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab runner unable to run aws commands\n\nI am trying to run GitLab's job using their shared Runners,\nI've created a .gitlab-ci.yml and kept it at my project's root,\nConfigured AWS creds as the environment variables -\nAWS_ACCESS_KEY_ID\nAWS_SECRET_ACCESS_KEY\nAWS_DEFAULT_REGION\n\nunder Settings -> CI / CD -> Variables\n\nDouble checked the branch I've trying to build from is protected\nFollowing is my .gitlab-ci.yml -\nstages:\n    - build\n\nbuild:\n    image: python:latest\n    stage: build\n    script:\n            - apt-get update\n            - apt-get install -y zip unzip\n            - pip install awscli\n            - mkdir ~/.aws/\n            - touch ~/.aws/credentials\n            - pip install awscli\n            - printf \"[eb-cli]\\naws_access_key_id = %s\\naws_secret_access_key = %s\\nregion = %s\\n\" \"$AWS_ACCESS_KEY_ID\" \"$AWS_SECRET_ACCESS_KEY\" \"$AWS_DEFAULT_REGION\" >> ~/.aws/credentials\n            - bash cicdScript.sh\n\nCICD script has the aws command -\n$(aws s3 ls)\n\nBut I still get the following error -\nUnable to locate credentials. You can configure credentials by running \"aws configure\".\n\nReference -\nhttps://medium.com/faun/continuous-static-upload-to-aws-s3-using-gitlab-runners-17f0260a5af2"}, {"role": "assistant", "content": "You can use\n- pip install awscli\n- aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID\n- aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY\n- aws configure set region $AWS_DEFAULT_REGION\n\ninstead of\n- mkdir ~/.aws/\n- touch ~/.aws/credentials\n- pip install awscli\n- printf \"[eb-cli]\\naws_access_key_id = %s\\naws_secret_access_key = %s\\nregion = %s\\n\" \"$AWS_ACCESS_KEY_ID\" \"$AWS_SECRET_ACCESS_KEY\" \"$AWS_DEFAULT_REGION\" >> ~/.aws/credentials"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to rename Gitlab repository name using API\n\nI have created several repositories in GitLab.Now I want to rename or remove repository. How can I do this? is there any API available? or is there any git command available for this?"}, {"role": "assistant", "content": "To rename a repository on GitLab:\n\nNavigate to your project's Settings > General > Advanced settings.\nUnder \"Rename repository\", change the \"Path\" to your liking.\nHit Rename project."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Host static website with GitLab pages\n\nI need to host a static website with gitlab pages. My repo is a private repository (or project) and the .gitlab-ci.yml that I tried to use looks like this:\nimage: gpecchio:BeCall\npages:\n  stage: deploy\n  script:\n  - echo 'Nothing to do...'\n  artifacts:\n    paths:\n    - private\n  only:\n  - master\n\nI believe that the image is wrong but I have no idea about what to change it to. I did some research but there aren't that many tutorials online for GitLab pages. How could I change this file to make it work?\nOther info that might be useful: \nGitLab username: gpecchio \nGitLab project name: BeCall \nGitLab project url: https://gitlab.com/gpecchio/BeCall"}, {"role": "assistant", "content": "Is your website created in html or are you using a static generator to create your website and then using gitlab pages to host it?\nIn the .gitlab-ci.yml file, the artifacts need to be public (even if your repository is private) for hosting your website using gitlab pages.\nHere are some examples of what your .gitlab-ci.yml file needs to look like for hosting your site with gitlab pages.\nHTML\npages:\n  stage: deploy\n  script:\n  - mkdir .public\n  - cp -r * .public\n  - mv .public public\n  artifacts:\n    paths:\n    - public\n  only:\n  - master\n\nJekyll\nimage: ruby:2.3\n\npages:\n  stage: deploy\n  script:\n  - gem install jekyll\n  - jekyll build -d public/\n  artifacts:\n    paths:\n    - public\n  only:\n  - master\n\nHexo\nimage: node:4.2.2\n\npages:\n  cache:\n    paths:\n    - node_modules/\n\n  script:\n  - npm install hexo-cli -g\n  - npm install\n  - hexo deploy\n  artifacts:\n    paths:\n    - public\n  only:\n  - master\n\nYou should check out https://gitlab.com/pages/ which has examples of static sites created using all the different static site generator and hosted using gitlab pages.\nYou can also find some Jekyll themes hosted on gitlab pages at https://gitlab.com/groups/jekyll-themes\nFinally, the link to your gitlab project url: https://gitlab.com/gpecchio/BeCall is private."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Put whole gitlab installation to read-only mode\n\nI wish to deny to push changes to any repository by any user. Technically, I need to switch whole gitlab to read-only mode. \nIs there simple way to do this?"}, {"role": "assistant", "content": "Actually a better answer is to change this flag to true. This makes the entire instance read only and adds a nice header in the app."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab Omnibus configuration for Postgres\n\nI'm trying to install gitlab_6.8.1-omnibus.4-1_amd64.deb on my development Debian 7 (Wheezy) machine where Postgres 9.1 is already installed.\nWhen I run sudo gitlab-ctl reconfigure I catch an error:\nError executing action `run` on resource 'execute[migrate database]'\n    ======================================================================\n\n    Mixlib::ShellOut::ShellCommandFailed  \n------------------------------------\nExpected process to exit with [0], but received '1'\n---- Begin output of /opt/gitlab/bin/gitlab-rake db:migrate ----\nSTDOUT:\nSTDERR: WARNING: Nokogiri was built against LibXML version 2.8.0, but has dynamically loaded 2.7.8\nrake aborted!\nFATAL:  password authentication failed for user \"gitlab\"\nFATAL:  password authentication failed for user \"gitlab\"\n\nI created both users git and gitlab (with passwords git and gitlab) in Postgres but it didn't help.\n/var/log/postgresql/postgresql-9.1-main.log is full of authentication errors:\n2014-05-10 14:51:30 MSK FATAL:  password authentication failed for user \"gitlab\"\n\nHow can I configure PostgreSQL options to install GitLab Omnibus?"}, {"role": "assistant", "content": "I solved the problem with my existing PostgreSQL instance.\n\nAdd to /etc/gitlab/gitlab.rb:\n# Disable the built-in Postgres\npostgresql['enable'] = false\n\ngitlab_rails['db_adapter'] = 'postgresql'\ngitlab_rails['db_encoding'] = 'unicode'\n# Create database manually and place its name here.\ngitlab_rails['db_database'] = 'gitlabhq_production'\ngitlab_rails['db_host'] = '127.0.0.1'\ngitlab_rails['db_port'] = '5432'\ngitlab_rails['db_username'] = 'git' # Database owner.\ngitlab_rails['db_password'] = 'git' # Database owner's password.\n\nRun sudo gitlab-ctl reconfigure.\nImport default data:  \nsudo gitlab-rake gitlab:setup\n\n\nAlternative variant is to set custom port for build-in PostgreSQL: \n    postgresql['enable'] = true\n    postgresql['port'] = 5433\n\nThis will run separate PostgreSQL instance on specified port."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab pipeline test stage to fail AND create artifacts anyway\n\nI have a gitlab pipeline running on a windows machine with Windows 7 and powershell 4.0. \nThe .yaml has the typical 3 stages: build, test and deploy.\nFor the second stage I want to perform some simple tests that generate a log file which should be available after the test stage finishes.\nHere the script section from the test:\nscript:\n  - '$exitCode = (start-process C:\\app_versions\\app_20181211\\bin\\app.exe -PassThru -Wait).ExitCode'\n  - 'cat .\\TestLogs\\BasicFunctionsTestPlan.log'\n  - 'exit $exitCode'\nartifacts:\n  paths:\n    - .\\TestLogs\n  expire_in: 1 year\n\nHere I had one problem, after the test run has finished the stage finishes always successfully even if the test themselves failed. Then I had to force the script exit with an error code in case the application tells me that the tests failed. \nThis caused the second problem: the artifacts link do not get created even they are available (my test produce it anyway). \nProbably if I knew how to tell gitlab that the test failed in a more clean way, the artifacts would be available anyway.\nI agree that the log file is not an artifact but I would like to keep that file in order to check how the tests have performed, maybe there is a better way to save this file.\nThanks in advance for your help!\nEDIT: \nLooks like there were more people having the same issue here, maybe it helps understanding better the problem."}, {"role": "assistant", "content": "I had the same question, but it's easily solved:\nYou can use artifacts:when to upload artifacts on job failure or despite the\nfailure.\n\nartifacts:when\nsource: Gitlab CI yaml reference: artifacts:when\n\nIntroduced in GitLab 8.9 and GitLab Runner v1.3.0.\n\nartifacts:when is used to upload artifacts on job failure or despite the\nfailure.\nartifacts:when can be set to one of the following values:\n\non_success - upload artifacts only when the job succeeds. This is\nthe default. \non_failure - upload artifacts only when the job\nfails. \nalways - upload artifacts regardless of the job status.\n\nExample:\nTo upload artifacts only when job fails:\njob:\n  artifacts:\n    when: on_failure\n\n\nallow_failure\nBTW: you can tell Gitlab CI to continue to the next job after a job failure with allow_failure: true \nsource: Gitlab CI yaml Reference: allow_failure\njob1:\n  stage: test\n  script:\n    - execute_script_that_will_fail\n  allow_failure: true\n\n\nSo combined it could look something like:\njob1:\n  stage: test\n  script:\n    - execute_script_that_will_fail\n  allow_failure: true\n  artifacts:\n    when: always # or 'on_failure'\n    paths:\n    - resulting_artifacts"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab Pages and React Router\n\nI will use Gitlab Pages. It seems that Gitlab Pages doesn't work with React Router. I get an empty page. How can I use gitlab Pages with react Router?\nHow can I solve this problem?\n/src/App.js\nimport React from 'react';\nimport { Route } from 'react-router-dom';\nimport HomePage from './components/pages/HomePage';\nimport LoginPage from './components/pages/LoginPage';\n\nconst App = () => (\n  <div>\n    <Route path=\"/\" exact component={HomePage} />\n    <Route path=\"/login\" exact component={LoginPage} />\n  </div>\n);\n\nexport default App;\n\nsrc/index.js\nimport React from 'react';\nimport ReactDOM from 'react-dom';\nimport { BrowserRouter } from 'react-router-dom';\nimport App from './App';\nimport registerServiceWorker from './registerServiceWorker';\n\nReactDOM.render(\n  <BrowserRouter>\n    <App />\n  </BrowserRouter>,\n  document.getElementById('root')\n);\nregisterServiceWorker();"}, {"role": "assistant", "content": "HashRouter is one solution.\nBut, you can still use the BrowserRouter\nShort Answer\n// In your src/index.js,\n<BrowserRouter basename={process.env.PUBLIC_URL}>\n    <App />\n</BrowserRouter>\n\nAnd for the environment variable, open your .gitlab-ci.yml and add the following.\nvariables:\n    PUBLIC_URL: \"/your-project-name\" # slash is important\n\nAlso in your .gitlab-ci.yml, in the stage where you deploy the page, add the following to the script section:\n- cp public/index.html public/404.html\n\nExplanation\nIf your project name is ABC,\nthe gitlab page url would be https://{username}.gitlab.io/ABC\nBut, react router expects the base url to be https://{username}.gitlab.io/.\nSo, you need to explicitly tell the ReactRouter about the basename.\nThe 404.html is needed to allow the user to directly navigate to all of your routes. Without it, GitLab has no idea that your client-side routing is located in your index.html, and will serve the default 404 page."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab Continuous Integration npm Background Process\n\nI have a setup of gitlab ci where I want to start a local npm server for testing in the background. My .gitlab-ci.yml is like:\nstages:\n  - setup\n  - build\n  - test\n\ncache:\n  paths:\n    - venv/\n    - node_modules/\n\nsetup_nvm:\n  stage: setup\n  script:\n    - \"echo installing npm and phantomJS via nvm\"\n    - \"git clone https://github.com/creationix/nvm.git ~/.nvm && cd ~/.nvm && git checkout `git describe --abbrev=0 --tags`\"\n    - \". ~/.nvm/nvm.sh\"\n    - \"nvm install 5.0\"\n    - \"nvm use 5.0\"\n    - \"npm install\"\n    - \"nohup npm run dev &\" # HERE I TRY TO RUN THE SERVER IN THE BACKGROUND\n\nsetup_python:\n  stage: setup\n  script:\n    - \"echo installing python dependencies in virtual environment\"\n    - \"[ ! -d venv ] && virtualenv -p python3 venv\"\n    - \"source venv/bin/activate\"\n    - \"pip3 install -r requirements.txt\"\n\nbuild_multilang:\n  stage: build\n  script:\n    - \"[ ! -d tu9onlinekurstest ] && make -f tools/makefiles/multilang\"\n\ndo_tests:\n  stage: test\n  script:\n    - \"cd src/test\"\n    - \"python -m unittest\"\n\nHowever the job halts and setup_python is never started and in status pending forever. I thought that jobs would be executed in parallel (according to gitlab runner docs). Do you have experience in running background tasks with gitlab runner?"}, {"role": "assistant", "content": "According to Tomasz Maczukin on a related GitLab issue:\n\nI think the best solution would be to use some service manager\n  (systemd, runit, upstart, sysv - whatever is present on this system).\nOn the server you should prepare configuration file to start the\n  service. Then in CI job you would do e.g. systemctl start tomcat. This\n  command is expected to exit just after calling and it's service\n  manager (outside of Runner's scope) who starts the process.\nProcess started with Runner, even if you add nohup and & at the end, is marked with process group ID. When job is finished Runner is\n  sending kill signal to whole process group. So any process started\n  directly from CI job will be terminated at job end. Using service\n  manager you're not starting the process in context of Runner's job.\n  Your only notifying a manager to start a process using prepared\n  configuration :)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to commit new changes to an open merge request?\n\nI am new to working in branching and git.\nI developed some test cases and created new branch to push the changes in that branch and opened a merge request in GitLab to be merged in master branch.\nAfter PR, my reviewer highlighted some code refactoring and other minor changes.\nNow, I have made those changes and the merge request is still open.  How can I push the new changes/commit to an already opened merge request?"}, {"role": "assistant", "content": "So, I should follow these steps? -> git add . -> git commit --amend --no-edit -> git push\nNo need for git commit --amend: you can make a new commit, explaining why those changes are introduced, and push.\nThat will update the current MR (Merge Request in GitLab parlor).\nAs mentioned in \"Merge requests versions\"/\n\nEvery time you push to a branch that is tied to a merge request, a new version of merge request diff is created.\nWhen you visit a merge request that contains more than one pushes, you can select and compare the versions of those merge request diffs."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Link another commit's reference in commit message gitlab\n\nI know we can mention issue in commit messages as'#issue_no', but is it possible to link it to another commit in gitlab?\neither mention commit SHA or complete commit URL in the commit message?"}, {"role": "assistant", "content": "See the documentation: https://docs.gitlab.com/ce/user/markdown.html#special-gitlab-references\n\n\n\n\n\nreferences\ninput\ncross-project reference\nshortcut inside same namespace\n\n\n\n\nspecific commit\n9ba12248\nnamespace/project@9ba12248\nproject@9ba12248\n\n\n\n\nSo you can just use the commit hash within one project."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab issue types and how to create new ones\n\nOk, i'm using Giltab  and noticed this\n\nthen found and read this docs about issue types.\nWhat it looks like is that i can use real issue types instead labels to identify an issue as a (e.g.) bug, a proposal, a enhancement, a new feature request, etc, but i connot understand if i can create new issue types.\nIs there anyone who managed to used this feature?"}, {"role": "assistant", "content": "Good question, I too was interested in taking this approach.\nFrom doing some digging, it appears that the Type was just introduced so that Incidents can also be tracked alongside Issues. So it is not currently possible to create a Type such as \"Bug\", \"Feature\", etc like you might do in other tools like Jira. You still need to use labels for categorizing your issues."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Can you change code in a GitLab pipeline?\n\nIs it possible for a GitLab CI/CD pipeline to commit code changes?\nI would like to run a stage that uses black to format my code automatically whenever I push my work.\ngitlab-ci.yml\nimage: python:3.6\n\nstages:\n  - test\n\nbefore_script:\n  - python3 -m pip install -r requirements.txt\n\ntest:linting:\n    script:\n        - black ./\n\n\nI made sure to include a file that needs reformatting to test if this works. \nJob output\n $ black ./\n reformatted test.py\n All done! \u2728 \ud83c\udf70 \u2728\n 1 file reformatted.\n\nThe file in my repository remains unchanged which leads me to believe that this might not be possible."}, {"role": "assistant", "content": "Black won't automatically commit corrected python code unless you use pre-commit hook.\nBest way to run black in CI is to include something like :\nblack . --check --verbose --diff --color\n\nThis will fail the test if python code fail to adhere to code format and force user to fix formatting.\nplease checkout black --help for all tags.\nThis is a good reference on Black : https://www.mattlayman.com/blog/2018/python-code-black/\nRepo : https://github.com/psf/black"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Which are the pros (and cons) of self-hosting your repositories (in other words: GitLab vs Bitbucket)? [closed]\n\nClosed. This question is opinion-based. It is not currently accepting answers.\n                                \n                            \n\n\n\n\n\n\n\n\n\n\n\nWant to improve this question? Update the question so it can be answered with facts and citations by editing this post.\n\n\nClosed 8 years ago.\n\n\n\n\n\n\n\n                        Improve this question\n                    \n\n\n\nI have to decide between Bitbucket and GitLab for repository hosting (yes, they have to be private). I've used Bitbucket in the past, but now I've discovered GitLab and I find the idea of having a self-hosted repository manager quite attractive. But, I have to justify the use of one of them (especially in the case of using GitLab, because of the overhead that supposes its installation and configuration).\nWe have to take into account the following considerations:\n\nI'm not sure about the backup frequency of the server where GitLab\nwould be installed in (I think this would be a mayor difference between the two options, but I don't know if Bitbucket assures 100% the integrity of the repos they host).\nI can have access to the server from anywhere with VMWare Horizon Client, so Bitbucket and self-hosted GitLab would be tied in this point.\n\nSo, which are the reasons I should opt for self-hosted repo manager (GitLab), instead of non self-hosted one (Bitbucket)?"}, {"role": "assistant", "content": "I\u2019ve used self-hosted repos in some occasions:\n\nGovernment work. They had strict security policies and a really big team. They also had remote access for some users.\nPharmacy lab, also strict security and big team but no need for remote access though. \nI also keep a home git server for a large range of projects from hardware (Raspberry Pi), to Dockerfiles for Pentests, and complimentary services. \n\nMy Pros: \n\nFlexibility for your git server code (custom integration and modules).\nFlexibility for your infrastructure.\nSecurity - depends on your organisation\nInternet connection independence\nSpeed - depends on your network of course but in my case (Gov work) working on site was much faster.\nData - containment and accessibility depends on you organisation\n\nMy Cons: \n\nIts usually a better fit for large teams because of the different tasks required to maintain it.\nSecurity - continuous monitoring just in case your neighbour gets curious\u2026and lucky. \nMaintenance - to keep up to date with new functionality you\u2019ll have to be upgrading periodically\n\nHosted:\nI also like the private repo functionality from both Bitbucket and Gitlab just take into consideration that Gitlab doesn\u2019t cap user quantity. Also if you use CI Gitlab has it integrated. \nBest of luck"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Scheduled pipeline in gitlab using .gitlab-ci.yaml file\n\nI was trying to schedule a ci/cd pipeline in gitlab using .gitlab-ci.yaml file. I did't find a right documentation to implement the schedule using the ci/cd yaml file.\nIs it possible to configure  a pipeline run schedule (say everyday 08:00 AM) in .gitlab-ci.yaml file?\nThanks\nArun"}, {"role": "assistant", "content": "Unfortunately, Scheduled pipeline is realized through GUI rather than .gitlab-ci.yml file in GitLab\nYou may find this document useful if you want to use GUI for schedule pipeline. Configuring in GUI is simpler than yaml coding.\nIf you really want it to be configured in yaml file, you may create an issue in GitLab repo. Actually, there's already an issue on this topic. It should not be a very difficult technically since it is only about keywords and parsing. Whether GitLab will do it or not is another story; so you'd better prepare a good scenario to persuade the GitLab team why you want this to be done."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab pipeline Docker build gets stuck on apk\n\nTrying to make a simple GitLab pipeline that builds a Docker image for Alpine Linux + Openshift CLI. \nThis is the code:\nFROM frolvlad/alpine-glibc:latest\n\nMAINTAINER Daniel Widerin <[email\u00a0protected]>\n\nENV OC_VERSION=v3.11.0 \\\n    OC_TAG_SHA=0cbc58b \\\n    BUILD_DEPS='tar gzip' \\\n    RUN_DEPS='curl ca-certificates gettext'\n\nRUN apk --no-cache add $BUILD_DEPS $RUN_DEPS && \\\n    curl -sLo /tmp/oc.tar.gz https://github.com/openshift/origin/releases/download/${OC_VERSION}/openshift-origin-client-tools-${OC_VERSION}-${OC_TAG_SHA}-linux-64bit.tar.gz && \\\n    tar xzvf /tmp/oc.tar.gz -C /tmp/ && \\\n    mv /tmp/openshift-origin-client-tools-${OC_VERSION}-${OC_TAG_SHA}-linux-64bit/oc /usr/local/bin/ && \\\n    rm -rf /tmp/oc.tar.gz /tmp/openshift-origin-client-tools-${OC_VERSION}-${OC_TAG_SHA}-linux-64bit && \\\n    apk del $BUILD_DEPS\n\nCMD [\"/bin/sh\"]\n\nNow for some reason when running the pipeline it gets stuck on the curl part that downloads the openshift archive.\nStatus: Downloaded newer image for frolvlad/alpine-glibc:latest\n ---> 38dd85a430e8\nStep 2/5 : MAINTAINER Daniel Widerin <[email\u00a0protected]>\n ---> Running in bdacc7e92e79\nRemoving intermediate container bdacc7e92e79\n ---> c56da0a68f7f\nStep 3/5 : ENV OC_VERSION=v3.11.0     OC_TAG_SHA=0cbc58b     BUILD_DEPS='tar gzip'     RUN_DEPS='curl ca-certificates gettext'\n ---> Running in cb1e6cdb39ca\nRemoving intermediate container cb1e6cdb39ca\n ---> 727952120e67\nStep 4/5 : RUN apk --no-cache add $BUILD_DEPS $RUN_DEPS &&     curl -sLo /tmp/oc.tar.gz https://github.com/openshift/origin/releases/download/${OC_VERSION}/openshift-origin-client-tools-${OC_VERSION}-${OC_TAG_SHA}-linux-64bit.tar.gz &&     tar xzvf /tmp/oc.tar.gz -C /tmp/ &&     mv /tmp/openshift-origin-client-tools-${OC_VERSION}-${OC_TAG_SHA}-linux-64bit/oc /usr/local/bin/ &&     rm -rf /tmp/oc.tar.gz /tmp/openshift-origin-client-tools-${OC_VERSION}-${OC_TAG_SHA}-linux-64bit &&     apk del $BUILD_DEPS\n ---> Running in ef344ef4a96b\nfetch http://dl-cdn.alpinelinux.org/alpine/v3.10/main/x86_64/APKINDEX.tar.gz\n\nIt stays like this for an hour until the pipeline times out.\nTried this same Dockerfile manually and it works fine. \nHow can I diagnose this issue? How can I find any logs for this?"}, {"role": "assistant", "content": "Found that this issue is related to Alpine image having networking issues when run in Docker-in-Docker configuration on Kubernetes/OpenShift based runner. Adding --network host to Docker build helps to fix this issue. \nDocker build --network host .\n\nRelated GitHub issue: github.com/gliderlabs/docker-alpine/issues/307"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Have sshd forward logins of git user to a (GitLab) Docker container\n\nI would like to configure sshd on my host machine to forward public key logins of a certain user to a Docker container that runs its own sshd service.\nTo give some context, I have GitLab running in a Docker container and I dislike opening another port on the host machine for the SSH GitLab communication but instead have sshd on the host machine redirect user and key directly to the port the GitLab exposes on the local machine.\nMy idea is to do something like this:\nMatch User git\n  ForceCommand ssh -p <GitLab port> <some arguments that forward to> git@localhost\n  ...\n\nHelp is greatly appreciated!"}, {"role": "assistant", "content": "I found a simple workaround to this. Just create a Git user on the host machine and provide a proxy script that executes the given Git commands in the GitLab container using the host's SSH daemon and the .ssh/authorized_keys from the container volume.\n\nOn the host machine, add the user git using the same UID & GID as in the GitLab docker container (998) and set your GitLab data directory as the user's home:\nuseradd -u 998 -s /bin/bash -d /your/gitlab/path/data git\n\nAdd the git user to the docker group\nusermod -G docker git\n\nAdd a proxy script /opt/gitlab/embedded/service/gitlab-shell/bin/gitlab-shell on the host machine with the following contents:\n#!/bin/bash\ndocker exec -i -u git <your_gitlab_container_id> sh -c \"SSH_CONNECTION='$SSH_CONNECTION' SSH_ORIGINAL_COMMAND='$SSH_ORIGINAL_COMMAND' $0 $1\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Fastest way to merge branches via gitlab (or git)?\n\nI have a development branch and a production branch. I push changes from my development server to a remote gitlab install. Then I login to gitlab GUI and do a merge request (which is quite time consuming). Then I \"git pull origin production\" from my production server.\nThe merge request step kind of takes a long time to do. Is there a faster way to do this? Could I just make a bash/shell script to merge development into production and pull down the updates with one command? If so what commands is this merge request running? \nI make merge requests a couple times a day. Anything to speed up the process I have would be great."}, {"role": "assistant", "content": "You can merge changes without going through a UI - this is one of the core functionalities of Git. Assuming you have two branches (development and production), here's how you would merge changes:\n# Check out development branch\ngit checkout development\n\n# Make changes, commit...\n...\n\n# Optional: Push development changes to the remote\ngit push origin development\n\n# Check out production branch\ngit checkout production\n\n# Merge the changes from the development branch\ngit merge development\n\n# Push the changes to the remote\ngit push origin production\n\n# Check out the development branch again\ngit checkout development\n\nNow log into the production server and pull the changes there.\nYou could of course put the above checkout/merge/push steps into a script - that's quite common to do.\nThere are ways to automatically pull changes when something changes. Here are a couple of links for you:\n\nGit: auto pull from repository?\nhttps://johnflynn.me/autodeploy-your-gitlab-projects/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab Cloud: Can't unprotect branch in project I own\n\nI was surprised to find that I could not force push to the master branch of a project I own on GitLab.\nAlso, there seems to be no way in the web UI for me to unprotect the branch.  \nHow would you address that issue?"}, {"role": "assistant", "content": "You can protect and unprotect branches at Settings -> Repository -> Protected Branches"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to override a gitlab group or project CD/CI variable in .gitlab-ci.yml?\n\nI have a project in Gitlab having defined variables in the Gitlab UI in the project group folder. On a new branch of one of my git repositories I need to override some of these variables.\nvariables:\n  GLOBALLY_DEFINED_VARIABLE: \"branch_specific_value\"\n\nBut in a concrete build the value is still the original one from the global variable.\nHow do I get the value inside the .gitlab_ci.yml file to win over the project value?\nI know, the docs (https://docs.gitlab.com/ee/ci/variables/#cicd-variable-precedence) say that variable in the yml have lower precedence, but this does not make any sense (the yml is inside a project, so it normally must have higher precedence than the project). Is there any way to make my yml file win? Note: I do not want to rule out all variables! Most of them are still needed, I just need to overwrite some.\nMy use case is this: the new branch prepares the code base to be able to run on a new webserver. So this branch obviously needs to have variables storing paths and similar of the new server. But of course the main branches of all repositories should still build to the current (old) live server until the migration on the main-new-server branch is finished and tested. So on this preparation branch I must be able to override the old-server settings. The old settings are stored in project group variables because they are the same for many repositories, but now need to change in a single branch of a single repository."}, {"role": "assistant", "content": "You could set the variable value from within your script or before_script:\nvariables:\n  LOCALLY_DEFINED_VARIABLE: \"branch_specific_value\"\nbefore_script:\n  - GLOBALLY_DEFINED_VARIABLE=$LOCALLY_DEFINED_VARIABLE"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI: how can I set two dependencies pipelines to run in parallel?\n\nAt the moment, I have a pipeline defined with 4 different stages to build dependencies for my project:\nstages:\n  - dependencies-A\n  - dependencies-B\n  - dependencies-C\n  - dependencies-D\n  - build\n\nThus, the jobs in the pipeline now run like this:\nA -> B -> C -> D -> build\n\nActually, B depends on A, and D depends on C. The sub-pipelines A->B and C->D being independent, I would like to run those two sub-pipelines in parallel, to speed up the build. So, that way:\nA -> B \\\n         build\nC -> D /\n\nIs that possible at all?\nThanks for your kind help."}, {"role": "assistant", "content": "If you are using Gitlab version > 12.2, you can use needs keyword to create a directed acyclic graph.  \nIn this case your .gitlab-ci.yml shoul look something like this:    \nHere depB will start after depA successfully completes. Same goes for depC and depD stages. \nbuild stage will run after all the other stages are done.  \nstages:\n  - dependencies-A-C\n  - dependencies-B-D\n  - build\n\ndepA:\n  stage: dependencies-A-C\n\ndepB:\n  stage: dependencies-B-D\n  needs: [\"depA\"]\n\ndepC:\n  stage: dependencies-A-C\n\ndepD:\n  stage: ependencies-B-D\n  needs: [\"depC\"]\n\nbuild:\n  stage: build\n\nFind more in docs:\nhttps://docs.gitlab.com/ee/ci/directed_acyclic_graph/ \nhttps://docs.gitlab.com/ee/ci/yaml/README.html#needs"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab: Unable to fork my own project\n\nI am trying to fork one of my private projects in GitLab, But when I press the fork button I'll receive this:\n\nNo available namespaces to fork the project. \n  You must have permission to create a project in a namespace before forking.\n\nBut I have Master privilege in the project."}, {"role": "assistant", "content": "From the top, blue navigation menu, go to Groups > Your Groups,\nClick the New group button on the top right corner,\nType in the details of your new group,\nClick the Create group button.\n\nOn the Members page of your new group, manage your members. Your account would probably already be added.\nNow you can fork that project."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to integrate Jira with GitLab CE?\n\nWe have self hosted GitLab CE and Jira, we want\n\nlink git commit with jira issue\nlink git commit with jira issue status, like we can start/move/close issue by git issues\nlimit above operations on specific branches, e.g., change issue status only when commits on master branch since we perform merge request for every single feature/bug\n\nbut only GitLab EE built-in supports Jira integration, how could I do that for GitLab CE?\nI'm on GitLab CE 7.8.2, Jira+Agile 6.4"}, {"role": "assistant", "content": "I think there is now a better way:\nhttps://docs.gitlab.com/ce/user/project/integrations/jira.html\n\nGitLab can be configured to interact with JIRA. Configuration happens via user name and password. Connecting to a JIRA server via CAS is not possible.\nEach project can be configured to connect to a different JIRA instance, see the configuration section. If you have one JIRA instance you can pre-fill the settings page with a default template. To configure the template see the Services Templates document.\nOnce the project is connected to JIRA, you can reference and close the issues in JIRA directly from GitLab."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab pages and Jekyll - issue with set up TLS Lets Encrypted\n\nI try to add SSL/TLS on my static web site. I use Gitlab static pages, and Jekyll is for content.\nI follow this instructions to set up TLS - Gitlab tutorial.\nI am stack on this part - I got 404 error from Gitlab pages\n\nOnce the build finishes, test again if everything is working well:\n# Note that we're using the actual domain, not localhost anymore\n$ curl http://YOURDOMAIN.org/.well-known/acme-challenge/5TBu788fW0tQ5EOwZMdu1Gv3e9C33gxjV58hVtWTbDM\n\n\nThe problem is next\nI am successfully generated certificate with command ./letsencrypt-auto certonly -a manual -d example.com\nI created custom page letsencrypt-setup.html in root directory whit appropriate content.  \nI run jekyll build command and it created _site/.well-known/acme-challenge/5TBu788fW0tQ5EOwZMdu1Gv3e9C33gxjV58hVtWTbDM.html page.\nWhen I run curl command to this page it worked with and without .html extension - both commands work, and return appropriate value\ncurl http://localhost:4000/.well-known/acme-challenge/5TBu788fW0tQ5EOwZMdu1Gv3e9C33gxjV58hVtWTbDM\ncurl http://localhost:4000/.well-known/acme-challenge/5TBu788fW0tQ5EOwZMdu1Gv3e9C33gxjV58hVtWTbDM.html\n\nWhen I commit changes and push to Gitlab after build and deploy I can fetch appropriate content only with second command  \ncurl http://example.com/.well-known/acme-challenge/5TBu788fW0tQ5EOwZMdu1Gv3e9C33gxjV58hVtWTbDM.html\n\nWhen I ran  \ncurl http://example.com/.well-known/acme-challenge/5TBu788fW0tQ5EOwZMdu1Gv3e9C33gxjV58hVtWTbDM\n\nI got 404 error.  \nIf I press continue in ./letsencrypte script I also got 404 error. This tool try against URL without .html extension.\nI read comments in the tutorial and try this workaround but it didn't work for me.  \nI have no clue what to try next - I have no lot experience with Jekyll/SSL"}, {"role": "assistant", "content": "Another solution (as suggested by Marthym) is simply to add a slash to the end of the permalink line:\npermalink: /.well-known/acme-challenge/5TBu788fW0tQ5EOwZMdu1Gv3e9C33gxjV58hVtWTbDM/\n\nIn this way, visiting YOURDOMAIN.org/.well-known/acme-challenge/... will redirect you to YOURDOMAIN.org/.well-known/acme-challenge/.../ (note the extra slash) which will have the correct data. It worked flawlessly for me, and I didn't need to update the .gitlab-ci.yml when I switched to a different domain."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Jenkins and Gitlab: Webhook isn't running\n\nI have a couple of servers:\n\nJenkins\nGitlab\n\nOn gitlab, I have a webhook:\nOn Push events -> http://{jenkinsIP}:8080/gitlab/build_now\n\nOn Jenkins, I have a job:\n\nSource Code Management:\nGit:\nRepository URL : git@{GitlabIP}:{Gitlabgroup}/{project}.git (copy from gitlab)\n\nCredential: key-pair working\nBranches to build: */master\nRepository browser: gitlab\nurl: http://{GitlabIP}/{Gitlabgroup}/{project}\n\nVersion: 6.5.1\nPoll SCM\nSchedule H/1 * * * *\n\n\nAny clue why Jenkins isn't running the job?"}, {"role": "assistant", "content": "On Jenkins, you should disable \"Poll SCM\" and set the \"Branches to build\" to \"master\" (not \"*/master\")"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "firebase deploy error, Error: Failed to list functions for (project name)\n\nI am hosting my web application in Firebase and I have been deploying it with Gitlab CI/CD and it has been working just fine! But today for some reason I am getting this error when the pipeline is working\n56Error: Failed to list functions for project-name\nThis is the command that I run in the pipeline\n firebase deploy --only hosting --non-interactive --token $FIREBASE_TOKEN\nThis is the error I am getting\ndeploying hosting\n50i  hosting[project-name]: beginning deploy...\n51i  hosting[project-name]: found 39 files in dist/dev\n52i  hosting: hashing files [34/39] (87%)\n53i  hosting: upload complete\n54\u2714  hosting[project-name]: file upload complete\n55i  hosting[project-name]: finalizing version...\n56Error: Failed to list functions for project-name\n\nKindly note that the command is working up to the point where it says \"finalizing version...\" then it stops.\nWhat could be causing this error?"}, {"role": "assistant", "content": "My firebase tools version was 11.14.0. I changed that to 11.13.0. Installed this specific version through npm install -g [email\u00a0protected]. After that, I could successfully deploy."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Set variables depending on Gitlab rules\n\nWe have 2 environments (development, production). Per default we deploy to production but if the branch name or the commit message start with dev we deploy to development environment.\nI create variables (app_url and app_url_dev) via gitlab GUI : (Project => Settings => CI/CD => Variables)\nI use gitlab rule to change the app_url variable of deployement. The script deploy.py (and many other scripts) are using app_url variable.\nThe gitlab-ci code is:\nTags:\n  stage: Deploy code\n  rules:\n  #    - if: $CI_COMMIT_REF_NAME == \"main\" && $CI_COMMIT_MESSAGE =~ /^dev/\n      - if: $CI_COMMIT_REF_NAME == \"main\" && $CI_COMMIT_BRANCH =~ /^dev/\n        variables:\n          app_url: $app_url_dev\n  script:\n  - Python deploy.py \n\nThe problem is that i never get the value of app_url_dev in app_url. I tried other combinaison but i always get the production url and not the dev one:\napp_url: ${app_url_dev}\napp_url: app_url_dev\n\nBut i get always the app_url and not the app_url_dev.\nAnyone can help please ?"}, {"role": "assistant", "content": "As Brennan said in a comment above, something might have changed as variable expansion works in the rules:variables block now.\nHere's what's working for me:\nvariables:\n  DEPLOY_KEY: \"$DEPLOY_KEY_DEV\" # global fallback\n\ndeploy:\n  stage: deploy\n  script:\n    - bash ./deploy.sh\n  rules:\n    - if: $DEPLOY_ENV == \"production\" # can use trigger variables for evaluation\n      variables:\n        DEPLOY_KEY: \"$DEPLOY_KEY_PROD\" # can expand project variables into other variables\n    - if: $DEPLOY_ENV == \"staging\"\n      variables:\n        DEPLOY_KEY: \"$DEPLOY_KEY_STAGING\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to upload project from local file system to GitLab\n\nI have locally developed an application using Laravel Framework and PhpStorm. So, in the file system of my pc I have the project that I want to upload in a repository created in GitLab.\nI have to mention that for development purposes I am currently using Homestead in windows with Vagrant virtual machine.\nI already have an account in GitLab and for now I have only created a README file.\nWhat are the necessary steps in order to upload my project in GitLab?"}, {"role": "assistant", "content": "you can create new project without Initialize repository with a README file.\nand follow \"Push an existing folder\" look like:\nPush an existing folder\ncd existing_folder\ngit init --initial-branch=main\ngit remote add origin [email\u00a0protected]:youraccount/project_name.git\ngit add .\ngit commit -m \"Initial commit\"\ngit push -u origin main"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to change pipeline badge name\n\nAs the standard pipeline badge from GitLab looks like this\n\nyou can tell pretty well that those are not really distinguishable.\nIs there a way to change the pipeline text manually or programmatically to something else for each badge?\nBtw, the badges were added with those links\nhttps://gitlab.com/my-group/my-repository/badges/master/pipeline.svg\nhttps://gitlab.com/my-group/my-repository/badges/dev/pipeline.svg\n\n\nAdditional facts:\n\nThe pipeline runs locally on my computer\nMy repo is private"}, {"role": "assistant", "content": "I know it is a bit of an old post, but I was looking for the same and found that it is available now since GitLab 13.1.\nThe text for a badge can be customized to differentiate between multiple coverage jobs that run in the same pipeline. Customize the badge text and width by adding the key_text=custom_text and key_width=custom_key_width parameters to the URL:\nhttps://gitlab.com/gitlab-org/gitlab/badges/main/coverage.svg?job=karma&key_text=Frontend+Coverage&key_width=130\n\nThe example is for the Coverage badge but this also works for Pipelines, so in your case:\nhttps://gitlab.com/my-group/my-repository/badges/master/pipeline.svg?key_text=master&key_width=50\nhttps://gitlab.com/my-group/my-repository/badges/dev/pipeline.svg?key_text=dev&key_width=50\n\n(Found this via https://microfluidics.utoronto.ca/gitlab/help/ci/pipelines/settings.md#custom-badge-text)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI - Shorten variable value\n\nI'm trying to enable Review Apps for my project with automatic deploy to Heroku for branches. Each deployment should have the following address:\nhttps://prefix-<branch-name>.herokuapp.com\n\nHeroku requires app names to be no longer than 30 characters, so my jobs should shorten the branch name, if it's too long.\nI've tried to do this in a common Unix way, like this:\nvariables:\n  REVIEW_APP_NAME: \"prefix-${CI_COMMIT_REF_SLUG:0:23}\"\n\nBut it resolved to \"prefix-\".\nI have also found the following solution, which allowed me to use the shortened branch name in the script section. But it still can't be used in environment url parameter. And this leads to app being deployed to Heroku, but doesn't tracked by GitLab at all (no deployment in the Environments list and no action on branch deletion).\nvariables:\n  REVIEW_APP_NAME: \"prefix-$${CI_COMMIT_REF_SLUG:0:23}\"\n\nbefore_script:\n  - eval export REVIEW_APP_NAME=${REVIEW_APP_NAME}\n\nAre there any other ways to achieve proper behavior?"}, {"role": "assistant", "content": "We use a simple bash script for that purpose:\n#!/bin/bash\nset -e\n\nout=${1:0:40}\nif [[ $out =~ ^.*-$ ]]; then\n    out=${out:0:-1}\nfi\necho $out\n\nThe if statement checks that the string does not end with a trailing dash.\nWe then use our script in the CI like this:\n[...]\n  script:\n    - export CI_COMMIT_REF_NAME=$(./infrastructure/utils/shorten_branchname.sh $CI_COMMIT_REF_NAME)\n[...]\n\nFor images that use docker or alpine you need to install bash before:\n[...]\nbefore_script:\n    - apk add --update bash\n[...]"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI/CD: This job does not have a trace. & No job log\n\nI am new to GitLab CI/CD's and I wonder what my pipeline is doing. The syntax is correct but the job keeps failing, but I don't know why and would like to check the trace. When viewing the job trace it says 'This job does not have a trace'. The same is happening if I view the job logs. There is just the text 'no job log'.\nEvery single job I ran has no trace, so I suspect it is a configuration issue in our self-hosted gitlab-runner. I found posts with the same issue but without any solution. I tried to run the gitlab-runner debug mode but its output is of no use.\nI am using a shell executor and installed docker on the gitlab-runner.\nEdit: I coincidently got a job log once, but rerunning the job gives me the same \"no job log\" / \"This job has no trace\"."}, {"role": "assistant", "content": "The issue was that the Gitlab Runner (11.0.2) was incompatible with the GitLab (14.0.6). This happened because we did migrate GitLab to version 14.0.6 but without updating the runner. We solved it by uninstalling the GitLab runner and installing the correct GitLab runner version. I suspect we got no job logs because the GitLab runner couldn't create logs with the GitLab versions being incompatible."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI/CD runner : mvn command not found\n\nMaven is well installed on my gitlab-runner server. When executing mvn clean directly on my repo it works, when running my pipeline using Gitlab UI got this error :\n\nbash: line 60: mvn: command not found\nERROR: Job failed: exit status 1\n\nI notice that I tried to fix the problem by adding the before_script section in the .gitlab-ci.yml file :\nbefore_script:    \n- export MAVEN_HOME=/usr/local/apache-maven\n\nI add also the line :\nenvironment = [\"MAVEN_HOME=/usr/local/apache-maven\"]\n\non the  config.toml file.\nthe problem still persist, my executor is : shell.\nAny advice!"}, {"role": "assistant", "content": "Just add the maven docker image, add below line as first line:\nimage: maven:latest or image: maven:3-jdk-10 or image: maven:3-jdk-9\n\nrefer: https://docs.gitlab.com/ee/ci/examples/artifactory_and_gitlab/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Jenkins pipeline for merge request in Gitlab\n\nI've started lately to use Jenkins and i need some help with creating a pipeline.\nI want to create the following pipeline:\nFor each merge request from develop to master in Gitlab, Trigger a Jenkins job that run an end-to-end test, And merge the branches in Gitlab only if the test succeeded.\nI have found the following article that gives me an explanation for most of the things that i need:\nhttps://vetlugin.wordpress.com/2017/01/31/guide-jenkins-pipeline-merge-requests/\nI'm still looking for an answer for one question:\nHow can Jenkins response to Gitlab with the result of the end-to-end test (Success/Fail), So Gitlab will know whether to merge to branches or not?\nPlease advise,\nThanks!"}, {"role": "assistant", "content": "You do not tell us how Gitlab and Jenkins are connected, but I'll assume you use the Jenkins Gitlab plugin https://github.com/jenkinsci/gitlab-plugin. If you're not, maybe you should :)\nWith this plugin, you can 'integrate' more deeply Jenkins and Gitlab, and your Jenkins builds will send back to Gitlab the result of the build. You will see something like this https://raw.githubusercontent.com/teeks99/gitlab-plugin-wiki-images/master/Setup_Example_img/Result_commit.png. Build results are marked near the commit which has been tested.\nIn this case, for each merge request, you can check the \"Merge if build succeed\" button (see https://raw.githubusercontent.com/teeks99/gitlab-plugin-wiki-images/master/Setup_Example_img/Merge_progress.png) to auto merge the code when build is successful.\nLook at the Jenkins Gitlab plugin README for more information and advanced setup, like test in your build the result of the merge, etc."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab Wiki same page links [closed]\n\nClosed. This question is off-topic. It is not currently accepting answers.\n                                \n                            \n\n\n\n\n\n\n\n\n\n\n\nWant to improve this question? Update the question so it's on-topic for Stack Overflow.\n\n\nClosed 11 years ago.\n\n\n\n\n\n\n\n                        Improve this question\n                    \n\n\n\nHow do I use same page links in the Gitlab wiki? For example:    \nContents\n\n - heading1 ---> this should move the page to heading 1\n - heading2\n - heading3\n - heading4\n\nHEADING 1\n\nBasically I am trying to create a page like Wikipedia where you can navigate a single page using a table of contents."}, {"role": "assistant", "content": "This has been added in this pull request.\nIt generates toc_x anchors, with x incremented for each new header.\nIf you define a link like:\n [My link to third header](#toc_3)\n\nIt will link you to the current page third header (no matter what level that header is)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is the default gitlab-ci image?\n\nI've looked at the gitlab docker documentation but I cannot find it, what is the default gitlab-ci docker image?\n(I'm not setting default:image:)"}, {"role": "assistant", "content": "So taking from the comments, the image is shown at start of build and for the curious around gitlab.com shared runners there's details on gitlab site for the saas_runners\nFor linux shared runners the default image at time of writing is ruby:3.1\nFor on premise (own runners), the default image is specified at time of registering the runner."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Configure Lerna to publish NPM packages to private Gitlab repo\n\nI'm doing some tests with Lerna to create a mono-repo with a bunch of packages that I'd like to share with some applications. I've followed Lerna's documentation to setup a project and this is the file structure:\n- lernatest/\n    - lerna.json\n    - package.json\n    - packages/\n        - common\n            - src/\n                - index.ts\n            - .npmrc\n            - package.json\n        - models\n            - src\n                - index.ts\n            - .npmrc\n            - package.json\n\nI need to publish the packages to a private project inside my Gitlab account. Before using Lerna, I could do it manually on each package adding a .npmrc file with the following content:\n@mypackages:registry=https://gitlab.com/api/v4/packages/npm/\n//gitlab.com/api/v4/projects/<PROJECT_ID>/packages/npm/:_authToken=<TOKEN>\n//gitlab.com/api/v4/packages/npm/:_authToken=<TOKEN>\n\nAnd in each package.json file:\n{\n  \"name\": \"@mypackages/common\",\n  \"publishConfig\": {\n    \"@mypackages:registry\": \"https://gitlab.com/api/v4/projects/<PROJECT_ID>/packages/npm/\"\n  }\n  (ETC...)\n}\n\nI don't know how to configure Lerna properly to publish the packages to my Gitlab registry. This is my lerna.json file:\n{\n  \"version\": \"0.0.5\",\n  \"packages\": [\n    \"packages/*\"\n  ],\n  \"command\": {\n    \"publish\": {\n      \"registry\": \"https://gitlab.com/api/v4/projects/<PROJECT_ID>/packages/npm/\"\n    }\n  }\n}\n\nBut when I run npx lerna publish, I get the following error:\nlerna info publish Publishing packages to npm...\nlerna notice Skipping all user and access validation due to third-party registry\nlerna notice Make sure you're authenticated properly \u00af\\_(\u30c4)_/\u00af\nlerna http fetch PUT 401 https://gitlab.com/api/v4/projects/<PROJECT_ID>/packages/npm/@mypackages%2fcommon 462ms\nlerna ERR! E401 401 Unauthorized - PUT https://gitlab.com/api/v4/projects/<PROJECT_ID>/packages/npm/@mypackages%2fgcommon\n\nI've tried searching the documentation but I can't find anything helpful, any ideas?\nThanks!"}, {"role": "assistant", "content": "It seems that the .npmrc files in each package are ignored when publishing. I've created a single .npmrc file in the root of the project with the needed authentication data and now it works like a charm.\nThis is how my .npmrc file looks like:\n@mypackages:registry=https://gitlab.com/api/v4/packages/npm/\n//gitlab.com/api/v4/projects/<PROJECT_ID>/packages/npm/:_authToken=<TOKEN>\n//gitlab.com/api/v4/packages/npm/:_authToken=<TOKEN>"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Convenient way to cache Node.js dependencies in GitLab CI/CD\n\nI'm using npm to install Node.js dependencies in my project. I want to cache Node.js packages (node_modules) globally to speed up jobs in pipelines when deploying to Heroku. An example from the official docs of GitLab:\ncache:\n  key: ${CI_COMMIT_REF_SLUG}\n  paths:\n  - .npm/\n\nbefore_script:\n  - npm ci --cache .npm --prefer-offline\n\nAnd here is another example in GitLab:\ncache:\n  paths:\n    - node_modules/\n\nFound some articles (Deploy Node.js App with GitLab CI/CD, Continuous Integration with Node.js, Heroku and GitLab CI/CD -Part 2) that used the second configuration above. I did give it a shot and I was able to deploy my app to Heroku with these settings successfully. But I'm not sure caching mechanism is working properly.\nWhat is the difference between these configurations? Which one is the most convenient way to cache Node.js packages?\nMy current setup for gitlab-ci.yml file:\nimage: node:latest\n\ncache:\n  paths:\n    - node_modules/\n\nstages:\n  - build\n  - deploy\n\nbuild:\n  stage: build\n  script:\n    - npm i\n    - npm i -g gulp-cli\n    - gulp build\n\ndeploy:\n  image: ruby:latest\n  stage: deploy\n  script:\n    - apt-get update -qy\n    - apt-get install -y ruby-dev\n    - gem install dpl\n    - dpl --provider=heroku --app=$HEROKU_APP_NAME --api-key=$HEROKU_API_KEY\n  only:\n    - master\n\nNot sure if I'm doing it the right way."}, {"role": "assistant", "content": "It depends if you want to use npm install, aka npm i, or if you want to use npm ci.\nnpm install will look first for an existent node_modules folder and will re-use it. If not, will fetch the dependencies. Check the full algorithm.\nnpm ci instead, removes an existing node_modules folder to perform a clean install of the dependencies. From the docs:\n\nIn short, the main differences between using npm install and npm ci are:\n\nThe project must have an existing package-lock.json or npm-shrinkwrap.json.\nIf dependencies in the package lock do not match those in package.json, npm ci will exit with an error, instead of updating the package lock.\nnpm ci can only install entire projects at a time: individual dependencies cannot be added with this command.\nIf a node_modules is already present, it will be automatically removed before npm ci begins its install.\nIt will never write to package.json or any of the package-locks: installs are essentially frozen.\n\n\nSome tests having ~/.npm and node_modules populated:\n$ npm i --prefer-offline\n#...\nupdated 2 packages in 17.472s\n\n$ rm -rf ~/.npm/ # removes global npm cache\n$ npm i --prefer-offline\n#...\nup to date in 16.271s # removing npm cache does not affects to npm i\n\n$ rm -rf node_modules/\n$ npm i --prefer-offline\n#...\nadded 2525 packages from 1197 contributors in 55.388s # removing node_modules affetcs to npm i\n\n$ npm ci --prefer-offline\n#...\nupdated 2 packages in 17.201s\n\n$ rm -rf ~/.npm/ # removes global npm cache\n$ npm ci --prefer-offline\n#...\nadded 2532 packages in 48.362s # removing npm cache affects to npm ci\n\n$ rm -rf node_modules/\n$ npm ci --prefer-offline\n#...\nadded 2532 packages in 18.695s # removing node_modules does not affetcs to npm ci\n\nSo ending up, npm ci has CI oriented features which can be interesting to use with but if there are no benefits for you just cache node_modules and use npm install instead."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab API to post inline comment to Merge Request\n\nUsing GitLab API it is possible to post a comment to a commit \"on a particular line of a particular file\" (see here).\nOn Merge Request in order to add comments it's required to use the notes resource (see here) but the note object does not seem to contain any parameter to comment on a particular line.\nHowever from the GitLab UI I'm able to add inline comments to a Merge Request in the Changes tab but when I call the API and look at the corresponding note object created from my inline comment there is nothing about the inline, it is only a regular note object without any line or line_type parameter...\nAnyone knows how to use the GitLab API to add inline comments to a Merge Request ?"}, {"role": "assistant", "content": "Code\nfunctions.yml\n.commit_comment:\n  script:\n    - export GITLAB_TOKEN=\"PROJECT_ACCESS_TOKEN\"\n    - |\n      commit_comment() {\n        curl --location --request POST \"https://gitlab.com/api/v4/projects/$CI_MERGE_REQUEST_PROJECT_ID/merge_requests/$CI_MERGE_REQUEST_IID/notes\" --header \"PRIVATE-TOKEN: $GITLAB_TOKEN\" --header \"Content-Type: application/json\" --data-raw \"{ \\\"body\\\": \\\"$1\\\" }\"\n      }\n\nHow to Use?\n# ...\nscript:\n    - !reference [.commit_comment, script]\n    - commit_comment \"YOUR_MESSAGE\"\n# ...\n\n\n\u2139\ufe0f Markdown is allowed for the message\n\nGenerating Token\n\nGo to Your Project > Settings > Access Tokens\nEnter a Token name\nChoose Reporter as role\nSelect the api scope. You can add more scopes but this is all we need here\nGenerate the token\n\n\nP.s. Here, I have created a function to use with multiple jobs but you also directly use the curl command anywhere directly by replacing $1 with your message.\nRef"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Watch a page in gitlab wiki\n\nHow can I watch a page in gitlab wiki and receive notifications every time someone edit/modify the page. I already watch the project and receive notifications for commits, comments etc"}, {"role": "assistant", "content": "I answer my own question after posting in Gital user group. \nIt is not possible to watch a page in Gitlab wiki. See link below\nhttps://groups.google.com/forum/#!msg/gitlabhq/v887P52tMXI/MqaCWztc7sAJ"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to use git flow in GitLab\n\nWe're using GitLab for our project and we think it's great.\nWe're also using git flow to manage the changes in feature, develop, master branches.\nCan you use the Merge Request build in GitLab to manage the branches in git flow style? \nMeaning when accepting a Merge Request for a release branch, it will merge the release branch into master AND into develop.. \nOr should we always use git flow on our local machines to accept the Merge Requests."}, {"role": "assistant", "content": "Like this issue 1628 illustrates, it is best to use GitLab to publish (push) branches, then to rely on a specific GitLab feature related to a particular workflow like git-flow.\nSo the natural approach is to limit those git-flow features to the local clones, and push to GitLab any branch you want, once the merge request is resolved."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Docker multi platform builds extremely slow for ARM64 on Gitlab CI\n\nI have the following dockerfile for a Node.js application\n# ---> Build stage\nFROM node:18-bullseye as node-build\n\nENV NODE_ENV=production\nWORKDIR /usr/src/app\nCOPY . /usr/src/app/\nRUN yarn install --silent --production=true --frozen-lockfile\nRUN yarn build --silent\n\n# ---> Serve stage\nFROM nginx:stable-alpine\nCOPY --from=node-build /usr/src/app/dist /usr/share/nginx/html\n\nUp until now I was building exclusively for AMD64, but now I need to build also for ARM64.\nI edited my .gitlab-ci.yml to look like the following\nimage: docker:20\n\nvariables:\n    PROJECT_NAME: \"project\"\n    BRANCH_NAME: \"main\"\n    IMAGE_NAME: \"$PROJECT_NAME:$CI_COMMIT_TAG\"\n\nservices:\n    - docker:20-dind\n\nbuild_image:\n    script:\n      # Push to Gitlab registry\n      - docker login $CI_REGISTRY -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD\n      - docker context create builder-context\n      - docker buildx create --name builderx --driver docker-container --use builder-context\n      - docker buildx build --tag $CI_REGISTRY/mygroup/$PROJECT_NAME/$IMAGE_NAME --push --platform=linux/arm64/v8,linux/amd64 .\n\nEverything works relatively fine for AMD64 but it is extremely slow for ARM64. Almost 10x slower than AMD64, giving me timeouts on the Gitlab Job.\nIs there any way to speed up the process?"}, {"role": "assistant", "content": "I'm guessing your pipeline is executing on amd64 hardware and that docker buildx is performing emulation to build the arm64 target. You will likely see a large improvement if you break build_image into two jobs (one for amd64 and one for arm64) and then send them to two different gitlab runners so that they each can execute on their native hardware.\nEven if you can't or don't want stop using emulation, you could still break the build_image job into two jobs (one per image built) in hopes that running them in parallel will allow the jobs to finish before the timeout limit.\nWith changes to your Dockerfile and the use of image caching you can make some of your subsequent builds faster, but these changes won't help you until you get an initial image built (which can be used as the cache).\nUpdated Dockerfile:\n# ---> Build stage\nFROM node:18-bullseye as node-build\n\nENV NODE_ENV=production\nWORKDIR /usr/src/app\n# only COPY yarn.lock so not to break cache if dependencies have not changed\nCOPY . /usr/src/app/yarn.lock \nRUN yarn install --silent --production=true --frozen-lockfile\n# once the dependencies are installed, then copy in the frequently changing source code files\nCOPY . /usr/src/app/\nRUN yarn build --silent\n\n# ---> Serve stage\nFROM nginx:stable-alpine\nCOPY --from=node-build /usr/src/app/dist /usr/share/nginx/html\n\nUpdated gitlab-ci.yml:\nimage: docker:20\n\nvariables:\n    PROJECT_NAME: \"project\"\n    BRANCH_NAME: \"main\"\n    IMAGE_NAME: \"$PROJECT_NAME:$CI_COMMIT_TAG\"\n    REGISTRY_IMAGE_NAME: \"$CI_REGISTRY/mygroup/$PROJECT_NAME/$IMAGE_NAME\"\n    CACHE_IMAGE_NAME: \"$CI_REGISTRY/mygroup/$PROJECT_NAME/$PROJECT_NAME:cache\"\n    BUILDKIT_INLINE_CACHE: \"1\"\n\nservices:\n    - docker:20-dind\n\nstages:\n   - build\n   - push\n\nbefore_script:\n   - docker login $CI_REGISTRY -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD\n   - docker context create builder-context\n   - docker buildx create --name builderx --driver docker-container --use builder-context\n\nbuild_amd64:\n    stage: build\n    script:\n      - docker buildx build --cache-from \"$CACHE_IMAGE_NAME\" --tag \"$CACHE_IMAGE_NAME\"  --push --platform=linux/amd64 .\n\nbuild_arm64:\n    stage: build\n    script:\n      - docker buildx build --cache-from \"$CACHE_IMAGE_NAME\" --tag \"$CACHE_IMAGE_NAME\"  --push --platform=linux/arm64/v8 .\n\npush:\n   stage: push\n   script: \n     - docker buildx build --cache-from \"$CACHE_IMAGE_NAME\" --tag \"$REGISTRY_IMAGE_NAME\"  --push --platform=linux/arm64/v8,linux/amd64 .\n\nThe build_amd64 and build_arm64 jobs each pull in the last image (of their arch) that was built and use it as a cache for docker image layers. These two build jobs then push their result back as the new cache.\nThe push stage runs docker buildx ... again, but they won't actually build anything new as they will just pull in the cached results from the two build jobs. This allows you to break up the builds but still have a single push command that results in the two different images ending up in a single multi-platform docker manifest."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "ruby_block[wait for logrotate service socket] action run\n\nDuring gitlab download on my PC(Ubuntu), \"ruby_block[wait for logrotate service socket] action run\" is waiting for a long time.\nIt continues when I run this command \"systemctl restart gitlab-runsvdir.service \" in a new terminal.\nBut the window does not load completely after logging into the Gitlab log in screen. Is this issue related to logrotation or could it be some other issue?"}, {"role": "assistant", "content": "I found that the runsvdir-start command (see here) solved the problem."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to pass values to a Gitlab CI Job\n\nI have a GitLab ci job to download and build few files and then publish to another server. I have done a POC and was successful. The problem is that I would like to customize the job when triggered manually or via API. How can i pass the dynamic values(user given) to reflect in CI job (like a filename, format etc)?\nI am using Windows runner. \nI saw trigger variables and environment variables but can be retrieved while execution once the value is set in UI. I want a bit different where I will get the values from user.\nIs it not possible in GitLab?\nEdit:\nA bit more info on how I'm using the pipeline. My pipeline has two stages - build and deploy. I want the build to run once, but I want to be able to call deploy multiple to deploy to different server. I can use the variable to determine to which server I want to deploy. Through GitLab UI this is possible - i can set variables for pipeline and also for job that overrides the pipeline variable. I just want to do the same thing through API."}, {"role": "assistant", "content": "You can pass variables when starting a pipeline: https://docs.gitlab.com/ee/ci/pipelines/#run-a-pipeline-manually\n\nPipelines can be manually executed, with predefined or manually-specified variables.\n\nThese variables can be also specified on the API call: https://docs.gitlab.com/ee/api/pipelines.html#create-a-new-pipeline\n\nAn array containing the variables available in the pipeline, matching the structure [{ \u2018key\u2019 => \u2018UPLOAD_TO_S3\u2019, \u2018value\u2019 => \u2018true\u2019 }]"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to configure Jenkins to access Gitlab private repository without Gitlab plugin?\n\nI have installed latest Jenkins on ubuntu server and Jenkinsfile in my project repo on Gitlab.\nI am able to connect to private repo on Gitlab using username/password credential on Jenkins configuration for the project pipeline without using Jenkins Gitlab plugin. This does not seem safe to me. How can I use Gitlab API token instead of username/password for Jenkins to access remote private Gitlab repo without using Jenkins Gitlab plugin. Another option is to set ssh private key on Jenkins server to athenticate against Gitlab repo. Is this option possible? \nJenkins Gitlab plugin is not officially supported and not well maintained because Gitlab wants customers to user their own CI/CD solution in order to tie customers to their platform for marketing reasons."}, {"role": "assistant", "content": "A relatively safe way to handle this situation is to store your credentials is the credentials system in Jenkins (that way you do not have to include the credentials in the JenkinsFile), and using a deploy token (available for Gitlab 10.7 and later) for the relevant repository. That token allows you to provide read-only rights to the repository.\nStep 1 - setup the deploy token in GitLab\nFrom the GitLab documentation\n\nYou can create as many deploy tokens as you like from the settings of your project:\n\nLog in to your GitLab account.\nGo to the project you want to create Deploy Tokens for.\nGo to Settings > Repository.\nClick on \u201cExpand\u201d on Deploy Tokens section.\nChoose a name and optionally an expiry date for the token.\nChoose the desired scopes.\nClick on Create deploy token.\nSave the deploy token somewhere safe. Once you leave or refresh the page, you won\u2019t be able to access it again.\n\n\nStep 2 - Saving the deploy token in Jenkins' credentials system\nSince the deploy tokens have a username and password, pick that as the type in the steps below. Write down the id you will use in this step (see below) as you will need it in your pipeline declaration.\nFrom the Jenkins documentation\n\nTo add new global credentials to your Jenkins instance:\n\nIf required, ensure you are logged in to Jenkins (as a user with the Credentials > Create permission).\nFrom the Jenkins home page (i.e. the Dashboard of the Jenkins classic UI), click Credentials > System on the left.\nUnder System, click the Global credentials (unrestricted) link to access this default domain.\nClick Add Credentials on the left. Note: If there are no credentials in this default domain, you could also click the add some credentials link (which is the same as clicking the Add Credentials link).\nFrom the Kind field, choose the type of credentials to add.\nFrom the Scope field, choose either:\n  \n  \n\nGlobal - if the credential/s to be added is/are for a Pipeline project/item. Choosing this option applies the scope of the credential/s to the Pipeline project/item \"object\" and all its descendent objects.\nSystem - if the credential/s to be added is/are for the Jenkins instance itself to interact with system administration functions, such as email authentication, agent connection, etc. Choosing this option applies the scope of the credential/s to a single object only.\n\n\nAdd the credentials themselves into the appropriate fields for your chosen credential type:\n  \n  \n(...)\n\nUsername and password - specify the credential\u2019s Username and Password in their respective fields.\n    (...)\n\n\nIn the ID field, specify a meaningful credential ID value - for example, jenkins-user-for-xyz-artifact-repository. You can use upper- or lower-case letters for the credential ID, as well as any valid separator character. However, for the benefit of all users on your Jenkins instance, it is best to use a single and consistent convention for specifying credential IDs. Note: This field is optional. If you do not specify its value, Jenkins assigns a globally unique ID (GUID) value for the credential ID. Bear in mind that once a credential ID is set, it can no longer be changed.\nSpecify an optional Description for the credential/s.\nClick OK to save the credentials.\n\n\nStep 3 - Use the credentials in your pipeline declaration\nYou can use the credentials in your jenkinsFile like so:\npipeline {\n  stages {\n    stage('Clone stage') {\n       steps {\n         git url: 'https://gitlab.com/[username]/[my-repo].git', branch: 'master', credentialsId: 'my-gitlab-repo-creds'\n       }\n    }\n  }    \n}\n\nIn the above example I assume you picked the id my-gitlab-repo-creds in step 2."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "how to pass variables between gitlab-ci jobs?\n\nI have a gitlab-ci like this:\nstages:\n- calculation\n- execution\n\ncalculation-job:\n  stage: calculation\n  script: ./calculate_something_and_output_results.sh\n  tags:\n  - my-runner\n\nexecution-job:\n  stage: execution\n  script: ./execute_something_with_calculation_results.sh foo\n  tags:\n  - my-runner\n\nThe foo argument in execution-job is base on the results of calculation-job. I want to pass the results from one job to another job via variables. How can I do that?"}, {"role": "assistant", "content": "If you're looking to get the results without storing a file anywhere you can use artifacts: reports: dotenv. This is taken entirely from DarwinJS shared-variables-across-jobs repo.\nstages:\n  - calculation\n  - execution\n\ncalculation-job:\n  stage: calculation\n  script: - |\n      # stores new or updates existing env variables, ex. $OUTPUT_VAR1\n      ./calculate_something_and_output_results.sh >> deploy.env\n  tags:\n    - my-runner\n  artifacts:\n    reports:\n      #propagates variables into the pipeline level, but never stores the actual file\n      dotenv: deploy.env\n\nexecution-job:\n  stage: execution\n  script: - |\n      echo \"OUTPUT_VAR1: $OUTPUT_VAR1\"\n      ./execute_something_with_calculation_results.sh foo\n  tags:\n    - my-runner"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I add a group reviewer in Gitlab?\n\nI periodically need to add more than 10 people to MR and I do it manually. I add only one person at a time, through the search. Can I somehow add the whole team to the reviewers?"}, {"role": "assistant", "content": "This does not seem to be supported, and could be added as a feature request, to be referenced in Epic: Merge request reviewers.\nThe alternative is to use quick actions, with GitLab 13.7+ (issue 241244)\n\nBut that presupposes you know the users' names beforehand."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI/CD ssh add return enter passphrase\n\nWhen triggered, pipeline runs and return the following error,  \n$ ssh-add <(echo \"$SSH_PRIVATE_KEY\")\nEnter passphrase for /dev/fd/63: ERROR: Job failed: exit code 1\n\nmy SSH_PRIVATE_KEY variable exist with a valid private key."}, {"role": "assistant", "content": "In my case, I had set the SSH_PRIVATE_KEY variable to \"protected\", so this worked when building from a protected branch. If your SSH_PRIVATE_KEY variable is Protected ensure your branch is also protected. Information on how to protect your gitlab branch"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab redirects push/fetch/clone to sign in\n\nI am trying to push a branch into a gitlab remote repository and an example of the behaviour would be:\ngit clone http://(path to branch)\nCloning into 'origin'...\nfatal: unable to update url base from redirection:\n    asked for: http://(path to branch)/info/refs?service=git-upload-pack\nredirect: http://(path to root)/users/sign_in\n\nplease note the changes on the urls and also I entered my credentials in .git/config, as presented below\n[user]\n    name = myname\n    pwd = mypassword\n    password = mypassword\n\nIt's probably relevant that when I signed up, the repository asked for a public key that I had to make exclusively for the project."}, {"role": "assistant", "content": "Try cloning the repository with no path to branch first, then checkout to the branch you want.\ngit clone git@(domain and path to the repository)\nSee details here. I'd recommend just setting up SSH access only takes a few minutes and much easier once it's running.\nNext, just cd into the project you made and run\ngit branch -a\nto view all project branches. Finally\ngit checkout [branchname]\nshould switch you to the branch."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Why is Gitlab CI re-uploading cache when key is still valid\n\nin gitlab CI file for an angular project; I define the global cache with the checksum of the package-lock.json file as key. so that the cache is only invalidated when the package-lock.json file changes.\ncache:\n  key:\n    files:\n      - package-lock.json\n  paths:\n    - node_modules/\n    - .npm\n\nPROBLEM: cache is still uploaded even when the cache-key is still valid. (see the picture the cache name did not change)\n\nI want the cache to be uploaded only when it is invalidated, is there anyway to achieve this? or any other remarks recommendations?"}, {"role": "assistant", "content": "By default, the cache is always uploaded on success (push-pull policy).\nYou can change this behavior by configuring the cache policy. If you want a job to only download the cache, but never upload it, set the cache policy to pull. However, you need to make sure at least one previous job populates the cache with either a push or push-pull policy.\nFor example:\nstages:\n  - one\n  - two\n\ncreate_cache:\n  stage: one\n  cache:\n    key:\n      files:\n        - package-lock.json\n    paths:\n      - node_modules/\n      - .npm\n    policy: \"push-pull\"  # default cache behavior\n    script:\n      - echo \"this job is responsible for creating/updating the cache as needed\"\n\nother_jobs:\n  stage: two\n  cache:\n    key:\n      files:\n        - package-lock.json\n    paths:\n      - node_modules/\n      - .npm\n    policy: \"pull\"  # only download cache, do not upload\n    script:\n      - echo \"this will rely on cache being created in previous stage\" \n\nUnfortunately, there is no configuration to say \"push cache if old-cache is invalidated\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI: Fail pipeline if variable not set?\n\nIs there a way fail my entire pipeline if the user triggered the pipeline and didn't set a variable called options with a value?\nI've tried things like only and rules but they just skip the job instead of failing all jobs."}, {"role": "assistant", "content": "Yes, though the way you fail would be dependent on the system your runner's based on.\nFor example, in a Linux/bash based runner, all you need is exit 1 (as opposed to exit 0) to stop execution and fail the pipeline"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Can\u2019t get submodules to work in gitlab\n\nI have a project in my computer with the following structure:\n.\n\u251c\u2500\u2500 bin\n\u251c\u2500\u2500 code\n\u2502 \u2514\u2500\u2500 src\n\u251c\u2500\u2500 data\n\u251c\u2500\u2500 doc\n\u251c\u2500\u2500 experiments\n\u2514\u2500\u2500 reports\n\u2514\u2500\u2500 summary\n\ncode/src and /reports/summary are submodules defined in .gitmodules\n[submodule \"code/src\"]\npath = code/src\nurl = ./code/src/\n\n[submodule \"reports/summary\"]\npath = reports/summary\nurl = /home/zunbeltz/Proyectos/reports/base/\n\nI created a project in the gitlab of my workplace (version 7.9.4). After adding the new origin and \ngit push -u origin master\nThe links of the submodules are broken with a 500 error code.\nI tried also in gitlab.com, (version 7.14) and I get a 404 error\nDoes someone know what is going here?\nNote: I did post this message on the gitlab forum, but have any answer."}, {"role": "assistant", "content": "The idea of submodule is to reference nested git repo with an url that you can access.\n./code/src/ and /home/zunbeltz/Proyectos/reports/base/ are file-based url that you can access locally.\nBut once pushed on Gitlab, said Gitlab wouldn't know how to interpreted/access those urls.\nHence the broken links.\nAs mentioned in the discussion:\nOn Gitlab, you would have to have 3 repos:\n\none for the parent repo\none for each submodules\n\nIn the parent repo on GitLab, you would see the same structure as on the local parent repo\nexcept GitLab would use a special icon to represent that folder.\nThat would represent a gitlink, a special entry in the index of a repo.\nIvan mentions in the comments the now (2018, three years later) official documentation \"Using Git submodules with GitLab CI\"."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab merge two branches\n\nWe have created 'dev' branch from the 'master' and have been working on the 'dev' branch. We have not merged the 'dev' to 'master' yet. Also at the same time we have created 'preprod' branch from the 'master' and working on the 'preprod' branch changes. We have not merged the 'preprod' to 'master' yet. \nNow what we are trying to achieve is to merge the 'preprod' changes alone to 'dev'. I tried this by creating a merge request through Gitlab and approved it. What I found is the changes in the 'dev' code was also moved to 'preprod' and vice versa. I do not want the 'dev' changes to be moved to the 'preprod' by any chance. How can i accomplish this ?"}, {"role": "assistant", "content": "If you got changes on both, it is likely that your merge request told gitlab to merge the two branches into each other, which is sometimes desirable. Depending on your development process, you may find it easier to use git itself (or a gui for it, for example git extensions or sourcetree) to do your merges. GUI versions do a good job of visually showing your branches and past merges, which makes it a lot easier to figure out which commands to run.\nFrom the command line, after you revert to a commit before the gitlab merge, check out the dev branch and merge preprod into it:\ngit checkout dev\ngit merge preprod\n\nThe preprod changes will be made on dev but not vice versa (don't forget to push dev). The git merge command's effect is to merge changes from the named branch in the command (preprod) INTO the CURRENT branch (in this case dev, but you can verify the current branch running \"git branch\" or \"git status\").\nLinks to the git tools I mentioned:\ngit extensions: https://sourceforge.net/projects/gitextensions/\nSourceTree: https://www.sourcetreeapp.com/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Why does ssh connection to gitlab not work (while http push and clone work fine)?\n\nI run a x86 raring ringtail on a old pc and having installed bitnami gitlab 5.3.\nHere is my error msg when trying to push the first master branch in SSH mode:\nfatal: Could not read from remote repository.\nPlease make sure you have the correct access rights and the repository exists.\n\n(it works in http protocol with the gitlab web dashboard credentials)\n\nI have launched bitnami-installer.run with root user so I think all the files went in /opt instead of /home (this was the good procedure?)\nI didn't have a git user before installing GitLab since I heard it could make a confusion in the .ssh/authorized_keys files and other permissions.\nWhen I run ssh -T [email\u00a0protected] it says permission denied (public key) but the pub key on my client computer is also in .ssh/authorized_keys?\nauthorized_keys has the proper content also, with for each line:\ncommand= \"/opt/gitlab/apps/\"\n\nI have also noticed that I cannot display the content of authorized_keys file with a sudo -su git nano authorized_keys because:\n\nthe user is not in the sudoers file.\n\nBut sudo /opt/gitlab/apps/gitlab/gitlab-shell/bin/check returns ok for each verification (gitlab api, acces, repo and /home/git/.ssh/authorized_keys file (because i have set in th config.yml gitlab_url to : http://myserver.com/gitlab (local server ip address) instead of http://loopbackaddress.com/gitlab). I have noticed that i have \u00ab two versions \u00bb of the gitlab-shell directory, one in /opt and one in /home and i don't know if it it is the appropriated demeanor ?\nWhen i try a ssh -Tv it seems the ssh server does not even accept my key, fail to authenticate and return \u00ab permission denied \u00bb at last.\nAlso nothing special in the /var/log/auth.log files other than sshd[number] : connection closed by IP address.\nThe authorized_keys file path is set to the correct absolute url in the /etc/ssh/sshd_config file (/home/git/.ssh/authorized_keys)\nAnd finally i am unable to debug with \u00ab bundle exec bin/rake \u00bb since i am not able to make my ubuntu install all the required pacakge to execute bundle.\n\nI am almost sure it's either a simple ssh misconfiguration or something wrong when invoking the command=\"/opt/...../gitlab-shell\" in the authorized_keys file\nPS: using git with HTTP protocole would be enough for my home server but the interest of the gitlab dashboard is to easily add a contributors by filling the ssh key in the web form and using ssh after"}, {"role": "assistant", "content": "I've got the following error trying to clone repo via ssh from freshly installed gitlab:\n\nfatal: Could not read from remote repository.\nPlease make sure you have the correct access rights and the repository\n  exists.\n\nSolution was found at https://github.com/gitlabhq/gitlab-public-wiki/wiki/Trouble-Shooting-Guide#ssh\nCheck ssh log /var/log/auth.log and if you find error:\nUser git not allowed because account is locked\n\nthen edit /etc/shadow and change git:!: to git:*:\nP.S. \nIn my case on CentOS 6.5 it was /var/log/secure and git:!!:"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to make one job only run after another job passes in a GitLab pipeline\n\nFrom what I have just ran into, the \"needs\" line in a gitlab-ci.yml file only checks to see if the job that is defined in the \"needs\" line is being run - not if it passes or fails.\nI ran the below code in my pipeline and the \"build-latest\" job runs even if the \"test-\ntag\" job fails.\nI only want    the \"build-latest\" job to run if the \"test-tag\" job passes.\nHow is this achieved?\nbuild-latest:\n stage: publish\n image:\n name: gcr.io/go-containerregistry/crane:debug\n entrypoint: [\"\"]\n rules:\n #- if: $CI_COMMIT_TAG != null\n    - if: $CI_COMMIT_REF_NAME == \"add-latest-tagging\"\n when: always\n needs:\n    - test-tag\n script:\n    - crane auth login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY"}, {"role": "assistant", "content": "The issue lies with the fact that you added\nwhen: always\n\nIt is true that since you specified needs, the build-latest job will need the job test-tag to execute first.\n\nAfter test-tag job concluded it will evaluate if it should execute the build-latest job.\nBy adding the always clause to the build-latest job will force it to execute, even if the test-tag fails. Provided test-tag job has at least concluded\n\nLong story sort, you should remove the when always clause"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab: Editing the merge request description triggers a merge request hook being sent\n\nFor my repository on GitLab I have a Merge Request Hook configured which triggers a build on a Jenkins CI machine. The hooks works as expected when a merge request is opened.\nThe webhook is configured with the following triggers:\n\nURL: https://example.com/project/ExampleApp_merge_requests\nPush events: Enabled\nMerge request events: Enabled\nEnable SSL verification: Off\n\nLately, when I edit the description of the merge requests then the hook also notifies the CI machine.\nHere is an example POST request:\nRequest headers:\nContent-Type: application/json\nX-Gitlab-Event: Merge Request Hook\n\nRequest body:\n{\n  \"object_kind\": \"merge_request\",\n  \"event_type\": \"merge_request\",\n  \"user\": {\n    \"name\": \"User Name\",\n    \"username\": \"username\",\n    \"avatar_url\": \"https://gitlab.example.com/uploads/-/system/user/avatar/145/avatar.png\"\n  },\n  \"project\": {\n    \"id\": 39,\n    \"name\": \"app\",\n    \"description\": \"Lorem ipsum.\",\n    \"web_url\": \"https://gitlab.example.com/projects/app\",\n    \"avatar_url\": \"https://gitlab.example.com/uploads/-/system/project/avatar/39/app.png\",\n    \"git_ssh_url\": \"[email\u00a0protected]:projects/app.git\",\n    \"git_http_url\": \"https://gitlab.example.com/projects/app.git\",\n    \"namespace\": \"projects\",\n    \"visibility_level\": 0,\n    \"path_with_namespace\": \"projects/app\",\n    \"default_branch\": \"develop\",\n    \"ci_config_path\": null,\n    \"homepage\": \"https://gitlab.example.com/projects/app\",\n    \"url\": \"[email\u00a0protected]:projects/app.git\",\n    \"ssh_url\": \"[email\u00a0protected]:projects/app.git\",\n    \"http_url\": \"https://gitlab.example.com/projects/app.git\"\n  },\n  \"object_attributes\": {\n    \"assignee_id\": null,\n    \"author_id\": 5,\n    \"created_at\": \"2019-03-19 16:42:28 UTC\",\n    \"description\": \"- s. https://fabric.io/development/projects/apps/com.example.app/issues/5974e5ffbe077a4dcc044254?time=last-thirty-days\\r\\n- Lorem ipsum.\",\n    \"head_pipeline_id\": 7473,\n    \"id\": 9258,\n    \"iid\": 844,\n    \"last_edited_at\": \"2019-03-20 09:00:21 UTC\",\n    \"last_edited_by_id\": 145,\n    \"merge_commit_sha\": null,\n    \"merge_error\": null,\n    \"merge_params\": {\n      \"force_remove_source_branch\": \"1\"\n    },\n    \"merge_status\": \"can_be_merged\",\n    \"merge_user_id\": null,\n    \"merge_when_pipeline_succeeds\": false,\n    \"milestone_id\": null,\n    \"source_branch\": \"fix/random\",\n    \"source_project_id\": 39,\n    \"state\": \"opened\",\n    \"target_branch\": \"develop\",\n    \"target_project_id\": 39,\n    \"time_estimate\": 0,\n    \"title\": \"Fix random\",\n    \"updated_at\": \"2019-03-20 09:00:21 UTC\",\n    \"updated_by_id\": 145,\n    \"url\": \"https://gitlab.example.com/projects/app/merge_requests/844\",\n    \"source\": {\n      \"id\": 39,\n      \"name\": \"app\",\n      \"description\": \"Lorem ipsum.\",\n      \"web_url\": \"https://gitlab.example.com/projects/app\",\n      \"avatar_url\": \"https://gitlab.example.com/uploads/-/system/project/avatar/39/app.png\",\n      \"git_ssh_url\": \"[email\u00a0protected]:projects/app.git\",\n      \"git_http_url\": \"https://gitlab.example.com/projects/app.git\",\n      \"namespace\": \"projects\",\n      \"visibility_level\": 0,\n      \"path_with_namespace\": \"projects/app\",\n      \"default_branch\": \"develop\",\n      \"ci_config_path\": null,\n      \"homepage\": \"https://gitlab.example.com/projects/app\",\n      \"url\": \"[email\u00a0protected]:projects/app.git\",\n      \"ssh_url\": \"[email\u00a0protected]:projects/app.git\",\n      \"http_url\": \"https://gitlab.example.com/projects/app.git\"\n    },\n    \"target\": {\n      \"id\": 39,\n      \"name\": \"app\",\n      \"description\": \"Lorem ipsum.\",\n      \"web_url\": \"https://gitlab.example.com/projects/app\",\n      \"avatar_url\": \"https://gitlab.example.com/uploads/-/system/project/avatar/39/app.png\",\n      \"git_ssh_url\": \"[email\u00a0protected]:projects/app.git\",\n      \"git_http_url\": \"https://gitlab.example.com/projects/app.git\",\n      \"namespace\": \"projects\",\n      \"visibility_level\": 0,\n      \"path_with_namespace\": \"projects/app\",\n      \"default_branch\": \"develop\",\n      \"ci_config_path\": null,\n      \"homepage\": \"https://gitlab.example.com/projects/app\",\n      \"url\": \"[email\u00a0protected]:projects/app.git\",\n      \"ssh_url\": \"[email\u00a0protected]:projects/app.git\",\n      \"http_url\": \"https://gitlab.example.com/projects/app.git\"\n    },\n    \"last_commit\": {\n      \"id\": \"cdda6f7d200468955ecbd224f0437932db607087\",\n      \"message\": \"Fix random\\n\\n\",\n      \"timestamp\": \"2019-03-20T08:45:40Z\",\n      \"url\": \"https://gitlab.example.com/projects/app/commit/cdda6f7d200468955ecbd224f0437932db607087\",\n      \"author\": {\n        \"name\": \"User Name\",\n        \"email\": \"username\"\n      }\n    },\n    \"work_in_progress\": false,\n    \"total_time_spent\": 0,\n    \"human_total_time_spent\": null,\n    \"human_time_estimate\": null,\n    \"action\": \"update\"\n  },\n  \"labels\": [\n    {\n      \"id\": 22,\n      \"title\": \"Bug fix\",\n      \"color\": \"#FF0000\",\n      \"project_id\": null,\n      \"created_at\": \"2018-10-19 09:55:26 UTC\",\n      \"updated_at\": \"2018-11-05 15:17:08 UTC\",\n      \"template\": false,\n      \"description\": \"\",\n      \"type\": \"GroupLabel\",\n      \"group_id\": 15\n    }\n  ],\n  \"changes\": {\n    \"description\": {\n      \"previous\": \"s. https://fabric.io/development/projects/apps/com.example.app/issues/5974e5ffbe077a4dcc044254?time=last-thirty-days\\r\\nLorem ipsum.\",\n      \"current\": \"- s. https://fabric.io/development/projects/apps/com.example.app/issues/5974e5ffbe077a4dcc044254?time=last-thirty-days\\r\\n- Lorem ipsum.\"\n    },\n    \"last_edited_at\": {\n      \"previous\": \"2019-03-19 16:42:50 UTC\",\n      \"current\": \"2019-03-20 09:00:21 UTC\"\n    },\n    \"last_edited_by_id\": {\n      \"previous\": 5,\n      \"current\": 145\n    },\n    \"updated_at\": {\n      \"previous\": \"2019-03-20 08:52:38 UTC\",\n      \"current\": \"2019-03-20 09:00:21 UTC\"\n    },\n    \"updated_by_id\": {\n      \"previous\": 5,\n      \"current\": 145\n    }\n  },\n  \"repository\": {\n    \"name\": \"app\",\n    \"url\": \"[email\u00a0protected]:projects/app.git\",\n    \"description\": \"Lorem ipsum.\",\n    \"homepage\": \"https://gitlab.example.com/projects/app\"\n  }\n}\n\nResponse headers:\nServer: nginx/1.10.3 (Ubuntu)\nDate: Wed, 20 Mar 2019 09:00:21 GMT\nTransfer-Encoding: chunked\nConnection: close\nX-Content-Type-Options: nosniff\n\nThe Jenkins plugin looks like this:\n\nOn the Jenkins machine the following GitLab plugins are installed:\n\n\nJenkins GitLab OAuth Plugin\nJenkins GitLab Hook Plugin\nJenkins GitLab Logo Plugin\nGitLab Merge Request Builder Plugin\nGitLab Plugin\n\nHow can I configure that a POST request is only sent to the CI machine when I create or update the branch of the pull request?"}, {"role": "assistant", "content": "Under triggers (Settings -> integrations) perform the below:\n\nEnable push events (optional branch name - Branch is created via push events even before MR is possible)\nEnable MR event triggers in your project repo \n\n\nThis URL will be triggered when a merge request is created/updated/merged\n\n\nIn Jenkins Plugin configuration - \n\nCheck \"Push Events\" (Any commits by way of direct Push or Creation)\nUn-check \"Opened Merge Request Events\"\nCheck \"Accepted Merge Request Events\" (Any commits by way of Merge Request)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "how do i use git namespaces locally?\n\ni've got an interesting use-case in which i want to share repositories via GitLab \u2014 but our company's got limited repos per user, and so i've got to ration those out by privacy (i.e. instead of repo 1 for project 1, i've got projects 1 & 2 \u2192 repo 1 for team 1, and projects 3 & 4 \u2192 repo 2 for team 2). \ninitially i was going to create pseudo-namespaces in the branch names, e.g. project1-branch1, project2-branch1, project2-branch2 \u2014 however i subsequently learned that git includes namespace functionality that is supposed to separate different reference namespaces while sharing one object store. i tried to test this locally by committing different branches to different namespaces, however i still see all branches in any (or no!) namespace:\n$ git init .\nInitialized empty Git repository in ~/tmp/test/.git/\n\n$ git --namespace test1 checkout --orphan test1\nSwitched to a new branch 'test1'\n\n$ touch test1\n\n$ git --namespace test1 add -- test1\n\n$ git --namespace test1 commit -m test1\n[test1 (root-commit) 27f9d70] test1\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 test1\n\n$ git --namespace test2 checkout --orphan test2\nSwitched to a new branch 'test2'\n\n$ touch test2\n\n$ git --namespace test2 add -- test2\n\n$ git --namespace test2 commit -m test2\n[test2 (root-commit) 4f0f7c5] test2\n 2 files changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 test1\n create mode 100644 test2\n\n$ git log --graph\n* commit 4f0f7c555d3c607d97829263a30170cc431c1d01\n  Author: RubyTuesdayDONO\n  Date:   Thu Jul 3 16:06:39 2014 -0500\n      test2\n\n$ git log --all --graph\n* commit 4f0f7c555d3c607d97829263a30170cc431c1d01\n  Author: RubyTuesdayDONO\n  Date:   Thu Jul 3 16:06:39 2014 -0500\n      test2\n\n* commit 27f9d703758ae401eb77e7e15d75ac863f296291\n  Author: RubyTuesdayDONO\n  Date:   Thu Jul 3 16:06:17 2014 -0500\n      test1\n\n$ git --namespace test1 log --all --graph\n* commit 4f0f7c555d3c607d97829263a30170cc431c1d01\n  Author: RubyTuesdayDONO\n  Date:   Thu Jul 3 16:06:39 2014 -0500\n      test2\n\n* commit 27f9d703758ae401eb77e7e15d75ac863f296291\n  Author: RubyTuesdayDONO\n  Date:   Thu Jul 3 16:06:17 2014 -0500\n      test1\n\n$ git --namespace test2 log --all --graph\n* commit 4f0f7c555d3c607d97829263a30170cc431c1d01\n  Author: RubyTuesdayDONO\n  Date:   Thu Jul 3 16:06:39 2014 -0500\n\n      test2\n\n* commit 27f9d703758ae401eb77e7e15d75ac863f296291\n  Author: RubyTuesdayDONO\n  Date:   Thu Jul 3 16:06:17 2014 -0500\n      test1\n\n# separate namespace should prevent conflict (but doesn't)\n$ git --namespace test3 checkout --orphan test1 \nfatal: A branch named 'test1' already exists.\n\n# should include refs/namespaces (but doesn't)\n$ tree -a\n.\n\u251c\u2500\u2500 .git\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 COMMIT_EDITMSG\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 config\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 description\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 HEAD\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 hooks\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 index\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 info\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 exclude\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 logs\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 HEAD\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 refs\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 heads\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0         \u251c\u2500\u2500 test1\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0         \u2514\u2500\u2500 test2\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 objects\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 18\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 c152442134ca652c83b111b6063c9b75f9157c\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 27\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 f9d703758ae401eb77e7e15d75ac863f296291\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 4f\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 0f7c555d3c607d97829263a30170cc431c1d01\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 e0\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 f402da78bd414bdd926713d2b54c246432adc5\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 e6\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 9de29bb2d1d6434b8b29ae775ad8c2e48c5391\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 info\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 pack\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 refs\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 heads\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 test1\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 test2\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 tags\n\u251c\u2500\u2500 test1\n\u2514\u2500\u2500 test2\n\n17 directories, 27 files\n\nis it not possible to see the namespaces locally before pushing to a remote repo? or if it works locally with git-remote-ext magick like git clone ext::'git --namespace=foo %s /tmp/prefixed.git', then why not simply with git --namespace ordinary-git-command?\nsorry in advance if i'm misunderstanding the purpose of git namespaces \u2014 i just want to feel assured that this will work before sharing with my colleagues, else i'll just use the branch names as a kind of pseudo-namespace instead (less elegant, but it'll work). i've reviewed the following posts without really understanding how git namespaces function:\n\nhttps://softwareengineering.stackexchange.com/q/170345/45261\nHow to clone a git repository namespace"}, {"role": "assistant", "content": "Git namespaces is only intended to work with remote repos, not locally (https://github.com/git/git/commit/6b01ecfe22f0b6ccb9665cd8d85d78a381fecffc).  Most of the operations that work using git namespaces appear to work on operations that go through the git-upload-pack and git-receive-pack functions. \nThats why the documenation suggests if you want to test it locally to fake it into thinking you're pulling from a remote machine eg: git clone ext::'git --namespace=foo %s /tmp/prefixed.git'\nso commands like\ngit --namespace foo add\ngit --namespace foo commit\ngit --namespace foo branch\n\nAll essentially do nothing.  The only operations that appear to have any effect are clone/fetch/pull and push. \nIn order to leverage namespaces the way you're hoping, you'd have to set up your own git backend that is capable of translating URL arguments into the GIT_NAMESPACE variable and pass it along to git-http-backend or something similar. The documentation recommends the following in your apache configuration:\n\nTo serve multiple repositories from different gitnamespaces in a single repository:\nSetEnvIf Request_URI \"^/git/([^/]*)\" GIT_NAMESPACE=$1\nScriptAliasMatch ^/git/[^/]*(.*) /usr/libexec/git-core/git-http-backend/storage.git$1\n\n\nAlso note that what this documentation does not say, is that what is going on here is extracting the GIT_NAMESPACE variable from a URL and setting an environment variable that git-http-backend is expecting. i.e. http://myserver.com/git/namespace/repository.git.  The 'storage.git' part is a typo and should not be there. I should submit a documentation patch.\nHere's most of the commits that created this feature.\nhttps://github.com/git/git/commits/398dd4bd039680ba98497fbedffa415a43583c16?author=joshtriplett"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "how can I get a global rss feed on Gitlab?\n\nIn Gitlab there is an RSS news feed button for every project. \nhttp://git.domain.name/userName/projectName/commits/master.atom?private_token=xxxxxxxxxxxxx\nIs there a way to retrieve a global RSS feed for all projects related to one user?\nOr even better, if there is a way to capture all user's feeds across all projects, that would be cool.\nthanks"}, {"role": "assistant", "content": "This is currently not supported.\nThe closest feature request there is would be \"Team-/groupwide RSS feeds\",  to have RSS feeds for all events in a team or a group. (not enough vote for now).\n\nThe global \"RSS\" shown on demo.gitlab.com is actually a html result of the event-items representing the activity in response to http://demo.gitlab.com/?limit=20&offset=0:\nThat would be for all public projects, but I don't see it exposed as an RSS feed.\nThe OP mauro reports in the comments\n\nthe global \"RSS\" shown in demo.gitlab.com is also showing on my gitlab dashboard, the only thing is that mine is giving a 500 error instead."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Does \"Allow access to this project with a CI_JOB_TOKEN\" in GitLab work between private repositories?\n\nI am part of a private group (our team in our department). All underlying projects and subgroups can only be private (this is how GitLab works) and we all have at least Report-level access to those. Not to be confused with the personal namespace for each user!\nI have created a subgroup with multiple repositories inside for a large Django project I am working on. One of the repositories (main, also includes manage.py as well as the Django project main files that are used by django-admin to configure and run the whole project) is referencing a couple of the others as submodules (Django apps).\nI am trying to create a building job using Kaniko that is configured in the main repo and uses both the repo's own code as well as all the submodules to make the application complete. Sadly, I am encountering an authentication problem.\nEven though I am the owner of the subgroup as well as the repos inside, cloning a submodule apparently still requires username and password. My setup does not allow me to use git config to add the required credentials - an automatically generated CI user and CI_JOB_TOKEN - I decided to look into sharing these credentials among all repos that are in some way linked (main repo + submodules).\nIn the CI/CD section of the Web UI in GitLab I have the following option:\n\nI tried to set the path to the project to my main repo that uses the current repo as a submodule. However, I am getting\nThe target_project that you are attempting to access does not exist or you don't have permission to perform this action\n\nThe project does exist (tried with and without the .git suffix) so the only thing that remains is, yet again a credentials issue.\nI might have missed a hint but the official documentation doesn't say that private repos cannot share a token."}, {"role": "assistant", "content": "I can confirm that is possible to add the permission to a private project. The problem is the confusing gitlab UI that does not accept the entire URL of a repo and requires the user to inform just the final part.\nI had a repo with the following url:\nhttps://gitlab.com/mygroup/mysubgroup/myreponame\n\nI was adding the entire url path to it, I was getting the same error:\nThe target_project that you are attempting to access does not exist or you don't have permission to perform this action\n\nThen I realized that all I needed to do was add just the final part:\nmygroup/mysubgroup/myreponame\n\nAnd it worked."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to merge or add a new stage in gitlab-ci.yml which includes a common template yml with default list of stages and job definitions\n\nCurrently in our project the gitlab-ci.yml includes a common template yml with default stages and job definitions. I want to include a stage and respective job specific to this project, which needs to run in between the stages defined in template yml. Below are the sample yml files which represent the scenario I am working on.\n\n.mvn-template.yml\n\nstages:\n  - build\n  - static-analysis\n  - unit-test\n  - package\n  - integration-test\n\ncompile:\n  stage: build\n  tags:\n    - docker\n  artifacts:\n    paths:\n      - target/\n    expire_in: 14 days\n  script:\n    - mvn $MAVEN_CLI_OPTS compile\n  interruptible: true\n  \n//and job definitions for - static-analysis\n//  - unit-test\n//  - package\n//  - integration-test\n\n\ngitlab-ci.yml\n\ninclude:\n  - project: 'xxx/common-pipeline'\n    ref: x.x.x\n    file: '/.mvn-template.yml'\n...\n\nNow I want include a new stage specific this project, say contract-testing, in between\n\npackage\nintegration-test\n\nSo the contract-testing should run after package and before integration-test.\nAs this is specific to this project I cannot include in common template. Thus needs to be included in gitlab-ci.yml.\nCould not figure out how to do this. I earlier worked with GitHub and just recently started on project with GitLab.\nCan I include the stage in common template but don't define respective job there. And include the Job definition in gitlab-ci.yml? Not sure if this is the correct way. Probably there could be better options to handle such scenario.\nPlease help."}, {"role": "assistant", "content": "In my opinion, you can do it in 2 different ways :\n\nAdd the stage contract-testing in your template file and define the specific job in the .gitlab-ci.yml of your project. The configuration will be valid : gitlab will concatenate and expand includes/anchors to build one single gitlab-ci at the end. Note : you can define a stage even if there is no job using this stage (a sort of an empty stage), it will not generate an error.\n\nIf you don't want to have this \"empty stage\" included in all your projects referring the include, you can move the stages outside of you template and put them in the .gitlab-ci.yml of your project. Like for solution 1), you need to define the job in .gitlab-ci.yml of your project (not in the template)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Run pipeline on gitlab when branch is deleted\n\nIs it possible to run a pipeline thanks to Gitlab CI/CD after a branch is deleted.\nIn fact I want to edit file after that branch is removed.\nFor example, I have two repositories, R1 and R2.\nIn R1 I have 2 branches\n\nB1\nB2\n\nI want to edit a file from R2 when B1 (which is a  R1's branch) is removed.\nI know how to access and edit the file but I don't know how can I set a trigger for removed branch."}, {"role": "assistant", "content": "You can use environments. Look at Stopping an environment.\n\nGitLab will automatically trigger a stop action when the associated branch is deleted. The stop_review job must be in the same stage as the deploy_review job in order for the environment to automatically stop.\n\ndeploy_review:\n  stage: deploy\n  script:\n    - echo \"Deploy a review app\"\n  environment:\n    name: review/$CI_COMMIT_REF_NAME\n    url: https://$CI_ENVIRONMENT_SLUG.example.com\n    on_stop: stop_review\n  only:\n    - branches\n  except:\n    - master\n\nstop_review:\n  stage: deploy\n  variables:\n    GIT_STRATEGY: none\n  script:\n    - echo \"Implement editing files from R2 here\"\n  when: manual\n  environment:\n    name: review/$CI_COMMIT_REF_NAME\n    action: stop\n\nIt's not fully what you want, but maybe more useful for you."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to get branch name when running pipeline on tag?\n\nI run pipeline from a tag (let's say v1.0.0) on a branch (let's say staging).\nMy output file is created with ${CI_PROJECT_NAME}-${CI_COMMIT_REF_NAME}.apk. \nThe result is a file named MyProject-v1.0.0.apk.\nI wish add branch name in the output filename to get MyProject-staging-v1.0.0.apk.\nFrom the gitlab documentation, i could use CI_COMMIT_TAG and CI_COMMIT_BRANCH like this ${CI_PROJECT_NAME}-${CI_COMMIT_BRANCH}-${CI_COMMIT_TAG}.apk.\nBut the documentation says:\n\nCI_COMMIT_BRANCH : The commit branch name. Present only when building\n  branches.\nCI_COMMIT_TAG : The commit tag name. Present only when building tags.\n\nSo how to get the branch name?"}, {"role": "assistant", "content": "You can find which branch a tag is part of.\nThe issue is: a tag can be referenced (part of the history of) multiple branch.\nSo, as in here, your gitlab.yml could call a script setting that branch (settings an environment variable), provided you have a convention in place to select the branch you want out of the (possibly) more than one branch which could refer said tag."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Upstream triggering in Gitlab-CI aka pipeline dependencies\n\nI can't seem to find the most obvious CI feature that one ever needs from such a tool: run a project pipeline after another project's pipeline has finished. You can do it with trigger but only for downstream triggering, which is the opposite of what you want in case you have a project that is a core dependency of 20 other projects which all need to be rebuilt.\nWhat you need in this case is to be able to define something like:\nProject A: nothing particular, just a normal pipeline\nProject B, that \"depends\" on project A:\n.gitlab-ci.yml\nfrom_upstream:\n  stage: pre\n  trigger:\n    project: ProjectA\n\nWhat it does is trigger ProjectB build whenever a ProjectA pipeline has [successfully] finished.\nInstead you must declare all dozens of downstreams in ProjectA in a similar fasion, which is silly and counter-productive, especially when ProjectA is a core library that gets constantly reused everywhere.\nSo, can someone please explain why GitlabCI is missing an obvious feature (which isn't available even in EE) that has been in Bamboo and Hudson/Jenkins for decades? And how do i do what i need with Gitlab-CI?\nUPDATE:\nIt seems the notion of upstream/downstream is really confusing for some people, so just to clarify: upstream Project A is and must always be decoupled from downstream Project B because separation of concern is a thing and upstream maintainers couldn't and shouldn't possibly have any knowledge on how their project is used downstream.\nSo, desired functionality (which, again, exists for decades in Bamboo and Jenkins) is that downstream pipelines declare passive triggers on upstream pipelines, not the other way around with active triggers as it's currently implemented in Gitlab-CI."}, {"role": "assistant", "content": "You can trigger a pipeline in your project whenever a pipeline finishes for a new tag in a different project. This feature was introduced in version 12.8. It is limited to new tags and requires a premium subscription.\n\nFeature proposal issue: https://gitlab.com/gitlab-org/gitlab/-/issues/9045\n\nDocumentation: https://docs.gitlab.com/ee/ci/pipelines/#trigger-a-pipeline-when-an-upstream-project-is-rebuilt"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Get raw file from repository\n\nI want to get a file content in gitlab by using its api.\nFirstly, I check my gitlab version, its written as,\nGitLab Community Edition 9.4.3 b125d21 update asap\nThen I create a private token and \nhttp://gitadress/api/v4/projects/id/repository/files?private_token=PRIVATE_TOKEN\nreturns as;\n{\"error\":\"404 Not Found\"}\n\nthen I modify the query as;\nhttp://gitadress/api/v4/projects/222/repository/tree?private_token=PRIVATE_TOKEN \nthis request returns as;\n[{\"id\":\"8078365d80c\",\"name\":\"test.js\",\"type\":\"blob\",\"path\":\"test.js\",\"mode\":\"100644\"}]\n\nWhat I want is to get the content of the test.js but whatever I tried I couldn't achieve it.\nhttp://gitadress/api/v4/projects/id/repository/tree/test.js/raw?private_token=PRIVATE_TOKEN&ref=master\nreturns as; \n{\"error\":\"404 Not Found\"}\n\nHow can I get the raw file content by using gitlab api?\nDocumentation is here;\nhttps://github.com/gitlabhq/gitlabhq/blob/master/doc/api/repository_files.md#get-raw-file-from-repository"}, {"role": "assistant", "content": "The documentation mentions:\n\nUrl encoded full path to new file. Ex. lib%2Fclass%2Erb\n\nThat means you need to URL encode test.js: test%2Ejs.\n(See Percent encoding: character data)\nhttp://gitadress/api/v4/projects/id/repository/files/test%2Ejs/raw?private_token=PRIVATE_TOKEN\n\nYou can add ?ref=master to make sure to get the content from the master branch for instance.\nhttp://gitadress/api/v4/projects/id/repository/files/test%2Ejs/raw?ref=master&private_token=PRIVATE_TOKEN\n\nThat being said, you have the gitlab-ce issue 31470 which is still open:\n\nAPI to \"Get raw file from repository\" fails for files with dots\n\nA fix is in progress: gitlab-ce merge_request 13370, and will be delivered for GitLab 9.5."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to use cache for a rails project in Gitlab CI?\n\nI've been trying to leverage Gitlab Ci's cache for my ruby on rails application but so far haven't had any luck, my application is using shared runners, maybe that's the issue?\nHere are the contents of my .gitlab-ci.yml\nservices:\n  - postgres:latest\n\nrspec:\n  stage: test\n  script:\n    - apt-get update -qy\n    - apt-get install -y nodejs\n    - gem install bundler\n    - bundle check --path vendor/bundle || bundle install --path vendor/bundle --jobs $(nproc)\n    - cp config/database.gitlab-ci.yml config/database.yml\n    - RAILS_ENV=test bundle exec rake db:create db:schema:load\n    - bundle exec rspec\n  cache:\n    paths:\n      - vendor/bundle\n  tags:\n    - ruby\n    - postgres\n\nWhen my tests run I do see the runner checking for cached content, but it never restores it:\ngitlab-ci-multi-runner 1.1.3 (a470667)\nUsing Docker executor with image ruby:2.1 ...\nPulling docker image postgres:latest ...\nStarting service postgres:latest ...\nWaiting for services to be up and running...\nPulling docker image ruby:2.1 ...\n\nRunning on runner-8a2f473d-project-1129003-concurrent-0 via runner-8a2f473d-machine-1462982763-a9a70bd7-digital-ocean-4gb...\nCloning repository...\nCloning into '/builds/foo/bar'...\nChecking out 30ea1b5f as master...\nNote: checking out '30ea1b5f036808f7e27bfa32e939c1f591343ba6'.\n\nYou are in 'detached HEAD' state. You can look around, make experimental\nchanges and commit them, and you can discard any commits you make in this\nstate without impacting any branches by performing another checkout.\n\nIf you want to create a new branch to retain commits you create, you may\ndo so (now or later) by using -b with the checkout command again. Example:\n\n  git checkout -b <new-branch-name>\n\nHEAD is now at 30ea1b5... Fix width of tables contained in table-scroll divs\nChecking cache for rspec/master...\n\n$ apt-get update -qy\n\nAnd when the build is about to finish I do see it trying to create the cache:\nCreating cache rspec/master...\nvendor/bundle: found 8917 matching files\n\nAny ideas?"}, {"role": "assistant", "content": "Gitlab Runner creates cache in git working directory by default. As you mentioned, your cache is created correctly, but it is stored in current git working directory of gitlab-runner. Whenever next build is run, gitlab-runner cleans the working directory (probably using git clean -dfx), which removes  cache directory in git working directory.\nYou need to specify a separate cache directory for gitlab-runner. You can specify manually in /etc/gitlab-runner/config.toml file in the [[runners]] section using cache_dir setting key. Gitlab CI advanced configuration\nYou can also specify cache directory during gitlab runner registration using the --cache-dir option as in\ngitlab-runner register --name blabblah --cache-dir /var/opt/gitlab/gitlab-runner-cache\n\nHope this helps"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Poor man's Gitlab CE and Jenkins integration\n\nUPDATE \nThe script in the answer is obsolete now, since Gitlab plugin for Jenkins can now report build status back to Jenkins.\nI'm trying to integrate Gitlab CE 8.4 and Jenkins. I've read that Jenkins CI integration is available in Gitlab EE, but currently its not an option.\nI've already set up Jenkins gitlab plugin and Web hooks, and pushes to my repo trigger builds of Jenkins jobs. \nHowever, these builds are not shown in the 'Builds' tab in the respective Gitlab page. \nIf I commit .gitlab-ci.yml file to the repository, web hooks still work, Jenkins jobs run, but the 'Builds' page shows that the build is stuck, since no runners are defined. \nIndeed, I haven't set up any Gitlab CI runners, since they are not related to Jenkins, as far as I understand.\nI'd like to keep my Jenkins job since some useful information is published there, and I also would like to have its status on the Gitlab page.\nI'm thinking in this regard about a simple script for Gitlab CI runner, that would capture console output from a Jenkins job and translate it to Gitlab. Something like running wget or curl, because Jenkins provides API to see job's output. \nHowever, documentation about Gitlab CI and .gitlab-ci.yml is limited, as well as examples. \nHow could I write that job file?\nAm I right in thinking that Gitlab receives job's stdout?"}, {"role": "assistant", "content": "Yes, Gitlab-CI prints stdout of a job and relates on exit codes.\nMy solution consists of installed Gitlab-CI runner and the python script, called from .gitlab-ci.yml, that gets git commit ID from CI_BUILD_REF environment variable, connects to the Jenkins host, finds respective build console, reads the output via urllib2.urlopen(...).readlines(), and prints it to stdout. \nIt uses bySHA1 url, provided by the Jenkins Git plugin, to find the build console.\nThe script also looks for the line, starting with the word Finished: and exits with the exit code, according to what follows that word: 0 if it is SUCCESS, and 1 if FAILURE, or UNSTABLE.\nScript text:\nimport urllib2\nimport os\nimport sys\nimport time\n\nTIMEOUT = 5\n\ndef get_build_console_for_sha1(url, sha1):\n    return '{}/scm/bySHA1/{}/consoleText'.format(url, sha1)\n\n\ndef parse_console(build_con):\n    retcode = 0\n\n    if build_con:\n        total_read_lines = 0\n        finished_line = None\n\n        while not finished_line:\n            current_read_lines = 0\n            try:\n                for line in urllib2.urlopen(build_con, \n                                             None, TIMEOUT).readlines():\n                    current_read_lines += 1\n                    if current_read_lines >= total_read_lines:\n                        print line,\n                        total_read_lines += 1\n                        sys.stdout.flush()\n                        if line.startswith('Finished: '):\n                            finished_line = line\n            except urllib2.HTTPError as e:\n                if e.code == 404:\n                    time.sleep(2)\n                    pass\n\n        if 'FAILURE' in finished_line or 'UNSTABLE' in finished_line:\n            retcode = 1\n\n    print \"retcode = \", retcode\n    return retcode\n\n\ndef main():\n    URL = 'JENKINS_JOB_URL'\n    sha1 = os.getenv('CI_BUILD_REF')\n    bc = get_build_console_for_sha1(URL, sha1)\n    return parse_console(bc)\n\n\nif __name__ == '__main__' :\n    sys.exit(main())\n\nAnd in addition, .gitlab-ci.yml:\njenkins-translate:\n  script: \n    - python jenkins-translate.py\n\nDrawbacks are obvious: pressing cancel button actually cancels the translation, not the Jenkins job, no clickable links to the Jenkins job page. \nAt least it informs about Jenkins job statuses.\nUPDATE. This script does not authorize to Jenkins, it assumes relaxed security setting, when everyone can see job output.\nUPDATE2. Jenkins-Gitlab plugin can now report build status back to Gitlab, which obsoletes this script."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Search filenames with GitLab API\n\nI'm using the GitLab API (http://doc.gitlab.com/ce/api/) to try to search for a specific file. I can successfully access a specific repository, but I was hoping to provide some text and retrieve any files that match the filename. If not that, then to at least get the full file structure of everything within the repository and do the search myself. Is this possible?"}, {"role": "assistant", "content": "http://doc.gitlab.com/ce/api/repositories.html\nI didnt skim through the full API docs, but a quick hack would be to list down the trees, you will get Gitlab ObjectifiedHash, run a loop and inside the loop put a condition saying if the type is a 'tree', then send its respective id again to fetch its tree and so on recursively and if its a blob, just save the name.\nThis way you get all the files/folder name. This is a bad way of doing it since you will do quite a few api calls. Read through the API docs fully.\nI know this post is old, just answered anyway. Hope it helped"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab: extend `!reference` with extra values in `variables`\n\nHow can one use !reference in variables block and then extend the list of entries?\nFor example, I want to be able to do something like\nvariables:\n  !reference [.common_variables, variables]\n  FOO: \"bar\"\n\nAt the moment I get an error in the GitLab linter:\n\nThis GitLab CI configuration is invalid: (): did not find expected key while parsing a block mapping at line 1 column 1\n\nP.S. Note that this question is specifically about !reference.\n\nYaml anchors are out of scope of this question, as I want to place .common_variables into a separate file that I include in my pipeline.\nextends: mechanism is out of scope of this question. It does work, but it has a weird behaviour that one also gets an extends variable in the environment, see GitLab: use `extends` in `variables`"}, {"role": "assistant", "content": "variables: !reference [.common_variables, variables]\n\nIs the correct way to reference, however gitlab yml structure will not support additional definitions after the !reference keyword.\nMy advice would be to have a more specific definition in your variables file that uses anchors to share the common varaibles.\ne.g:\nin 'variables.gitlab-ci.yml':\n.common_variables: &common_variables\n     COMMON_VAR: value\n\n.variables:Example-job\n    variables:\n        <<: *common_variables\n        FOO: \"bar\"\n\nin '.gitlab.ci.yml':\nExample-job:\n    variables: !reference [\".variables:Example-job\", \"variables\"]\n    script:\n        ..."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Show git contributions from GitLab account on my GitHub\n\nI worked a summer job as a software developer for which I was given a git account to use (my own email on the company's domain), and that repository was saved on GitLab. I had TONS of contributions on that which I would like to be shown on my GitHub account. Is it possible to show that?\nI have tried adding the git email to my GitHub account, but that did not help (waited >24hrs).\nPlease let me know if there is a possibility of me being able to do this. Thanks in advance."}, {"role": "assistant", "content": "You can upload your GitLab repos to GitHub. Commits with timestamps from previous days will show up on your heatmap. You can do this by creating a repository on GitHub without a README, so that your original repo's .git directory is preserved when you push it upstream. Otherwise, all your timestamps won't be saved, and the entire repo will look like one big commit on the day you upload it.\nFor contributions to GitLab repos you don't own, you could try uploading the fork you've created for it."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "can`t configure/register dockerized gitlab runner\n\nI have running container with gitlab.\nAlso I try setup dockerized gitlab runner by this article.\nFirst i tried run gitlab runner by: \ndocker run -d --name gitlab-runner --restart always -v /srv/gitlab-runner/config:/etc/gitlab-runner -v /var/run/docker.sock:/var/run/docker.sock gitlab/gitlab-runner:latest\n\nlogs says: \n...\nListen address not defined, session server disabled  builds=0\nERROR: Failed to load config stat /etc/gitlab-runner/config.toml: no such file or directory  builds=0\nERROR: Failed to load config stat /etc/gitlab-runner/config.toml: no such file or directory  builds=0\n...\n\nAlso I tried register runner by this article:\ndocker run --rm -t -i -v /srv/gitlab-runner/config:/etc/gitlab-runner gitlab/gitlab-runner register\n\nafter 5 step:\nPlease enter the gitlab-ci tags for this runner (comma separated):\n my-tag,another-tag\n\nI get error:\nERROR: Registering runner... failed                 runner=KuwydETA status=couldn't execute POST against http://localhost/api/v4/runners: Post http://localhost/api/v4/runners: dial tcp 127.0.0.1:80: getsockopt: connection refused\nPANIC: Failed to register this runner. Perhaps you are having network problems"}, {"role": "assistant", "content": "In the /srv/gitlab-runner/config directory you need to insert the config.toml file.\nYou can locate the registration token at:\nhttps://{your_gitlab_host}/project_namespace/project_name/runners\n\nCreate a temporary configuration file using the following as a template:\n$ cat > /tmp/test-config.template.toml << EOF\n[[runners]]\n[runners.docker]\n[[runners.docker.services]]\nname = \"mysql:latest\"\n[[runners.docker.services]]\nname = \"redis:latest\"\nEOF\n\nYou can now register the runner using the configuration file you just created:\ngitlab-runner register \\\n  --non-interactive \\\n  --url \"https://gitlab.com\" \\\n  --registration-token \"$REGISTRATION_TOKEN\" \\\n  --template-config /tmp/test-config.template.toml \\\n  --description \"gitlab-ce-ruby-2.7\" \\\n  --executor \"docker\" \\\n  --docker-image ruby:2.7\n\nSource: https://docs.gitlab.com/runner/examples/gitlab.html\nhttps://docs.gitlab.com/runner/configuration/advanced-configuration.html"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Remove buttons from Gitlab interface\n\nIs there a way to remove the buttons for Add Changelog, Add license, Add Contribution guide, Add kubernetes cluster, and set up CI/CD, as well as the banner for Auto DevOps (Beta) from a project page?\nThese are all features that are not necessary for me at the moment and it would be a much cleaner interface without the buttons & banner. There is an image below to show what  I mean.\nVersion GitLab 10.6.0-ee"}, {"role": "assistant", "content": "This process worked for me on GitLab 10.8.14 to remove the auto devops message from annoying everyone.\nsudo gitlab-rails console\n\nFeature.get(:auto_devops_banner_disabled).enable => true\n\nexit\n\nsudo gitlab-ctl reconfigure"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Is it possible to configure N postgresql service instance in a GitLab CI?\n\nIs there a way to configure 5 postgresql instance in a Gitlab CI?\nThis is my configuration:\nimage: something:latest\n\nvariables:\n  SPRING_PROFILES_ACTIVE: gitlab-ci\n  POSTGRES_USER: gitlab-ci\n  POSTGRES_PASSWORD: gitlab-ci\n  POSTGRES_DB: DATA_V1\n  LDAP_DOMAIN: domain.com\n  LDAP_ORGANISATION: org\n  LDAP_ADMIN_PASSWORD: hello-ci\n\nservices:\n- name: docker:dind\n- name: osixia/openldap:1.1.9\n- name: postgres:10.0-alpine\n  alias: user-management-db\n- name: postgres:10.0-alpine\n  alias: company-management-db\n\nIt generate errors in CI : \n[0;m[0KStarting service docker:dind ...\n[0;m[0KPulling docker image docker:dind ...\n[0;m[0KUsing docker image docker:dind ID=sha256:4998cc824d9ac8e4be3bb89afa004c87911e796cde15f0676d437fcb8a8dd06b for docker service...\n[0;m[0KStarting service osixia/openldap:1.1.9 ...\n[0;m[0KPulling docker image osixia/openldap:1.1.9 ...\n[0;m[0KUsing docker image osixia/openldap:1.1.9 ID=sha256:0670342c5b82a10b014f0cf1060752ccb740cd8bd28a704ac3fa1191a4e31594 for osixia/openldap service...\n[0;m[0KStarting service postgres:10.0-alpine ...\n[0;m[0KPulling docker image postgres:10.0-alpine ...\n[0;m[0KUsing docker image postgres:10.0-alpine ID=sha256:0f0ff37589e948e31d9e64bb6c1b31cdbd4d7d0336b656cb6094be568e54ad04 for postgres service...\n[0;m[0;33mWARNING: Service postgres:10.0-alpine is already created. Ignoring.\n[0;m[0KStarting service postgres:10.0-alpine ...\n[0;m[0KPulling docker image postgres:10.0-alpine ...\n[0;m[0KUsing docker image postgres:10.0-alpine ID=sha256:0f0ff37589e948e31d9e64bb6c1b31cdbd4d7d0336b656cb6094be568e54ad04 for postgres service...\n[0;m[0;33mWARNING: Service postgres:10.0-alpine is already created. Ignoring.\n[0;m[0KStarting service postgres:10.0-alpine ...\n[0;m[0KPulling docker image postgres:10.0-alpine ...\n[0;m[0KUsing docker image postgres:10.0-alpine ID=sha256:0f0ff37589e948e31d9e64bb6c1b31cdbd4d7d0336b656cb6094be568e54ad04 for postgres service...\n[0;m[0;33mWARNING: Service postgres:10.0-alpine is already created. Ignoring.\n[0;m[0KStarting service postgres:10.0-alpine ...\n[0;m[0KPulling docker image postgres:10.0-alpine ...\n[0;m[0KUsing docker image postgres:10.0-alpine ID=sha256:0f0ff37589e948e31d9e64bb6c1b31cdbd4d7d0336b656cb6094be568e54ad04 for postgres service...\n[0;m[0;33mWARNING: Service postgres:10.0-alpine is already created. Ignoring.\n[0;m[0KStarting service postgres:10.0-alpine ...\n[0;m[0KPulling docker image postgres:10.0-alpine ...\n[0;m[0KUsing docker image postgres:10.0-alpine ID=sha256:0f0ff37589e948e31d9e64bb6c1b31cdbd4d7d0336b656cb6094be568e54ad04 for postgres service...\n[0;m[0;33mWARNING: Service postgres:10.0-alpine is already created. Ignoring.\n[0;m[0KStarting service postgres:10.0-alpine ...\n[0;m[0KPulling docker image postgres:10.0-alpine ...\n[0;m[0KUsing docker image postgres:10.0-alpine ID=sha256:0f0ff37589e948e31d9e64bb6c1b31cdbd4d7d0336b656cb6094be568e54ad04 for postgres service...\n[0;m[0;33mWARNING: Service postgres:10.0-alpine is already created. Ignoring.\n\nIt also can't be configured individually with variables that way.\nSo far my workaround was to create only one service with multiple database that won't be always possible. (two ldap for example)\nDid anybody have ever tried such configuration in Gitlab-CI?\nSeems like it has been repaired in gitlab 9.3 https://gitlab.com/gitlab-org/gitlab-runner/merge_requests/639/pipelines"}, {"role": "assistant", "content": "It's possible. For example:\nunit-test:\n  services:\n    - name: registry.company.com/postgres:14.6\n      alias: db1\n      variables:\n        POSTGRES_DB: \"db1\"\n        POSTGRES_USER: \"user1\"\n        POSTGRES_PASSWORD: \"pw1\"\n        POSTGRES_INITDB_ARGS: \"--encoding=UTF8 --no-locale\"\n    - name: registry.company.com/postgres:14.6\n      alias: db2\n      variables:\n        POSTGRES_DB: \"db2\"\n        POSTGRES_USER: \"user2\"\n        POSTGRES_PASSWORD: \"pw2\"\n        POSTGRES_INITDB_ARGS: \"--encoding=UTF8 --no-locale\"\n\nThis will start two postgreses, one reachable under the hostname db1 and the other with the hostname db2.\nHere is the documentation: https://docs.gitlab.com/ee/ci/services/index.html#available-settings-for-services"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Create a wiki page in gitlab\n\nI'm trying to create a simple wiki page on gitlab. Anyone knows of any good tutorials that could assist me in achieving that? I tried searching google for any tutorials but could not find any that are relevant."}, {"role": "assistant", "content": "You can use http://pad.haroopress.com/ as an editor, to see how it will look like in a wiki gitlab page.\nIn the bottom-left corner is a button, when you hit that button, you will get the markdown help."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI/CD and Nx affected:build\n\nI'm having trouble getting Nx to build properly inside Gitlab's CI/CD tool.\n\n> nx affected:build \"--prod\" \"--base=remotes/origin/development~1\" \"--head=remotes/origin/development\"\n\n\nfatal: Not a valid object name remotes/origin/development~1 Command\n  failed: git merge-base remotes/origin/development~1\n  remotes/origin/development fatal: Not a valid object name\n  remotes/origin/development~1\n\nI've tried different branches/commands such as just a plain: nx affected:build and I get the same error(just with a master branch indicated in the error message)\nAnyone able to get the Nx monorepo working with Gitlab?"}, {"role": "assistant", "content": "Had a similar problem. Running \"git fetch\" before the nx command fixed the issue."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "git fsck: duplicateEntries: contains duplicate file entries - cannot push to gitlab\n\nWe have a big git repository, which I want to push to a self-hosted gitlab instance.\nThe problem is that the gitlab remote does not let me push my repo:\ngit push --mirror https://mygitlab/xy/myrepo.git\n\nThis will give me this error:\nEnumerating objects: 1383567, done.\nCounting objects: 100% (1383567/1383567), done.\nDelta compression using up to 8 threads\nCompressing objects: 100% (207614/207614), done.\nremote: error: object c05ac7f76dcd3e8fb3b7faf7aab9b7a855647867: \nduplicateEntries: contains duplicate file entries\nremote: fatal: fsck error in packed object    \n\nSo I did a git fsck:\nerror in tree c05ac7f76dcd3e8fb3b7faf7aab9b7a855647867: duplicateEntries: contains duplicate file entries\nerror in tree 0d7286cedf43c65e1ce9f69b74baaf0ca2b73e2b: duplicateEntries: contains duplicate file entries\nerror in tree 7f14e6474400417d11dfd5eba89b8370c67aad3a: duplicateEntries: contains duplicate file entries\n\nNext thing I did was to check git ls-tree c05ac7f76dcd3e8fb3b7faf7aab9b7a855647867:\n100644 blob c233c88b192acfc20548d9d9f0c81c48c6a05a66    fileA.cs\n100644 blob 5d6096cb75d27780cdf6da8a3b4d357515f004e0    fileB.cs\n100644 blob 5d6096cb75d27780cdf6da8a3b4d357515f004e0    fileB.cs\n100644 blob d2a4248bcda39c0dc3827b495f7751b7cc06c816    fileC.xaml\n\nNotice that fileB.cs is displayed twice, with the same hash. I assume that this is the problem, because why would the file be two times in the same tree with the same file name and blob hash?\nNow I googled the problem but could not find a way how to fix this. \nOne seemingly good resource I found was this: Tree contains duplicate file entries\nHowever, it basically comes down to using git replace which does not really fix the problem, so git fsck will still print the error and prevent me from pushing to the remote.\nThen there is this one which seems to remove the file entirely (but I still need the file, but only once, not twice in the tree): https://stackoverflow.com/a/44672692/826244\nIs there any other way to fix this? I mean it really should be possible to fix so that git fsck does not throw any errors, right? I am aware that I will need to rewrite the entire history after the corrupted commits. I could not even find a way to get the commit that points to the specific trees, otherwise I might be able to use rebase and patching the corrupted commit or something. Any help would be greatly appreciated!\nUPDATE:\nPretty sure I know what to do, but not yet how to do it:\n\nCreating a new tree object from the old tree, but corrected with git mktree <- done\nCreate a new commit that is identical to the old one that references the bad tree but with the newly fixed tree <- difficult, I cannot easily get the commit to the tree, my current solution runs like an hour or more and I do not know how to create the modified commit then, once I have found it\nRun git filter-branch -- --all <- Should persist the replacements of the commits\n\nSadly I cannot just use git replace --edit on the bad tree and then run git filter-branch -- --all because filter-branch seems to only work on commits, but ignores tree-replaces..."}, {"role": "assistant", "content": "You can try running git fast-export to export your repository into a data file, and then run git fast-import to re-import the data file into a new repository. Git will remove any duplicate entries during the fast-import process, which will solve your problem.\nBe aware that you may have to make a decision about how to handle signed tags and such when you export by passing appropriate arguments to git fast-export; since you're rewriting history, you probably want to pass --signed-tags=strip."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Git failed to push (LFS upload missing objects)\n\nI\u2019ve been using Gitlab with LFS just fine for a while now but somehow ran into this problem today:\nme@some-PC MINGW32 /b/Unity Projects/Platballer (master)\n$ git push\nLFS upload missing objects: (32/33), 30 MB | 0 B/s\nUploading LFS objects:  97% (32/33), 30 MB | 0 B/s, done\n  (missing) Assets/External Assets/TimelineEvents/setup-guide.pdf (6ef8ef61e49821309de416925bf4e068ebb10a57f3398cb926e967eeb90cf034)\nCounting objects: 401, done.\nDelta compression using up to 16 threads.\nCompressing objects: 100% (400/400), done.\nWriting objects: 100% (401/401), 1.40 MiB | 9.56 MiB/s, done.\nTotal 401 (delta 177), reused 0 (delta 0)\nremote: Resolving deltas: 100% (177/177), completed with 31 local objects.\nremote: GitLab: LFS objects are missing. Ensure LFS is properly set up or try a manual \"git lfs push --all\".\nTo arvzrg.asuscomm.com:arvz/platballer.git\n ! [remote rejected] master -> master (pre-receive hook declined)\nerror: failed to push some refs to '[email\u00a0protected]:me/project.git'\n\nSo I did what they said and ran git lfs push --all origin master\nwhich gives me:\nUploading LFS objects: 100% (330/331), 52 MB | 0 B/s, done\nLFS upload missing objects:\n  (missing) Assets/External Assets/TimelineEvents/setup-guide.pdf (6ef8ef61e49821309de416925bf4e068ebb10a57f3398cb926e967eeb90cf034)\n\nIt seems like that did whatever needed doing, right? So I tried pushing again, but I still get the exact same problem I did before.\nI'm running my own installation of GitLab on a server on my network.\nWhat else can I do here?"}, {"role": "assistant", "content": "Check if this is similar to gitlab-org/gitlab-ce issue 40616:\n\nI've verified that it is possible to push to GitLab if the LFS objects are stored elsewhere, but LFS must be disabled for the project so that the LFS validation is disabled.\nDisabled LFS for the project using the API (I'm using HTTPie)\nhttp PUT https://gitlab.com/api/v4/projects/<id> name=<project-name> lfs_enabled=false Private-Token:<your token>\nAdd the lfs.url to the lfs config (for example GitHub)\ngit config -f .lfsconfig lfs.url https://github.com/<user>/<project>.git/info/lfs\n\nPush to GitLab should now work"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI can't fetch repo because keep asking for keychain password\n\nI have project on company Gitlab. Project is for iOS platform so my node for building project is Mac Mini with OS Sierra.\nRunner works great - connecting etc works. But when I try to run pipeline I get message on node like on picture. This alert appear when gitlab runner wants to checkout code.\nI checked in KeychainAccess that git-credential-osxkeychain app have access to password for gitlab on login keychain. \nHow to fix that and disable dialog for keychain password?\nconfig.toml file:\nconcurrent = 1\ncheck_interval = 0\n\n[[runners]]\nname = \"Mac mini runner\"\nurl = \"URLtoMyGitLab\"\ntoken = \"token\"\nexecutor = \"shell\"\n[runners.cache]"}, {"role": "assistant", "content": "For me the solution for this was to configure git, to use keychain in the project root.\n- git config --global credential.helper osxkeychain\n\nalong with unlocking the keychain in before_script:\n- security unlock-keychain -p $PASSWORD /Users/[MASKED]/Library/Keychains/login.keychain-db\n- security set-keychain-settings -t 3600 -l /Users/[MASKED]/Library/Keychains/login.keychain-db"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab Webhook and Jenkins: No Data Received\n\nI have been following the below links in order to integrate Gitlab with Jenkins using web hooks. All the below links mention to receive 'JSON' or 'payload' or token over at Jenkins side, but I do not see anything when I try to echo or print these parameters in the Shell script of Jenkins configurations.\nIn shell script I have this, but I never receive any payloads:\n\necho \"the build worked! The payload is $payload\"\n\nI do see some JSON coming through on /var/log/Jenkins/Jenkins.logs, but I want to see the messages coming in inside my 'Console Output', so that I can use the messages coming in from Gitlab to whether trigger a build or not.\nMost of these links mention options are not available via Gitlab. One article was mentioning to convert web hook format to application/json, but there are no such options on the Gitlab UI.\nHow to process a github webhook payload in Jenkins?\nhttp://chloky.com/github-json-payload-in-jenkins/\nJenkins Settings:\n\nGitlab webhook: \n\nhttp://xx.xx.xx.xxx:8080/job/Interim_Build/buildWithParameters?token=TOKEN_NAME\n\nAny help would be great. Thanks."}, {"role": "assistant", "content": "I suggest you to try two solutions (both working for me):\n\nconvert json data from Gitlab webhook using this elegant proxy written in Go https://github.com/akira/githookproxy .\nIt will take the webhook request, and translate it to a request to the target_url in the format of:\n\npayload: JSON body\nSTART: Start commit hash\nEND: End commit hash\nREFNAME: Ref name\n\nemulate jenkins as a Gitlab CI using this Jenkins plugin https://github.com/jenkinsci/gitlab-plugin \n\nFor me the best is the first because it is simple and more transparent."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab Runner - ERROR: Failed to remove network for build\n\nHere is my gitlab-ci.yml:\nimage: vibraniumcore/gcc-cmake-boost-mysqlcon\n#image: gitlab/dind\n\nstages:\n  - test\n  - build\n\nRun Tests:\n  stage: test\n  tags:\n    - c++\n  script:\n    - mkdir build\n    - cd build\n    - cmake ..\n    - cmake --build . --target VibraniumCoreTests\n    - cd ./Tests\n    - ./VibraniumCoreTests\n\nBuild VibraniumCore:\n  stage: build\n  tags:\n    - c++\n  script:\n    - mkdir build\n    - cd build\n    - cmake ..\n    - cmake --build .\n\nBuild AuthServer:\n  stage: build\n  tags:\n  - c++\n  script:\n    - cd Scripts\n    - ./build_authserver.sh\n\nBuild WorldServer:\n  stage: build\n  tags:\n  - c++\n  script:\n    - cd Scripts\n    - ./build_worldserver.sh\n\nWhen I try to run my pipeline I get this error:\nRunning with gitlab-runner 13.1.1 (6fbc7474)\n  on GCC-CMAKE HdBd6UX6\nPreparing the \"docker\" executor\n00:35\nERROR: Failed to remove network for build\nERROR: Preparation failed: error during connect: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.25/info: read unix @->/var/run/docker.sock: read: connection reset by peer (docker.go:894:4s)\nWill be retried in 3s ...\nERROR: Failed to remove network for build\nERROR: Preparation failed: error during connect: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.25/info: read unix @->/var/run/docker.sock: read: connection reset by peer (docker.go:894:10s)\nWill be retried in 3s ...\nERROR: Failed to remove network for build\nERROR: Preparation failed: error during connect: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.25/info: read unix @->/var/run/docker.sock: read: connection reset by peer (docker.go:894:10s)\nWill be retried in 3s ...\nERROR: Job failed (system failure): error during connect: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.25/info: read unix @->/var/run/docker.sock: read: connection reset by peer (docker.go:894:10s)\n\nAny idea why I get this error and how can I fix it?"}, {"role": "assistant", "content": "If you want to have your runner setup with executor=\"docker\", you may encounter the \"ERROR: Failed to remove network for build\" error if you have not installed docker on your machine hosting the runner.\nIn Ubuntu, try:\nsudo apt install docker.io\n\nAnd then re-run the pipeline."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Is there a way to display all sub wikis in an index page in gitlab?\n\nSo in gitlab you can use [[_TOC_]] to display a table of contents for the current page - which works on headings.\nBut I want to have a heirachy in my wiki like:\n<home-url>/Project1\n<home-url>/Project1/Tools\n<home-url>/Project1/Debugging\n<home-url>/Project1/Debugging/GDB\n<home-url>/Project1/Debugging/MSVS\n\nSuch that in the Project1 page I get an index (links) to each section similar to the table of contents layyout - e.g.:\n - Tools\n - Debugging\n    - GDB\n    - MSVS\n\nI can do this manually, but that's a pain to maintain. Is there some automatic tool to do this for me like TOC?"}, {"role": "assistant", "content": "Thanks to VonC for the actual answer - i.e. there is not such a feature at the moment (well, not quite as I want it) - but there is the side bar in gitlab wiki which shows you the pages within your wiki.\nIf you structure you wiki into folders and subfolders then you can navigate with this side bar \"tree\". Its not collapseable - so its just a bog-roll off text, but it is indented to aid navigation.\nIt works well enough for simple wikis with a few dozen pages - but probably if there are hundreds of pages it might start to breakdown - at that point you might want to break your wiki up into several wikis with a top-level links page or some such.\nHere is (a crap) picture - it was the best I could see on google without looking too hard see here\n\nYou get this for free (without doing anything) so its decent for most cases."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to show gitlab badges per branch in readme.md\n\nI am trying to show the build status of my branch on that branch's readme.md.\nhttps://mygitlab.com/<namespace>/<project>/badges/<branch>/coverage.svg  I tried this but branch place holder isn't getting evaluated."}, {"role": "assistant", "content": "You could create a README.md with the following for each branch\n[![Coverage](https://gitlab.com/<namespace>/<project>/badges/<branch>/coverage.svg)](https://gitlab.com/<namespace>/<project>/)\n\nfor example:\nMaster Branch README.md\n\nOther Branch README.md"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Move git repo with git clone --mirror and git push --mirror\n\nI have to move a couple of repos from Gitlab to Bitbucket and discovered that the easiest way to do it seems to be:\n\nCreate new empty repository in Bitbucket\ngit clone --mirror [email\u00a0protected]:path/to/repo.git\ncd repo.git\ngit remote set-url origin [email\u00a0protected]:path/to/repo.git\ngit push --mirror\n\nThis seems to copy the entire repo including tags, all branches etc. and I haven't discovered any disadvantages of this method yet. However, as I haven't seen this method anywhere on the internet, I'm afraid I'm missing something.\nCan I safely use this method and remove the old repositories afterwards?"}, {"role": "assistant", "content": "From a repo-only standpoint, it should be safe. All refs (branches, tags) are copied as-is.\nAs torek mentioned in the comments, other things might be left out: configuration, hosting-specific settings, hooks."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How is Gitlab's \"project workspace\" defined and propagated between jobs?\n\nGitlab's documentation often mentions a \"project workspace\" without actually defining its construction and functionality. One example is from the chapter about Git strategy which just plain tells the user \"Using git fetch which is faster as it re-uses the project workspace (falling back to clone if it doesn't exist).\" and doesn't define the way of reusage in any way.\nI would like to understand how it's created, how it's tranferred between jobs and how this impacts jobs running in a Docker executor. Is there some kind of information about this apart from the source code? Have I missed some crucial part of the documentation?"}, {"role": "assistant", "content": "There is no concept of a GitLab-specific workspace as far as I know. Perhaps it might be worth suggesting a change in that documentation page (everyone can submit a merge request using the links at the bottom of each docs page).\nI would say workspace in that concepts simply refers to either the parent directory under which you clone a Git repository, or the repository's own directory. This other document provides some more context."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI: Set dynamic variables\n\nFor a gitlab CI I'm defining some variables like this:\nvariables:\n  PROD: project_package\n  STAGE: project_package_stage\n  PACKAGE_PATH: /opt/project/build/package\n  BUILD_PATH: /opt/project/build/package/bundle\n  CONTAINER_IMAGE: registry.example.com/project/package:e2e\n\nI would like to set those variables a bit more dynamically, as there are mainly only two parts: project and package. Everything else depends on those values, that means I have to change only two values to get all other variables.\nSo I would expect something like\nvariables:\n  PROJECT: project\n  PACKAGE: package\n  PROD: $PROJECT_$PACKAGE\n  STAGE: $PROD_stage\n  PACKAGE_PATH: /opt/$PROJECT/build/$PACKAGE\n  BUILD_PATH: /opt/$PROJECT/build/$PACKAGE/bundle\n  CONTAINER_IMAGE: registry.example.com/$PROJECT/$PACKAGE:e2e\n\nBut it looks like, that the way doing this is wrong..."}, {"role": "assistant", "content": "I don't know where your expectation comes from, but it is trivial to check there is no special meaning for $, _, '/' nor : if not followed by a space in YAML. There might be in gitlab, but I doubt strongly that there is in the way you expect.\nTo formalize your expectation, you assume that any key (from the same mapping) preceded by a $ and terminated by the end of the scalar, by _ or by / is going to be \"expanded\" to that key's value. The _ has to be such terminator otherwise $PROJECT_$PACKAGE would not expand correctly.\nNow consider adding a key-value pair:\n BREAKING_TEST: $PACKAGE_PATH\n\nis this supposed to expand to:\n BREAKING_TEST: /opt/project/build/package/bundle\n\nor follow the rule you implied that _ is a terminator  and just expand to:\n BREAKING_TEST: project_PATH\n\nTo prevent this kind of ambiguity programs like bash use quoting around variable names to be expanded ( \"$PROJECT\"_PATH vs. $PROJECT_PATH), but the more sane, and modern, solution is to use clamping begin and end characters (e.g. { and }, $% and %, ) with some special rule to use the clamping character as normal text.\nSo this is not going to work as you indicated as indeed you do something wrong.\nIt is not to hard to pre-process a YAML file, and it can be done with e.g. Python (but watch out that { has special meaning in YAML), possible with the help of jinja2: load the variables, and then expand the original text using the variables until replacements can no longer be made. \nBut it all starts with choosing the delimiters intelligently. Also keep in mind that although your \"variables\" seem to be ordered in the YAML text, there is no such guarantee when the are constructed as dict/hash/mapping in your program.\nYou could e.g. use << and >>:\nvariables:\n  PROJECT: project\n  PACKAGE: package\n  PROD: <<PROJECT>>_<<PACKAGE>>\n  STAGE: <<PROD>>_stage\n  PACKAGE_PATH: /opt/<<PROJECT>>/build/<<PACKAGE>>\n  BUILD_PATH: /opt/<<PROJECT>>/build/<<PACKAGE>>/bundle\n  CONTAINER_IMAGE: registry.example.com/<<PROJECT>>/<<PACKAGE>>:e2\n\nwhich, with the following program (that doesn't deal with escaping << to keep its normal meaning) generates your original, expanded, YAML exactly.\nimport sys\nfrom ruamel import yaml\n\n\ndef expand(s, d):\n    max_recursion = 100\n    while '<<' in s:\n        res = ''\n        max_recursion -= 1\n        if max_recursion < 0:\n            raise NotImplementedError('max recursion exceeded')\n        for idx, chunk in enumerate(s.split('<<')):\n            if idx == 0:\n                res += chunk  # first chunk is before <<, just append\n                continue\n            try:\n                var, rest = chunk.split('>>', 1)\n            except ValueError:\n                raise NotImplementedError('delimiters have to balance \"{}\"'.format(chunk))\n            if var not in d:\n                res += '<<' + chunk\n            else:\n                res += d[var] + rest\n        s = res\n    return s\n\n\nwith open('template.yaml') as fp:\n    yaml_str = fp.read()\nvariables = yaml.safe_load(yaml_str)['variables']\ndata = yaml.round_trip_load(expand(yaml_str, variables))\nyaml.round_trip_dump(data, sys.stdout, indent=2)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to use gitlab-ci to manage test/construction of interdependent wheels\n\nI have 3 python packages proj1, proj12 and proj13. Both proj12 and\nproj13 depend on proj1 (with from proj1.xxx import yyy).\nThe 3 projects are on a private gitlab instance, each one has it's own .gitlab-ci.\nIn proj1 http://gitlab.me.com/group/proj1/.gitlab-ci.yml we run unittest\nand create a wheel exposed as an artifact::\n# http://gitlab.me.com/group/proj1/.gitlab-ci.yml\nimage: python:2\nmytest:\n  artifacts:\n    paths:\n    - dist\n  script:\n  - apt-get update -qy; apt-get install -y python-dev python-pip\n  - pip install -r requirements.txt\n  - python setup.py test\n  - python setup.py bdist_wheel\nlook:\n  stage: deploy\n  script:\n  - ls -lah dist\n\nFor proj12 and proj13 in e.g.\nhttp://gitlab.me.com/group/proj12/.gitlab-ci.yml we would like to run tests\ntoo, but I need to install proj1 wheel to make it run.\nAll 3 projects are in the same gitlab private group.\nWhat is the gitlab way to do this ?\n\nto pass the proj1 wheel to the proj12 with an artifact\n\nin this case I don't know how to call/get the artifact in\nhttp://gitlab.me.com/group/proj12/.gitlab-ci.yml ? It's the same gitlab, the\nsame group, but a different project.\n\nUse a gitlab Secret Variable to store ssh_keys to clone proj2 in proj12/.gitlab-ci.yml ?\n\n\nrelated to https://gitlab.com/gitlab-org/gitlab-ce/issues/4194 \nthis does not take benefit of the fact that proj1, proj12 and\nproj13 are in the same gitlab and same group, the person who do the build\nfor one project as credentials to do the others. All 3 are connected by the user private token.\n\n\nI try to avoid to have to deploy devpi or pypiserver like solutions.\nSo I'm looking on what to write in the proj12 .gitlab-ci.yml to get the \ndist/proj1-0.42-py2-none-any.whl wheel from the proj1 precedent build::\n# http://gitlab.me.com/group/proj12/.gitlab-ci.yml\nimage: python:2\nmytest12:\n  script:\n  - apt-get update -qy; apt-get install -y python-dev python-pip\n  - pip install -r requirements.txt\n  - pip install .\n  - => some way here to get the proj1 wheel \n  - pip install proj1-0.42-py2-none-any.whl\n  - python setup.py test\n\nLinks related to our issue:\n\nAllow access to build artifacts by using restricted access tokens https://gitlab.com/gitlab-org/gitlab-ce/issues/19628\n\"People need to be able to share links to artifacts based on a git ref (branch, tag, etc.), without knowing a specific build ID https://gitlab.com/gitlab-org/gitlab-ce/issues/4255\nhttps://docs.gitlab.com/ce/api/ci/builds.html#upload-artifacts-to-build \ndownload-the-artifacts-file https://docs.gitlab.com/ce/api/builds.html#download-the-artifacts-file https://gitlab.com/gitlab-org/gitlab-ce/issues/22957"}, {"role": "assistant", "content": "You have two ways you can do it:\n\nPass the object from previous build using the artifacts (works inside the same project only)\nBuild a docker image with your packages pre-installed in a git job, store it in the in-built registry and use that to run build in your other projects.\nClone the repository\n\nI would advise passing as an artifact since then you will have it build exactly in the pipeline you are running. As for the cloning, AFAIK you don't need any workaround when cloning submodules but for cloning other repositories I would go with ssh deploy key as it's connected with a repo and not a user like the private token."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Mermaid class diagrams get wider only, ignore direction\n\nI am having a problem using Mermaid syntax to layout class diagrams inside GitLab markdown. I have some evidence that I made a mistake in my Mermaid syntax, irrespective of GitLab. Thus, I felt it OK to ask on SO.\nThe class diagrams I am trying to create with Mermaid only lays out wider and wider as I add elements. The text in the diagram also get smaller and smaller. I cannot get the layout to expand vertically instead.\nHere is screen shot with H1 element for reference.\n\nI added the direction key word, but the layout ignores it. I have tried TD and TB and LR and RL for direction values. The class diagrams renders the same in all cases.\nI found this a more complicated diagram that renders nicely in GitLab. That layout uses both horizontal and vertical space. This makes me think that GitLab is working, but my syntax is wrong.\nHow do I get Mermaid to expand more vertically instead of horizontally and/or to not reduce the text size so much?\nHere is the code:\nclassDiagram\n%% Direction does not seem to be working?\ndirection TB\n%% ---- Lib Classes ----\nclass Lib_FancyFruit\nclass Lib_GoodBread{\n    +Double yeastAmount\n}\nLib_FancyFruit *-- \"0..*\" Lib_GoodBread : breads\nclass Lib_SeasideManor\nclass Lib_LiberalSpice{\n    +String currentFlavor\n}\nLib_SeasideManor *-- \"0..*\" Lib_LiberalSpice : spicesAllAround\nclass Lib_PrimeCurrents\nclass Lib_GardenFresh\nLib_GardenFresh *-- \"0..*\" Lib_PrimeCurrents : currentCurrents\nclass Lib_RepeatingHistory\nclass Lib_TranslationInformation\nclass Lib_HistoryLayerAgain\nLib_RepeatingHistory *-- \"0..*\" Lib_TranslationInformation : recentHistory\nLib_TranslationInformation *-- \"0..*\" Lib_HistoryLayerAgain : anotherTranslationInformation\n%% ---- Interfaces ----\nclass HappinessSadnessDisplay{\n    <<interface>>\n    ~String formattedCurrentThings\n    ~Date onceDate\n    ~String formattedDayDate\n    ~String goryDetail\n    ~String firstName\n    ~Bool workComplete\n    ~Bool appointmentScheduled\n}\nclass RedTrainSchedule{\n    <<interface>>\n    ~Double dailyCrayonsDue\n    ~Bool willBeOnTimeToday\n    ~createFreightTrainRailLine() FreightTrainRailLine\n}\n%% ---- Enums ----\nclass Pill{\n    <<enumeration>>\n    reallyOval\n    circularizedKind\n}\n%% ---- Main Classes ----\nclass WanderingMan\nWanderingMan o-- \"1\" Lib_LiberalSpice : spice\nWanderingMan o-- \"0..1\" Pill : pill\nWanderingMan o-- \"0..1\" Lib_GardenFresh : gardenAccounts\nWanderingMan o-- \"0..1\" PoliteHamAction : hamStory\nWanderingMan o-- \"0..1\" PoliteHamAction : scheduledPorkchops\nWanderingMan o-- \"0..1\" Lib_GoodBread : unwrappedBread\nWanderingMan ..|> RedTrainSchedule\nWanderingMan ..|> HappinessSadnessDisplay\nclass PoliteHamAction{\n    ~String porkNumber\n}\nPoliteHamAction o-- \"1\" Lib_HistoryLayerAgain : actionLayerDetail"}, {"role": "assistant", "content": ""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Table divider/bold row line in GitLab Flavored Markdown\n\nI have made a long table in GitLab, but would like to divide the rows within the table to highlight different groups. I would wish for a bold table row line as a divider or different background colors for the different groups.\nFrom what I have read, it does not seem to be possible by using only the GitLab Flavored Markdown syntax, and the closest I have come is to use an empty row as a divider, but I am not fully satisfied with that solution.\n| ---- |Precision | Recall | F1 | Support |\n| ---- | ---- | ---- | ---- |---- | ---- |\n| Group 1 |0.5 | 0.6 | 0.55 | 5 |\n| Group 1 |0.5 | 0.6 | 0.55 | 5 |\n|      |    |     |      |   |\n| Group 2 |0.5 | 0.6 | 0.55 | 5 |\n| Group 2 |0.5 | 0.6 | 0.55 | 5 |\n\nresults in this:\n\nAre there any other ways to do this more nicely? Perhaps with html/css?"}, {"role": "assistant", "content": "Have a Look at the gitlab markdown guide. A bold line separator isn't possible but the guide describes some options you can try to make your Groups differ:\nmix html and markdown\nyou can add html elements in your markdown. You could use that to color your groups differently\nstyles\ngitlab markdown allows you to define styles in your document:\n<style>\n  .purple {\n    color:inherit;\n  }\n  .purple:hover {\n    color:rgb(107,79,187);\n  }\n</style>\n\nYou can then apply this style like this:\nHey! Hover the cursor over me and guess what?! :)\n{: .purple}\n\nMaybe those options help you"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Best practices for using GOOGLE_APPLICATION_CREDENTIALS in gitlab CI/CD [closed]\n\nClosed. This question is opinion-based. It is not currently accepting answers.\n                                \n                            \n\n\n\n\n\n\n\n\n\n\n\nWant to improve this question? Update the question so it can be answered with facts and citations by editing this post.\n\n\nClosed last year.\n\n\n\n\n\n\n\n                        Improve this question\n                    \n\n\n\nI'm trying to make GitLab pipelines that deploy GCP instances through the GCP terraform provider.  Other platforms like AWS have environmental variables like $AWS_ACCESS_KEY_ID and $AWS_SECRET_ACCESS_KEY that can be used to authenticate requests, but GCP seems to use service account credential files instead.  \nI could create a CI gitlab file variable to contain my GCP service account credential file, but I can only add it in an insecure way.  If I attempt to mask my file variable under the GitLab ci-cd settings it produces the error message This variable can not be masked.\nWhat is the proper best practice for storing GCP service account credential files in GitLab CI/CD environmental variables?"}, {"role": "assistant", "content": "One approach is to take the environment variable and write it out as a file. When you add variable in the newer versions of Gitlab, there is a dropdown that lets you choose between \"Variable\" and \"File\". If you put the contents in the value field, you can use a cp $VARIABLE_NAME name-of-file.bob.\nYou don't need to mask it because it is never written to the log (unless you cat it), but I do recommend you check the \"Protect\" check box which means it will only be used on protected branches.\nA second approach is to encrypt it and decrypt it using a password which is in a protected variable. It would require getting another program in the build, but that might work for you.\nA third is use something like age to check in the encrypted file, write out a SSH as a fancy decryption key, and then package the SSH.\nBut, the first approach is probably going to be your best bet."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "sbt: Add http headers when fetching private maven repo with credentials\n\nI try to use credentials in my build.sbt config in order to retrieve private artifacts from a gitlab private maven repository.\nBut as sbt documentation states :\n\nThe credentials file is a properties file with keys realm, host, user, and password.\n\nAnd gitab private maven documentation states :\n\nIf a project is private or you want to upload Maven artifacts to GitLab,\n  credentials will need to be provided for authorization. Support is available for personal access tokens and CI job tokens only. Deploy tokens and regular username/password credentials do not work.\n\nThe only way to authenticate when fetching or pushing artifacts to gitlab maven private repository is to use a maven settings.xml file with :\n<settings>\n  <servers>\n    <server>\n      <id>gitlab-maven</id>\n      <configuration>\n        <httpHeaders>\n          <property>\n            <name>Private-Token</name>\n            <value>REPLACE_WITH_YOUR_PERSONAL_ACCESS_TOKEN</value>\n          </property>\n        </httpHeaders>\n      </configuration>\n    </server>\n  </servers>\n</settings>\n\nI found a workaround to push my private artifacts (intermediate step locally) but I am out of options to use these private artifacts as libraryDependencies in other scala repositories.\n\nIs there anyway to have sbt fetching my private gitlab repository with the required httpHeaders ?\nDo you know any workaround (multi-step fetchs) to have my private artifacts retrieved ?"}, {"role": "assistant", "content": ""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "On Premise Gitlab Pages: How to increase/debug public folder allowed size // ERROR: Uploading artifacts to coordinator... too large archive\n\nI'm creating a big (satis) package repository in a GitLab CI build step and wanted to just host it in GitLab Pages (on premise install). This works flawlessly, until the public folder size gets big, as soon as not only package versions, but downloads are stored in it as well. I added a last step to the pages task to show folder size:\n$ du -h public\n2.7G    public\nCreating cache default...\npublic: found 564 matching files                   \nvendor: found 3808 matching files                  \nCreated cache\nUploading artifacts...\npublic: found 564 matching files                   \nERROR: Uploading artifacts to coordinator... too large archive  id=494 responseStatus=413 Request Entity Too Large status=413 Request Entity Too Large token=kDf7gQEd\nFATAL: Too large                                   \nERROR: Job failed: exit code 1\n\nOf course that is a whole lot. I managed to delete some outdated minor version and was at\n950MB public\n\nStill the same problem. After some investigation there seem to be two relevant limits:\n\nGitlab Pages System Configuration: Max Pages Size (was set to 0 for unlimited)\nNGINX max post size in /etc/gitlab/gitlab.rb (was set to disabled, seems to default to 250M). Which I changed to nginx['client_max_body_size'] = '1024m'\n\nStill the same problem. Even after deleting even more versions down to 580M folder size the same error resides.\nAs soon as I disable downloads and thus only have <10Meverything works.\nHow can I debug the cause of this? Or is there some other hidden configuration?"}, {"role": "assistant", "content": "Since GitLab 12.7 (Jan 2020) it is possible for GitLab administrators to set the maximum pages size for individual groups and projects directly in the project/group settings.\nIn the project under settings -> pages, you can set the \"Maximum size of pages\" in MB.\n\nAdministrators can also set the global limit under Admin -> Settings -> Preferences -> Pages."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to send GitLab only schedule pipeline fail email?\n\nI wanted to send an email when schedule pipeline is failed. I have configure Project -> Settings -> Integrations -> Pipelines emails but these are sending emails for all the pipelines. \nI want to apply Pipeline Emails only for schedule ones. \nCould you please suggest any solution."}, {"role": "assistant", "content": "Looks like this isn't possible in GitLab. There is an issue about it here: https://gitlab.com/gitlab-org/gitlab/-/issues/220059\nYou probably have to turn off the automated GitLab emails entirely and then set up something manually in the schedule pipelines to email you, which is quite a drag but I guess should work."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Why does `nuxt generate` with @nuxt/pwa module generates always default icon in Gitlab-CI?\n\nI have the following problem. I am using nuxt with the pwa module to generate a pre-rendered webpage. The @nuxt/pwa icon module should generate the different sized icons for the manifest.\nThis is also working when I run nuxt generate on my laptop.\nIn my gitlab-ci pipeline the generation also is working but it is always generating the default nuxt icon\n\nThis icon I can not in my workspace so I guess it is somehow referenced in the docker build from node_modules.\nI am using the following gitlab-ci job\nbuild:\n  image: node:alpine\n  stage: build\n  script:\n    - npm run generate\n  artifacts:\n    paths:\n      - dist/*\n    expire_in: 14 days\n  only:\n    - master\n\nThe package.json looks like this:\n  \"scripts\": {\n    \"generate\": \"nuxt generate\",\n    ...\n  },\n  \"dependencies\": {\n    \"@nuxtjs/pwa\": \"^3.0.0-beta.20\",\n    \"nuxt\": \"^2.14.0\",\n    ...\n  },\n  \"devDependencies\": {\n   ...\n  }\n\nI also tried a lot of different settings in my nuxt.conf.js as I guessed that the icon is not referenced correctly.\nThis was my last try\n  pwa: {\n    icon: {\n      source: resolve(__dirname, './client/static/icon.png'),\n    },\n  },\n\nBut as it is found locally I thik that it is right.\nHas anyone an idea why the nuxt generate does not work in gitlab-ci?"}, {"role": "assistant", "content": "The issue seems to be the old cache located at /node_modules/.cache/pwa/icon\nNuxt doesn't generate new icons if the filenames are not changed so that is why the default icons are used. Especially if your new icon file is 'icon.png'.\nYou could go about this three ways:\n\nDelete the cache at /node_modules/.cache/pwa/icon before deploying but this only works with local/dev environment so this is out.\n\nYou could rename your file as the other comment suggested but you would have to rename it every time you change the file. So while this would work, it is still far from good, even for a hacky solution.\n\nThe third approach would be to delete that folder in your yarn/npm generate script. This would look something like this:\n\n\ngenerate: 'rm -r /node_modules/.cache/pwa/icon && nuxt generate';"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to list a subgroup's projects using the GitLab API?\n\nIn GitLab you can create subgroups within a group and projects within those subgroups. The GitLab documentation allows you to list the subgroups of a group and the projects of a group, but I cannot find anything about listing projects of a subgroup. Does anyone know the curl command for this, or at least know that it's not supported yet?\nI've tried:\ncurl -s -H 'PRIVATE-TOKEN: xxxxx' https://gitlab.com/api/v4/groups/mygroup/subgroups/mysubgroup/projects\ncurl -s -H 'PRIVATE-TOKEN: xxxxx' https://gitlab.com/api/v4/subgroups/mysubgroup/projects\nand other similar variations with no luck so far."}, {"role": "assistant", "content": "Use %2f to specify full path to subgroup:\ncurl -s https://gitlab.com/api/v4/groups/gitlab-org%2fgitter/projects\n\nSee this issue."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Developer unable to push to protected branch after git reset\n\nCan anyone explain why a member of my team is unable to push changes to the master branch (changes that will revet the repo back a few commits) after committing this git reset command:\ngit reset --hard (previous commit SHA)\n\nThis is the error that was received after attempting git push:\n ! [rejected]            master -> master (non-fast-forward)\nerror: failed to push some refs to '[email\u00a0protected]:xxx/xxxx.git'\nhint: Updates were rejected because the tip of your current branch is behind\nhint: its remote counterpart. Integrate the remote changes (e.g.\nhint: 'git pull ...') before pushing again.\nhint: See the 'Note about fast-forwards' in 'git push --help' for details.\n\nThe branch, master, is protected so that only \"Developers + Maintainers\" can push to it.\nMy team mate is a member of the Gitlab group in question with \"Developer\" privileges and has had no issue pushing to the remote repo before. I have Maintainer privileges and also was not able to push to the protected branch and received the same error.\nTo work around the issue I removed the branch protection and he was able to force push the changes (git push -f).\nDoes anyone know why this operation fails on a protected branch?"}, {"role": "assistant", "content": "You can try allowing force push / deletions from github repo 'settings'\nrepository => settings => branches => add rules"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How can I embed a snippet code at my Linkedin article?\n\nI want to embed a snippet code at my LinkedIn article, like that:\n\nThat image is from Gitlab snippets (https://gitlab.com/snippets/1841785). Is there some way to render its content in the LinkedIn articles? I saw that post at my LinkedIn feed and I got curious how to do this.\nI noticed that Gitlab provides two way to get the snippet: a embed or share content. How should I use?\nThank you."}, {"role": "assistant", "content": "Use https://carbon.now.sh/ for creating beautiful code snippets and download the pic and use it wherever you want"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Not asking password in my gitlab Repository\n\nPS E:\\Angular> git clone https://gitlab.com/souravgolui/MatDash.git <br>\nCloning into 'MatDash'...\nremote: HTTP Basic: Access denied<br>\nfatal: Authentication failed for 'https://gitlab.com/souravgolui/MatDash.git/'\n\nThis error will show in command prompt. please help.\nI entered wrong password , but not asking password 2nd time."}, {"role": "assistant", "content": "If password not asking(prompt popup), and saying authentication failed then follow below steps:\n\nclick on start\nType : Credential Manager\nSee the Windows (Manager shortcut or Credential Manager shortcut) and double-click it to open the application\nOnce the app is open, click on the (\"Windows Credentials\" or \"Generic Credentials\") tab where git:https://...\nselect edit and modify your update pwd then save it.***\n\nNow enjoy your work :)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI get last artifact\n\nI'm trying to get the latest build artifact using curl. Here's what I've tried. \nFirst, get last pipeline id:\ncurl -v -H \"Content-Type: application/json\" -H \"PRIVATE-TOKEN: <my-token-here>\" https://<project>/api/v4/projects/<project>/pipelines?per_page=1&page=1\n\nNext, get job id based on pipeline id just obtained before:\ncurl -sS --header \"PRIVATE-TOKEN: <my-token-here>\" \"https://[redacted,host]/api/v4/projects/[redacted,project]/pipelines/<pipeline-id>/jobs\" | jq '.[] | select(.name == \"build-assets\" and .status == \"success\" and .artifacts_file != null) | .id'\n\nFinally, get the artifacts to build.zip based on job id:\ncurl -sS --header \"PRIVATE-TOKEN: <my-token-here>\" \"https://[redacted,host]/api/v4/projects/[redacted, project]/jobs/<JOB_ID>/artifacts\" > build.zip\n\nThese steps above do work, but I have to hit three endpoints (and process the JSON response for each step).\nI also read in GitLab's documentation, that there's a single endpoint available for this. So I also tried this:\ncurl -sS --header \"PRIVATE-TOKEN: <my-token-here>\" \"https://<url>/<namespace>/<project>/-/jobs/artifacts/<refs>/download?job=<job_name>\"\n\nbut this always redirects me to the login page, saying this:\n<html><body>You are being <a href=\"https://<url>/users/sign_in\">redirected</a>.</body></html>\n\nIs there any simpler way to do this task? Or how to use the endpoint that is described on the documentation above propeprly?"}, {"role": "assistant", "content": "Scripting artifacts download\nTwo methods. The second one is the solution in your use case.\nFrom a Public project\ncurl -sS \"https://<url>/<namespace>/<project>/-/jobs/artifacts/<refs>/download?job=<job_name>\"\n\nNote : I gess you can't use your personal token here, it's reserved to API usage bellow.\nGitlab doc : downloading the latest artifacts\nFrom a Private project\ncurl -L --header \"PRIVATE-TOKEN: 123456abcdef\" \"https://gitlab.com/api/v4/projects/awesome-organization%2Fawesome-group%2Fowesome-project/jobs/artifacts/master/download?job=publish-release\"\n\nNote1 : the -l tells curl to follow the redirection since gitlab will move you to its google storage location.\nNote2 : the %2F value is the url-encoded replacement for the slash if your project is part or a group or subgroup in gitlab.\nGitlab api doc : downloading the latest artifacts"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab code quality: where is the report?\n\nOn this project: https://gitlab.com/tyvain/parcoursup/tree/master\nI have a code quality stage:\ncode_quality:\n  stage: code_quality\n  image: docker:stable\n  variables:\n    DOCKER_DRIVER: overlay2\n  allow_failure: true\n  services:\n    - docker:stable-dind\n  script:\n    - export SP_VERSION=$(echo \"$CI_SERVER_VERSION\" | sed 's/^\\([0-9]*\\)\\.\\([0-9]*\\).*/\\1-\\2-stable/')\n    - docker run\n        --env SOURCE_CODE=\"$PWD\"\n        --volume \"$PWD\":/code\n        --volume /var/run/docker.sock:/var/run/docker.sock\n        \"registry.gitlab.com/gitlab-org/security-products/codequality:$SP_VERSION\" /code\n  artifacts:\n    paths: [gl-code-quality-report.json]\n\nThis stage always endup 'passed'. Logs: https://gitlab.com/tyvain/parcoursup/-/jobs/94665791\nI doubt that my code is perfect, so there should be some code quality issues somewhere. \nWhere is the code quality report supposed to be output ?\nWhat is this parameter: \"paths: [gl-code-quality-report.json]\" ?"}, {"role": "assistant", "content": "2 problems here:\n\nthe report is only available for merge request in 'gitlab EE edition' (not free)\nthe report can be downloaded as a json file here:"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab 'fatal: repository '...' not found' - unable to push to a newly created project\n\nCan anyone spot what  I could possibly be doing wrong? You can browser zoom in to see image details. \nThis is a fresh account, new project, owner of group and I am simply unable to push (HTTPS) following instructions provided."}, {"role": "assistant", "content": "When adding the remote URL to the initial configuration, instead of using the URL that Gitlab gives you, try adding the following URL instead and replace the details below as mentioned, to reflect your info & your project info:\nREMOTE URL FORMAT:\nhttps://YOUR_USER_NAME:[email\u00a0protected]/YOUR_USER_NAME/YOUR_PROJECT_NAME.git/\n\nREPLACEMENTS IN THE ABOVE URL:\nYOUR_USER_NAME - Replace this with your gitlab username\nPASSWORD - Replace this with your gitlab password\nYOUR_PROJECT_NAME - Replace this with your gitlab project name (whatever is generated for you)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Error loading key \"(stdin)\": invalid format Gitlab CI\n\nThis is piece of my yaml file about ssh for gitlab ci:\neval $(ssh-agent -s)\necho \"$SSH_PRIVATE_KEY\" | tr -d '\\r' | ssh-add - > /dev/null\nmkdir -p ~/.ssh\nchmod 700 ~/.ssh\n'[[ -f /.dockerenv ]] && echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" > ~/.ssh/config'\n\nWhen I attempted to set SSH_PRIVATE_KEY variable to protected state, it occurs error:\n\nError loading key \"(stdin)\": invalid format\n\nand I don't know why it's okay when I set SSH_PRIVATE_KEY variable to unprotected state"}, {"role": "assistant", "content": "For me it also failed because the SSH_PRIVATE_KEY was marked as \"Protected\" but the tag I was using was not.\nSo either make the branch or tag you are using also protected or remove the \"Protected\" setting from the SSH_PRIVATE_KEY variable.\nSee: https://gitlab.com/help/ci/variables/README#create-a-custom-variable-in-the-ui\n\nProtect variable (Optional): If selected, the variable will only be available in pipelines that run on protected branches or tags."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "svn to git conversion: Correct remote ref must start with 'refs/' error\n\n(I'm posting this question with the intention of answering it myself as I could not find the answer elsewhere. Hopefully it will help others who run into the same issue and it will help me next time I'm trying to do it.)\nThe Challenge\nI want to convert an SVN repository to a locally hosted gitlab GIT repository and maintain history.\nThe Setup\nGitlab 8.5, Ubuntu 14.04 LTS, subversion 1.8.8\nThe Problem\nInitial attempts to convert from svn to git using git-svn or svn2git resulted in the following error.\nError\nsvn-remote.svn: remote ref '//example.com:81/svn/myrepository/trunk:refs/remotes/trunk' must start with 'refs/'\nWhat I've tried\nI've followed both guides in the external references below.\nExternal References used\n\nhttp://doc.gitlab.com/ce/workflow/importing/migrating_from_svn.html\nhttp://john.albin.net/git/convert-subversion-to-git"}, {"role": "assistant", "content": "Generate an authors.txt file. This will contain a mapping between your SVN users and your Gitlab users:\n\nFrom an existing svn repository: svn log -q | awk -F '|' '/^r/ {sub(\"^ \", \"\", $2); sub(\" $\", \"\", $2); print $2\" = \"$2\" <\"$2\">\"}' | sort -u > authors.txt\nOtherwise, manually create it following this format:\noldSVNusername = newGitlabUsername <[email\u00a0protected]>\n\nCreate a temporary directory init SVN repo\n\nmkdir temp\ncd temp\ngit svn init --no-metadata  http://username:[email\u00a0protected]:81/svn/myrepository\n\nConfigure git\n\ngit config svn.authorsfile ~/authors.txt\ngit config --global user.name myusername\ngit config --global user.email [email\u00a0protected]\n\nGrab the files and clone them into a new git repo\n\ngit svn fetch\ngit clone . ../myrepository\ncd ../myrepository\n\nSetup new repository in gitlab, make sure your user has access to it.\nAdd a remote gitlab repository\n\ngit remote add gitlab gitlab.example.com:gitlab-group/myrepository.git\n\nDouble check your configuration in myrepository/.git/config (especially the URL line)\n[core]\n   repositoryformatversion = 0\n    filemode = true\n    bare = false\n    logallrefupdates = true\n[remote \"origin\"]\n    url = /root/temp/.\n    fetch = +refs/heads/*:refs/remotes/origin/*\n[branch \"master\"]\n    remote = gitlab\n    merge = refs/heads/master\n[remote \"gitlab\"]\n    url = http://gitlab.example.com/gitlab-group/myrepository.git\n    fetch = +refs/heads/*:refs/remotes/gitlab/*\n[user]\n    name = myusername\nPush it all upstream\n\ngit push --set-upstream gitlab master\n\n\nNow you should have all the files and history converted to git and displaying in gitlab."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab Configuration Issues:: NGINX Unicorn Port Conflict\n\nI have managed to partly setup Gitlab on a Linux CentOS server with Apache, Git, PHP, PostGreSQL and MySQL. I am running the Chef Cookbook version. I got the rpm from here. I wanted to use it to manage my Git repo better and more visually and this seemed to be a good choice. But now I run into issues getting it to work.\nJust to make it really work and update all files I decided to rerun the configuration using gitlab-ctl reconfigure. Second run did work:\nChef Client finished, 4 resources updated\ngitlab Reconfigured!\n\nSee full log\nThe hoster had already put NGINX on 8080 not get into an argument with Apache running on port 80 where we have a LAMP project running.  But now Ruby's Unicorn Web Server seems to be conflicting with NGINX. I have worked with NGINX a little bit, not much and this is my first stab at Gitlab. Anyways this is what I figured out with the help of my hoster.\nWhen I log into testserver.domain.net and pass the following command:\nnetstat -ln |grep 8080 I see\ntcp        0      0 127.0.0.1:8080              0.0.0.0:*                   LISTEN      \n\nSo something is running on 8080\nAccording to my hoster it should run on 0.0.0.0:8080. And when we check what is running on that port we see\nnetstat -tupln |grep 8080\ntcp        0      0 127.0.0.1:8080              0.0.0.0:*                   LISTEN      21627/unicorn maste \n\nWhen we check the process id 21627, we see\ncat /proc/21627/cmdline \nunicorn master -E production -c /var/opt/gitlab/gitlab-rails/etc/unicorn.rb /opt/gitlab/embedded/service/gitlab-rails/config.ru\n\nThat is a Ruby process, and not a NGINX process.\nSo NGINX seems to be conflicting with Unicorn.\nAnd when we check the logs of nginx we see that nginx cannot get going because of this:\ntail -f /var/log/gitlab/nginx/error.log \n2014/07/28 09:43:10 [emerg] 23122#0: bind() to 0.0.0.0:8080 failed (98: Address already in use)\n2014/07/28 09:43:10 [emerg] 23122#0: still could not bind()\n2014/07/28 09:43:12 [emerg] 23123#0: bind() to 0.0.0.0:8080 failed (98: Address already in use)\n2014/07/28 09:43:12 [emerg] 23123#0: bind() to 0.0.0.0:8080 failed (98: Address already in use)\n2014/07/28 09:43:12 [emerg] 23123#0: bind() to 0.0.0.0:8080 failed (98: Address already in use)\n2014/07/28 09:43:12 [emerg] 23123#0: bind() to 0.0.0.0:8080 failed (98: Address already in use)\n2014/07/28 09:43:12 [emerg] 23123#0: bind() to 0.0.0.0:8080 failed (98: Address already in use)\n2014/07/28 09:43:12 [emerg] 23123#0: still could not bind()\n\nI googled Unicorn.rb and found this link. I also read that:\n\nUnicorn is an HTTP server for Rack applications designed to only serve\n  fast clients on low-latency, high-bandwidth connections and take\n  advantage of features in Unix/Unix-like kernels. Slow clients should\n  only be served by placing a reverse proxy capable of fully buffering\n  both the the request and response in between Unicorn and slow clients.\n\nWhen I check the file /var/opt/gitlab/gitlab-rails/etc/unicorn.rb I do see it uses 8080. Issue is that it seems Unicorn should work together with NGINX so perhaps I should not change the port. \nWhat step should I take to make Gitlab work? Can Gitlab work without Unicorn? I would think not.  Should I then pick another port for it or perhaps for NGINX?"}, {"role": "assistant", "content": "You should override the ports in /etc/gitlab/gitlab.rb. Don't mess with /var/opt/gitlab/... because any manual configuration will be lost after a reconfigure. In particular read on Setting the NGINX listen port. In the downloads page there is a sentence: For troubleshooting and configuration options please see the Omnibus GitLab readme. I wonder if this is not seen by people :/ If not we should make it more clear."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Unsupported URL protocol in git provider error\n\nI have two separate PCs that connect to the same Gitlab repo. Both running Visual Studio Update 3 and using Team Explorer with Git. On one PC, I have no problem updating the project and then pushing the commits to the remote repo. On the other PC however any operation (push or fetch or sync) will fail with an Unsupported URL protocol error, although originally I managed to clone the repo. I suspect it doesn't like something in the connection string, since I can commit and sync the repo using command line git (version 2.9.2 so fairly recent). What is the cause of this error and is there a workaround?"}, {"role": "assistant", "content": "I have checked the difference between the two local repos, and git remote -v on PC1 gives:  \n\norigin https://gitlab.com/ ...\n\nwhile on PC2:\n\norigin [email\u00a0protected]: ...\n\nAfter further investigation it appears that the old version of LibGit2 which VS2015 Update3 uses lacks SSH support. The first repo was the original and created in VS, the second repo was cloned via a command-line, hence the SSH connection string. \nThe workaround is to change the connection string in .git/config to  \n\nurl = https://gitlab.com/ ...\n\nIf one absolutely needs SSH than it is possible to recompile gitlib2, or use command line git which works. It might be possible to use other Git Source Providers in VS2015, however I haven't tested it. (for example Git Source Control Provider 2015)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab-ci.yml only on master branch\n\nI have a gitlab-ci.yml file like this, and want to run it only on Branch Master. If there is a push into develop branch the Pipeline should NOT start.\nI tried with 'only' keyword, but it shows an Error.\nstages:\n  - info\n  - build\n  - test\n  - review\n  - cleanup\n  - deploy-dev\n  - integration-test\n  - deploy-test\n  - system-test\n  - deploy-production\n\nonly:\n  refs:\n    - master"}, {"role": "assistant", "content": "To define a trigger rule for every stage you can use the workflow keyword, like this:\n    workflow:\n      rules:\n        - if: $CI_COMMIT_TAG\n          when: never\n        - if: $CI_COMMIT_BRANCH == 'master'\n\nThis has to be on the \"root\" of your yaml, as it is not part of any job in particular.\nIn the example above, I am telling the pipeline to avoid running when a repository tag is pushed and to run only when a commit is done in the master branch.\nYou can use this as a base and add other conditions to trigger the stages in the pipeline, the complete documentation on this matters can be found here: https://docs.gitlab.com/ee/ci/yaml/#workflow"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Resolving a merge request locally with a protected branch\n\nI am using Gitlab, and I have a conflict on my merge request that I cannot resolve with the online tool. I checkout the target branch and resolve the conflict, then ... Then what ?\n\nThe branch is protected, so no one is allowed to push on it.\nNo option available on Gitlab to do something like this.\n\nWhat is supposed to be the correct \"way\" of doing in those cases ? Are we supposed to create another branch to solve the conflict, then another merge request ? Or is there a commmand line / an alternative I failed to see when searching for a solution, like \"push the result of the solving conflict which is not a commit per se\" ?"}, {"role": "assistant", "content": "Are we supposed to create another branch to solve the conflict, then\n  another merge request ?\n\nYes, I'd suggest doing this.\n1) Create a new branch off the destination branch\n2) Merge your feature branch in it\n3) Solve conflicts, add them, and commit the merge\n4) Push that new branch to remote\n5) Create a new PR from the new branch to the destination one"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab Runner - New folder for each build\n\nI'm using Gitlab CI for my project. When I push on develop branch, it runs tests and update the code on my test environment (a remote server).\nBut the gitlab runner is already using the same build folder : builds/a3ac64e9/0/myproject/myproject\nBut I would like to create a now folder every time : \n\nbuilds/a3ac64e9/1/yproject/myproject\nbuilds/a3ac64e9/2/yproject/myproject\nbuilds/a3ac64e9/3/yproject/myproject\nand so on\n\nUsing this, I could just update my website by changing a symbolic link pointing to the last runner directory.\nIs there a way to configure Gitlab Runner this way ?"}, {"role": "assistant", "content": "While it doesn't make sense to use your build directory as your deployment directory, you can setup a custom build directory\nOpen config.toml in a text editor: (more info on where to find it here)\nSet enabled = true under [runners.custom_build_dir] (more info here)\n[runners.custom_build_dir]\n  enabled = true\n\nIn your .gitlab-ci.yml file, under variables set GIT_CLONE_PATH.  It must start with $CI_BUILDS_DIR/, e.g. $CI_BUILDS_DIR/$CI_JOB_ID/$CI_PROJECT_NAME, which will probably give you what you're looking for, although if you have multiple stages, they will have different job IDs.  Alternatively, you could try $CI_BUILDS_DIR/$CI_COMMIT_SHA, which would give you a unique folder for each commit.  (More info here)\nvariables:\n    GIT_CLONE_PATH: '$CI_BUILDS_DIR/$CI_JOB_ID/$CI_PROJECT_NAME'\n\n\nUnfortunately there is currently an issue with using GIT_BUILDS_DIR in GIT_CLONE_PATH, if you're using Windows and Powershell, so you may have to do something like this as a work-around, if all your runners have the same build directory: GIT_CLONE_PATH: 'C:\\GitLab-Runner/builds/$CI_JOB_ID/$CI_PROJECT_NAME'\n\nYou may want to take a look at the variables available to you (predefined variables) to find the most suitable variables for your path."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Prevent commit when gitlab-CI pipeline fail\n\nIs there a way to prevent a push to gitlab if the pipeline fail?\nHere's a gitlab-ci.yml sample with multiple jobs. This pipeline is triggered on every push. \nIf one of the job failed  I don't want my code to be pushed on my repository. (I know this feature exist for pull request).\nimage: node:9.4.0\n\ncache:\n  paths:\n  - node_modules/\n\nbefore_script:\n  - npm install\n\nstages:\n    - lint\n    - test\n\nlint:\n  stage: lint\n  script:\n   - npm run lint\n\ntest:\n  stage: test\n  script:\n   - npm run test"}, {"role": "assistant", "content": "Sorry Simon - this is not how this is supposed to work. You need the stuff in the repo so the pipeline can run.\nYou should use a branching flow, where you only allow successful builds/merge requests to be merged against develop/master, so you don't have to care if failing code is added in the repo. Your main branches always stay clean. You can enforce this behavior by only allowing merges against develop/master (protected branches) and not allow direct pushes.\nFor simpler things you can use pre-commit hooks, with only allow pushing if, for example, npm run lint succeeds. But, running a whole pipeline is too much for a pre-commit-hook (it may work, but it's not best practice)."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Using GitLab API, how do I get a list of active users?\n\nGitlab-CE v8.14.3\nI'm reading the GitLAB API docs, and am trying to get the list of active users. I'm an admin and created a personal token. I do this\n$ curl -XGET \"Private-Token: kfjakjfkjkd\" https://company.domain.com/api/v3/users?active=true\n\nand keep getting 401 (Unauthorized) error. Like I said, I'm an admin. What gives?"}, {"role": "assistant", "content": "You must specify the header using the -H option as noted in Bertrand Martel's answer. That will retrieve up to 20 users.\nAbove 20 users, you must get fancier. The JSON output is paginated, and each query is limited to 100 users per page. So to get 300 users, you must get three pages, 100 users at a time:\ncurl -H \"Private-Token: kfjakjfkjkd\" \"https://company.domain.com/api/v4/users?active=true&per_page=100&page=1\" > gitlabusers1.json\ncurl -H \"Private-Token: kfjakjfkjkd\" \"https://company.domain.com/api/v4/users?active=true&per_page=100&page=2\" > gitlabusers2.json \ncurl -H \"Private-Token: kfjakjfkjkd\" \"https://company.domain.com/api/v4/users?active=true&per_page=100&page=3\" > gitlabusers3.json"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Referencing repository files at a given commit in gitlab wiki\n\nGitlab Markdown has support for references to files in the repository structure, like:\n[README](doc/README)\nor\n[README](doc/README#L13)\nBut are there ways to reference files and lines in these files, but from a given commit, at least in the Wiki ? \nMaybe something like:\n[README](1ab3fa71:doc/README#L13)\nor using the file hash id like:\n[README](9a27b101#L13)"}, {"role": "assistant", "content": "To use relative links from wiki to the repository (or wise versa) is not supported officially  according to Gitlab's documentation (cited from v11.5, still valid for v15.3):\n\nNote: Relative links do not allow referencing project files in a wiki page or wiki page in a project file. The reason for this is that, in GitLab, wiki is always a separate Git repository. For example, I'm a reference-style link will point the link to wikis/style when the link is inside of a wiki markdown file.\n\nThere is, however, a syntax which seems to work currently:\n[[README|/../blob/1ab3fa71/doc/README#L13]]\n\nBut be aware: all text of the same paragraph will just be lost!\nI work around that by phrasing like this, which renders like expected for Gitlab CE v11.3.0 at least:\nHere you see xyz:\n* [[README|/../blob/1ab3fa71/doc/README#L13]]\n\nThe root-anchored link (/../blob/<version>/<path-to-file>) ensures that it works from every Wiki page independently from their nesting depth.\nFor sure this syntax also works for branch names or any other relative link like /../tree/1ab3fa71/doc for example."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab-runner locally - No such command sh\n\nI have gitlab-runner installed locally. \nkm@Karls-MBP ~ $ gitlab-runner --version\nVersion:      10.4.0\nGit revision: 857480b6\nGit branch:   10-4-stable\nGO version:   go1.8.5\nBuilt:        Mon, 22 Jan 2018 09:47:12 +0000\nOS/Arch:      darwin/amd64\n\nDocker:\nkm@Karls-MBP ~ $ docker --version\nDocker version 17.12.0-ce, build c97c6d6\n\n.gitlab-ci.yml:\nimage: docker/compose:1.19.0\n\nbefore_script:\n  - echo wtf\n\ntest:\n  script:\n    - echo test\n\nResults:\nkm@Karls-MBP ~ $ sudo gitlab-runner exec docker --docker-privileged test\nWARNING: Since GitLab Runner 10.0 this command is marked as DEPRECATED and will be removed in one of upcoming releases \nWARNING: You most probably have uncommitted changes. \nWARNING: These changes will not be tested.         \nRunning with gitlab-runner 10.4.0 (857480b6)\n  on  ()\nUsing Docker executor with image docker/compose:1.19.0 ...\nUsing docker image sha256:be4b46f2adbc8534c7f6738279ebedd6106969695f5e596079e89e815d375d9c for predefined container...\nPulling docker image docker/compose:1.19.0 ...\nUsing docker image docker/compose:1.19.0 ID=sha256:e06b58ce9de2ea3f11634e022ec814984601ea3a5180440c2c28d9217b713b30 for build container...\nRunning on runner--project-0-concurrent-0 via x.x.x...\nCloning repository...\nCloning into '/builds/project-0'...\ndone.\nChecking out b5a262c9 as km/ref...\nSkipping Git submodules setup\nNo such command: sh\n\nCommands:\n  build              Build or rebuild services\n  bundle             Generate a Docker bundle from the Compose file\n  config             Validate and view the Compose file\n  create             Create services\n  down               Stop and remove containers, networks, images, and volumes\n  events             Receive real time events from containers\n  exec               Execute a command in a running container\n  help               Get help on a command\n  images             List images\n  kill               Kill containers\n  logs               View output from containers\n  pause              Pause services\n  port               Print the public port for a port binding\n  ps                 List containers\n  pull               Pull service images\n  push               Push service images\n  restart            Restart services\n  rm                 Remove stopped containers\n  run                Run a one-off command\n  scale              Set number of containers for a service\n  start              Start services\n  stop               Stop services\n  top                Display the running processes\n  unpause            Unpause services\n  up                 Create and start containers\n  version            Show the Docker-Compose version information\n\nDon't really know what the issue is."}, {"role": "assistant", "content": "It seems that the docker/compose image is configured with docker-compose as an entrypoint.\nYou can override the default entrypoint of the docker/compose image in your .gitlab-ci.yml file :\nimage: \n  name: docker/compose:1.19.0\n  entrypoint: [\"\"]\n\nbefore_script:\n  - echo wtf\n\ntest:\n  script:\n    - echo test"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Get gitlab-ci token with gitlab API\n\nThis question's answers are a community effort. Edit existing answers to improve this post. It is not currently accepting new answers or interactions.\n                                \n                            \n\n\n\n\n\n\nIt's unclear from the API how to get the token that can be used to clone http repositories.\nFrom the documentation here: \nhttp://doc.gitlab.com/ee/ci/api/README.html\nIt should be possible to GET this url:\nhttp://gitlab.com/ci/api/v1/projects?private_token=QVy1PB7sTxfy4pqfZM1U&url=http://demo.gitlab.com/\n\nI'm not sure where the url parameter is taken from but even with just my private token, it receive a 404 error page.\nI tried with the ci subdomain but it simply redirect me to gitlab.com.\nThat said, I'll explain a bit more the reason why I need that. I have a server that could have multiple projects. Each projects will contain a list of repositories private/public each project has to be cloned/pulled and whatever regularly. Unlike github, gitlab doesn't provide a oauth2 token that is sitewide and instead provide a CI-token for each project. I could make sure that the user enter the token for each project but that is way more complicated than entering the private token.\nOn the other hand, I could generate SSH keys for each users and add the public key to their account and this way it would be possible to fetch/clone with ssh instead of http. But that is a bit more work on my end than just fetching a token and cloning with a basic auth url\ngit clone https://gitlab-ci-token:[email\u00a0protected]/project.git"}, {"role": "assistant", "content": "You can find the token by doing the following from gitlab.com\n\nClick on the project you are working on from the starting screen\nClick \"Settings\" on the left hand navigation\nScroll down to the bottom and click \"CI / CD\" which is nested in Settings\nUnder the \"Runners\" section click expand\nToken is hidden here.\n\nTook me 10 minutes to find this... not documented anywhere."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab api get group list only 20 groups not all\n\nWe use Gitlab 7.8, i'm trying to get full list of groups on our prod server via gitlab api, unfortunately gitlab api is returning only 20 groups out of 80 available group. Any help in this would be appreciated.\ncommand used is curl -k --header \"PRIVATE-TOKEN: token of admin users\"  https://server_name/api/v3/groups\n\nRunning this as admin and adding admin account to all the groups didn't help either."}, {"role": "assistant", "content": "20 is the default number of results returned by GitLab API\nYou could pass the per_page=80 parameter, to get your 80 expected groups."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Is there any way to force pip install to retry on requirements install failure?\n\nI'm trying to install some pip requirements in a container I build. But due to my setup (docker build runs in a VM on a system connected over VPN to the network where the git server is located. COVID-19 situation) I get the error below. I know the issue is caused by my setup as sometimes works fine. Plus if i run the same docker build on a machine within the same network with the git server, also works fine. I spend some time to try to figure out my network problem, but haven't found any proper solution yet.\nSo knowing that some time the pin install git clone works, i was wondering if there is any way of instructing pip to retry the installation o failed component, until it succeeds?\nThis is how I call pip install:\npip install --no-cache-dir --disable-pip-version-check -r requirements.txt\n\nThe git lab repo URL is properly defined in the requirements.txt\nThanks\nCollecting git+https://gitlab%2Bdeploy-token-98:****@git.my.host.com/core-tech/tools/nlu/[email\u00a0protected] (from -r requirements.txt (line 19))\n  Cloning https://gitlab%2Bdeploy-token-98:****@git.my.host.com/core-tech/tools/nlu/trsx-converter.git (to revision 0.0.3) to /tmp/pip-req-build-t8m2io14\n  Running command git clone -q 'https://gitlab%2Bdeploy-token-98:****@git.my.host.com/core-tech/tools/nlu/trsx-converter.git' /tmp/pip-req-build-t8m2io14\n  fatal: unable to access 'https://git.my.host.com/core-tech/tools/nlu/trsx-converter.git/': The requested URL returned error: 511                                                                                                       \nERROR: Command errored out with exit status 128: git clone -q 'https://gitlab%2Bdeploy-token-98:****@git.my.host.com/core-tech/tools/nlu/trsx-converter.git' /tmp/pip-req-build-t8m2io14 Check the logs for full command output."}, {"role": "assistant", "content": "There's a --retries option on the pip install command:\npip install --help\n\nGeneral Otions:\n\n  --retries <retries>         Maximum number of retries each connection should attempt (default 5 times).\n\nIt's 5 by default, so I'm not sure it will actually fix your issue, but you could try with a higher value, just in case."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI Pipeline: Pipeline cannot be run\n\nI can't find out why the GitLab CI Pipelines for my Repo won't run. I have a .gitlab-ci.yml file and the feature enabled, but the pipeline won't run. Also if I try to trigger the pipeline manually I get the following error back.\nPipeline cannot be run.\nPipeline will not run for the selected trigger. The rules configuration prevented any jobs from being added to the pipeline.\n\n\nThe CI feature is enabled.\n\nHere is my .gitlab-ci.yml file.\nstages:\n  - build\n  - deploy\n\nnpm-run-build:\n  stage: build\n  image: node:19\n  only: \n    - main\n  cache:\n    key: ${CI_COMMIT_REF_SLUG}-build\n    paths:\n      - dist/\n  script:\n    - cp .env.example .env\n    - npm ci\n    - npm run build-only\ndeploy-dist:\n  stage: deploy\n  image: fedora:latest\n  only: \n    - main\n  environment:\n    name: production\n    url: https://example.com\n  needs:\n    - npm-run-build\n  cache:\n    key: ${CI_COMMIT_REF_SLUG}-build\n    paths:\n      - dist/\n      \n  before_script:\n    - dnf install -y openssh-clients\n    - mkdir -p ~/.ssh\n    - echo \"$SSH_PRIVATE_KEY\" > ~/.ssh/id_rsa\n    - chmod 600 ~/.ssh/id_rsa\n    - ssh-keyscan -t rsa example.com > ~/.ssh/known_hosts\n  script:\n    # create remote project dir if not available\n    - ssh [email\u00a0protected] \"mkdir -p /home/thomas/example.com\"\n    # upload project files\n    - scp -prq . [email\u00a0protected]:/home/thomas/example.com\n    # restart the container\n    - ssh [email\u00a0protected] \"cd /home/thomas/example.com && docker-compose down && docker-compose up -d\"\n\nThank you! \ud83d\ude01"}, {"role": "assistant", "content": "As D Malan pointed out in the comments, I have restricted the runs with only to the main branch. But the branch name is actually master \ud83e\udd26\nSo I just changed the rule form main to master and now it is running \ud83d\udc4c"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "ArgoCD - what need be done after build a new image\n\nI have deployed the application via ArgoCD successfully, and I can access it via its ingress url\nThe applicaiton uses the image name with latest tag, such as\nimage: <private_registry>/app_1_service:latest\n\nI also manage other tags on same of tag latest, such as image:<commit_id> or image:<1.0.xxx>\nNow, developers will update the codes, after commit changes, a gitlab pipeline  automatically runs and build a new image and override to tag latest with other tags and push to private docker registry\nSo what's the next step in ArgoCD?\nHow argocd know the application is changed, and need be redeployed, and the image:latest need be pull again?"}, {"role": "assistant", "content": "You can use ArgoCD image-updater\nBut before using the the image-updater, you need to install and set appropriate permission\nhelm repo add argo https://argoproj.github.io/argo-helm\nhelm install argocd-image-updater argo/argocd-image-updater\n\nOnce image-updator is up and running, then you need to set a few annotations in the Argocd application, as the update workers on different strategies\n\nsemver - Update to the latest version of an image considering semantic versioning constraints\nlatest - Update to the most recently built image found in a registry\ndigest - Update to the latest version of a given version (tag), using the tag's SHA digest\nname - Sorts tags alphabetically and update to the one with the highest cardinality\n\nlatest strategies working awesome with tagging under some regex and digest more suited for testing environment.\nupdate-strategies\nYou can also pull the private image from gitlab as well.\nHere is the working example with helm-release\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  annotations:\n    argocd-image-updater.argoproj.io/image-alias.allow-tags: 'regexp:^1.3.0-SNAPSHOT.[0-9]+$'\n    argocd-image-updater.argoproj.io/image-alias.force-update: 'true'\n    argocd-image-updater.argoproj.io/image-alias.pull-secret: 'pullsecret:develop-namespace/develop-app-gitlab-secrets'\n    argocd-image-updater.argoproj.io/image-alias.update-strategy: latest\n    argocd-image-updater.argoproj.io/image-list: >-\n      image-alias=registry.gitlab.com/myorg/my-test-image\n  finalizers:\n    - resources-finalizer.argocd.argoproj.io\n  labels:\n    app.kubernetes.io/instance: develop-platform\n  name: develop-app\n  namespace: argocd\nspec:\n  destination:\n    namespace: develop-app\n    server: 'https://kubernetes.default.svc'\n  project: develop-app-west6-b\n  source:\n    helm:\n      releaseName: develop-app\n      valueFiles:\n        - develop-platform/values.yaml\n    path: helm-chart/helm-chart\n    repoURL: 'https://gitlab.com/my-org/develop-app.git'\n    targetRevision: staging\n  syncPolicy:\n    automated:\n      prune: true\n      selfHeal: true\n\nIf you need digest or just a latest then remove this\n  argocd-image-updater.argoproj.io/image-alias.allow-tags: 'regexp:^1.3.0-SNAPSHOT.[0-9]+$'\n\nthis is working base on regex.\nso in your case <1.0.xxx>\nit can be 'regexp:^1.0.[0-9]+$'\nIf everything configured properly and image updater working fine then you should be able to see logs image updater logs like this\ntime=\"2022-04-27T15:18:36Z\" level=info msg=\"Successfully updated image 'registry.gitlab.com/test-image:0.3.0-SNAPSHOT.115' to 'registry.gitlab.com/test-image:0.3.0-SNAPSHOT.118'"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": ".gitlab-ci stages execution order\n\nI have this .gitlab-ci.yml file:\nstepA:\n  script:\n    - echo \"A\"\ndeploy:\n  script:\n    - echo \"1\"\nstepB:\n  script:\n    - echo \"B\"\n\nHow can I set which stage should be run in first ?\nSome jobs can be run in parallel by multiple gitlab runners.\nI just want to be sure step A to B are finished before running deploy stage"}, {"role": "assistant", "content": "This is exactly what stages is for. You are using the word \"stage\" here when actually describing a \"job\". \nJobs in the same stage may be run in parallel (if you have the runners to support it) but stages run in order.\nFirst define your 2 stages at the top level of the .gitlab-ci.yml:\nstages:\n  - build\n  - dist\n\nThen on each job, specify the stage it belongs to:\nstepA:\n  stage: build\n  script:\n    - echo \"A\"\ndeploy:\n  stage: dist\n  script:\n    - echo \"1\"\nstepB:\n  stage: build\n  script:\n    - echo \"B\"\n\nNow stepA and stepB will run first (in any order or even in parallel) followed by deploy provided the first stage succeeds."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Move a repository from Github to Gitlab\n\nIs there a way to move an entire repository from Github to GitLab?\nFor the code itself, this would be a simple matter of creating a new repo on GitLab and pushing to it.\nWiki pages live in a separate branch on Github and are managed with Git mechanisms; AFAIK the same goes for GitLab. Same story for pages.\nThat leaves issues and merge requests as the main open points. Is there a way to copy those from Github to GitLab, at least in the state they were in at the time of the migration?\nGithub offers an export ferature, and GitLab has an import feature which can import a Github repository\u2014do any of these help with the above?"}, {"role": "assistant", "content": "GitLab\u2019s import feature has worked quite nicely.\n\nOn https://gitlab.com (make sure you are logged in), you will get a list of your projects. Click New Project.\nOpen the Import Project tab, and click Github.\nIf you have not granted Gitlab authorization to access your Github account, you will be prompted to do so now.\nA list of your Github repos will appear. For each repo you wish to import, choose the namespace (your personal one or that of any of your organizations, if any) and change the project name if you wish. (Default is to import to your personal namespace and use the same repo name as on Github.) Then click Import next to the repo you wish to import.\n\nImport will take a couple of minutes. When it finishes, you will get your entire repo, including wiki, issues and merge requests. Issues and merge requests will retain ticket numbers as on Github, and labels also seem to get migrated.\nGithub Pages do not seem to get migrated automatically. This requires some manual steps. For purely static content (no SSG), with content stored in the gh-pages branch, the process is as follows:\n\nSwitch to your gh-pages branch.\nCreate a new folder public and move all content there.\nCommit your changes.\nSwitch back to master and merge gh-pages (so that your content now resides on a separate folder in master rather than its own branch).\nOn your project\u2019s main page, click Add CI/CD. This will create a new .gitlab-ci.yml file; add the following content and commit:\n\nimage: alpine:latest\n\npages:\n  stage: deploy\n  script:\n  - echo 'Nothing to do...'\n  artifacts:\n    paths:\n    - public\n  only:\n  - master\n\nThis will take another few minutes. Navigate to Settings > Pages and click the link to your pages.\nGithub has multiple options for storing web content; the above may also work for others with slight modifications."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Commit message linking to issue AND issue link to commit\n\nHow is it possible to linkg a commit message to issue AND the issue to the commits?  \nIf I add in the commit message #123 it is a link to the issue, but on the issue there is no link to the commit.\nIs this in any way possible to show the commit in the issue?"}, {"role": "assistant", "content": "Seems GitLab has now added this feature.\nIf you add to your commit message the issue id the commit number will be mentioned in the issue like this:\n\nLinks to docs:\nhttps://docs.gitlab.com/ee/user/markdown.html#gitlab-specific-references\nhttps://docs.gitlab.com/ee/user/project/issues/managing_issues.html#default-closing-pattern"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Can I pass environment variables from Gitlab .gitlab-ci.yml to a React app?\n\nI'm trying to set environment variables dynamically using the gitlab CI pipeline. \nWhat I am trying to achieve is to inject the right API keys and URLs depending on the stage I am deploying to (stage, prod).\nIn my React app I access the variables using process.env.REACT_APP_APPSYNC_URL as decribed in the react documentation. \nSo far I have tried setting the variables in the gitlab UI and referencing them in my .gitlab-ci.yml file (see code below). \nUnfortunately I cannot access the variables this way, so I would be very thankful for any help. \nI'm just getting started on CI/CD and different environments, so if I am generally using a bad approach here please let me know!\nHere's the .gitlab-ci.yml:\nimage: nikolaik/python-nodejs:latest\n\nstages:\n  - install\n  - test\n  - deploy\n\ninstall:\n  stage: install\n  script:\n    - npm install\n    - npm run build\n  artifacts:\n    untracked: true\n  only:\n    - stage\n    - master\n\ntest:\n  stage: test\n  dependencies:\n    - install\n  script:\n    - npm run test\n  artifacts:\n    untracked: true\n  only:\n    - stage\n    - master\n\ndeployDev:\n  stage: deploy\n  only:\n    - stage\n  dependencies:\n    - install\n    - test\n  script:\n    - pip3 install awscli\n    - aws configure set aws_access_key_id \"$DEV_AWS_KEY\"\n    - aws configure set aws_secret_access_key \"$DEV_AWS_SECRET\"\n    - aws s3 sync ./build/ s3://example.dev\n  variables:\n    REACT_APP_COGNITO_REGION: $DEV_COGNITO_REGION\n    REACT_APP_COGNITO_USER_POOL_ID: $DEV_COGNITO_USER_POOL_ID\n    REACT_APP_COGNITO_APP_CLIENT_ID: $DEV_COGNITO_APP_CLIENT_ID\n    REACT_APP_COGNITO_IDENTITY_POOL_ID: $DEV_COGNITO_IDENTITY_POOL_ID\n    REACT_APP_APPSYNC_URL: $DEV_APPSYNC_URL\n    REACT_APP_APPSYNC_REGION: $DEV_APPSYNC_REGION\n    REACT_APP_APPSYNC_AUTHENTIACTION_TYPE: $DEV_APPSYNC_AUTHENTIACTION_TYPE\ndeployProd:\n  stage: deploy\n  only:\n    - master\n  dependencies:\n    - install\n    - test\n  script:\n    - pip3 install awscli\n    - aws configure set aws_access_key_id \"$PROD_AWS_KEY\"\n    - aws configure set aws_secret_access_key \"$PROD_AWS_SECRET\"\n    - aws s3 sync ./build/ s3://example.com\n\nCheers!"}, {"role": "assistant", "content": "This line from CRA docs is important: The environment variables are embedded during the build time. So set the variables before running build command. \nimage: node:10.16.0-alpine\n\nstages:\n  - build\n  - deploy\n\nbuild_app:\n  stage: build\n  script:\n    - export REACT_APP_SECRET_API_KEY=$API_KEY # set REACT_APP variables before build command\n    - yarn install\n    - yarn build\n  artifacts:\n    name: \"$CI_PIPELINE_ID\"\n    paths:\n      - build\n    when: on_success\n\ndeploy_app:\n  stage: deploy\n  dependencies:\n    - build_app\n  script:\n    - echo \"Set deployment variables\"\n    - echo \"Deployment scripts\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Difference between GitLab CI and GitHub Actions Beta\n\nWhat is the difference between GitLab CI and GitHub Actions Beta?\nBoth talk about devops/automation from Git repo"}, {"role": "assistant", "content": "GitHub copied a lot of Gitlab`s features, including CI (similar configuration and price). Actions looks like GitLab CI/CD but there are some differences between them.\nGitLab CI/CD has integration with Pages, issues, packages registry, it has environments dashboard, review support, manual pipelines, multi-project pipelines, support a lot of different reports (such as Container scanning report), good API, ability to use your own runner, and a lot of other features. Also, it is open source.\nYou can see more full comparsion here\nGitHub Actions - simple CI; GitLab CI/CD - configurable and powerful open-source CI/CD with integrations with different software and unique features."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "ImagePullBackOff error Google Kubernetes Engine\n\nI know a lot of people already had similar question, i read a few of them, but found nothing what actualy helped me so far.\nI have a gitlab with private repo enabled, I also use Google Kubernetes Engine. I have a few Docker container in my private repo, and I want to deploy one of them to the Kubernetes Engine.\nI have created a secret with kubectl create secret generic db-user-pass --from-file=./username.txt --from-file=./password.txt\nI also tried kubectl create secret docker-registry name --docker-server=registry.xy.z --docker-username=google --docker-password=xyz [email\u00a0protected]\nThen I created my Deployment file:\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\nname: backend-test\nlabels:\napp: 13371337\nspec:\nreplicas: 1\ntemplate:\nmetadata:\nlabels:\napp: 13371337\nspec:\n  containers:\n  - name: backend\n    image: registry.xy.z/group/project/backend:latest\n    imagePullPolicy: Always\n    ports:\n    - containerPort: 8080\n  imagePullSecrets:\n  - name: db-user-pass or name\n\nAny ideas how to get it running?"}, {"role": "assistant", "content": "Using kubectl create secret docker-registry name is a right way to provide credentials of private docker registry.\nimagePullSecrets options looking good too, if you specify there a name of your docker-registry secret.\nSo, from Kubernetes path everything looking good.\nTry to check events of the pod which will be created by Deployment, just find you pod by kubectl get pods and call kubectl describe pod $name_of_your_pod, you will see an actual reason why it cannot pull an image.\nAlso, if your depository is insecure or has self-signed certificate, try to follow that guide to allow docker daemon pulling image from there, that is an often reason of image pull failures."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab 6.0.2 Jenkins CI services not showing\n\nI have a gitlab server version \"Gitlab 6.0.2 10b0b8f\". I want to connect \"Jenkins CI\" for build purpose. for this I am following - http://doc.gitlab.com/ee/integration/jenkins.html .But In a project services I am not able to see \"Jenkins CI\". Only I can See \"Gitlab CI\". Can you please help me. Any example will be appriciated."}, {"role": "assistant", "content": "Solved. Jenkins CI support is only included in the Enterprise version (EE). gitlab server version \"Gitlab 6.0.2 10b0b8f\" is not a enterprise edition. so it is not possible. Check \nhttps://github.com/gitlabhq/gitlabhq/issues/7525"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Docker - Gitlab container. SSH git login error\n\nI have a Docker container with a Gitlab application. When i execute a git clone/push/pull the command not work and output this message:\n\"fatal protocol error bad line length character: Welc\"\nThe server response is not the response expected by git (it is a response for a common ssh connection).\nThis occurs because there is an error during the connection, see:\n Mar 20 14:55:31 gitlab sshd[7934]: reverse mapping checking getaddrinfo for XXXX.XXXX.XXX.XX.static.host.gvt.net.br [XXXX.XXXX.XXX.XX] failed - POSSIBLE BREAK-IN ATTEMPT!\n Mar 20 14:55:32 gitlab sshd[7934]: Accepted publickey for git from XXXX.XXXX.XXX.XX port XXXX ssh2\n Mar 20 14:55:32 gitlab sshd[7934]: pam_loginuid(sshd:session): set_loginuid failed\n Mar 20 14:55:32 gitlab sshd[7934]: pam_unix(sshd:session): session opened for user git by (uid=0)\n Mar 20 14:55:32 gitlab sshd[7934]: pam_env(sshd:session): Unable to open env file: /etc/default/locale: No such file or directory\n Mar 20 14:55:32 gitlab sshd[7934]: error: PAM: pam_open_session(): Cannot make/remove an entry for the specified session\n\nInfo \n\nGitLab version: 6.6.5\nDocker version: 9.0\nHost: Ubuntu 13.10\nContainer: Ubuntu 13.10\n\nI think i need to enable something in my Docker container because outside a Docker container the gitlab works correctly.\nHow to fix this?\nThanks!"}, {"role": "assistant", "content": "I fix this following this article: \nhttp://www.linuxweblog.com/blogs/sandip/20090203/setloginuid-failed-opening-loginuid\nJust comment this line in file \"/etc/pam.d/sshd\":\nsession required        pam_loginuid.so"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab deploy script - envsubst: command not found\n\nI have a gitlab repo with CI/CD pipeline. It has deploy.sh script, which runs smoothly until envsubst command:\n#!/bin/bash\n\nset -e\n<...>\n# deploy via ssh\nSSH=\"ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -o LogLevel=ERROR -l $SSH_USER \n$HOST\"\n\necho \"create project dir\"\n$SSH \"mkdir -p $PROJECT_ROOT\"\n\necho \"create env file\"\nenvsubst < $CI_ENVIRONMENT_NAME.tmpl.env | $SSH \"cat > ${PROJECT_ROOT}/${CI_ENVIRONMENT_NAME}.env\"\n\nJob fails with error:\ncreate env file\n./deploy.sh: line 65: envsubst: command not found\n\nHeaders of '.gitlab-ci.yml' file:\nimage: docker:latest\nservices:\n  - docker:dind"}, {"role": "assistant", "content": "As DavidMaze pointed out, I added 'gettext' package to '.gitlab-ci.yml' file:\ndeploy-on-server:\n  stage: deploy\n  when: manual\n  before_script:\n    - 'which ssh-agent || ( apt-get update -y && apt-get install openssh-client -y )'\n    - apk update && apk add bash\n    - apk update && apk add gettext\n  <...>"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab-ci build asp.net core docker\n\nI am working on a gitlab CI/CD project to build an asp.net core application into a docker.\nCurrently I have 2 possible implementations in mind. The first one have the full logic in the Dockerfile, but I can't visualize the stages in Gitlab this way (build, test, publish). So I thought about moving the main logic to the gitlab-ci.yml file. But what bothers me now is that I have to manage the image docker dotnet versions on 2 places (sdk:3.1, aspnet:3.1.1-alpine3.10). Is it a good idea to deliver the version via build-arg or is there a more elegant solution?\n.gitlab-ci.yml\nstages:\n  - build\n  - test\n  - docker\n\nbuild:\n  stage: build\n  image: mcr.microsoft.com/dotnet/core/sdk:3.1\n  only:\n    - master\n  script:\n    - cd src\n    - dotnet restore --interactive\n    - dotnet build --configuration Release\n    - dotnet publish --configuration Release --output ../publish/\n  artifacts:\n    paths:\n      - ./publish/*.*\n    expire_in: 1 week\n  tags:\n  - docker\n\ntest:\n  stage: test\n  image: mcr.microsoft.com/dotnet/core/sdk:3.1\n  only:\n    - master\n  script:\n    - cd src\n    - dotnet test --test-adapter-path:. --logger:\"junit;LogFilePath=../../MyProject.xml\"\n  artifacts:\n    paths:\n      - ./MyProject.xml\n    reports:\n      junit: ./MyProject.xml\n  tags:\n  - docker\n\ndocker:\n  stage: docker\n  image: docker:stable\n  services:\n    - docker:dind\n  variables:\n    DOCKER_DRIVER: overlay2\n    DOCKER_TLS_CERTDIR: \"\"\n  only:\n    - master\n  script:\n    - docker login -u \"gitlab-ci-token\" -p \"$CI_JOB_TOKEN\" $CI_REGISTRY\n    - docker build --tag \"$CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA\" --tag \"$CI_REGISTRY_IMAGE:latest\" --build-arg EXECUTABLE=Test.WebApi.dll .\n    - docker push \"$CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA\"\n    - docker push \"$CI_REGISTRY_IMAGE:latest\"\n  tags:\n  - docker\n\nDockerfile\nFROM mcr.microsoft.com/dotnet/core/aspnet:3.1.1-alpine3.10\nARG EXECUTABLE\n\nWORKDIR /app\nCOPY /publish .\n\nENV ASPNETCORE_URLS \"http://*:5000\"\nENV ASPNETCORE_ENVIRONMENT \"Staging\"\nCMD [\"dotnet\", \"$EXECUTABLE\"]"}, {"role": "assistant", "content": "Here is my solution, I have defined the variables above and replace them in the docker file with sed\nMy Solution have this two Projects\n\nTest.WebApi (WebApi Project)\nTest.WebApi.UnitTest (Unit Test Project)\n\n@ThomasBr\u00fcggemann thanks for the Inspiration.\n.gitlab-ci.yml\nvariables:\n    PROJECT_NAME: \"Test.WebApi\"\n    BUILD_IMAGE: \"mcr.microsoft.com/dotnet/core/sdk:3.1\"\n    RUNTIME_IMAGE: \"mcr.microsoft.com/dotnet/core/aspnet:3.1.1-alpine3.10\"\n\nstages:\n  - build\n  - test\n  - docker\n\nbuild:\n  stage: build\n  image: $BUILD_IMAGE\n  only:\n    - master\n  script:\n    - cd src/$PROJECT_NAME\n    - dotnet restore --interactive\n    - dotnet build --configuration Release\n    - dotnet publish --configuration Release --output ../../publish/\n  artifacts:\n    paths:\n      - ./publish/*\n    expire_in: 1 week\n  tags:\n  - docker\n  \ntest:\n  stage: test\n  image: $BUILD_IMAGE\n  only:\n    - master\n  script:\n    - cd src/$PROJECT_NAME.UnitTest\n    - dotnet test --test-adapter-path:. --logger:\"junit;LogFilePath=../../UnitTestResult.xml\"\n  artifacts:\n    paths:\n      - ./UnitTestResult.xml\n    reports:\n      junit: ./UnitTestResult.xml\n  tags:\n  - docker\n\ndocker:\n  stage: docker\n  image: docker:stable\n  services:\n    - docker:18.09.7-dind\n  variables:\n    DOCKER_DRIVER: overlay2\n    DOCKER_TLS_CERTDIR: \"\"\n  only:\n    - master\n  script:\n    # Prepare Dockerfile\n    - sed -i \"s~\\$DOCKERIMAGE~$RUNTIME_IMAGE~g\" Dockerfile\n    - sed -i 's/$ENVIRONMENT/Staging/g' Dockerfile\n    - sed -i \"s/\\$ENTRYPOINT/$PROJECT_NAME.dll/g\" Dockerfile\n\n    # Process Dockerfile\n    - docker login -u \"gitlab-ci-token\" -p \"$CI_JOB_TOKEN\" $CI_REGISTRY\n    - docker build --tag \"$CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA\" --tag \"$CI_REGISTRY_IMAGE:latest\" .\n    - docker push \"$CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA\"\n    - docker push \"$CI_REGISTRY_IMAGE:latest\"\n  tags:\n  - docker\n\nDockerfile\nFROM $DOCKERIMAGE\n\nWORKDIR /app\nCOPY /publish .\n\nEXPOSE 5000/tcp\n\nENV ASPNETCORE_URLS \"http://*:5000\"\nENV ASPNETCORE_ENVIRONMENT \"$ENVIRONMENT\"\nCMD [\"dotnet\", \"$ENTRYPOINT\"]"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to checkout on an old commit and push it on current branch?\n\nI have some incorrect commit/push on my branch, then I want to revert to an old correct commit and push it on the current branch.\nI have a problem with:\ngit log\n    new: xxxxxxx\n    ...\n    old: ac758a3\n\ngit checkout ac758a3\ngit commit -m 'revert to old branch (ac758a3) to push it on current branch'\n\nOut:\nHEAD detached at ac758a3\nnothing to commit, working directory clean\n\n\n[EDIT]\nSchematically:\n\nA(correct commit that I want) --- B(incorrect commit) --- C(incorrect\ncommit)\n\nSo I want to have the following flow:\n\nA --- B --- C --- A\n\nI want revert to A(old commit) and push it on current branch (the same branch).\nWhat is the fast solution?\n\nThanks in advance."}, {"role": "assistant", "content": "git reset --hard <commit-id> is your friend dear.\nFollow below steps:\n\nOn your current branch run command: git log\nCopy correct commit id from the log on which you want to go back.\nRun command: git reset --hard <commit-id-copied-in-step-2 above>\nPush your branch to remote: git push origin <my-feature-branch> -f.\n\nNote: You will not be able to push it normally, you have to push it forcefully since we have changed the history of that branch and is not in sync with remote."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Adding an existing android studio project to gitlab repository\n\nI have a project in android studio that i want to commit to a gitlab repository. I have a link for this repository. What do i need to do, step for step, to add this project to said repository?"}, {"role": "assistant", "content": "First you have to guarantee that this project is already a git repository on your local machine.\nYou can do this by checking if there's a folder .git in the directory. If there's none, do the following command:\n# create a git repository on the current directory\ngit init\n\nAfter that you need to make your repository point to gitlab\ngit remote add origin \"url from gitlab\"\n\nAdd files for your initial commit\ngit add -A\n\nCommit the files\ngit commit -m \"your initial commit message\"\n\nPush all the files to the remote(gitlab)\ngit push -u origin master\n\nMore information of each command can be found typing:\nman git command\n\n# example\nman git push"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Cannot push to gitlab from xcode 7\n\nOne unhappy side effect of upgrading to Xcode 7 is that I can no longer push to my Gitlab repo.  I have been pushing and pulling from my project without problem for the last two years, so I suspect Xcode 7 is doing something different.  I have verified my u/p for Gitlab by logging into and out of it via the web interface. When I go to Xcode > Preferences > Accounts, select the gitlab project, I see that the username and password are in there (just like they have been for 2 years) and I verify that they are correct.\nIt is worth noting that I can successfully post from Terminal, however, I do not wish to use Terminal to push my code to Gitlab on a regular basis.  Has anyone else encountered this problem since upgrading?  Any suggestions as to a fix?\nThe specific error I am getting is \"Authentication failed because the user name or password was incorrect.\"  This error appears in the Accounts dialog, as well as after trying to perform a push to the gitlab repo."}, {"role": "assistant", "content": "So this one was quite a bear to wrestle, and to be honest, I am not sure what the root cause of this error was, but the way I resolved it was this:\n\nRemoved my old ssh key from GitLab\nCreated a new ssh key on the command line, then added it to GitLab\nRemoved the GitLab repo from Xcode > Preferences > Accounts\nRe-added the GitLab account, using the SSH Keys Option (which it was before as well, this is not new)\nClosed Xcode\nBlew away the working directory of the project\nOpened Xcode, then chose Source Control > Checkout\nProvided the SSH address (which you can get from GitLab within your project folder)\nMade a minor change to the project for the purposes of testing the ability to Push\nPushed to GitLab via Xcode Source Control > Push\n\nVoila!  Worked.  This was definitely the nuclear option but it got me working again.  I firmly believe that upgrading Xcode to 7 screwed something up.  If anyone else has this problem I hope this resolves it!"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "what is the difference between a gitlab runner and a gitlab agent?\n\nI'm new to Gitlab and Kubernetes and I'm wondering what the difference between a Gitlab runner and a Gitlab agent is.\nOn gitlab it says an agent is used to connect to the cluster, run pipelines, and deploy applications.\nBut with a regular runner you could just have a pipeline that invokes kubectl to interact with the cluster.\nWhat is possible with an agent that isn't with a runner using kubectl?"}, {"role": "assistant", "content": "The GitLab Agent (for Kubernetes) is the way GitLab interacts with the Kubernetes cluster (https://docs.gitlab.com/ee/user/clusters/agent/) and is used to allow GitLab to generate GitLab runners which are like Jenkins agents (https://docs.gitlab.com/runner/install/). Consider it like a broker or manager in this case. The agent would spawn the runners inside the cluster with the configuration you have setup.\nFor example, in my case, I have a node-pool dedicated specifically for gitlab runners. These nodes are more expensive to run, since they're higher-spec than the standard nodes used by the rest of the cluster, so I want to make sure only the GitLab runners spawn on there. I configure the Runner to have a node selector and toleration pointing at that specific node pool so the cluster scales up that node pool to put the runner on it.\nThe agent itself provides way more functionality than just spawning runners, but your question only asks about the GitLab agent and Runner. You can review the pages I've linked if you would like to find out more."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Access env variables in node js app when using gitlab ci cd pipeline\n\nI am using gitlab ci cd pipe line to deploy my application to ubuntu server. I have different .env file for local and for dev env and its not a part of git repo (included in gitignore) how to get env variables in my app when deployed to ubuntu server\nmy gitlab-ci.yml\nstages:\n     - deploy\ncache:\n  paths:\n    - node_modules/\ndeploy:\n    stage: deploy\n    script:\n      - npm install\n      - sudo pm2 delete lknodeapi || true\n      - sudo pm2 start server.js --name lknodeapi"}, {"role": "assistant", "content": "I guess you are looking for this -Create Variables Gitlab.You can create your environment variables in the ui and then change your gitlab-ci.yml like below\nstages:\n     - deploy\ncache:\n  paths:\n    - node_modules/\ndeploy:\n    stage: deploy\n    script:\n      - echo \"NGINX_REPO_KEY\"=$NGINX_REPO_KEY >> \".env\"\n      - npm install\n      - sudo pm2 delete lknodeapi || true\n      - sudo pm2 start server.js --name lknodeapi\n\nThis will create a .env file in root folder and put your variables in it."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "snap and gitlab-CI: error: cannot communicate with server: Post http://localhost/v2/snaps/hello-world\n\nIf I try to run snap under a gitlab-CI pipeline, installing the most simple package, it fails with:\n\n$ snap install hello-world\nerror: cannot communicate with server: Post\n  http://localhost/v2/snaps/hello-world: dial unix /run/snapd.socket:\n  connect: no such file or directory\n\nThe gitlab-ci yml configuration file is the simplest ever:\nimage: ubuntu:18.04\n\nbefore_script:\n  - apt-get update -qq\n\ntest:\n  script:\n    - apt-get install -y snapd\n    - snap version\n    - snap install hello-world\n    - hello-world\n\nWhat's going on?"}, {"role": "assistant", "content": "Unfortunately, snaps use many of the underlying security tech used by docker, and they don't play very nicely. Installing a snap also requires snapd to be running, which it's not in docker (hence the error). I'm afraid you simply cannot reliably install snaps in docker containers today.\nNote that there are other non-docker-based CI systems. You can, with a little custom work, use LXD as the backend for your GitLab CI runner, which handle snaps fine. You can also use GitHub Actions, which seem so be based on a Azure VM, which also handles snaps fine."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Can we re-trigger the gitlab pipeline?\n\nAfter creating merge request in GitLab, merge request got failed and jenkins has deleted the failed job logs due to retention period defined under jenkins job. Now, i want to re-trigger that specific merge request only from gitlab so that it will trigger the merge request job  in jenkins. Is it possible ? If yes, how can i do the same ?\nP.S. There is a pipeline defined from Gitlab to Jenkins. Whenever a merge request get creates in gitlab, it triggers the Jenkins Merge Request job which merge the specific changes to the git master branch."}, {"role": "assistant", "content": "Go to the merge request page.\nIn the tabs section (next to Overview), Go to the Pipelines tab.\nClick on the button Run pipeline."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab - Defined stages for CI and CD are not being taken in the pipeline\n\nI have a .gitlab-ci.yml file as below:\n\n\nimage: node:6.10.3\r\n\r\nstages:\r\n  - ver\r\n  - init\r\n  - deploy\r\n\r\nver:\r\n  stage: ver\r\n  script:\r\n    - node --version\r\n    - whoami\r\ninit:\r\n  stage: init\r\n  script:\r\n    - npm cache clean\r\n    - rm -rf node-modules\r\n    - npm install\r\n\r\ndeploy_staging:\r\n  stage: deploy\r\n  before_script:\r\n  - 'which ssh-agent || ( apt-get update -y && apt-get install openssh-client -y )'\r\n  - mkdir -p ~/.ssh\r\n  - eval $(ssh-agent -s)\r\n  - '[[ -f /.dockerenv ]] && echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" > ~/.ssh/config'\r\n  script:\r\n    - ssh-add <(echo \"$STAGING_PRIVATE_KEY\" | base64 --decode)\r\n    - git pull\r\n    - echo \"deployed to staging server\"\r\n  environment:\r\n    name: staging\r\n    url: MY SERVER\r\n\r\n  only:\r\n    - master\n\n\n\nIn Gitlab when I go to pipeline I am expecting to see 3 stages which are ver, init, and deploy. However, It only takes the first to stages and I don't see anything for deploy."}, {"role": "assistant", "content": "So using the only: master statement in the deploy job you exclude that from being touched at all in other branches. Gitlab doesn't show it in the pipeline as it was never used for non-master branches."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I assign exe output to a variable in gitlab ci scripts?\n\nWhen running my gitlab ci I need to check whether a specified svn directory exists.\nI was using the script:\nvariables:\n  DIR_CHECK: \"default\"\n\nstages:\n  - setup\n  - test\n  - otherDebugJob\n  \n.csharp:\n  only:\n    changes:\n      - \"**/*.cs\"\n      - \"**/*.js\"\n\nsetup:\n  script:\n    - $DIR_CHECK = $(svn ls https://server.fsl.local:port/svn/myco/personal/TestNotReal --depth empty)\n    - echo $DIR_CHECK\ntest:\n  script:\n    - echo \"DIR_CHECK is blank\"\n    - echo $DIR_CHECK\n  rules:\n    - if: $DIR_CHECK == ''\n\notherDebugJob:\n  script:\n    - echo \"DIR_CHECK is not blank\"\n    - echo $DIR_CHECK\n  rules:\n    - if: $DIR_CHECK != ''\n    \n\nthe svn command works and echos back the correct reply but $DIR_CHECK does not get set to anything but the original default.  It does not store the returned string from the svn command.\nHow do I store the returned string from an exe in a variable in gitlab ci?\nTest run:\n\nExecuting \"step_script\" stage of the job script 00:00  $ $DIR_CHECK =\n$(svn ls https://server.fsl.local:port/svn/myco/personal/TestNotReal\n--depth empty)  svn: E170000: Illegal repository URL https://server.fsl.local:port/svn/myco/personal/TestNotReal'  $ echo\n$DIR_CHECK  Cleaning up file based variables 00:01  Job succeeded"}, {"role": "assistant", "content": "Passing variables between jobs\nUnfortunately, you cannot use DIR_CHECK variable the way you described. List of steps to be executed generates before steps actually runs, that means for all of the steps DIR_CHECK will be equal to default. First of all there are few tips how you can pass variables between jobs:\nFirst way\nYou can add desired command to the before_script section in your .csharp template:\n.csharp:\n  before_script:\n    - export DIR_CHECK=$(svn ls https://server.fsl.local:port/svn/myco/personal/TestNotReal --depth empty)\n\nand extend other steps with this .csharp.\nSecond way\nYou can pass variables between jobs with job artifacts:\nsetup:\n  stage: setup\n  script:\n    - DIR_CHECK=$(svn ls https://server.fsl.local:port/svn/myco/personal/TestNotReal --depth empty)\n    - echo \"DIR_CHECK=$DIR_CHECK\" > dotenv_file\n  artifacts:\n    reports:\n      dotenv: \n        - dotenv_file\n\nThirds way\nYou can trigger or use parent/child pipelines to pass variables into pipelines.\nstaging:\n  variables:\n    DIR_CHECK: \"you are awesome, guys!\"\n  stage: deploy\n  trigger: my/deployment\n\nIn the triggered pipeline your variable will exists at the very start moment, and all the rules will be applied correctly.\nSolution\nIn your case, if you really don't want to include otherDebugJob step in your pipeline you can do the following:\nFirst approach\nThis is quite easy way and this will work, but looks like not a best practice. So, we are already know how to pass our DIR_CHECK variable from setup step , just add some check in the test step script block:\nscript:\n- |\n  if [ -z \"$DIR_CHECK\" ]; then\n    exit 0\n  fi\n- echo \"DIR_CHECK is blank\"\n- echo $DIR_CHECK\n\nDo the almost same thing for the otherDebugJob but check if DIR_CHECK is not empty with if [ -n \"$DIR_CHECK\" ].\nThis approach is helpful when your pipeline not contains a lot of steps, but after the test and otherDebugJob follows another few steps.\nSecond approach\nYou can fail your setup step and then handle this fail in otherDebugJob step:\nsetup:\n  script:\n    - DIR_CHECK=$(svn ls https://server.fsl.local:port/svn/myco/personal/TestNotReal --depth empty)\n    - |\n      if [ -z \"$DIR_CHECK\" ]; then\n        exit 1\n      fi\n\notherDebugJob:\n  script:\n    - echo \"DIR_CHECK is not blank\"\n  when: on_failure\n\nThis approach is useful if you only want to make some debug stuff after this setup step. After all on_failure jobs, pipeline will be marked as Failed and stopped."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to pass variables from .gitlab.ci.yml to Dockerfile\n\nHow can I pass one variables value from .gitlab-ci.yml to Dockerfile?\ne.g.\nThe .gitlab-ci.yml contains:\nvariables:\n  var1: ex_variable_1\n  var2: ex_variable_1\n\nstages:\n  - build\n\nbuild:\n  stage: build\n  script:\n    - sudo docker build . -t ${CI_PROJECT_PATH_SLUG}\n                          --build-arg var1\n                          --build-arg var2\n    - sudo docker run -dit --name ${CI_PROJECT_PATH_SLUG} --cap-add=NET_ADMIN ${CI_PROJECT_PATH_SLUG}:latest\n\nThe Dockefile contains:\nFROM centos:6.9\n\nENV var1 ${var1}\nENV var2 ${var2}\n\nRUN echo \"Print var1 $var1\"\nRUN echo \"Print var2 $var2\n\nSo what I want is to pass var1 and var2 from .gitlab-ci.yml to Dockerfile."}, {"role": "assistant", "content": "To pass environment variables from .gitlab-ci.yml to an image or container:\n\nat build time (if the variable is used by the Dockerfile):\n\nuse the docker build --build-arg option: docker build --build-arg var1=\"$var1\"\n\nand change your Dockerfile like this:\n  FROM centos:6.9\n  ARG var1\n  ARG var2\n\n  RUN echo \"Print var1 $var1\"\n  RUN echo \"Print var2 $var2\"\n\n  # The following is optional \u2212 only useful if you want to\n  # keep the environment variables at runtime (docker run)\n  ENV var1=${var1}\n  ENV var2=${var2}\n\nNote: the ARG instruction can also take a default value:\n  ARG var1=\"default value if var1 was not passed using --build-arg\"\n\n\n\n\nat runtime (if the variable is used by the container, i.e., by the ENTRYPOINT / CMD-specified program):\n\nuse the docker run -e CLI option: docker run -e var1=\"$var1\"."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to merge artifacts across jobs for the same stage in Gitlab CI?\n\nIn Gitlab CI artifacts are segregated based on the jobs which generated them and hence when downloading, you can only download it on a per-job basis.\nIs there a way to download all the artifacts, or pass on the artifacts to some other stage and upload from there? Basically some way to merge all the artifacts of a stage.\nA possible scenario where it can be needed: Let's say in a stage deploy, I am deploying my project on 10 different servers, using 10 different parallel jobs. Each of these generates some artifacts. However, there is no way to download them all from the UI.\nSo does anyone know of a workaround? I am not looking for API based solution, but instead UI based or editing the CI yaml file to make it work."}, {"role": "assistant", "content": "You can create a \"final\" (package) stage in your pipeline which combines all the artifacts together, using the artifacts syntax.\nFor example:\nstages:\n  - build\n  - package\n\n.artifacts_template:\n  artifacts:\n    name: linux-artifact\n    paths:\n      - \"*.txt\"\n    expire_in: 5 minutes\n\nbuild:linux-1:\n  extends: .artifacts_template\n  stage: build\n  script:\n    - touch hello-world-linux-1.txt\n\nbuild:linux-2:\n  extends: .artifacts_template\n  stage: build\n  script:\n    - touch hello-world-linux-2.txt\n\nbuild:linux-3:\n  extends: .artifacts_template\n  stage: build\n  script:\n    - touch hello-world-linux-3.txt\n\npackage:\n  stage: package\n  script:\n    - echo \"packaging everything here\"\n  needs:\n    - build:linux-1\n    - build:linux-2\n    - build:linux-3\n  artifacts:\n    name: all-artifacts\n    paths:\n      - \"*.txt\"\n    expire_in: 1 month"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Publishing to gitlab pypi package registry for a group\n\nI am trying to publish a package to gitlab pypi registry. What is the repository url we need to use to publish to a group package registry?.\nI tried using this https://gitlab.example.com/api/v4/groups/id/packages/pypi\nbut it is throwing 404 now found.\nThe api https://gitlab.example.com/api/v4/groups/id/packages/ returns a empty array for me.\nBut when I manually take the registry from the UI pypy, npm etc are present.\nPublishing to individual project repositories is working fine.\nhttps://gitlab.example.com/api/v4/projects/id/packages/pypi"}, {"role": "assistant", "content": "I run into the same problem.\nAs far as I understand, groups don't have their own registries. If you go in your group settings, you won't see the option to activate it.\nGroups are only placeholders to organize projects, they don't hold any data.\nWhat you see in the UI when clicking on the group registry is the aggregation of all the registries of the projects inside that group.\nThis is only a search UI, not a registry per se.\nBottom-line is that you have to publish your artefacts to a specific project.\nNote that you can have a dedicated project to hold only your registry, and have all your code repositories publish in the same registry."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Failed to install gitlab-runner: Init already exists\n\nI installed gitlab-runner via sudo apt install gitlab-runner, configured it according to the tutorial and it worked well. \nNow I want to change the user of the gitlab-runner. So I stop the service with service gitlab-runner stop and try to change the user via \nsudo gitlab-runner install --user=my-user --working-directory=/home/my-user \n\nI get following error message:\n\nFATAL: Failed to install gitlab-runner: Init already exists: /etc/systemd/system/gitlab-runner.service\n\nHow to proceed?"}, {"role": "assistant", "content": "Rename the init file with \nsudo mv /etc/systemd/system/gitlab-runner.service  /etc/systemd/system/gitlab-runner.service.bak\n\nand execute again\nsudo gitlab-runner install --user=my-user --working-directory=/home/my-user\n\ncleanup the backup file\nsudo rm /etc/systemd/system/gitlab-runner.service.bak\n\n\nFinally you can start the runner again with service gitlab-runner start."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What \"Hack\" means in the languages bar on gitlab\n\nI've noticed, on the languages bar, that 1.3% of the languages used on my project are \"Hack\".\nI was just wondering what this \"hack\" actually means ?"}, {"role": "assistant", "content": "As explained in this issue: https://github.com/github/linguist/issues/4229#issuecomment-412846757\nA php file is considered a hack file by Gitlab and Github when there is only HTML code in it."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Pull Image from Gitlab Registry in Docker Compose File\n\nI want to deploy a docker stack on my own server. I've written a .gitlab-ci.yml file that currently builds the images in my stack and pushes them to my gitlab registry:\nbuild:\n  stage: build\n  image: docker:stable\n  services: \n    - docker:dind\n  before_script:\n    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY\n    - docker info\n  script:\n    - docker build -t $DOCKER_IMAGE1_TAG -f dir1/Dockerfile ./dir1\n    - docker push $DOCKER_IMAGE1_TAG\n    - docker build -t $DOCKER_IMAGE2_TAG -f dir2/Dockerfile ./dir2\n    - docker push $DOCKER_IMAGE2_TAG  \n\nI'm struggling for a way to run the docker deploy command on my own server with the docker-compose.yml file I've written, that successfully pulls the images from my gitlab registry. I figure I could use sshpass to ssh into my server and then copy the docker-compose.yml file across and run docker deploy from there, but I'm not sure what's the best way to allow my server to access the images now located in my gitlab registry:\n# Need to ssh into the server, transfer over docker-stack file and run docker swarm deploy\ndeploy:\n  stage: deploy\n  environment:\n    name: production\n  image: trion/ng-cli-karma\n  before_script:\n    - apt-get update -qq && apt-get install -y -qq sshpass\n    - eval $(ssh-agent -s)\n\nThis is a section of my docker-compse file:\nversion: \"3.2\"\nservices:\n  octeditor:\n    image: image # how to set this to the image in my container registry?\n    ports:\n      - \"3000:3000\"\n    networks:\n      - front-tier\n    deploy:\n      replicas: 1\n      update_config:\n        parallelism: 1\n      failure_action: rollback\n      placement:\n        constraints:\n          - 'node.role == manager'\n      restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 120s\n\nHow can I pull the images from my gitlab registry? Is this the preferred way of creating a docker deployment on a remote server, via gitlab ci?"}, {"role": "assistant", "content": "I equally had this difficulty recently, finally I found out that the solution is just to insert the link to the image in the private registry as is the case for me with gitlab.\nversion: \"3.2\"\nservices:\n  octeditor:\n    image: registry.gitlab.com/project-or-group/project-name/image-name:tag\n    ports:\n      - \"3000:3000\"\n    networks:\n      - front-tier"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to connect to a target server via SSH with a key from a GitLab pipeline?\n\nI want to connect to a server via SSH with a public key when GitLab pipeline succeeds.\nAs I see, I need to generate a key with ssh-keygen on GitLab side and add it to server where I want to connect.\nI can generate a key during the pipeline but as the public key is not added to the target server, it makes no sense.\nI suppose it's a common scenario to connect from a CI build to a remote SSH with a key.\nHow can I make it work?"}, {"role": "assistant", "content": "You can run ssh-keygen from wherever you want as long as you use the appropriate keys on the appropriate server.\nHere is what you need:\n\nGenerate a key pair\nCopy the private key to a gitlab CI variable (let's call it SSH_PRIVATE_KEY)\nCopy the public key to the server gitlab will connect to and add it to your ~/.ssh/authorized_keys file\nTell your CI pipeline to use the private key that is stored in the Gitlab CI variable\n\nIn order to do that last step, just add the following to your .gitlab-ci.yml in the script or before_script section of the job of interest: \n- 'which ssh-agent || ( apt-get update -y && apt-get install openssh-client -y )'\n# Run ssh-agent (inside the build environment)\n- eval $(ssh-agent -s)\n# Add the SSH key stored in SSH_PRIVATE_KEY variable to the agent store\n- ssh-add <(echo \"$SSH_PRIVATE_KEY\")\n- mkdir -p ~/.ssh\n- '[[ -f /.dockerenv ]] && echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" > ~/.ssh/config'\n\nThen do your SSH connections and voil\u00e0 !\nEDIT: I couldn't remember where I had found this info the first time but here it is : https://docs.gitlab.com/ee/ci/ssh_keys/README.html"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Add GitLab Web hook for all projects in group\n\nI would like all my projects in a GitLab group to have shared configuration for a webhook:\n<MY_JENKINS_INSTANCE>/git/notifyCommit?url=$CHANGED_REPOSITORY\n\nGitLab webhook documentation suggests it should be possible:\n\nIf you have a big set of projects in the one group then it will be convenient for you to configure web hooks globally for the whole group. You can add the group level web hooks on the group settings page.\n\nThat sound exactly like what I am after though I see no such thing on group settings page in my gitlab 7.0.0. I was not able to find out if this feature is not newer than that in the changelog.\nDoes the feature exist? How do I use it?"}, {"role": "assistant", "content": "That's possible in the enterprise version only:\n\nIn GitLab Enterprise Edition you can configure web hooks globally for the whole group. You can add the group level web hooks on the group settings page Settings > Web Hooks."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How do I track the origin of a token in Gitlab?\n\nGiven a gitlab project/group access token, how do I find out the name of the token and from which group/project it came from?"}, {"role": "assistant", "content": "You can use the user api such as:\nwget --header \"PRIVATE-TOKEN: <TOKEN>\" https://www.gitlab.com/api/v4/user\n\nThough this API you'll get the user that token is attached to. If the token is attached to a group or a project, you'll see the type and project/group ID in the results."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Can I schedule only one specific GitLab CI/CD job?\n\nAt the moment, I have a couple of CI/CD jobs configured in gitlab-ci.yaml within a pipeline. For instance, I have the build and deploy configured within one branch. One of the jobs is creating a backup.\nI would like to schedule only the backup job every night. However, in the schedule section of GitLab CI/CD, I can only select a branch or a tag. This will result in all the stages/jobs to be triggered, whereas I only want the backup to be triggered.\nI've seen the option to configure rules and excepts to only trigger the jobs in a certain context. That, however, feels a bit like a patch solution. Is there another way to trigger only a single job in the Gitlab CI/CD scheduler?"}, {"role": "assistant", "content": "I've seen the option to configure rules and excepts to only trigger the jobs in a certain context. That, however, feels a bit like a patch solution. Is there another way to trigger only a single job in the Gitlab CI/CD scheduler?\n\nNo, there's no other way than using rules: or only:/except: to control which jobs run when the pipeline is triggered by a schedule.\nYou can make this more manageable by splitting your pipeline configuration to multiple files then using the appropriate rules: on the include:\ninclude:\n  - local: /do-backup.yml\n    rules:\n      - if: '$CI_PIPELINE_SOURCE == \"schedule\"'\n  - local: /do-pipeline.yml\n    rules:\n      - if: '$CI_PIPELINE_SOURCE != \"schedule\"'\n\nThat way you don't have to necessarily apply the same rules: to every single job and you can define additional rules: per job with less conflict."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is causing a push to origin to hang up, with Github Desktop?\n\nI am trying to push some files to a remote GitLab repo using GitHub Desktop. And after getting it to finish writing the objects, by increasing the buffer size in the command line; I am stuck halfway in the push.\nI have this pop up, while it is stuck,\nTotal 505 (delta 18), reused 0 (delta 0), pack-reused 0.\nWhat could fix this issue?"}, {"role": "assistant", "content": "Searching for a similar problem, I found this solution here:\n\nanywhere run\ngit config --global http.postBuffer 157286400\n\nin your local repo run git rm -r --cached ."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to deploy private jar to gitlab Maven repository\n\nI would like to know if it is possible to deploy a custom jar file into an existing maven repository. By custom, I mean, my own existing jar from my local machine.\nSo, I have a project test-project on gitlab (https://gitlab.com/group/test-project), and it is a java application that I build and deploy using gitlab pipelines. In the build stage, I am doing mvn deploy and the package test-project.jar is pushed to a gitlab maven repository (https://gitlab.com/group/test-project/-/packages). \nNow, I have a dependency.jar file which is listed as a dependency in my pom.xml. I would like to push that file into the same maven repository as my test-project.jar. There is nothing about that in the documentation here. https://docs.gitlab.com/ee/user/packages/maven_repository\nI tried to push it with maven-deploy-plugin in a way described here http://maven.apache.org/guides/mini/guide-3rd-party-jars-remote.html\nI am getting an error Failed to deploy artifacts: Could not find artifact... which is strange because I am trying to push new artifact, of course, it does not exist.\nI am not sure if this is an issue with GitLab (I doubt that) or I am doing something wrong, or what I want is just not possible.\n\nEdit\nI was able to push the package but the thing is I needed to run deploy:deploy-file from the build, not from my local. \nThis would be the pipeline configuration\n\nstages:\n  - build\n\nmaven-repo-push:\n  stage: build\n  image: maven:3.6.2\n  variables:\n    GROUP: \"com.example\"\n    ARTIFACT: \"myproject\"\n    VERSION: \"1.1.1\"\n    REPO_PROJECT_ID: \"12345678\" #gitlab project ID\n  script:\n    - mvn deploy:deploy-file\n      -DgroupId=$GROUP\n      -DartifactId=$ARTIFACT\n      -Dversion=$VERSION\n      -Dpackaging=jar\n      -Dfile=$ARTIFACT-$VERSION.jar\n      -DgeneratePom=false\n      -DpomFile=$ARTIFACT-$VERSION.pom\n      -Dfiles=$ARTIFACT-$VERSION-tests.zip\n      -Dtypes=zip\n      -Dclassifiers=tests\n      -DrepositoryId=gitlab-maven\n      -Durl=https://gitlab.com/api/v4/projects/$REPO_PROJECT_ID/packages/maven\n      -s settings.xml\n  when: manual\n\n\nMake sure you have pushed with this configuration the files you want to push in format $ARTIFACT-$VERSION.jar and \nThe default settings.xml needed for authentication\nhttps://docs.gitlab.com/ee/user/packages/maven_repository/#authenticating-with-a-ci-job-token \nStill, my question remains, is it possible to do this from local"}, {"role": "assistant", "content": "You can publish a library/jar from local file system as well, just have a settings.xml something like\n<settings>\n  <servers>\n    <server>\n      <id>gitlab-maven</id>\n      <configuration>\n        <httpHeaders>\n          <property>\n            <name>Private-Token</name>\n            <value>PUT-YOUR-PRIVATE-TOKEN-HERE</value>\n          </property>\n        </httpHeaders>\n      </configuration>\n    </server>\n  </servers>\n</settings>\n\nOr if you wan to use a group token or deploy token , make sure you update the property name above , documented here https://docs.gitlab.com/ee/user/packages/maven_repository/#authenticate-with-a-deploy-token-in-maven\nAnd then use this to publish your jar on GitLab's package registry, keep in mind that you can only publish to project api endpoints , but you can use group endpoints to download/install artifacts locally\nmvn -s settings.xml deploy:deploy-file \\\n-Durl=https://gitlab.com/api/v4/projects/<PUT-PROJECT-ID-HERE>/packages/maven \\\n-DrepositoryId=REPOSITORY-ID # has to match the settings.xml server:id \\\n-Dfile=your-lib.jar \\\n-DgroupId=your.group.id \\\n-DartifactId=artifact-name \\\n-Dversion=1.0 \\\n-Dpackaging=jar \\\n-DgeneratePom=false"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "gitlab api: how to retrieve userId of current user\n\nI'd like to have a individually callable url to see issues in gitlab for a specific user.\nHow can I retrieve the currently logged in user?\nhttps://server/folder/project/issues?scope=all&state=opened&assignee_id=<how to get this id>\nor\nhttps://server/folder/project/issues?scope=all&state=opened&assignee_username=<how to get this name>\n\nEdit:\n\nSolved with scope=assigned_to_me\nhttps://server/folder/project/issues?scope=assigned_to_me&state=opened"}, {"role": "assistant", "content": "List current user: Gets currently authenticated user.\nGET /user\n\nexample: https://gitlab.example.org/api/v4/user."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Duplicating git client hooks on the server side\n\nI've defined a post-commit hook in .git/hooks that I want to also execute on the server side (Gitlab.com in my case).\nBackground: I'm using gitinfo2 along with a post-commit hook in a LaTeX project to quote info about the latest git tag within the pdf. This works well on my computer, but fails when I push the repo to Gitlab.\nIt doesn't cause an error, but gives the following warning, which basically means that the git hook never executed.\nPackage gitinfo2 Warning: I can't find the file '.git/gitHeadInfo.gin'.\n(gitinfo2)                All git metadata has been set to '(None)'.\n\nFrom what I've read online so far, client side git hooks don't execute on the server - but why not? In a situation like this, I would want the hook to execute on both the client and the server.\nSo, basically, I want the sequence of events to be like this:\n\nI make a commit of the .tex file.\nI push the commit to Gitlab.\nOnce it's at Gitlab, the git hook is executed leading to a file called gitHeadInfo.gin being created in the .git folder.\nThe latex document is built using Gitlab CI, with the gitinfo package helping to pull the git version info from gitHeadInfo.gin.\nThe pdf is deployed to Gitlab Pages.\n\nI've got everything working except step 3. So, my current workaround is to build the pdf on my computer as well and commit it rather than relying on Gitlab CI.\nContents of the git hook:\n#!/bin/sh\n# Copyright 2015 Brent Longborough\n# Part of gitinfo2 package Version 2\n# Release 2.0.7 2015-11-22\n# Please read gitinfo2.pdf for licencing and other details\n# -----------------------------------------------------\n# Post-{commit,checkout,merge} hook for the gitinfo2 package\n#\n# Get the first tag found in the history from the current HEAD\nFIRSTTAG=$(git describe --tags --always --dirty='-*' 2>/dev/null)\n# Get the first tag in history that looks like a Release\nRELTAG=$(git describe --tags --long --always --dirty='-*' --match '[0-9]*.*' 2>/dev/null)\n# Hoover up the metadata\ngit --no-pager log -1 --date=short --decorate=short \\\n    --pretty=format:\"\\usepackage[%\n        shash={%h},\n        lhash={%H},\n        authname={%an},\n        authemail={%ae},\n        authsdate={%ad},\n        authidate={%ai},\n        authudate={%at},\n        commname={%cn},\n        commemail={%ce},\n        commsdate={%cd},\n        commidate={%ci},\n        commudate={%ct},\n        refnames={%d},\n        firsttagdescribe={$FIRSTTAG},\n        reltag={$RELTAG}\n    ]{gitexinfo}\" HEAD > .git/gitHeadInfo.gin"}, {"role": "assistant", "content": "client side git hooks don't execute on the server - but why not? \n\nGenerally, you are pushing to a bare repo (a repo without working tree, where you cannot do any commit directly)\nSo server-side commits are more about enforcing policies than creating new commits.\nIf you really needed new content to be created on the server side (especially one you have no direct control, like GitLab.com), you would need:\n\neither to activate some kind of server-side hook, which is for now only available at GitHub, with GitHub actions.\nor setup a listener to a GitLab webhook: that webhook would call (on each push events) your listener which could in turn get the latest history, do any modification you need, create new commit and push back."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Android: Could not find or load main class org.gradle.wrapper.GradleWrapperMain\n\nI am trying to build my project on GitLab CI but unfortunately for me I keep getting this error inside the runner:\nError: Could not find or load main class org.gradle.wrapper.GradleWrapperMain\nNow I know there is something wrong with my environment but I just cant get my mind wrapped around the problem. I searched on the web and I found I needed to update my .gitignore file and I did here it is:\n### Java ###\n*.class\n\n### Android ###\n*.apk\n*.ap_\n\n### Package files ###\n*.war\n*.ear\n*.aar\n\n### Gradle ###\n.gradle\n build\nbin/\nbuild/\nbuild.xml\ngen/\n.gradle/\ngradlew\ngradlew.bat\ngradle-wrapper.jar\ngradle-wrapper.properties\n\n### Android Studio ###\n.idea\nlocal.properties\n.DS_Store\n/captures\n\nI also eddied my gradle.build to contain the following lines: \ntask wrapper(type: Wrapper) {\ngradleVersion = '2.0' \n}\n\nBut again every time I run a build I get stack! Here is also my .gitlab-ci.yml:\nbefore_script:\n- apt-get --quiet update --yes\n- apt-get --quiet install --yes wget tar unzip openjdk-7-jdk lib32stdc++6   lib32z1\n - wget --quiet --output-document=gradle.zip https://services.gradle.org/distributions/gradle-2.8-bin.zip\n - unzip -q gradle.zip\n - export ANDROID_HOME=\"/opt/android-sdk\"\n - chmod +x gradlew\n\n dev:\n script:\n - ./gradlew assembleDebug\n\nAnd the line where the error appears is:\n- wget --quiet --output-document=gradle.zip https://services.gradle.org/distributions/gradle-2.8-bin.zip"}, {"role": "assistant", "content": "According to your gitignor, CI is never getting the gradle-wrapper.jar library, because it wasn't commited yet, but it has to be, since it is used to run the wrapper.\nCheck, whether is gradle-wrapper.jar commited, if no, then just commit it."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "git commands on GitLab HTTP remote fail with 403\n\nI have a GitLab 5.0 installation that suddenly, for no apparent reason, started failing git commands on the HTTP URLs. Any command such as git clone/pull/push fails with the following error:\nfatal: unable to access 'http://host/user/project.git/': The requested URL returned error: 403\n\nThe error happens before any prompt for user/password. This happens for existing and new projects. The SSH URLs continue to work just fine. The GitLab UI on HTTP works fine too.\nAny idea what might be wrong or how to troubleshoot it?"}, {"role": "assistant", "content": "As is often the case I found what the problem was shortly after posting. The clue was that HTTP worked locally on the hosting machine. Turns out I had HTTP_PROXY variable configured on all Windows boxes I tried (I needed it recently for cabal which doesn't detect proxy automatic setting on Windows). Looks like git was connecting to GitLab endpoint via proxy leading to the error. I went to C:\\Users\\{User} and removed the line related to Proxy in the file .gitconfig. Leaving the answer in case it helps someone else."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "How to set an (environment) variable in the build script in Gitlab CI?\n\nI have a dummy build script in the Gitlab CI:\npwd\nci_app_path=$(pwd)\necho \"INFO: current directory: $ci_app_path\"\n\nand I get this output when the system start the build process:\npwd\n/home/kai/gitlab-runners/gitlab-ci-runner/tmp/builds/project-1\n\nci_app_path=$(pwd)\n\necho \"INFO: current directory: $ci_app_path\"\nINFO: current directory:\n\nso the variable was not set (or was set only for that line: as I know each line executed separately)\nI heard about push/pop mechanism to reach the functionality I desired, but could not find any details, how to implement that. \nUpdate:\nas I thought, each line is going executed separately. So the variable scope is only one line, where it is defined:\nscript:\npwd\nci_app_path=$(pwd) && echo \"INFO: current directory: $ci_app_path\"\n\noutput:\npwd\n/home/devuser/gitlab-runners/gitlab-ci-runner/tmp/builds/project-1\n\nci_app_path=$(pwd) && echo \"INFO: current directory: $ci_app_path\"\nINFO: current directory: /home/kai/gitlab-runners/gitlab-ci-runner/tmp/builds/project-1\n\nI don't think that writing the whole script as a one-liner is a good idea/practice.\nHow to get the variables set while executing the build script?\nP.S.\nactually I wonder why the whole build script must contain no empty lines?, otherwise it returns:\nNo such file or directory\n\nand a build fails on this place"}, {"role": "assistant", "content": "Gitlab CI just plays shell commands so do what you do in *sh:\nexport ci_app_path=$(pwd)\necho \"INFO: current directory: $ci_app_path\""}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab Personal Access Token - where to keep the token for seamless clone / pull / push\n\nCan anyone tell where to put the Gitlab PAT - Personal Access Token?\nDownloading git::https://gitlab.com/mycompany/myproject.git?ref=v0.0.1 - unable to download - I can't change the URL as its fixed in project repo.\nI tried to set it in my git config --global\ngitlab.accesstoken=abcdef1233TVHEPkNxyz\nalso as environment variable\nTOKEN=abcdef1233TVHEPkNxyz\nPRIVATE_TOKEN=abcdef1233TVHEPkNxyz\nAny advice please?"}, {"role": "assistant", "content": "Basically we need to:\n\nGenerate PAT https://gitlab.com/profile/personal_access_tokens    [permissions as per requirement]\ngit clone https://oauth2:[email\u00a0protected]/mycompany/myproject.git?ref=v0.0.1\n\nHowever, if we can not change the url from: git::https://gitlab.com/mycompany/myproject.git?ref=v0.0.1 to the above format or we want to avoid entering the token each time we clone a repo or use GitLab APIs, we need to do the following:\n\nSetup a credential store, example on Ubuntu:\n`sudo apt-get install libsecret-1-0 libsecret-1-dev`\n`sudo make --directory=/usr/share/doc/git/contrib/credential/libsecret`\n`git config --global credential.helper /usr/share/doc/git/contrib/credential/libsecret/git-credential-libsecret`\n\n\nGit clone a http url:\n`git clone https://gitlab.com/mycompany/myproject.git?ref=v0.0.1`\n\n\n\nwhen prompted for password use PAT instead. The PAT will be stored in the libsecret store for default 15 minutes. use git config --global credential.helper 'cache --timeout=1800' to change the timeout duration.\nRefer: https://www.softwaredeveloper.blog/git-credential-storage-libsecret"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Duplicated code in .gitlab-ci.yml's script section\n\nIs there a way within gitlab ci to create something like a function? I would like to don't have the duplicated code in the stages or should I use a external script for such a task?\nI had a look into the gitlab template but with a template I can only use a job in the template once.\nstages:\n  - build-artefakts\n  - build-image\n\nvariables:\n  CI_REGISTRY_NAMESPACE: 'main'\n  CI_BASE_IMAGE: '...'\n\n  1_GROUP_ID: '...'\n  1_ARTIFACT_ID: '...'\n  1_CLASSIFIER: '...'\n  1_JAR_NAME: '...'\n  1_IMAGE_NAME: '...'\n\n  2_GROUP_ID: '...'\n  2_ARTIFACT_ID: '...'\n  2_CLASSIFIER: '...'\n  2_JAR_NAME: '...'\n  2_IMAGE_NAME: '...'\n\n\ndeploy-maven:\n  image: maven:3.6-jdk-11\n  stage: build-artefakts\n  script:\n    - 'mvn deploy -f pom.xml -s ~config/maven/ci_settings.xml -P prod'\n  only:\n    - master\n  artifacts:\n    paths:\n      - ./target\n    expire_in: 1 weeks\n\ndeploy-docker-1:\n  image: $CI_BASE_IMAGE\n  stage: build-image\n  variables:\n    ARTIFACT_ID: $1_ARTIFACT_ID\n    JAR_NAME: $1_JAR_NAME\n    IMAGE_NAME: $1_IMAGE_NAME\n\n  before_script:\n    - 'docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_TOKEN  $CI_REGISTRY'\n  script:\n    - 'cd docker'\n    - 'mv ../target/$ARTIFACT_ID/*.jar $JAR_NAME'\n    - 'docker build . -t $IMAGE_NAME:$PROJECT_VERSION --build-arg JAR_FILE=$JAR_NAME'\n    - 'docker tag $IMAGE_NAME:$PROJECT_VERSION $CI_REGISTRY/$CI_REGISTRY_NAMESPACE/$IMAGE_NAME:$PROJECT_VERSION'\n    - 'docker push $CI_REGISTRY/$CI_REGISTRY_NAMESPACE/$IMAGE_NAME:$PROJECT_VERSION'\n\ndeploy-docker-2:\n  image: $CI_BASE_IMAGE\n  stage: build-image\n  variables:\n    ARTIFACT_ID: $2_ARTIFACT_ID\n    JAR_NAME: $2_JAR_NAME\n    IMAGE_NAME: $2_IMAGE_NAME\n\n  before_script:\n    - 'docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_TOKEN  $CI_REGISTRY'\n  script:\n    - 'cd docker'\n    - 'mv ../target/$ARTIFACT_ID/*.jar $JAR_NAME'\n    - 'docker build . -t $IMAGE_NAME:$PROJECT_VERSION --build-arg JAR_FILE=$JAR_NAME'\n    - 'docker tag $IMAGE_NAME:$PROJECT_VERSION $CI_REGISTRY/$CI_REGISTRY_NAMESPACE/$IMAGE_NAME:$PROJECT_VERSION'\n    - 'docker push $CI_REGISTRY/$CI_REGISTRY_NAMESPACE/$IMAGE_NAME:$PROJECT_VERSION'"}, {"role": "assistant", "content": "You can use YAML-Anchors in \"script\"-sections:\n.some-script: &some-script\n  - echo \"executed script\"\n\n.some-other-script: &some-other-script\n  - echo \"executed other script\"\n\nfirst_job:\n  script:\n    - *some-script\n\nsecond_job:\n  script:\n    - *some-other-script\n\nSince GitLab 13.9 you can also use the custom YAML tag !reference:\n.some-script:\n  script:\n    - echo \"executed script\"\n\n.some-other-script:\n  script:\n    - echo \"executed other script\"\n\nfirst_job:\n  script:\n    - !reference [.some-script, script]\n\nsecond_job:\n  script:\n    - !reference [.some-other-script, script]\n\nThe difference between the two approaches is that YAML anchors cannot be used across included YAML files. Referenced tags, on the other hand, can be used across included YAML files."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI can't connect to service / No HOST or PORT found\n\nI am trying to run an integration test against my containers on gitlab. \nTo keep things as minimal as possible, here are the relevant parts of my .gitlab-ci.yml\nimage: ubuntu:latest\n\ncoverage:\n    stage: test\n    dependencies:\n        - build\n    services:\n        - postgres:latest\n        - registry.gitlab.com/username/project/image:latest\n\nWhen I try and run the job, I get a container health check warning. \n2019-06-06T02:13:34.508595817Z FATAL: No HOST or PORT found\nNormally I would start my image with the standard docker run -p port:port image:version but I'm not sure how those options translate to gitlab services. How do I define the host and the port?"}, {"role": "assistant", "content": "in my case, Dockerfile without EXPOSE, will give the wrong log msg in ci runner:\nHealth check error:\nexit code 1\n\nHealth check container logs:\n2020-05-12T03:42:49.645731131Z No HOST or PORT\n\nfixed by expose service port in Dockerfile."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Regex for Gitlab CI Test coverage parsing\n\nI have been struggling to find a regular expression that will work in the \"Test coverage parsing\" input on the \"CI/CD Pipelines\" page. It doesn't help that the examples show inconsistent examples, i.e. some escape parenthesis and other don't, same with percent symbols, some capture the explicit result in $1, etc. Anyway, here is my text - whats the regex?\nCI Badge:\n![coverage](https://gitlab.com/mycompany/master/badges/master/coverage.svg?job=coverage)\n\nOutput text:\nUnit test coverage:\n   10.01% blocks\n   10.01% lines\n\nTried so far: (added the slashes simply to represent the space at front or regex)\n/ \\(\\d+\\.\\d+\\%\\) blocks/\n/ (\\d+\\.\\d+\\%) blocks/\n/ (\\d+\\.\\d+%) blocks/\n/ (\\d+\\.\\d+)% blocks/"}, {"role": "assistant", "content": "There is a useful Ruby regex web page. \nhttp://www.rubular.com/\nI didn't not help for me with my GitLab code coverage parsing. I think it is because there seems to be a bug registered for a regex problem in GitLab.\nhttps://gitlab.com/gitlab-org/gitlab-ce/issues/21495"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab Ldap Authentication Settings\n\nCurrent Environment:\n\nGitlab Server: Centos 6.5\nActive Directory: Windows Server 2008 R2\n\nCould anyone check these fictitious settings for Ldap authentication in Gitlab 7.1.1?\ngitlab_rails['ldap_enabled'] = true\ngitlab_rails['ldap_host'] = 'myserver.dom.com.net'\ngitlab_rails['ldap_port'] = 389\ngitlab_rails['ldap_uid'] = 'sAMAccountName'\ngitlab_rails['ldap_method'] = 'plain' # 'ssl' or 'plain'\ngitlab_rails['ldap_bind_dn'] = 'OU=Users,DC=dom,DC=com,DC=net'\ngitlab_rails['ldap_password'] = '????'\ngitlab_rails['ldap_allow_username_or_email_login'] = true\ngitlab_rails['ldap_base'] = 'DC=dom,DC=com,DC=net'\n\nWhich ldap_bind_dn has to be set in order to Gitlab works (user account equivalent)?\nWhich ldap_password has to be set in order to Gitlab works?\nI followed suggestions from: @metaDiego and @heinglandreas. Both were in the right path. So I modified my settings in the lines:\nSolution\ngitlab_rails['ldap_bind_dn'] = 'CN=the_allowed_user_for_access_ldap,OU=Users,DC=dom,DC=com,DC=net'\ngitlab_rails['ldap_password'] = 'the_password_of_allowed_user'\n\nThe ldap_bind_dn may vary according to the AD structure and the current level where the allowed user is located.\nMy company AD doesn't allow anonymous Ldap queries. So adding those parameters were mandatory.\nSearch help in the domain administrators, for getting those parameters. \nUseful article from gitlabhq at Github\nIf gitlab_rails['ldap_allow_username_or_email_login'] = true, the login user could be with email format or only domain user."}, {"role": "assistant", "content": "The ldap_bind_dn has to be the DN of a user that has read access to the LDAP. As far as I can see you are pointing to a directory structure with OU=Users,DC=dom,DC=com,DC=net. You will have to use that users password as ```\nSo ldap_bind_dn should read something like uid=userid,OU=Users,DC=com,DC=com,DC=net and ldap_password should then be userids password.\nOn some LDAP-Servers ldap_bind_dn can be left empty as they allow anonymous bind. In that case the ldap_password has to be left empty also. \nDoes that make sense? Otherwise feel free to comment!"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Error unauthorized: HTTP Basic: Access denied on docker push registry.gitlab.com\n\nI have error with:\ndocker push registry.gitlab.com/user/rep-name\n\nThe push refers to repository [registry.gitlab.com/user/rep]\nf319ccdf8ee4: Preparing \n..\n7032a7172c0a: Preparing \nb16cd70f3a2c: Waiting \n...\nunauthorized: HTTP Basic: Access denied\n\nBut prev login is Succeeded:\ndocker login registry.gitlab.com\nUsername: user\nPassword: \nLogin Succeeded\n\nDocker ver:\ndocker -v\nDocker version 19.03.8, build afacb8b7f0\n\nI use Personal Access Token is \"api\"\nhttps://gitlab.com/profile/personal_access_tokens\nbecause I have 2-factor athorization."}, {"role": "assistant", "content": "I change:\n\nPersonal Access Token scope:\nhttps://gitlab.com/-/profile/personal_access_tokens to \"api\" and \"read_registry\"\n\nusename in docker login from @user to [email\u00a0protected]\n\n\nnow it is works.\nSeems issue is in \"read_registry\" scope.\nAnd it is strange because \"api\" also have read access.\nFrom Gitlab:\n\nGrants complete read/write access to the API, including all groups and\nprojects, the container registry, and the package registry."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": ".gitlab-ci.yml error: \"apk: command not found\"\n\nI have the following .gitlab-ci.yml file:\nimage: docker\n\nservices:\n  - docker:dind\n\nstages:\n  - test\n  - build\n  - deploy\n\ntest:\n  stage: test\n  before_script:\n    - apk add --update -y python-pip\n    - pip install docker-compose\n  script:\n    - echo \"Testing the app\"\n    - docker-compose run app sh -c \"python manage.py test && flake8\"\n\nbuild:\n  stage: build\n  only:\n    - develop\n    - production\n    - feature/deploy-debug-gitlab\n  before_script:\n    - apk add --update -y python-pip\n    - pip install docker-compose\n  script:\n    - echo \"Building the app\"\n    - docker-compose build\n\ndeploy:\n  stage: deploy\n  only:\n    - master\n    - develop\n    - feature/deploy\n    - feature/deploy-debug-gitlab\n  before_script:\n    - apk add --update -y python-pip\n    - pip install docker-compose\n  script:\n    - echo \"Deploying the app\"\n    - docker-compose up -d\n  environment: production\n  when: manual\n\n\nWhen the Gitlab runner executes it, I get the following error:\n$ apk add --update -y python-pip\nbash: line 82: apk: command not found\nERROR: Job failed: exit status 1\n\nHow am I supposed to install apk? Or what image other than docker should I be using to run this gitlab-ci.yml file?"}, {"role": "assistant", "content": "Well, it turns out I had two different runners: one marked as \"shell executor\" (Ubuntu) and the other marked as \"docker executor\u201c.\nThis error was being thrown out only when the Ubuntu runner was dispatching the job, since Ubuntu doesn\u00b4t come with apk.\nI disabled the Ubuntu runner and solved the problem."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Unable to clone repository from Gitlab: Permission denied, please try again\n\nI'm trying to clone an empty repository from my Gitlab account. I simply use the address shown on my Gitlab repository page under SSH:\n[email\u00a0protected]:USERNAME/project-name.git\n\n\nThen simply try this in an empty folder, but it keeps telling me permission denided, asking for retry:\ngit clone [email\u00a0protected]:USERNAME/project-name.git\nCloning into 'project-name'...\n[email\u00a0protected]'s password:\nPermission denied, please try again.\n[email\u00a0protected]'s password:\n\nand when I choose the https address for clone, this is the message:\nremote: HTTP Basic: Access denied\nfatal: Authentication failed for ....\n\nI am able to login to Gitlab homepage with that password, so I don't know what is really wrong. \nWhat is wrong? How to fix it?"}, {"role": "assistant", "content": "As I'm in Windows, this answer was the life saver:\nIt happen every time I'm forced to change the Windows password and none of above answers helped to me.\nTry below solution which works for me:\nGo to Windows Credential Manager (press Windows Key and type credential) to edit the git entry under Windows Credentials. Replace old password with the new one."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab CI with r testthat package\n\nCan anyone run testthat tests for a minimal R package using GitLab.com continuous integration tools? \nMy attempt:\nhttps://gitlab.com/djchapman/CI_example\nThis is the .gitlab-CI.yml text I am using, \nimage: rocker/rstudio\ntest:\n   script:\n    - R -e 'install.packages(c(\"devtools\", \"testthat\"))'\n    - R CMD build . --no-build-vignettes --no-manual\n    - PKG_FILE_NAME=$(ls -1t *.tar.gz | head -n 1)\n    - R CMD check \"${PKG_FILE_NAME}\" --no-build-vignettes --no-manual\n    - R -e 'devtools::test()'\n\nIt is adapted from this website. I realize that devtools has dependencies which may need to be included as packages are installed, and I tried that, but the libraries for git2r didn't seem to install correctly, and now I wonder if I'm going about it wrong. Thanks."}, {"role": "assistant", "content": "You do not need to run the tests via devtools since R CMD check does that already. The following should work:\nimage: rocker/rstudio\ntest:\n   script:\n    - R -e 'install.packages(c(\"testthat\"))'\n    - R CMD build . --no-build-vignettes --no-manual\n    - PKG_FILE_NAME=$(ls -1t *.tar.gz | head -n 1)\n    - R CMD check \"${PKG_FILE_NAME}\" --no-build-vignettes --no-manual\n\nAlternatively you could use an image that allows for binary installs:\nimage: rocker/r-base\ntest:\n   script:\n    - apt-get update\n    - apt-get install --yes --no-install-recommends r-cran-testthat r-cran-devtools\n    - R -e \"devtools::install_deps()\"\n    - R CMD build . --no-build-vignettes --no-manual\n    - PKG_FILE_NAME=$(ls -1t *.tar.gz | head -n 1)\n    - R CMD check \"${PKG_FILE_NAME}\" --no-build-vignettes --no-manual\n\nThis is useful if you have dependencies that have not been packaged for Debian, or if you don't want to update your CI script when you add a new dependency."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab Coverage badge not working\n\nI am deploying Django application using Gitlab CI/CD and pytest for testing of code and pytest-cov for generating coverage report\nMy .gitlab-ci.yml\nstages:\n  - test\n  - deploy\n\nimage: python:3.6\n\ntest:\n  stage: test\n  script:\n    - pip install pipenv\n    - pipenv install\n    - pipenv run py.test src/\n  artifacts:\n    paths:\n      - htmlcov/\n\npages:\n  stage: deploy\n  dependencies:\n    - test\n  script:\n    - mv htmlcov/ public/\n  artifacts:\n    paths:\n      - public\n    expire_in: 30 days\n  only:\n    - master\n\nstaging:\n  stage: deploy\n  script:\n    - apt-get update -qy\n    - apt-get install -y ruby-dev\n    - gem install dpl\n    - dpl --provider=heroku --app=app-staging --api-key=$HEROKU_PRODUCTION_API_KEY\n  only:\n    - master\n\nproduction:\n  stage: deploy\n  script:\n    - apt-get update -qy\n    - apt-get install -y ruby-dev\n    - gem install dpl\n    - dpl --provider=heroku --app=app-production --api-key=$HEROKU_PRODUCTION_API_KEY\n  when: manual\n  only:\n    - master\n\nSince repository is under a group namespace, the url to the coverage report is\nhttps://<group>.gitlab.io/<repository>/\n\nFor coverage report,\n[![coverage report](https://gitlab.com/<group>/<repository>/badges/master/coverage.svg?job=coverage)](https://<group>.gitlab.io/<repository>/)\n\nBut this is displaying Unknown\n\nI have setup Test Coverage parsing regex for python"}, {"role": "assistant", "content": "I know this is an old question, but this may help others see this question in the future.\nExcept setting the Test Coverage parsing regex in the Settings, CI/CD page, you need to make sure the test coverage percent is printed somewhere in the CI's console log. The printed line should match the given regex. So, Gitlab can parse and save it as the code coverage percent.\nI've answered with more detail the same question: Gitlab coverage badge always unknow"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Added SSH key to Gitlab but it still asks for my credentials\n\nGitLab's HTTP pull & push are working when I enter my credentials. \nBut when using an added SSH key, it is always is asking for my password, which I don't know. Why is GitLab doing this? Is it a server fault?\nAnd when calling ssh -vT [email\u00a0protected] there is an error:\n\nPermission denied (publickey)\n\nI've tried everything, even re-installing Git, but nothing works. Even their own solution is not working, as described here: https://help.github.com/articles/error-permission-denied-publickey/"}, {"role": "assistant", "content": "I had the same issue, after checking\n/var/log/auth.log\n\nI got : \n*User git not allowed because account is locked\n*input_userauth_request: invalid user git [preauth]\n*Connection closed by IP.IP.IP.IP [preauth]\n\nSo the fix was \n\nsudo passwd -d git\n\nThanks to Noah (source)"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Integrating Gitlab with ReviewBoard - File Blob vs. Commit SHA1\n\nI'm trying to integrate Gitlab server that our company has been using with a new ReviewBoard server. From everything I've read about ReviewBoard setup, the most straightforward way to integrate git-like repositories is to use \"Raw file URL mask\" field if the repository has a web front end.\nLuckily, Gitlab, appears to support such a front end and even has a well documented public API:\nhttps:///api/v2/projects//repository/commits//blob?private_token=&filepath=\nIn ReviewBoard's repository setup, one can specify a custom URL that could be used to retrieve individual files from the git server.  This URL has two placeholders:\n\n{filename} - file path\n{revision} - sha1 of the file blob\n\nUnfortunately, I have learned that Gitlab's API expects SHA1 of the commit, not of the individual file and ReviewBoard as far as I can tell only sends SHA1 of the individual file but not of the commit\n\nHas anyone successfully integrated Gitlab with ReviewBoard?  If so, I'd be interested in hearing about it\nIs anyone aware of another, possibly undocumented, API call that Gitlab supports that would allow us to retrieve files based on SHA1 of the file blob?                                   \nIs anyone aware of a setting in ReviewBoard to force it to pass in SHA1 of the commit instead of the file blob?"}, {"role": "assistant", "content": "Reviewboard 1.7.21 includes support for GitLab http://www.reviewboard.org/news/2014/01/14/review-board-1-7-21-released/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Mounting a volume for a gitlab service\n\nI'm trying to run a gitlab service running wiremock on my gitlab ci.\nI want to take my json files for configure wiremock from the repository and mount as a volume to the wiremock image that run as an service on gitlab ci\n.gitlab-ci.yml\nvariables:\n  SHARED_PATH: $CI_PROJECT_PATH/src/main/resources\n\nservices:\n    - name: wiremock/wiremock\n      alias: wiremock\n      \nimage: openjdk:11\n\ndeploy:jdk11:\n  stage: deploy\n  script:\n    - 'curl -X POST http://wiremock:8080/'\n\nI want to mount the SHARED_PATH as a volume for the wiremock service"}, {"role": "assistant", "content": "Currently there is no possibility to mount a volume.\nSee this in the Gitlab issue tracker: https://gitlab.com/gitlab-org/gitlab-runner/-/issues/28121"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Having Gitlab Runner use node_modules as an artifact instead of in cache\n\nAccording to the GitLab Documentation for cache vs artifacts the node_modules should be stored as cache instead of an artifact. The issue with this is if there are multiple runners and a different runner from what created the \"build\" picks up a job then the cache (node_modules) won't exist which will fail the GitLab CI randomly (if the same runner happens to do the rest of the jobs then it will succeed).\nI could make it so everything is done in one job but once I have to put in deployment this issue will reoccur. Another option is to tag it so only one specific runner completes the job but I feel like that is slow.\nAfter researching I realized I could just put in node_modules as an artifact instead of the cache and it will be picked up no matter which runner runs the job but I can't find any documentation on if this is bad or not.\nSo is it okay to put node_modules as an artifact? If so, why wouldn't people put it as an artifact normally (assuming they add an expiration)?"}, {"role": "assistant", "content": "The short answer here is that you can use the tool however you want to. You absolutely can use artifacts for node_modules. However, there's a way to make the cache work too.\nBy default, when a runner caches a file or directory, it stores it locally on the host running that runner (which is why it's not available on other runners). In the runner config however, you can change this to store cached objects in AWS S3 or an S3-like repo (like Minio). If all runners are configured this way, or at least 2 are, then those runners can also use the same cached items.\nYou can read about the runner's cache config options here: https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-runnerscache-section\nYou can read about Minio (an open source storage solution that provides an S3 API interface) here: https://docs.min.io/"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Minimum hardware requirements for gitlab-runner\n\nHow can I determine what is the minimum hardware requirement for install the gitlab-runner on a host? \nI want a specific runner which will run tests, build docker images, and deploy the apps."}, {"role": "assistant", "content": "Gitlab documentation gives some advices and put focus on memory :\n\nDepending on how you decide to configure GitLab Runner and what tools you use to exercise your application in the CI environment, GitLab Runner can consume significant amount of available memory.\n\nAfter that, it's really depending the type of application you want to test/build/deploy. Test and build job will be the largest resource consumers. You can also set limits on cpu/memory for docker runner."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Do GitHub and GitLab support git clone's --filter parameter?\n\nI want to use git's partialClone feature. In this answer I saw the git clone --filter=tree:none <repo> command.\nBut when trying to execute on github, the prompt warning: filtering not recognized by server, ignoring. It did not work.\nI want to know if it is not supported by the GitHub website, or if there is a problem with my settings.\nI asked the feedback staff of GitHub and have not got the answer from the technician."}, {"role": "assistant", "content": "This almost certainly isn't supported by GitHub or GitLab yet.\nThe --filter option is under active development and isn't really ready for general-purpose consumption yet. GitHub's blog post about the release of Git 2.19 in September, 2018 says\n\nNote that most public servers do not yet support the feature, but you can play with git clone --filter=blob:none against your local Git 2.19 install.\n\nOnce this feature becomes more fully-developed and hosts start to support it I'm sure they won't do so quietly. As far as I know, no major cloud provider has made such an announcement yet.\nUpdate from OP 2019-03-21:\n\nNot long ago, I received an official reply from github. They think that the --filter parameter is still an immature feature and is accompanied by some security issues. Therefore, this feature will not be supported in the short term."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab: How to change merge commit message template?\n\nTypical message looks like:\nMerge branch \u2018mass-refactoring\u2019 into \u2018master\u2019\n\nMass refactoring\n\nSee merge request group/project!13\n\nIs it possible to change template to something like: ?\nHEADER\n\nBODY\n\nMerge branch SRC_BRANCH into TGT_BRANCH. See merge-request GROUP/PROJECT!N"}, {"role": "assistant", "content": "As listed here (gitlab issue #2551) the wish for such a feature is still present (4 weeks ago). \nTo answer your question, no, there is none built-in gitlab feature to change the merge message template."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI + Docker Hub: requested access to the resource is denied\n\nI'm trying to push my image to my docker repositoy repository using gitlab-ci, but i'm receiving the error:\ndenied: requested access to the resource is denied\nERROR: Job failed: exit code 1\nMy .gitlab-ci.yml\n# This file is a template, and might need editing before it works on your project.\n# Official docker image.\nimage: docker:latest\n\nservices:\n  - docker:dind\n\nbefore_script:\n   - docker version\n   - docker-compose version\n   - docker login -u $USER -p $PASS index.docker.io\n\n\nbuild-master:\n  stage: build\n  script:\n    - apk add --no-cache py-pip\n    - pip install docker-compose    \n    - docker build --pull -t index.docker.io/$REPOSITORY .\n    - docker push index.docker.io/$REPOSITORY\n  only:\n    - master\n  tags:\n  - docker\n\nbuild:\n  stage: build\n  script:\n    - docker build --pull -t index.docker.io/$REPOSITORY:latest .\n    - docker push index.docker.io/$REPOSITORY:latest\n  except:\n    - master\n  tags:\n  - docker\n\nHe build the image correctly, but when go to push\nThe push refers to repository [docker.io/$REPOSITORY]\nfc57a6fc4d42: Preparing\n09b261acf68f: Preparing\n04ea2928643d: Preparing\n1132926ce5ae: Preparing\nde09db5a8cb2: Preparing\n0b75a2e7b59f: Preparing\nd01d9d1902f1: Preparing\n3dab7cdf2eed: Preparing\n1da4e8fff32b: Preparing\n23c522961836: Preparing\na51421a28d33: Preparing\n8b1c06910686: Preparing\n30e8a3d88591: Preparing\nfd8fae5cd65a: Preparing\n6b68dfad3e66: Preparing\ncd7100a72410: Preparing\n0b75a2e7b59f: Waiting\nd01d9d1902f1: Waiting\n3dab7cdf2eed: Waiting\n1da4e8fff32b: Waiting\n23c522961836: Waiting\na51421a28d33: Waiting\n8b1c06910686: Waiting\n30e8a3d88591: Waiting\nfd8fae5cd65a: Waiting\n6b68dfad3e66: Waiting\ncd7100a72410: Waiting\ndenied: requested access to the resource is denied\nERROR: Job failed: exit code 1\n\nI change the repository name for the $REPOSITORY only for paste here.\nI already give the right permissions on hub.docker.com for the user has make the docker login, has a colaborator on the repository.\nThanks"}, {"role": "assistant", "content": "use $CI_REGISTRY and $CI_PROJECT_PATH.\nExample code:\n- docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY/$CI_PROJECT_PATH\n- docker build -t $CI_REGISTRY/$CI_PROJECT_PATH/name:latest\n- docker push $CI_REGISTRY/$CI_PROJECT_PATH/name:latest"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Edit in configuration file of gitlab and bitbuket by git\n\nI can edit in the configuration file that contains the username,password  and github email using git with \ngit config --global -e \n\nOR\ngit config --global --edit\n\nor in the .gitconfig file \nHow can I edit the gitlab and bitbucket config files to contain a username, password, and email, and then where do I save it in Windows?"}, {"role": "assistant", "content": "I don't know where that configuration is, but all you need to do in Windows is make sure you have set the right credential helper to cache your credentials:\ngit config --global credential.helper manager\n\nThen, at the first push, you will be prompted for your GitLab username/password.\nOnce entered, they will be cached in the Windows Credential Manager, and never asked for directly again."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "xcodebuild: error: 'APP.xcworkspace' does not exist\n\nI am trying to set up CI with gitlab. When I try to build locally, I get this error : xcodebuild: error: 'APP.xcworkspace' does not exist.\n\"APP\" not being the real name. I am also using CocoaPods.\nThis happens after I run this command in terminal:\ngitlab-ci-multi-runner exec shell build_project\nI have checked and the file does exist in the same folder I call the command.\nThis is my .gitlab-ci.yml file:\nstages:\n  - build\n\nbuild_project:\n  stage: build\n  script:\n    - xcodebuild clean -workspace APP.xcworkspace -scheme APP | xcpretty\n    - xcodebuild test -workspace APP.xcworkspace -scheme APP -destination 'platform=iOS Simulator,name=iPhone 7,OS=10.2' | xcpretty -s\n  tags:\n    - v0.0.1\n\nXcode version: 8.2.1\nCocoapods version: 1.2.0\nGitlab-runner version : 1.11.0\nAlex"}, {"role": "assistant", "content": "On React Native I've solved this issue by running command inside /ios folder."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Automate code deploy from Git lab to AWS EC2 instance\n\nWe're building an application for which we are using GitLab repository. Manual deployment of code to the test server which is Amazon AWS EC2 instance is tedious, I'm planning to automate deployment process, such that when we commit code, it should reflect in the test instance.\nfrom my knowledge we can use AWS code-deploy service to fetch the code from GitHub. But code deploy service does not support GitLab repository . Is there a way to automate the code deployment process to AWS Ec2 instance through GitLab. or Is there a shell scripting possibility to achieve this? Kindly educate me."}, {"role": "assistant", "content": "One way you could achieve this with AWS CodeDeploy is by using the S3 option in conjunction with Gitlab-CI: http://docs.aws.amazon.com/codepipeline/latest/userguide/getting-started-w.html\nDepending on how your project is setup, you may have the possibility to generate a distribution Zip (Gradle offers this through the application plugin). You may need to generate your \"distribution\" file manually if your project does not offer such a capability.\nGitlab does not offer a direct S3 integration, however through the gitlab-ci.yml you would be able to download it into the container and run the necessary upload commands to put the generated zip file on the S3 container as per the AWS instructions to trigger the deployment. \nHere is an example of what your brefore-script could look like in the gitlab-ci.yml file:\nbefore_script:\n  - apt-get update --quiet --yes\n  - apt-get --quiet install --yes python\n  - pip install -U pip\n  - pip install awscli\n\nThe AWS tutorial on how to use CodeDeploy with S3 is very detailed, so I will skip attempting to reproduce the contents here.\nIn regards to the actual deployment commands and actions that you are currently performing manually, AWS CodeDeploy provides the capability to run certain actions through scripts defined in the app-spec file depending on event hooks for the application: \n\nhttp://docs.aws.amazon.com/codedeploy/latest/userguide/writing-app-spec.html\nhttp://docs.aws.amazon.com/codedeploy/latest/userguide/app-spec-ref.html\nhttp://docs.aws.amazon.com/codedeploy/latest/userguide/app-spec-ref-hooks.html\n\nI hope this helps."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab-CI and node.js - how to start a local server then run tests?\n\nI've set up GitLab-CI, and am writing my .gitlab-ci.yml to run my tests. My app is written in node.js, and the file looks like this:\nbefore_script:\n  - npm install\n  - node server.js\n\nstages:\n  - test\n\njob_name:\n  stage: test\n  script:\n    - npm run test\n\nI'm having trouble actually starting the server then running tests, as node server.js creates a foreground process that never exists unless you do so manually. Is there a way to start the server, then move on, then stop it once the tests have finished?\nOr am I actually doing this wrong, and should my server get started in the tests themselves? Everything I read just says \"start node then in another terminal run your tests against your local server\" but this is obviously pointless in an automated CI system?"}, {"role": "assistant", "content": "Alternatively, you can use nohup command to launch your server in background.\n$ nohup node server.js &\n( & at the end of line is used to return to the prompt)\nIn your example: \nbefore_script:\n  - npm install\n  - nohup node server.js &\n\nstages:\n  - test\n\njob_name:\n  stage: test\n  script:\n    - npm run test"}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Are gitlab deployment keys read only?\n\nAre gitlab deployment keys read only?\nI need to clone on ci server using a deployment key and then push the tag created by the ci process.\nis that possible using a deployment key?"}, {"role": "assistant", "content": "Edit2: This change currently has a sideeffect, as there are no users on deployment keys.  So you will find some ugly messages like ERROR -> POST-RECEIVE: Triggered hook for non-existing user.  The cache-invalidation (and possibly other things) are therefor not handled on write pushes through deployment-keys, which is a bit ugly.  bundle exec rake cache:clear RAILS_ENV=production is your friend until I can find a way to fix that (see link to GitHub below) - and please remember, that clearing the Redis-cache logs out all users, too.\n\nHere is a short workaround to archive following on a per-key basis:\n\nMake My SSH keys readonly.  This allows to add machines with readonly access to all repos of an account.  Good if you work with trainloads of git subprojects.\nMake Deploy-Keys read-write on developer level.\nMake Deploy-Keys read-write on master level.\n\nThis is archived by prepending the key's title with some special characters:\n\n* to make a My SSH keys readonly\n! to make Deploy-Keys read-write\n!! to make Deploy-Keys master (write to protected branches)\n\nSo instead naming the key \"My global key\" you name it \"* my global readonly key\" etc.\ndiff --git a/lib/api/internal.rb b/lib/api/internal.rb\nindex ed6b50c..ce350b1 100644\n--- a/lib/api/internal.rb\n+++ b/lib/api/internal.rb\n@@ -30,7 +30,11 @@ module API\n\n\n         if key.is_a? DeployKey\n-          key.projects.include?(project) && DOWNLOAD_COMMANDS.include?(git_cmd)\n+return false unless key.projects.include?(project)\n+return true if DOWNLOAD_COMMANDS.include?(git_cmd)\n+return true if key.title.start_with? '!!'\n+return false if project.protected_branch?(params[:ref])\n+key.title.start_with? '!'\n         else\n           user = key.user\n\n@@ -42,6 +46,7 @@ module API\n                      then :download_code\n                    when *PUSH_COMMANDS\n                      then\n+return false if key.title.start_with? '*' # VAHI 2014-02-09\n                      if project.protected_branch?(params[:ref])\n                        :push_code_to_protected_branches\n                      else\n\nEdit1: This patch now is available as cherry-pick on GitHub, see https://github.com/hilbix/gitlabhq/wiki\nEdit3: You probably want following workaround, too, in case you push through a deployment key.  This is not perfect, as it does not trigger all those hooks, but it invalidates the caches such that the web pages no more show stale data:\ndiff --git a/app/workers/post_receive.rb b/app/workers/post_receive.rb\nindex 6416aa6..2fe98d4 100644\n--- a/app/workers/post_receive.rb\n+++ b/app/workers/post_receive.rb\n@@ -26,6 +26,8 @@ class PostReceive\n\n     unless user\n       log(\"Triggered hook for non-existing user \\\"#{identifier} \\\"\")\n+      project.ensure_satellite_exists\n+      project.repository.expire_cache\n       return false\n     end\n\nThere still is are some problems left:\nA minor one, you cannot use the same key on the account level and on the deploy level at the same time.  So for keys which only have read-only access on a global basis (which probably is the default key used), you need a second special \"push only\" key, which allows push access to the repos.\nEdit3: And the major one that deployment keys do not have a user attached, so that all the convenience things do not work.  If this is a problem for you the only way is, for each SSH key create a dummy-user, and add it to the group/project and give this dummy-users the correct permissions.\nComplete example under Linux for a test repo at [email\u00a0protected]:root/test.git\n\nApply above patch to GitLab\nRestart GitLab to read in the new code\nAdd your ~/.ssh/id_rsa.pub to GitLab Admin under My SSH keys and name it * my readonly key (or something different, starting with *).\nVerify, that following works: git clone [email\u00a0protected]:root/test.git\nVerify, that following fails on the git push step:\ncd test\ndate > DATE.tmp\ngit add DATE.tmp\ngit commit -m testing\ngit push\n\nCreate a second SSH key ~/.ssh/id_push: ssh-keygen -b 4096 -f ~/.ssh/id_push\nAdd ~/.ssh/id_push.pub as Deploy-Key to repo root/test.git.  Name it ! my push key (or something different, starting with !)\nAdd following to ~/.ssh/config\nHost gitlab-push\n        Hostname gitlab.example.com\n        User git\n        IdentityFile ~/.ssh/id_push\n\nAdd this target to your cloned repo:\ngit remote add to gitlab-push:root/test.git\nVerify following works: git push to master\n\nNotes:\nI used copy+paste to insert the patch.  It is likely it will not apply cleanly.  Sorry.\nYes, this is really a very crude hack which should not make it into the mainline.  The correct implementation would be to have a flag in the database which does this, such that you can edit it through the GUI.\nFor deploy keys this \"key-level\"-flag should be in the interesection table between key and project.  And in the non-deploy-key variant it should be on the key itself.  Perhaps this field can then act as a default value when adding a deploy key to another project and record the last usage of such key.\nUnfortunately I am not able to implement this properly myself as I lack the knowledge how to add the necessary elements to the GUI, sorry. ;("}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "GitLab configuration\n\nI try to install Gitlab 5.2 on OS-X Server 10.8.5.  I follow the procedure document from :\n    \"http://thoughtpointers.net/2013/05/23/installing-gitlab-v52-on-os-x/\".\nIn the section of the document titled \"Configure GitLab\" they ask to edit the file \"gitlab.yml\" and change  \"gitlab.example.com\" with the \"fully qualified domain name\" of your host serving Gitlab.\nI dont understand what I need to change..\n\n1. Do I need to change \"host: gitlab.example.com\" with \"localhost\" ? or with \"server.local => what I get when typing \"hostname\") ?\n\n\n2. What is \"gitlab.example.com\" ?  Something to download and install on my computer (so where?)?  What replace it ?\n\n\nI think when I type the address on my browser :\n\n    \"http://fully qualified domain name\"\n\n\nI will receive a page, from where comes that page (is it an index.html/php?) - where is the folder of that page/project...\n\n\nThanks for the assistance."}, {"role": "assistant", "content": "By default, what you see in the config/gitlab.yml is:\n  ## GitLab settings\n  gitlab:\n    ## Web server settings\n    host: localhost\n    port: 80\n    https: false\n\nThat allows you to test Gitlab locally.\nIf you replace:\nhost: localhost\n\nwith:\nhost: ip.address (192.168.x.x)\n#\nhost: fqn (your fully qualified name)\n\nThen you will be able to test / access GitLab from another computer.\nSo gitlab.example.com is an example of such a fully qualified name, and should be changed by your own.\nAs explained here, check what host hostname returns."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab CI fails with ERROR: Job failed: exit code 1\n\nI am pretty new to gitlab ci and I have a project with a pre-existing gitlab configuration which was running fine but after pushing a few code changes, it has now completely stopped working and I can't figure out why. Here is the .gitlab-ci.yml\nstages:\n  - build\n  - deploy\n\nvariables:\n  DOCKER_HOST: tcp://localhost:2375\n\nassets:\n  stage: build\n  image: node:10-alpine\n  script:\n    - npm ci\n    - NODE_ENV=production npm run build\n  artifacts:\n    expire_in: 1 day\n    paths:\n      - public/assets\n  tags:\n    - docker\n\npackage:\n  stage: deploy\n  image: php:7.3-cli-alpine\n  dependencies:\n    - assets\n  before_script:\n    - php -r \"copy('https://getcomposer.org/installer', 'composer-setup.php');\"\n    - php -r \"if (hash_file('sha384', 'composer-setup.php') === 'e0012edf3e80b6978849f5eff0d4b4e4c79ff1609dd1e613307e16318854d24ae64f26d17af3ef0bf7cfb710ca74755a') { echo 'Installer verified'; } else { echo 'Installer corrupt'; unlink('composer-setup.php'); } echo PHP_EOL;\"\n    - php composer-setup.php --install-dir=/usr/local/bin --filename=composer\n    - php -r \"unlink('composer-setup.php');\"\n  script:\n    - composer install --prefer-dist --no-progress --optimize-autoloader --no-scripts\n    - rm -fr .git\n  artifacts:\n    expire_in: 1 day\n    paths:\n      - .\n  tags:\n    - docker\n\ndocker:\n  stage: deploy\n  image: docker:latest\n  services:\n    - docker:18-dind\n  dependencies:\n    - assets\n  script:\n    - docker build -t $CI_REGISTRY_IMAGE:latest .\n    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY\n    - docker push $CI_REGISTRY_IMAGE:latest\n  only:\n    - master\n  tags:\n    - docker\n\ndeploy:\n  stage: deploy\n  image: php:7.3-cli-alpine\n  dependencies:\n    - assets\n  before_script:\n    - curl -LO https://deployer.org/deployer.phar\n    - mv deployer.phar /usr/local/bin/dep\n    - chmod +x /usr/local/bin/dep\n    - apk add --update openssh rsync\n    - eval $(ssh-agent -s)\n    - echo \"$SSH_PRIVATE_KEY\" | tr -d '\\r' | ssh-add -\n    - mkdir -p ~/.ssh\n    - chmod 700 ~/.ssh\n    - ssh-keyscan -t rsa domain.co.uk >> /root/.ssh/known_hosts\n  script:\n    - dep deploy -p --tag=\"$CI_COMMIT_TAG\"\n  only:\n    - tags\n  tags:\n    - docker\n\nI am consistently getting the following error and I am wondering what has changed and if it is the server or gitlab-ci causing the following issue. I checked the server and it's running fine but there is no docker installed there and I presume the docker is not supposed to be installed on the server for what it is trying to do anyways?\nChecking out a50d58fd as master...\n Skipping Git submodules setup\nDownloading artifacts for assets (447059035)...\n00:01\n Downloading artifacts from coordinator... ok        id=447059035 responseStatus=200 OK token=cp4GCzgJ\n$ docker build -t $CI_REGISTRY_IMAGE:latest .\n00:02\n time=\"2020-02-24T03:53:41Z\" level=error msg=\"failed to dial gRPC: cannot connect to the Docker daemon. Is 'docker daemon' running on this host?: dial tcp [::1]:2375: connect: connection refused\"\n error during connect: Post http://localhost:2375/v1.40/build?buildargs=%7B%7D&cachefrom=%5B%5D&cgroupparent=&cpuperiod=0&cpuquota=0&cpusetcpus=&cpusetmems=&cpushares=0&dockerfile=Dockerfile&labels=%7B%7D&memory=0&memswap=0&networkmode=default&rm=1&session=sja0dvuf6gm0w8tneigulo3ha&shmsize=0&t=registry.gitlab.com%2Fnir.npl%2Fbrayleys-honda%3Alatest&target=&ulimits=null&version=1: context canceled\n ERROR: Job failed: exit code 1"}, {"role": "assistant", "content": "Check if this is similar to this thread from a year ago:\n\nIt seems docker updated their latest stable images and gitlab has not updated their runners yet, changing the images to be on the 18 major fixes these issues, eg:\n\nimage: docker:18-git\n\nvariables:\n  DOCKER_HOST: tcp://docker:2375/\n  DOCKER_DRIVER: overlay2\n\nservices:\n  - docker:18-dind\n\nIn you case, a year later, that would be docker:19-dind, especially if you are using image: docker:latest, which is not a good practice, because \"latest\" can vary at any time.\nimage: docker:19-git would be preferable."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "unable to write symref for HEAD: Permission denied unable to update HEAD\n\nGit checkout to new branch gives below error \n\nunable to write symref for HEAD: Permission denied unable to update\n  HEAD\n\nBut it works if I delete the repo and create a new one. The moment I restart my laptop I guess it stops working.\nThe problem is in Windows 10."}, {"role": "assistant", "content": "This happened to me when I had git and 2 Visual studio instances open with the same solution. Git checkout gave the same error and showed some changes as staged for commit when they shouldn't have been. I've reverted those changes, closed one of the Visual Studios and tried checkout again, it worked nicely."}]}
{"messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "Gitlab cross-reference project\n\nI am trying to find the best way to document my project in Gitlab. And I found two different alternatives:\n\nMarkdown in the actual repository (my-repo.git)\nWiki using markdown (my-repo/wiki.git)\n\nNote that the suffix .git indicates that these are two different git repositories.\nI like the approach to simply modify the Wiki using markdown from the webpage (for everyones simplicity), but I am missing how to link between them or any other project in Gitlab.\nIn the documentation is provided some information to link (issues, commits, etc...) to other projects but not link files like the README.md and other documentation.\nIs there such functionality?"}, {"role": "assistant", "content": "I also don't know if I am 100% getting your question, but Gitlab does support special syntax for referencing other projects/commits/etc..\nYou can reference other project like so,\nnamespace/project>\n\nIt doesn't support referencing files in other projects (as far as I can tell), but you can reference files in the same project:\n[README](doc/README.md)\n\nAnd to specify a line number:\n[README](doc/README.md#L13)"}]}
